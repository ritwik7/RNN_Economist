{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    " \n",
    "# # generate a sequence of random numbers in [0, 99]\n",
    "# def generate_sequence(length=25):\n",
    "# \treturn [randint(0, 99) for _ in range(length)]\n",
    " \n",
    "# # one hot encode sequence\n",
    "# def one_hot_encode(sequence, n_unique=100):\n",
    "# \tencoding = list()\n",
    "# \tfor value in sequence:\n",
    "# \t\tvector = [0 for _ in range(n_unique)]\n",
    "# \t\tvector[value] = 1\n",
    "# \t\tencoding.append(vector)\n",
    "# \treturn array(encoding)\n",
    " \n",
    "# # decode a one hot encoded string\n",
    "# def one_hot_decode(encoded_seq):\n",
    "# \treturn [argmax(vector) for vector in encoded_seq]\n",
    " \n",
    "# # generate data for the lstm\n",
    "# def generate_data():\n",
    "# \t# generate sequence\n",
    "# \tsequence = generate_sequence()\n",
    "# \t# one hot encode\n",
    "# \tencoded = one_hot_encode(sequence)\n",
    "# \t# create lag inputs\n",
    "# \tdf = DataFrame(encoded)\n",
    "# \tdf = concat([df.shift(4), df.shift(3), df.shift(2), df.shift(1), df], axis=1)\n",
    "# \t# remove non-viable rows\n",
    "# \tvalues = df.values\n",
    "# \tvalues = values[5:,:]\n",
    "# \t# convert to 3d for input\n",
    "# \tX = values.reshape(len(values), 5, 100)\n",
    "# \t# drop last value from y\n",
    "# \ty = encoded[4:-1,:]\n",
    "# \treturn X, y\n",
    " \n",
    "# # define model\n",
    "# model = Sequential(name=\"seq\")\n",
    "# model.add(LSTM(50, batch_input_shape=(5, 5, 100), stateful=True,name=\"LSTM\"))\n",
    "# model.add(Dense(100, activation='softmax',name=\"dense\"))\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# # # fit model\n",
    "# for i in range(3):\n",
    "#   X, y = generate_data()\n",
    "#   model.fit(X, y, epochs=1, batch_size=5, verbose=2, shuffle=False)\n",
    "# # \tmodel.reset_states()\n",
    "# # # evaluate model on new data\n",
    "# X, y = generate_data()\n",
    "# yhat = model.predict(X, batch_size=5)\n",
    "# print('Expected:  %s' % one_hot_decode(y))\n",
    "# print('Predicted: %s' % one_hot_decode(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "    \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/example_RKN\"\n",
    "# file_name = file_path + \"/subj_num_39.csv\"\n",
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subj_num_39\"\n",
    "# file_name = file_path + \"/experiment_data.csv\"\n",
    "\n",
    "file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_41/\"\n",
    "file_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_41/experiment_data.csv\"\n",
    "file_dopa_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/dopadata/subject_num_41/dopa_experiment_data.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_11/\"\n",
    "# file_name = file_path +\"PT_generate_choice.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>12.298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.910</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>2.926</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.446</td>\n",
       "      <td>0.846354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.883</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.728</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>3.062</td>\n",
       "      <td>0.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>2.483</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>2.136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           1.0   0.0      45.0       -37.0         1.0     1.0   \n",
       "2         2           1.0 -30.0       0.0       -55.0         1.0     1.0   \n",
       "3         3           1.0 -15.0       0.0       -37.0         1.0     1.0   \n",
       "4         4           1.0  15.0      63.0         0.0         1.0     1.0   \n",
       "5         5           1.0  15.0      25.0         0.0         2.0     0.0   \n",
       "6         6           1.0  20.0     100.0         0.0         1.0     1.0   \n",
       "7         7           1.0 -25.0       0.0      -105.0         2.0     0.0   \n",
       "8         8           1.0 -20.0       0.0       -63.0         2.0     0.0   \n",
       "9         9           1.0 -15.0       0.0       -75.0         2.0     0.0   \n",
       "\n",
       "   Outcome      RT  Happiness  \n",
       "0      NaN     NaN   0.811198  \n",
       "1    -37.0  12.298        NaN  \n",
       "2      0.0   7.910        NaN  \n",
       "3    -37.0   2.926        NaN  \n",
       "4     63.0   2.446   0.846354  \n",
       "5     15.0   4.883        NaN  \n",
       "6    100.0   1.728        NaN  \n",
       "7    -25.0   3.062   0.667969  \n",
       "8    -20.0   2.483        NaN  \n",
       "9    -15.0   2.136        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df = pd.read_csv(file_name)\n",
    "task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.365</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>2.479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>3.335</td>\n",
       "      <td>0.175781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>2.452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.215</td>\n",
       "      <td>0.652344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           1.0  25.0     105.0         0.0         1.0     1.0   \n",
       "2         2           1.0 -15.0       0.0       -47.0         2.0     0.0   \n",
       "3         3           1.0 -35.0       0.0      -175.0         2.0     0.0   \n",
       "4         4           1.0 -30.0       0.0       -95.0         2.0     0.0   \n",
       "5         5           1.0 -20.0       0.0       -63.0         2.0     0.0   \n",
       "6         6           1.0 -20.0       0.0      -100.0         2.0     0.0   \n",
       "7         7           1.0  30.0     126.0         0.0         1.0     1.0   \n",
       "8         8           1.0 -15.0       0.0       -37.0         2.0     0.0   \n",
       "9         9           1.0   0.0      65.0       -65.0         2.0     0.0   \n",
       "\n",
       "   Outcome     RT  Happiness  \n",
       "0      NaN    NaN   0.890625  \n",
       "1      0.0  2.365        NaN  \n",
       "2    -15.0  2.479        NaN  \n",
       "3    -35.0  3.335   0.175781  \n",
       "4    -30.0  2.452        NaN  \n",
       "5    -20.0  1.960        NaN  \n",
       "6    -20.0  1.281        NaN  \n",
       "7    126.0  1.215   0.652344  \n",
       "8    -15.0  1.993        NaN  \n",
       "9      0.0  2.503        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dopa_task_df = pd.read_csv(file_dopa_name)\n",
    "dopa_task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "    task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "    task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "    task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "    task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "    task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "    task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "    task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "    task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "    return task_df\n",
    "\n",
    "task_df = add_releveant_features (task_df)\n",
    "dopa_task_df = add_releveant_features(dopa_task_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder=OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 5)\n",
      "(300, 1)\n",
      "(300, 5)\n",
      "(300, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "stop = 300\n",
    "\n",
    "# include_ind = np.setdiff1d(np.arange(task_df.shape[0]),np.arange(0,task_df.shape[0],301))\n",
    "# include_ind = np.arange(1,task_df.shape[0])\n",
    "# X_y_split\n",
    "## TRAIN\n",
    "# train_X = task_df.loc[include_ind,['Safe','BigRisky','SmallRisky']].values\n",
    "# train_y = task_df.loc[include_ind,['Choice']].values.astype(np.int32)\n",
    "\n",
    "##----------------- UNCOMMENT BELOW\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice']].values\n",
    "\n",
    "train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "# ## TEST\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice']].values\n",
    "\n",
    "test_y = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "## ---------------------------\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "\n",
    "# extra_features = 5;\n",
    "\n",
    "#### -------------------\n",
    "# train_X = Binned_EV_diff_task\n",
    "# train_X = onehot_encoder.fit_transform(train_X)\n",
    "\n",
    "\n",
    "## GENERATED CHOICES #####\n",
    "\n",
    "# train_X = task_df.loc[:2990000,['Safe','BigRisky','SmallRisky']].values\n",
    "# test_X = task_df.loc[2990000:,['Safe','BigRisky','SmallRisky']].values\n",
    "\n",
    "# train_X = task_df.loc[1:2500,['Safe','BigRisky','SmallRisky']].values\n",
    "# test_X = task_df.loc[2500:,['Safe','BigRisky','SmallRisky']].values\n",
    "\n",
    "\n",
    "\n",
    "# train_y = task_df.loc[1:2500,['Choice']].values\n",
    "# test_y = task_df.loc[2500:,['Choice']].values\n",
    "\n",
    "# test_X = task_df.loc[-10000:,[['Safe','BigRisky','SmallRisky']]].values\n",
    "# test_y = task_df.loc[-10000:,[['Choice']]].values.astype(np.int32)\n",
    "\n",
    "\n",
    "# test_X = Binned_EV_diff_dopa_task\n",
    "# test_X = onehot_encoder.fit_transform(test_X)\n",
    "\n",
    "\n",
    "###### when splitting data into train and validation\n",
    "\n",
    "# train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.35, random_state=1)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_X[:stop], train_X[stop:], train_y[:stop], train_y[stop:]\n",
    "\n",
    "##############\n",
    "\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "# # center and scale\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "\n",
    "# train_X[0,-extra_features + 1:]= 0;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_X = np.array(train_X).reshape(-1,time_steps,inputs)\n",
    "# test_X = np.array(test_X).reshape(-1,time_steps,inputs)\n",
    "\n",
    "\n",
    "#  # reshape input to 3D array\n",
    "# encode_categorical = train_X.reshape(len(train_X), 1)\n",
    "# encode_categorical_test = test_X.reshape(len(test_X), 1)\n",
    "# train_X = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "# test_X= onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_X = train_X[None,:,:]\n",
    "# val_X = val_X[None,:,:]\n",
    "test_X = test_X[None,:,:]\n",
    "\n",
    "\n",
    "# # one-hot encode the outputs\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "encode_categorical_test = test_y.reshape(len(test_y), 1)\n",
    "# encode_categorical_val = val_y.reshape(len(val_y),1)\n",
    "\n",
    "\n",
    "train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "test_y = onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "# val_y = onehot_encoder.fit_transform(encode_categorical_val).toarray()\n",
    "\n",
    "\n",
    "# train_y =  train_y.reshape(-1,time_steps,outputs)\n",
    "# test_y =  test_y.reshape(-1,time_steps,outputs)\n",
    "\n",
    "\n",
    "\n",
    "train_y = train_y[None,:,:]\n",
    "test_y = test_y[None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "seq_length = 200\n",
    "feature_count = 8 #train_X.shape[-1]#20\n",
    "class_count = 2\n",
    "rnn_width = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_sequence_classifier():\n",
    "  input = Input(shape=(seq_length, feature_count))\n",
    "  x = LSTM(rnn_width, return_sequences=True,activation = 'relu')(input)\n",
    "  # x = LSTM(rnn_width, return_sequences=True)(x)\n",
    "  # x = LSTM(rnn_width)(x)\n",
    "  x = Dense(class_count, activation='softmax')(x)\n",
    "  return Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 200, 8)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 200, 8)            544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200, 2)            18        \n",
      "=================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classic_model = classic_sequence_classifier()\n",
    "classic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ba3f86fe1c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "classic_model.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
