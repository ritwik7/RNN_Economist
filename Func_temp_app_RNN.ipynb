{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "onehot_encoder=OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "time_steps = 1\n",
    "inputs = 5\n",
    "outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "    task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "    task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "    task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "    task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "    task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "    task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "    task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "    task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "#     task_df['PrevRT']=task_df['RT'].shift(1)\n",
    "#     task_df.loc[1,'PrevRT']= 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    return task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_split_data(data,start_chunk,end_chunk):\n",
    "    \n",
    "    a=[k for k in range(start_chunk,end_chunk)]\n",
    "    out=[]\n",
    "\n",
    "    for d in range(0,data.shape[0],20):\n",
    "\n",
    "        c= [c+d for c in a]\n",
    "        out = out+c\n",
    "\n",
    "    while out[-1]>=data.shape[0]-1:\n",
    "        out.pop()\n",
    "#     return out\n",
    "    return data[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y): \n",
    "    reset_graph()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 50000\n",
    "    batch_size = int(train_X.shape[0]/2)\n",
    "    # batch_size = 100\n",
    "    length = train_X.shape[0]\n",
    "    display = 100\n",
    "    neurons = neurons\n",
    "\n",
    "    num_batches = 100\n",
    "    seq_len = 10\n",
    "\n",
    "    percent_above_PT = 1\n",
    "\n",
    "    train_threshold = 1.5#PT_R2 + percent_above_PT\n",
    "\n",
    "\n",
    "    save_step = 100\n",
    "\n",
    "\n",
    "    best_loss_val = np.infty\n",
    "    checks_since_last_progress = 0\n",
    "    max_checks_without_progress = 1000\n",
    "\n",
    "\n",
    "    # clear graph (if any) before running\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, time_steps, inputs])\n",
    "\n",
    "    y = tf.placeholder(tf.float32, [None, outputs])\n",
    "\n",
    "    # LSTM Cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=neurons, activation=tf.nn.relu)\n",
    "    cell_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "    # pass into Dense layer\n",
    "    stacked_outputs = tf.reshape(cell_outputs, [-1, neurons])\n",
    "    out = tf.layers.dense(inputs=stacked_outputs, units=outputs)\n",
    "\n",
    "    probability = tf.nn.softmax(out)\n",
    "\n",
    "    # squared error loss or cost function for linear regression\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=y, logits=out))\n",
    "\n",
    "    # optimizer to minimize cost\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels =  tf.argmax(y, 1),\n",
    "                          predictions = tf.argmax(out, 1),\n",
    "                          name = \"accuracy\")\n",
    "    precision = tf.metrics.precision(labels=tf.argmax(y, 1),\n",
    "                                 predictions=tf.argmax(out, 1),\n",
    "                                 name=\"precision\")\n",
    "    recall = tf.metrics.recall(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"recall\")\n",
    "    f1 = 2 * accuracy[1] * recall[1] / ( precision[1] + recall[1] )\n",
    "\n",
    "    acc_up,acc_val = accuracy\n",
    "    auc = tf.metrics.auc(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"auc\")\n",
    "    \n",
    "    valid_store = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #######################\n",
    "#         saver.restore(sess, \"./checkpts/Original_RNN_LSTM_8features_v2.ckpt\")\n",
    "#         saver.restore(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "        \n",
    "        if pretraining == True:\n",
    "\n",
    "            saver.restore(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        #######################\n",
    "        \n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "\n",
    "        # Train the model\n",
    "        for steps in range(epochs):\n",
    "            mini_batch = zip(range(0, length, batch_size),\n",
    "                       range(batch_size, length+1, batch_size))\n",
    "\n",
    "            # train data in mini-batches\n",
    "            for (start, end) in mini_batch:\n",
    "    #             print(start,end)\n",
    "                sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "                                                   y: train_y[start:end,:]}) \n",
    "\n",
    "            ## train data in batches of length subsequence\n",
    "\n",
    "    #         for k in range(num_batches):\n",
    "    #             X_seq, y_seq = random_subsequence(train_X,train_y,seq_len)\n",
    "\n",
    "    #             sess.run(training_op, feed_dict = {X:X_seq,y:y_seq}) \n",
    "            loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "            loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "            # print training performance \n",
    "            if (steps+1) % display == 0:\n",
    "                # evaluate loss function on training set\n",
    "\n",
    "\n",
    "                loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining loss: {}'.format((steps+1), loss_fn))\n",
    "\n",
    "                acc_train = acc_val.eval(feed_dict={X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining accuracy: {}'.format((steps+1), acc_train))\n",
    "\n",
    "\n",
    "                acc_test = acc_val.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest accuracy: {}'.format((steps+1), acc_test))\n",
    "\n",
    "                loss_test = loss.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest loss: {}'.format((steps+1), loss_test))\n",
    "\n",
    "                accu_val = acc_val.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "                loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "                print('Step: {}  \\tValid loss: {}'.format((steps+1), loss_val))\n",
    "\n",
    "                valid_store.append(loss_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (1 + loss_fn/np.log(0.5)) > train_threshold:\n",
    "                    print(\"Threshold achieved, quit training\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            if loss_val < best_loss_val:\n",
    "\n",
    "                        best_loss_val = loss_val\n",
    "                        checks_since_last_progress = 0\n",
    "            else:\n",
    "                            checks_since_last_progress += 1\n",
    "\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if checks_since_last_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "\n",
    "            if (steps+1) % save_step ==0:\n",
    "                                save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#                 save_path = saver.save(sess, \"./checkpts/RNN_Internet_LSTM_model_5features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     evaluate model accuracy\n",
    "        acc, prec, recall, f1, AUC = sess.run([accuracy, precision, recall, f1,auc],\n",
    "                                         feed_dict = {X: train_X, y: train_y})\n",
    "        prob_train = probability.eval(feed_dict = {X: train_X, y: train_y})\n",
    "        prob_test = probability.eval(feed_dict = {X: test_X, y: test_y})\n",
    "        prob_valid = probability.eval(feed_dict = {X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nEvaluation  on training set')\n",
    "        print('Accuracy:', acc[1])\n",
    "        print('Precision:', prec[1])\n",
    "        print('Recall:', recall[1])\n",
    "        print('F1 score:', f1)\n",
    "        print('AUC:', AUC[1])\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        \n",
    "#         save_path = saver.save(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/LaterDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## APP DATA\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "        save_path = saver.save(sess, \"./checkpts/Later_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "    metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,AUC[1],loss_fn,accu_val,best_loss_val,acc_test,loss_test,neurons,learning_rate,epochs,steps]).reshape(-1,14),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\",\"loss\",\"accuracy_val\",\"loss_val\",\"accuracy_test\",\"loss_test\",\"neurons\",\"learning_rate\",\"n_epochs\",\"steps\"])\n",
    "    return metric_out_df, prob_train, prob_test, prob_valid\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def random_subsequence(X,y,seq_len):\n",
    "    rnd  = random.randint(0,len(X)-seq_len)\n",
    "    X_seq, y_seq = X[rnd:rnd+seq_len,:], y[rnd:rnd+seq_len,:]\n",
    "    return X_seq, y_seq\n",
    "\n",
    "    print(y_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odd plays train, even plays test and valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\")\n",
    "dir_path =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"\n",
    "\n",
    "subj_files_list =[]; ## list of subject_files fullfilling a criteria\n",
    "\n",
    "dir_files = [i for i in os.listdir(dir_path) if i.startswith('sub')]\n",
    "\n",
    "for subj_file_path in dir_files:\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "    \n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]   \n",
    "    \n",
    "    if len(play_names) >= 50: ## criteria\n",
    "        subj_files_list.append(subj_file_path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subj_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "num_shuffles=1\n",
    "for num, subj_file_path in enumerate(subj_files_list):\n",
    "    print(num)\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "    \n",
    "#     train_data,test_data, val_data = np.empty((0,task_df.columns.shape[0])),  np.empty((0,task_df.columns.shape[0])), np.empty((0,task_df.columns.shape[0]))\n",
    "    train_data,test_data, val_data = np.empty((0,15)),  np.empty((0,15)), np.empty((0,15))\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "        \n",
    "    comp_task_train_df = pd.DataFrame()\n",
    "\n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]    \n",
    "\n",
    "    for randomization_counter in range(0,num_shuffles):\n",
    "            randomized_play_names= random.sample(play_names,len(play_names))\n",
    "            \n",
    "            for play_num, play_name in enumerate(randomized_play_names):\n",
    "#         for play_num,play_name in enumerate(play_names):\n",
    "\n",
    "                file_name = file_path + \"/\" + play_name\n",
    "                task_df = pd.read_csv(file_name)\n",
    "                task_df = add_releveant_features(task_df)\n",
    "\n",
    "                if np.mod(play_num,2)==0: ## odd trials\n",
    "                    train_data = np.append(train_data,task_df[task_df.TrialNum>1].values, axis=0)\n",
    "\n",
    "                else:\n",
    "                    test_data =  np.append(test_data, task_df[task_df.TrialNum>1].values[0:16], axis=0)\n",
    "                    val_data =  np.append(val_data, task_df[task_df.TrialNum>1].values[16:], axis=0)\n",
    "\n",
    "\n",
    "    train_data_df= pd.DataFrame(train_data,columns=task_df.columns)\n",
    "    val_data_df = pd.DataFrame(test_data,columns=task_df.columns)\n",
    "    test_data_df= pd.DataFrame(val_data,columns=task_df.columns)\n",
    "\n",
    "#     file_path = file_path + \"/OddEvenPlays/\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "#     os.mkdir(file_path)\n",
    "    train_data_df.to_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df.to_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df.to_csv(file_path+\"/val_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_odd_even(train_data_df,test_data_df,val_data_df):\n",
    "\n",
    "#     train_len = 29\n",
    "#     test_len = 14\n",
    "#     val_len = 15\n",
    "\n",
    "    ##----------------- UNCOMMENT BELOW\n",
    "    \n",
    "    if hist_flag==0: ## CURR OPTIONS ONLY\n",
    "        \n",
    "    \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "    elif hist_flag==1: ## CURR OPTIONS, PREV ACTIONS:\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "        \n",
    "        \n",
    "    elif hist_flag==2: ## CURR OPTIONS, PREV ACTIONS, PREV OUTCOME\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "             \n",
    "        \n",
    "\n",
    "####### Prev O + C+ R + CurrO--------------------\n",
    "    elif hist_flag==3: # CURR OPTIONS, PREV ACTIONS, PREV OUTCOME, PREV OPTIONS\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######## sampling \n",
    "    \n",
    "    \n",
    "#### - Prev RT+C+R+O + Curr O----------------------\n",
    "\n",
    "#     train_X = task_df.loc[task_df.TrialNum>1, ['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     train_y = task_df.loc[task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### PRE TRAINING\n",
    "#     stop = int(0.7*len(train_X))\n",
    "#     print(stop)\n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y= train_X[:stop], train_X[stop:stop+int((len(train_X)-stop)/2)], train_X[stop+int((len(train_X)-stop)/2):],train_y[:stop], train_y[stop:stop+int((len(train_X)-stop)/2)], train_y[stop+int((len(train_X)-stop)/2):]\n",
    "    \n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y = train_X, test_X, test_X, train_y, test_y, test_y\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "    print(val_X.shape)\n",
    "    print(val_y.shape)\n",
    "    print(test_X.shape)\n",
    "    print(test_y.shape)\n",
    "\n",
    "    # # center and scale\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.fit_transform(test_X)\n",
    "    val_X = scaler.fit_transform(val_X)\n",
    "\n",
    "\n",
    "    train_X = train_X[:,None,:]\n",
    "    val_X = val_X[:,None,:]\n",
    "    test_X = test_X[:,None,:]\n",
    "\n",
    "\n",
    "    # # one-hot encode the outputs\n",
    "\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "    encode_categorical_test = test_y.reshape(len(test_y), 1)\n",
    "    encode_categorical_val = val_y.reshape(len(val_y),1)\n",
    "\n",
    "\n",
    "    train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "    test_y = onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "    val_y = onehot_encoder.fit_transform(encode_categorical_val).toarray()\n",
    "\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y, val_X,val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1189, 5)\n",
      "(1189, 1)\n",
      "(640, 5)\n",
      "(640, 1)\n",
      "(520, 5)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.35643652081489563\n",
      "Step: 100  \tTraining accuracy: 0.8696383237838745\n",
      "Step: 100  \tValid loss: 0.37299397587776184\n",
      "Step: 200  \tTraining loss: 0.3162817060947418\n",
      "Step: 200  \tTraining accuracy: 0.8651780486106873\n",
      "Step: 200  \tValid loss: 0.35062503814697266\n",
      "Step: 300  \tTraining loss: 0.2835092544555664\n",
      "Step: 300  \tTraining accuracy: 0.8642772436141968\n",
      "Step: 300  \tValid loss: 0.3428322374820709\n",
      "Step: 400  \tTraining loss: 0.26558586955070496\n",
      "Step: 400  \tTraining accuracy: 0.8671685457229614\n",
      "Step: 400  \tValid loss: 0.350076287984848\n",
      "Step: 500  \tTraining loss: 0.2614310681819916\n",
      "Step: 500  \tTraining accuracy: 0.8701936602592468\n",
      "Step: 500  \tValid loss: 0.3593922257423401\n",
      "Step: 600  \tTraining loss: 0.2606891691684723\n",
      "Step: 600  \tTraining accuracy: 0.871192216873169\n",
      "Step: 600  \tValid loss: 0.3619684875011444\n",
      "Step: 700  \tTraining loss: 0.26032280921936035\n",
      "Step: 700  \tTraining accuracy: 0.8718838095664978\n",
      "Step: 700  \tValid loss: 0.3620494306087494\n",
      "Step: 800  \tTraining loss: 0.26004675030708313\n",
      "Step: 800  \tTraining accuracy: 0.8723911046981812\n",
      "Step: 800  \tValid loss: 0.36202502250671387\n",
      "Step: 900  \tTraining loss: 0.2597954571247101\n",
      "Step: 900  \tTraining accuracy: 0.8728792071342468\n",
      "Step: 900  \tValid loss: 0.36183813214302063\n",
      "Step: 1000  \tTraining loss: 0.2595718204975128\n",
      "Step: 1000  \tTraining accuracy: 0.8732646703720093\n",
      "Step: 1000  \tValid loss: 0.36172425746917725\n",
      "Step: 1100  \tTraining loss: 0.2593725621700287\n",
      "Step: 1100  \tTraining accuracy: 0.8736172318458557\n",
      "Step: 1100  \tValid loss: 0.3616471290588379\n",
      "Step: 1200  \tTraining loss: 0.25919389724731445\n",
      "Step: 1200  \tTraining accuracy: 0.8738715648651123\n",
      "Step: 1200  \tValid loss: 0.3615734279155731\n",
      "Step: 1300  \tTraining loss: 0.25903862714767456\n",
      "Step: 1300  \tTraining accuracy: 0.8741532564163208\n",
      "Step: 1300  \tValid loss: 0.361523300409317\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.87442476\n",
      "Precision: 0.9269663\n",
      "Recall: 0.9574468\n",
      "F1 score: 0.88856864\n",
      "AUC: 0.7271105\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.874425   0.926966  0.957447  0.888569  0.727111  0.259036       0.87353   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.342831       0.874302   0.304584      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1301.0  \n",
      "1\n",
      "(4263, 5)\n",
      "(4263, 1)\n",
      "(2352, 5)\n",
      "(2352, 1)\n",
      "(1911, 5)\n",
      "(1911, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5127460360527039\n",
      "Step: 100  \tTraining accuracy: 0.7593244314193726\n",
      "Step: 100  \tValid loss: 0.5398445725440979\n",
      "Step: 200  \tTraining loss: 0.48025959730148315\n",
      "Step: 200  \tTraining accuracy: 0.7556493878364563\n",
      "Step: 200  \tValid loss: 0.5049644112586975\n",
      "Step: 300  \tTraining loss: 0.4412953853607178\n",
      "Step: 300  \tTraining accuracy: 0.7620924115180969\n",
      "Step: 300  \tValid loss: 0.462371826171875\n",
      "Step: 400  \tTraining loss: 0.4092418849468231\n",
      "Step: 400  \tTraining accuracy: 0.7701149582862854\n",
      "Step: 400  \tValid loss: 0.4259050190448761\n",
      "Step: 500  \tTraining loss: 0.3968777060508728\n",
      "Step: 500  \tTraining accuracy: 0.7774128913879395\n",
      "Step: 500  \tValid loss: 0.4110395908355713\n",
      "Step: 600  \tTraining loss: 0.3942534327507019\n",
      "Step: 600  \tTraining accuracy: 0.7829526662826538\n",
      "Step: 600  \tValid loss: 0.407516211271286\n",
      "Step: 700  \tTraining loss: 0.393618106842041\n",
      "Step: 700  \tTraining accuracy: 0.7870044708251953\n",
      "Step: 700  \tValid loss: 0.4066471755504608\n",
      "Step: 800  \tTraining loss: 0.39320558309555054\n",
      "Step: 800  \tTraining accuracy: 0.7900070548057556\n",
      "Step: 800  \tValid loss: 0.4062178134918213\n",
      "Step: 900  \tTraining loss: 0.39278796315193176\n",
      "Step: 900  \tTraining accuracy: 0.7922893166542053\n",
      "Step: 900  \tValid loss: 0.40586307644844055\n",
      "Step: 1000  \tTraining loss: 0.3923195004463196\n",
      "Step: 1000  \tTraining accuracy: 0.7941281795501709\n",
      "Step: 1000  \tValid loss: 0.40546199679374695\n",
      "Step: 1100  \tTraining loss: 0.39172035455703735\n",
      "Step: 1100  \tTraining accuracy: 0.7957172989845276\n",
      "Step: 1100  \tValid loss: 0.4049147069454193\n",
      "Step: 1200  \tTraining loss: 0.3909929692745209\n",
      "Step: 1200  \tTraining accuracy: 0.7970606684684753\n",
      "Step: 1200  \tValid loss: 0.4041547477245331\n",
      "Step: 1300  \tTraining loss: 0.3902152478694916\n",
      "Step: 1300  \tTraining accuracy: 0.7982265949249268\n",
      "Step: 1300  \tValid loss: 0.40350908041000366\n",
      "Step: 1400  \tTraining loss: 0.38896888494491577\n",
      "Step: 1400  \tTraining accuracy: 0.7992545962333679\n",
      "Step: 1400  \tValid loss: 0.4028247594833374\n",
      "Step: 1500  \tTraining loss: 0.38819536566734314\n",
      "Step: 1500  \tTraining accuracy: 0.8001731038093567\n",
      "Step: 1500  \tValid loss: 0.40226635336875916\n",
      "Step: 1600  \tTraining loss: 0.38729092478752136\n",
      "Step: 1600  \tTraining accuracy: 0.8009428381919861\n",
      "Step: 1600  \tValid loss: 0.4017995297908783\n",
      "Step: 1700  \tTraining loss: 0.3864089250564575\n",
      "Step: 1700  \tTraining accuracy: 0.8016334772109985\n",
      "Step: 1700  \tValid loss: 0.4017023742198944\n",
      "Step: 1800  \tTraining loss: 0.38546162843704224\n",
      "Step: 1800  \tTraining accuracy: 0.8022184371948242\n",
      "Step: 1800  \tValid loss: 0.40173810720443726\n",
      "Step: 1900  \tTraining loss: 0.3845050632953644\n",
      "Step: 1900  \tTraining accuracy: 0.8027781248092651\n",
      "Step: 1900  \tValid loss: 0.40192002058029175\n",
      "Step: 2000  \tTraining loss: 0.3836108446121216\n",
      "Step: 2000  \tTraining accuracy: 0.8033345937728882\n",
      "Step: 2000  \tValid loss: 0.4020964801311493\n",
      "Step: 2100  \tTraining loss: 0.38263943791389465\n",
      "Step: 2100  \tTraining accuracy: 0.8039054274559021\n",
      "Step: 2100  \tValid loss: 0.4021374583244324\n",
      "Step: 2200  \tTraining loss: 0.3810822069644928\n",
      "Step: 2200  \tTraining accuracy: 0.8044940233230591\n",
      "Step: 2200  \tValid loss: 0.4006653428077698\n",
      "Step: 2300  \tTraining loss: 0.3800058662891388\n",
      "Step: 2300  \tTraining accuracy: 0.8050668835639954\n",
      "Step: 2300  \tValid loss: 0.4009985327720642\n",
      "Step: 2400  \tTraining loss: 0.3792871832847595\n",
      "Step: 2400  \tTraining accuracy: 0.805625855922699\n",
      "Step: 2400  \tValid loss: 0.40102702379226685\n",
      "Step: 2500  \tTraining loss: 0.37871620059013367\n",
      "Step: 2500  \tTraining accuracy: 0.8061727285385132\n",
      "Step: 2500  \tValid loss: 0.40101757645606995\n",
      "Step: 2600  \tTraining loss: 0.3782947361469269\n",
      "Step: 2600  \tTraining accuracy: 0.8067134618759155\n",
      "Step: 2600  \tValid loss: 0.40093994140625\n",
      "Step: 2700  \tTraining loss: 0.3779454231262207\n",
      "Step: 2700  \tTraining accuracy: 0.8072178959846497\n",
      "Step: 2700  \tValid loss: 0.4009610712528229\n",
      "Step: 2800  \tTraining loss: 0.3776743710041046\n",
      "Step: 2800  \tTraining accuracy: 0.8076898455619812\n",
      "Step: 2800  \tValid loss: 0.4010169506072998\n",
      "Step: 2900  \tTraining loss: 0.3774527311325073\n",
      "Step: 2900  \tTraining accuracy: 0.8081328272819519\n",
      "Step: 2900  \tValid loss: 0.4010818898677826\n",
      "Step: 3000  \tTraining loss: 0.3772619664669037\n",
      "Step: 3000  \tTraining accuracy: 0.808565616607666\n",
      "Step: 3000  \tValid loss: 0.40112215280532837\n",
      "Step: 3100  \tTraining loss: 0.3770926296710968\n",
      "Step: 3100  \tTraining accuracy: 0.8090007901191711\n",
      "Step: 3100  \tValid loss: 0.4011761546134949\n",
      "Step: 3200  \tTraining loss: 0.376941055059433\n",
      "Step: 3200  \tTraining accuracy: 0.809419572353363\n",
      "Step: 3200  \tValid loss: 0.4011964201927185\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8098053\n",
      "Precision: 0.8627737\n",
      "Recall: 0.9128823\n",
      "F1 score: 0.8326578\n",
      "AUC: 0.7273963\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.809805   0.862774  0.912882  0.832658  0.727396  0.376934       0.80959   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.400624       0.809546   0.377059      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3203.0  \n",
      "2\n",
      "(754, 5)\n",
      "(754, 1)\n",
      "(416, 5)\n",
      "(416, 1)\n",
      "(338, 5)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6063272356987\n",
      "Step: 100  \tTraining accuracy: 0.6472148299217224\n",
      "Step: 100  \tValid loss: 0.5771676301956177\n",
      "Step: 200  \tTraining loss: 0.5878878235816956\n",
      "Step: 200  \tTraining accuracy: 0.6578249335289001\n",
      "Step: 200  \tValid loss: 0.5770272016525269\n",
      "Step: 300  \tTraining loss: 0.5796958208084106\n",
      "Step: 300  \tTraining accuracy: 0.6580901741981506\n",
      "Step: 300  \tValid loss: 0.5723430514335632\n",
      "Step: 400  \tTraining loss: 0.5735880732536316\n",
      "Step: 400  \tTraining accuracy: 0.6612353324890137\n",
      "Step: 400  \tValid loss: 0.567375123500824\n",
      "Step: 500  \tTraining loss: 0.5686087608337402\n",
      "Step: 500  \tTraining accuracy: 0.664603590965271\n",
      "Step: 500  \tValid loss: 0.5626415610313416\n",
      "Step: 600  \tTraining loss: 0.5646767616271973\n",
      "Step: 600  \tTraining accuracy: 0.6672292947769165\n",
      "Step: 600  \tValid loss: 0.5585575103759766\n",
      "Step: 700  \tTraining loss: 0.5616915225982666\n",
      "Step: 700  \tTraining accuracy: 0.6699653267860413\n",
      "Step: 700  \tValid loss: 0.5553466081619263\n",
      "Step: 800  \tTraining loss: 0.5594875812530518\n",
      "Step: 800  \tTraining accuracy: 0.6727674603462219\n",
      "Step: 800  \tValid loss: 0.5529283881187439\n",
      "Step: 900  \tTraining loss: 0.5578722357749939\n",
      "Step: 900  \tTraining accuracy: 0.6756124496459961\n",
      "Step: 900  \tValid loss: 0.5510987639427185\n",
      "Step: 1000  \tTraining loss: 0.5566861629486084\n",
      "Step: 1000  \tTraining accuracy: 0.6780678629875183\n",
      "Step: 1000  \tValid loss: 0.5496947765350342\n",
      "Step: 1100  \tTraining loss: 0.5558122992515564\n",
      "Step: 1100  \tTraining accuracy: 0.680245041847229\n",
      "Step: 1100  \tValid loss: 0.5485814213752747\n",
      "Step: 1200  \tTraining loss: 0.5551710724830627\n",
      "Step: 1200  \tTraining accuracy: 0.6822165846824646\n",
      "Step: 1200  \tValid loss: 0.5476987361907959\n",
      "Step: 1300  \tTraining loss: 0.5547018051147461\n",
      "Step: 1300  \tTraining accuracy: 0.6840848922729492\n",
      "Step: 1300  \tValid loss: 0.546983540058136\n",
      "Step: 1400  \tTraining loss: 0.5543587803840637\n",
      "Step: 1400  \tTraining accuracy: 0.6857255101203918\n",
      "Step: 1400  \tValid loss: 0.5464085936546326\n",
      "Step: 1500  \tTraining loss: 0.5541073679924011\n",
      "Step: 1500  \tTraining accuracy: 0.6871398687362671\n",
      "Step: 1500  \tValid loss: 0.5459458231925964\n",
      "Step: 1600  \tTraining loss: 0.553920328617096\n",
      "Step: 1600  \tTraining accuracy: 0.6887139678001404\n",
      "Step: 1600  \tValid loss: 0.5455718636512756\n",
      "Step: 1700  \tTraining loss: 0.5537790060043335\n",
      "Step: 1700  \tTraining accuracy: 0.690057098865509\n",
      "Step: 1700  \tValid loss: 0.545268177986145\n",
      "Step: 1800  \tTraining loss: 0.5536689162254333\n",
      "Step: 1800  \tTraining accuracy: 0.6911330223083496\n",
      "Step: 1800  \tValid loss: 0.5450198650360107\n",
      "Step: 1900  \tTraining loss: 0.5535805225372314\n",
      "Step: 1900  \tTraining accuracy: 0.6920567750930786\n",
      "Step: 1900  \tValid loss: 0.5448158383369446\n",
      "Step: 2000  \tTraining loss: 0.5535071492195129\n",
      "Step: 2000  \tTraining accuracy: 0.6927497982978821\n",
      "Step: 2000  \tValid loss: 0.5446469783782959\n",
      "Step: 2100  \tTraining loss: 0.553444504737854\n",
      "Step: 2100  \tTraining accuracy: 0.6934398412704468\n",
      "Step: 2100  \tValid loss: 0.5445066690444946\n",
      "Step: 2200  \tTraining loss: 0.553389310836792\n",
      "Step: 2200  \tTraining accuracy: 0.6940040588378906\n",
      "Step: 2200  \tValid loss: 0.5443900227546692\n",
      "Step: 2300  \tTraining loss: 0.5533392429351807\n",
      "Step: 2300  \tTraining accuracy: 0.6945181488990784\n",
      "Step: 2300  \tValid loss: 0.544292688369751\n",
      "Step: 2400  \tTraining loss: 0.5532934069633484\n",
      "Step: 2400  \tTraining accuracy: 0.6949884295463562\n",
      "Step: 2400  \tValid loss: 0.5442115068435669\n",
      "Step: 2500  \tTraining loss: 0.553250253200531\n",
      "Step: 2500  \tTraining accuracy: 0.6954745054244995\n",
      "Step: 2500  \tValid loss: 0.5441440939903259\n",
      "Step: 2600  \tTraining loss: 0.5532092452049255\n",
      "Step: 2600  \tTraining accuracy: 0.6959223747253418\n",
      "Step: 2600  \tValid loss: 0.5440881252288818\n",
      "Step: 2700  \tTraining loss: 0.5531697869300842\n",
      "Step: 2700  \tTraining accuracy: 0.6963615417480469\n",
      "Step: 2700  \tValid loss: 0.5440420508384705\n",
      "Step: 2800  \tTraining loss: 0.5531317591667175\n",
      "Step: 2800  \tTraining accuracy: 0.6967446208000183\n",
      "Step: 2800  \tValid loss: 0.544004499912262\n",
      "Step: 2900  \tTraining loss: 0.553094744682312\n",
      "Step: 2900  \tTraining accuracy: 0.6971241235733032\n",
      "Step: 2900  \tValid loss: 0.5439742803573608\n",
      "Step: 3000  \tTraining loss: 0.5530582070350647\n",
      "Step: 3000  \tTraining accuracy: 0.6974778771400452\n",
      "Step: 3000  \tValid loss: 0.5439502000808716\n",
      "Step: 3100  \tTraining loss: 0.5530225038528442\n",
      "Step: 3100  \tTraining accuracy: 0.6977866888046265\n",
      "Step: 3100  \tValid loss: 0.5439315438270569\n",
      "Step: 3200  \tTraining loss: 0.5529870390892029\n",
      "Step: 3200  \tTraining accuracy: 0.6980969309806824\n",
      "Step: 3200  \tValid loss: 0.5439174771308899\n",
      "Step: 3300  \tTraining loss: 0.552951991558075\n",
      "Step: 3300  \tTraining accuracy: 0.6983880996704102\n",
      "Step: 3300  \tValid loss: 0.5439072847366333\n",
      "Step: 3400  \tTraining loss: 0.5529170632362366\n",
      "Step: 3400  \tTraining accuracy: 0.6986618638038635\n",
      "Step: 3400  \tValid loss: 0.5439003109931946\n",
      "Step: 3500  \tTraining loss: 0.5528824925422668\n",
      "Step: 3500  \tTraining accuracy: 0.6989197731018066\n",
      "Step: 3500  \tValid loss: 0.5438963174819946\n",
      "Step: 3600  \tTraining loss: 0.5528479218482971\n",
      "Step: 3600  \tTraining accuracy: 0.6991631388664246\n",
      "Step: 3600  \tValid loss: 0.5438946485519409\n",
      "Step: 3700  \tTraining loss: 0.5528134703636169\n",
      "Step: 3700  \tTraining accuracy: 0.6993932127952576\n",
      "Step: 3700  \tValid loss: 0.5438946485519409\n",
      "Step: 3900  \tTraining loss: 0.5527443885803223\n",
      "Step: 3900  \tTraining accuracy: 0.699817419052124\n",
      "Step: 3900  \tValid loss: 0.543899416923523\n",
      "Step: 4000  \tTraining loss: 0.5527099967002869\n",
      "Step: 4000  \tTraining accuracy: 0.7000134587287903\n",
      "Step: 4000  \tValid loss: 0.5439032912254333\n",
      "Step: 4100  \tTraining loss: 0.5526753664016724\n",
      "Step: 4100  \tTraining accuracy: 0.7001997828483582\n",
      "Step: 4100  \tValid loss: 0.5439077615737915\n",
      "Step: 4200  \tTraining loss: 0.5526404976844788\n",
      "Step: 4200  \tTraining accuracy: 0.7003771066665649\n",
      "Step: 4200  \tValid loss: 0.5439126491546631\n",
      "Step: 4300  \tTraining loss: 0.5526057481765747\n",
      "Step: 4300  \tTraining accuracy: 0.7005460858345032\n",
      "Step: 4300  \tValid loss: 0.543915331363678\n",
      "Step: 4400  \tTraining loss: 0.5525707602500916\n",
      "Step: 4400  \tTraining accuracy: 0.7007225751876831\n",
      "Step: 4400  \tValid loss: 0.543919563293457\n",
      "Step: 4500  \tTraining loss: 0.5525357127189636\n",
      "Step: 4500  \tTraining accuracy: 0.7008911371231079\n",
      "Step: 4500  \tValid loss: 0.5439237952232361\n",
      "Step: 4600  \tTraining loss: 0.5525003671646118\n",
      "Step: 4600  \tTraining accuracy: 0.7010377049446106\n",
      "Step: 4600  \tValid loss: 0.5439277291297913\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.70117795\n",
      "Precision: 0.7254902\n",
      "Recall: 0.8604651\n",
      "F1 score: 0.7608526\n",
      "AUC: 0.65621114\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.701178    0.72549  0.860465  0.760853  0.656211  0.552491      0.701101   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.543894       0.700995   0.582097      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4624.0  \n",
      "3\n",
      "(783, 5)\n",
      "(783, 1)\n",
      "(416, 5)\n",
      "(416, 1)\n",
      "(338, 5)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5370991230010986\n",
      "Step: 100  \tTraining accuracy: 0.7522349953651428\n",
      "Step: 100  \tValid loss: 0.5876095294952393\n",
      "Step: 200  \tTraining loss: 0.5154679417610168\n",
      "Step: 200  \tTraining accuracy: 0.7431034445762634\n",
      "Step: 200  \tValid loss: 0.5795631408691406\n",
      "Step: 300  \tTraining loss: 0.5013244152069092\n",
      "Step: 300  \tTraining accuracy: 0.742546021938324\n",
      "Step: 300  \tValid loss: 0.5691050887107849\n",
      "Step: 400  \tTraining loss: 0.48896241188049316\n",
      "Step: 400  \tTraining accuracy: 0.7437893748283386\n",
      "Step: 400  \tValid loss: 0.5581889748573303\n",
      "Step: 500  \tTraining loss: 0.47743096947669983\n",
      "Step: 500  \tTraining accuracy: 0.7453469634056091\n",
      "Step: 500  \tValid loss: 0.547517716884613\n",
      "Step: 600  \tTraining loss: 0.4671369791030884\n",
      "Step: 600  \tTraining accuracy: 0.7479924559593201\n",
      "Step: 600  \tValid loss: 0.5377342700958252\n",
      "Step: 700  \tTraining loss: 0.45830219984054565\n",
      "Step: 700  \tTraining accuracy: 0.7501249313354492\n",
      "Step: 700  \tValid loss: 0.52913498878479\n",
      "Step: 800  \tTraining loss: 0.4507467746734619\n",
      "Step: 800  \tTraining accuracy: 0.7517760992050171\n",
      "Step: 800  \tValid loss: 0.5217679738998413\n",
      "Step: 900  \tTraining loss: 0.4439587891101837\n",
      "Step: 900  \tTraining accuracy: 0.7534215450286865\n",
      "Step: 900  \tValid loss: 0.5150038003921509\n",
      "Step: 1000  \tTraining loss: 0.43699997663497925\n",
      "Step: 1000  \tTraining accuracy: 0.7551997900009155\n",
      "Step: 1000  \tValid loss: 0.5078288316726685\n",
      "Step: 1100  \tTraining loss: 0.4284684360027313\n",
      "Step: 1100  \tTraining accuracy: 0.7575682401657104\n",
      "Step: 1100  \tValid loss: 0.49863988161087036\n",
      "Step: 1200  \tTraining loss: 0.4177139699459076\n",
      "Step: 1200  \tTraining accuracy: 0.7602600455284119\n",
      "Step: 1200  \tValid loss: 0.487333744764328\n",
      "Step: 1300  \tTraining loss: 0.40674471855163574\n",
      "Step: 1300  \tTraining accuracy: 0.7629895210266113\n",
      "Step: 1300  \tValid loss: 0.47694987058639526\n",
      "Step: 1400  \tTraining loss: 0.3973318934440613\n",
      "Step: 1400  \tTraining accuracy: 0.7653631567955017\n",
      "Step: 1400  \tValid loss: 0.46855130791664124\n",
      "Step: 1500  \tTraining loss: 0.3897053301334381\n",
      "Step: 1500  \tTraining accuracy: 0.7679027915000916\n",
      "Step: 1500  \tValid loss: 0.4616168141365051\n",
      "Step: 1600  \tTraining loss: 0.38365310430526733\n",
      "Step: 1600  \tTraining accuracy: 0.7704924941062927\n",
      "Step: 1600  \tValid loss: 0.45593029260635376\n",
      "Step: 1700  \tTraining loss: 0.37894535064697266\n",
      "Step: 1700  \tTraining accuracy: 0.7728472948074341\n",
      "Step: 1700  \tValid loss: 0.4515211284160614\n",
      "Step: 1800  \tTraining loss: 0.37532633543014526\n",
      "Step: 1800  \tTraining accuracy: 0.7750817537307739\n",
      "Step: 1800  \tValid loss: 0.4482061266899109\n",
      "Step: 1900  \tTraining loss: 0.3725438117980957\n",
      "Step: 1900  \tTraining accuracy: 0.7770395874977112\n",
      "Step: 1900  \tValid loss: 0.4457661509513855\n",
      "Step: 2000  \tTraining loss: 0.3703848421573639\n",
      "Step: 2000  \tTraining accuracy: 0.7789635062217712\n",
      "Step: 2000  \tValid loss: 0.44398215413093567\n",
      "Step: 2100  \tTraining loss: 0.3686816394329071\n",
      "Step: 2100  \tTraining accuracy: 0.7806363701820374\n",
      "Step: 2100  \tValid loss: 0.4426652491092682\n",
      "Step: 2200  \tTraining loss: 0.3673096001148224\n",
      "Step: 2200  \tTraining accuracy: 0.7822141647338867\n",
      "Step: 2200  \tValid loss: 0.4416715204715729\n",
      "Step: 2300  \tTraining loss: 0.36617952585220337\n",
      "Step: 2300  \tTraining accuracy: 0.7836517691612244\n",
      "Step: 2300  \tValid loss: 0.44089895486831665\n",
      "Step: 2400  \tTraining loss: 0.3652273118495941\n",
      "Step: 2400  \tTraining accuracy: 0.7849670648574829\n",
      "Step: 2400  \tValid loss: 0.440280020236969\n",
      "Step: 2500  \tTraining loss: 0.3644087612628937\n",
      "Step: 2500  \tTraining accuracy: 0.7862812280654907\n",
      "Step: 2500  \tValid loss: 0.439761757850647\n",
      "Step: 2600  \tTraining loss: 0.36369195580482483\n",
      "Step: 2600  \tTraining accuracy: 0.7874923348426819\n",
      "Step: 2600  \tValid loss: 0.43931785225868225\n",
      "Step: 2700  \tTraining loss: 0.3630543649196625\n",
      "Step: 2700  \tTraining accuracy: 0.7886121273040771\n",
      "Step: 2700  \tValid loss: 0.43892794847488403\n",
      "Step: 2800  \tTraining loss: 0.36247941851615906\n",
      "Step: 2800  \tTraining accuracy: 0.7897213697433472\n",
      "Step: 2800  \tValid loss: 0.4385761618614197\n",
      "Step: 2900  \tTraining loss: 0.36195483803749084\n",
      "Step: 2900  \tTraining accuracy: 0.790775716304779\n",
      "Step: 2900  \tValid loss: 0.438253253698349\n",
      "Step: 3000  \tTraining loss: 0.3614719808101654\n",
      "Step: 3000  \tTraining accuracy: 0.7917364835739136\n",
      "Step: 3000  \tValid loss: 0.43795305490493774\n",
      "Step: 3100  \tTraining loss: 0.36102375388145447\n",
      "Step: 3100  \tTraining accuracy: 0.7926343083381653\n",
      "Step: 3100  \tValid loss: 0.43767115473747253\n",
      "Step: 3200  \tTraining loss: 0.3606055676937103\n",
      "Step: 3200  \tTraining accuracy: 0.7934750914573669\n",
      "Step: 3200  \tValid loss: 0.43740469217300415\n",
      "Step: 3300  \tTraining loss: 0.36021286249160767\n",
      "Step: 3300  \tTraining accuracy: 0.7942442297935486\n",
      "Step: 3300  \tValid loss: 0.4371528923511505\n",
      "Step: 3400  \tTraining loss: 0.3598427474498749\n",
      "Step: 3400  \tTraining accuracy: 0.7949673533439636\n",
      "Step: 3400  \tValid loss: 0.43691378831863403\n",
      "Step: 3500  \tTraining loss: 0.35949239134788513\n",
      "Step: 3500  \tTraining accuracy: 0.7956675291061401\n",
      "Step: 3500  \tValid loss: 0.436689555644989\n",
      "Step: 3600  \tTraining loss: 0.3591602146625519\n",
      "Step: 3600  \tTraining accuracy: 0.7963281869888306\n",
      "Step: 3600  \tValid loss: 0.4364715814590454\n",
      "Step: 3700  \tTraining loss: 0.35884469747543335\n",
      "Step: 3700  \tTraining accuracy: 0.7969526648521423\n",
      "Step: 3700  \tValid loss: 0.43626320362091064\n",
      "Step: 3800  \tTraining loss: 0.3585437834262848\n",
      "Step: 3800  \tTraining accuracy: 0.7975438833236694\n",
      "Step: 3800  \tValid loss: 0.436034619808197\n",
      "Step: 3900  \tTraining loss: 0.3582582175731659\n",
      "Step: 3900  \tTraining accuracy: 0.7980706095695496\n",
      "Step: 3900  \tValid loss: 0.4358455538749695\n",
      "Step: 4000  \tTraining loss: 0.3579859733581543\n",
      "Step: 4000  \tTraining accuracy: 0.7985706329345703\n",
      "Step: 4000  \tValid loss: 0.4356688857078552\n",
      "Step: 4100  \tTraining loss: 0.35772600769996643\n",
      "Step: 4100  \tTraining accuracy: 0.799045979976654\n",
      "Step: 4100  \tValid loss: 0.43550175428390503\n",
      "Step: 4200  \tTraining loss: 0.3574778735637665\n",
      "Step: 4200  \tTraining accuracy: 0.79951411485672\n",
      "Step: 4200  \tValid loss: 0.43533846735954285\n",
      "Step: 4300  \tTraining loss: 0.3572406768798828\n",
      "Step: 4300  \tTraining accuracy: 0.799960196018219\n",
      "Step: 4300  \tValid loss: 0.435201495885849\n",
      "Step: 4400  \tTraining loss: 0.3570137023925781\n",
      "Step: 4400  \tTraining accuracy: 0.8003857731819153\n",
      "Step: 4400  \tValid loss: 0.4350726902484894\n",
      "Step: 4500  \tTraining loss: 0.3567960560321808\n",
      "Step: 4500  \tTraining accuracy: 0.8007922768592834\n",
      "Step: 4500  \tValid loss: 0.43494415283203125\n",
      "Step: 4600  \tTraining loss: 0.3565869629383087\n",
      "Step: 4600  \tTraining accuracy: 0.801180899143219\n",
      "Step: 4600  \tValid loss: 0.43482017517089844\n",
      "Step: 4700  \tTraining loss: 0.35638609528541565\n",
      "Step: 4700  \tTraining accuracy: 0.8015527725219727\n",
      "Step: 4700  \tValid loss: 0.4347020387649536\n",
      "Step: 4800  \tTraining loss: 0.356192946434021\n",
      "Step: 4800  \tTraining accuracy: 0.8019090294837952\n",
      "Step: 4800  \tValid loss: 0.43459033966064453\n",
      "Step: 4900  \tTraining loss: 0.3560073971748352\n",
      "Step: 4900  \tTraining accuracy: 0.8022505640983582\n",
      "Step: 4900  \tValid loss: 0.4344688653945923\n",
      "Step: 5000  \tTraining loss: 0.3558286726474762\n",
      "Step: 5000  \tTraining accuracy: 0.802578330039978\n",
      "Step: 5000  \tValid loss: 0.4343631863594055\n",
      "Step: 5100  \tTraining loss: 0.35565656423568726\n",
      "Step: 5100  \tTraining accuracy: 0.8028931021690369\n",
      "Step: 5100  \tValid loss: 0.43426698446273804\n",
      "Step: 5200  \tTraining loss: 0.3554903566837311\n",
      "Step: 5200  \tTraining accuracy: 0.8031956553459167\n",
      "Step: 5200  \tValid loss: 0.4341774582862854\n",
      "Step: 5300  \tTraining loss: 0.3553297519683838\n",
      "Step: 5300  \tTraining accuracy: 0.803486704826355\n",
      "Step: 5300  \tValid loss: 0.43409428000450134\n",
      "Step: 5400  \tTraining loss: 0.3551744818687439\n",
      "Step: 5400  \tTraining accuracy: 0.8037668466567993\n",
      "Step: 5400  \tValid loss: 0.4340171217918396\n",
      "Step: 5500  \tTraining loss: 0.35502395033836365\n",
      "Step: 5500  \tTraining accuracy: 0.8040367364883423\n",
      "Step: 5500  \tValid loss: 0.433944433927536\n",
      "Step: 5600  \tTraining loss: 0.35487785935401917\n",
      "Step: 5600  \tTraining accuracy: 0.8042968511581421\n",
      "Step: 5600  \tValid loss: 0.4338774085044861\n",
      "Step: 5700  \tTraining loss: 0.35473597049713135\n",
      "Step: 5700  \tTraining accuracy: 0.8045477867126465\n",
      "Step: 5700  \tValid loss: 0.43382373452186584\n",
      "Step: 5800  \tTraining loss: 0.3545980453491211\n",
      "Step: 5800  \tTraining accuracy: 0.8047900199890137\n",
      "Step: 5800  \tValid loss: 0.43376901745796204\n",
      "Step: 5900  \tTraining loss: 0.3544636070728302\n",
      "Step: 5900  \tTraining accuracy: 0.8050239682197571\n",
      "Step: 5900  \tValid loss: 0.43371641635894775\n",
      "Step: 6000  \tTraining loss: 0.3543323576450348\n",
      "Step: 6000  \tTraining accuracy: 0.805260956287384\n",
      "Step: 6000  \tValid loss: 0.43366703391075134\n",
      "Step: 6100  \tTraining loss: 0.3542039394378662\n",
      "Step: 6100  \tTraining accuracy: 0.8054901361465454\n",
      "Step: 6100  \tValid loss: 0.4336211085319519\n",
      "Step: 6200  \tTraining loss: 0.3540782034397125\n",
      "Step: 6200  \tTraining accuracy: 0.8057118654251099\n",
      "Step: 6200  \tValid loss: 0.43357816338539124\n",
      "Step: 6300  \tTraining loss: 0.3539547324180603\n",
      "Step: 6300  \tTraining accuracy: 0.805926501750946\n",
      "Step: 6300  \tValid loss: 0.4335382580757141\n",
      "Step: 6400  \tTraining loss: 0.3538334369659424\n",
      "Step: 6400  \tTraining accuracy: 0.8061343431472778\n",
      "Step: 6400  \tValid loss: 0.4334881901741028\n",
      "Step: 6500  \tTraining loss: 0.3537140488624573\n",
      "Step: 6500  \tTraining accuracy: 0.8063358068466187\n",
      "Step: 6500  \tValid loss: 0.4334433376789093\n",
      "Step: 6600  \tTraining loss: 0.35359618067741394\n",
      "Step: 6600  \tTraining accuracy: 0.8065310716629028\n",
      "Step: 6600  \tValid loss: 0.4334069788455963\n",
      "Step: 6700  \tTraining loss: 0.3534797728061676\n",
      "Step: 6700  \tTraining accuracy: 0.806720495223999\n",
      "Step: 6700  \tValid loss: 0.43337535858154297\n",
      "Step: 6800  \tTraining loss: 0.35336434841156006\n",
      "Step: 6800  \tTraining accuracy: 0.8069042563438416\n",
      "Step: 6800  \tValid loss: 0.4333468973636627\n",
      "Step: 6900  \tTraining loss: 0.35324984788894653\n",
      "Step: 6900  \tTraining accuracy: 0.8070827126502991\n",
      "Step: 6900  \tValid loss: 0.43332159519195557\n",
      "Step: 7000  \tTraining loss: 0.35313621163368225\n",
      "Step: 7000  \tTraining accuracy: 0.8072559833526611\n",
      "Step: 7000  \tValid loss: 0.43329891562461853\n",
      "Step: 7100  \tTraining loss: 0.35302308201789856\n",
      "Step: 7100  \tTraining accuracy: 0.8074243664741516\n",
      "Step: 7100  \tValid loss: 0.43327850103378296\n",
      "Step: 7200  \tTraining loss: 0.3529108464717865\n",
      "Step: 7200  \tTraining accuracy: 0.8075880408287048\n",
      "Step: 7200  \tValid loss: 0.4332681894302368\n",
      "Step: 7300  \tTraining loss: 0.3527988791465759\n",
      "Step: 7300  \tTraining accuracy: 0.8077471852302551\n",
      "Step: 7300  \tValid loss: 0.43325698375701904\n",
      "Step: 7400  \tTraining loss: 0.35268712043762207\n",
      "Step: 7400  \tTraining accuracy: 0.8079108595848083\n",
      "Step: 7400  \tValid loss: 0.43324658274650574\n",
      "Step: 7500  \tTraining loss: 0.35257551074028015\n",
      "Step: 7500  \tTraining accuracy: 0.8080701231956482\n",
      "Step: 7500  \tValid loss: 0.4332379996776581\n",
      "Step: 7600  \tTraining loss: 0.3524637222290039\n",
      "Step: 7600  \tTraining accuracy: 0.8082252144813538\n",
      "Step: 7600  \tValid loss: 0.4332270324230194\n",
      "Step: 7700  \tTraining loss: 0.35235166549682617\n",
      "Step: 7700  \tTraining accuracy: 0.8083761930465698\n",
      "Step: 7700  \tValid loss: 0.4332098364830017\n",
      "Step: 7800  \tTraining loss: 0.35223934054374695\n",
      "Step: 7800  \tTraining accuracy: 0.8085232973098755\n",
      "Step: 7800  \tValid loss: 0.43319958448410034\n",
      "Step: 7900  \tTraining loss: 0.3521270155906677\n",
      "Step: 7900  \tTraining accuracy: 0.8086667060852051\n",
      "Step: 7900  \tValid loss: 0.43319401144981384\n",
      "Step: 8000  \tTraining loss: 0.3520144820213318\n",
      "Step: 8000  \tTraining accuracy: 0.8088146448135376\n",
      "Step: 8000  \tValid loss: 0.4331910014152527\n",
      "Step: 8100  \tTraining loss: 0.35189157724380493\n",
      "Step: 8100  \tTraining accuracy: 0.808958888053894\n",
      "Step: 8100  \tValid loss: 0.4333043396472931\n",
      "Step: 8200  \tTraining loss: 0.35175204277038574\n",
      "Step: 8200  \tTraining accuracy: 0.8091076016426086\n",
      "Step: 8200  \tValid loss: 0.4334326386451721\n",
      "Step: 8300  \tTraining loss: 0.3516198992729187\n",
      "Step: 8300  \tTraining accuracy: 0.8092526793479919\n",
      "Step: 8300  \tValid loss: 0.43345996737480164\n",
      "Step: 8400  \tTraining loss: 0.35149458050727844\n",
      "Step: 8400  \tTraining accuracy: 0.809394359588623\n",
      "Step: 8400  \tValid loss: 0.4334383010864258\n",
      "Step: 8500  \tTraining loss: 0.3513725697994232\n",
      "Step: 8500  \tTraining accuracy: 0.8095248937606812\n",
      "Step: 8500  \tValid loss: 0.43340200185775757\n",
      "Step: 8600  \tTraining loss: 0.35125115513801575\n",
      "Step: 8600  \tTraining accuracy: 0.8096524477005005\n",
      "Step: 8600  \tValid loss: 0.43339279294013977\n",
      "Step: 8700  \tTraining loss: 0.3511291444301605\n",
      "Step: 8700  \tTraining accuracy: 0.809777021408081\n",
      "Step: 8700  \tValid loss: 0.43338826298713684\n",
      "Step: 8800  \tTraining loss: 0.35100647807121277\n",
      "Step: 8800  \tTraining accuracy: 0.8098987340927124\n",
      "Step: 8800  \tValid loss: 0.4333959221839905\n",
      "Step: 8900  \tTraining loss: 0.35088279843330383\n",
      "Step: 8900  \tTraining accuracy: 0.8100250959396362\n",
      "Step: 8900  \tValid loss: 0.4334120452404022\n",
      "Step: 9000  \tTraining loss: 0.3507584035396576\n",
      "Step: 9000  \tTraining accuracy: 0.8101558685302734\n",
      "Step: 9000  \tValid loss: 0.4334316551685333\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8102837\n",
      "Precision: 0.870607\n",
      "Recall: 0.92529714\n",
      "F1 score: 0.8349591\n",
      "AUC: 0.7538857\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.810284   0.870607  0.925297  0.834959  0.753886  0.35069      0.810113   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0   0.43319       0.810164   0.383465      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  9054.0  \n",
      "4\n",
      "(725, 5)\n",
      "(725, 1)\n",
      "(400, 5)\n",
      "(400, 1)\n",
      "(325, 5)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6387779712677002\n",
      "Step: 100  \tTraining accuracy: 0.7337930798530579\n",
      "Step: 100  \tValid loss: 0.641704261302948\n",
      "Step: 200  \tTraining loss: 0.4887915551662445\n",
      "Step: 200  \tTraining accuracy: 0.7544827461242676\n",
      "Step: 200  \tValid loss: 0.5125570893287659\n",
      "Step: 300  \tTraining loss: 0.3912321925163269\n",
      "Step: 300  \tTraining accuracy: 0.7820689678192139\n",
      "Step: 300  \tValid loss: 0.43231460452079773\n",
      "Step: 400  \tTraining loss: 0.353636771440506\n",
      "Step: 400  \tTraining accuracy: 0.7994088530540466\n",
      "Step: 400  \tValid loss: 0.4031119644641876\n",
      "Step: 500  \tTraining loss: 0.33718690276145935\n",
      "Step: 500  \tTraining accuracy: 0.8095018863677979\n",
      "Step: 500  \tValid loss: 0.39093253016471863\n",
      "Step: 600  \tTraining loss: 0.3276544511318207\n",
      "Step: 600  \tTraining accuracy: 0.8160501718521118\n",
      "Step: 600  \tValid loss: 0.38456740975379944\n",
      "Step: 700  \tTraining loss: 0.3200959265232086\n",
      "Step: 700  \tTraining accuracy: 0.8206896781921387\n",
      "Step: 700  \tValid loss: 0.3794950842857361\n",
      "Step: 800  \tTraining loss: 0.3131398856639862\n",
      "Step: 800  \tTraining accuracy: 0.8242758512496948\n",
      "Step: 800  \tValid loss: 0.37488627433776855\n",
      "Step: 900  \tTraining loss: 0.30646708607673645\n",
      "Step: 900  \tTraining accuracy: 0.8270182609558105\n",
      "Step: 900  \tValid loss: 0.37054747343063354\n",
      "Step: 1000  \tTraining loss: 0.29996562004089355\n",
      "Step: 1000  \tTraining accuracy: 0.8291832804679871\n",
      "Step: 1000  \tValid loss: 0.3662974238395691\n",
      "Step: 1100  \tTraining loss: 0.2936358153820038\n",
      "Step: 1100  \tTraining accuracy: 0.8309359550476074\n",
      "Step: 1100  \tValid loss: 0.36222347617149353\n",
      "Step: 1200  \tTraining loss: 0.28743383288383484\n",
      "Step: 1200  \tTraining accuracy: 0.8323838114738464\n",
      "Step: 1200  \tValid loss: 0.35797059535980225\n",
      "Step: 1300  \tTraining loss: 0.28137755393981934\n",
      "Step: 1300  \tTraining accuracy: 0.8336551785469055\n",
      "Step: 1300  \tValid loss: 0.35365980863571167\n",
      "Step: 1400  \tTraining loss: 0.27561667561531067\n",
      "Step: 1400  \tTraining accuracy: 0.8349425196647644\n",
      "Step: 1400  \tValid loss: 0.3497433066368103\n",
      "Step: 1500  \tTraining loss: 0.270243763923645\n",
      "Step: 1500  \tTraining accuracy: 0.8360522985458374\n",
      "Step: 1500  \tValid loss: 0.34614381194114685\n",
      "Step: 1600  \tTraining loss: 0.2652040123939514\n",
      "Step: 1600  \tTraining accuracy: 0.8370189070701599\n",
      "Step: 1600  \tValid loss: 0.34288477897644043\n",
      "Step: 1700  \tTraining loss: 0.2604794204235077\n",
      "Step: 1700  \tTraining accuracy: 0.837868332862854\n",
      "Step: 1700  \tValid loss: 0.34001073241233826\n",
      "Step: 1800  \tTraining loss: 0.25603312253952026\n",
      "Step: 1800  \tTraining accuracy: 0.8388177156448364\n",
      "Step: 1800  \tValid loss: 0.33748018741607666\n",
      "Step: 1900  \tTraining loss: 0.251986563205719\n",
      "Step: 1900  \tTraining accuracy: 0.8399254679679871\n",
      "Step: 1900  \tValid loss: 0.3348853290081024\n",
      "Step: 2000  \tTraining loss: 0.24808989465236664\n",
      "Step: 2000  \tTraining accuracy: 0.8410964012145996\n",
      "Step: 2000  \tValid loss: 0.3325847387313843\n",
      "Step: 2100  \tTraining loss: 0.24387964606285095\n",
      "Step: 2100  \tTraining accuracy: 0.842186689376831\n",
      "Step: 2100  \tValid loss: 0.3293007016181946\n",
      "Step: 2200  \tTraining loss: 0.23985418677330017\n",
      "Step: 2200  \tTraining accuracy: 0.8433681130409241\n",
      "Step: 2200  \tValid loss: 0.32553941011428833\n",
      "Step: 2300  \tTraining loss: 0.23606404662132263\n",
      "Step: 2300  \tTraining accuracy: 0.8445976972579956\n",
      "Step: 2300  \tValid loss: 0.32235872745513916\n",
      "Step: 2400  \tTraining loss: 0.23255717754364014\n",
      "Step: 2400  \tTraining accuracy: 0.8458987474441528\n",
      "Step: 2400  \tValid loss: 0.32017502188682556\n",
      "Step: 2500  \tTraining loss: 0.22944150865077972\n",
      "Step: 2500  \tTraining accuracy: 0.847178041934967\n",
      "Step: 2500  \tValid loss: 0.3182905316352844\n",
      "Step: 2600  \tTraining loss: 0.22669558227062225\n",
      "Step: 2600  \tTraining accuracy: 0.8483029007911682\n",
      "Step: 2600  \tValid loss: 0.3167721629142761\n",
      "Step: 2700  \tTraining loss: 0.2242586612701416\n",
      "Step: 2700  \tTraining accuracy: 0.8494990468025208\n",
      "Step: 2700  \tValid loss: 0.3157329261302948\n",
      "Step: 2800  \tTraining loss: 0.2220761626958847\n",
      "Step: 2800  \tTraining accuracy: 0.8506833910942078\n",
      "Step: 2800  \tValid loss: 0.31490567326545715\n",
      "Step: 2900  \tTraining loss: 0.2200799137353897\n",
      "Step: 2900  \tTraining accuracy: 0.8517846465110779\n",
      "Step: 2900  \tValid loss: 0.3142803907394409\n",
      "Step: 3000  \tTraining loss: 0.21829622983932495\n",
      "Step: 3000  \tTraining accuracy: 0.8527410626411438\n",
      "Step: 3000  \tValid loss: 0.3139510750770569\n",
      "Step: 3100  \tTraining loss: 0.2166871428489685\n",
      "Step: 3100  \tTraining accuracy: 0.8535895943641663\n",
      "Step: 3100  \tValid loss: 0.31372928619384766\n",
      "Step: 3200  \tTraining loss: 0.2152329683303833\n",
      "Step: 3200  \tTraining accuracy: 0.8544061183929443\n",
      "Step: 3200  \tValid loss: 0.3137182593345642\n",
      "Step: 3300  \tTraining loss: 0.21391934156417847\n",
      "Step: 3300  \tTraining accuracy: 0.8551723957061768\n",
      "Step: 3300  \tValid loss: 0.31371524930000305\n",
      "Step: 3400  \tTraining loss: 0.21273569762706757\n",
      "Step: 3400  \tTraining accuracy: 0.8558105826377869\n",
      "Step: 3400  \tValid loss: 0.3138471245765686\n",
      "Step: 3500  \tTraining loss: 0.21162036061286926\n",
      "Step: 3500  \tTraining accuracy: 0.8565117716789246\n",
      "Step: 3500  \tValid loss: 0.3141023516654968\n",
      "Step: 3600  \tTraining loss: 0.2106097787618637\n",
      "Step: 3600  \tTraining accuracy: 0.8571539521217346\n",
      "Step: 3600  \tValid loss: 0.31439468264579773\n",
      "Step: 3700  \tTraining loss: 0.20968101918697357\n",
      "Step: 3700  \tTraining accuracy: 0.8577987551689148\n",
      "Step: 3700  \tValid loss: 0.31498560309410095\n",
      "Step: 3800  \tTraining loss: 0.20879361033439636\n",
      "Step: 3800  \tTraining accuracy: 0.8584275841712952\n",
      "Step: 3800  \tValid loss: 0.3153589069843292\n",
      "Step: 3900  \tTraining loss: 0.2080327272415161\n",
      "Step: 3900  \tTraining accuracy: 0.8590237498283386\n",
      "Step: 3900  \tValid loss: 0.31561920046806335\n",
      "Step: 4000  \tTraining loss: 0.2073652446269989\n",
      "Step: 4000  \tTraining accuracy: 0.859589695930481\n",
      "Step: 4000  \tValid loss: 0.3158896267414093\n",
      "Step: 4100  \tTraining loss: 0.20677921175956726\n",
      "Step: 4100  \tTraining accuracy: 0.8600766062736511\n",
      "Step: 4100  \tValid loss: 0.31629905104637146\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8605401\n",
      "Precision: 0.8766067\n",
      "Recall: 0.94722223\n",
      "F1 score: 0.89385873\n",
      "AUC: 0.90785766\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0   0.86054   0.876607  0.947222  0.893859  0.907858  0.206523      0.859966   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.313694           0.86   0.312554      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4147.0  \n",
      "5\n",
      "(841, 5)\n",
      "(841, 1)\n",
      "(464, 5)\n",
      "(464, 1)\n",
      "(377, 5)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 200  \tTraining loss: 0.6617884039878845\n",
      "Step: 200  \tTraining accuracy: 0.5953230261802673\n",
      "Step: 200  \tValid loss: 0.6398040652275085\n",
      "Step: 300  \tTraining loss: 0.6459786295890808\n",
      "Step: 300  \tTraining accuracy: 0.6140308976173401\n",
      "Step: 300  \tValid loss: 0.6256847977638245\n",
      "Step: 400  \tTraining loss: 0.6259564757347107\n",
      "Step: 400  \tTraining accuracy: 0.6264650821685791\n",
      "Step: 400  \tValid loss: 0.6109500527381897\n",
      "Step: 500  \tTraining loss: 0.6142792105674744\n",
      "Step: 500  \tTraining accuracy: 0.6349583864212036\n",
      "Step: 500  \tValid loss: 0.6064304113388062\n",
      "Step: 600  \tTraining loss: 0.606848418712616\n",
      "Step: 600  \tTraining accuracy: 0.6412279605865479\n",
      "Step: 600  \tValid loss: 0.6039767265319824\n",
      "Step: 700  \tTraining loss: 0.6016796827316284\n",
      "Step: 700  \tTraining accuracy: 0.6463916301727295\n",
      "Step: 700  \tValid loss: 0.6024447679519653\n",
      "Step: 800  \tTraining loss: 0.5978971719741821\n",
      "Step: 800  \tTraining accuracy: 0.6502576470375061\n",
      "Step: 800  \tValid loss: 0.6014347076416016\n",
      "Step: 900  \tTraining loss: 0.5951219201087952\n",
      "Step: 900  \tTraining accuracy: 0.6533538699150085\n",
      "Step: 900  \tValid loss: 0.6007629632949829\n",
      "Step: 1000  \tTraining loss: 0.5929583311080933\n",
      "Step: 1000  \tTraining accuracy: 0.6564866304397583\n",
      "Step: 1000  \tValid loss: 0.6000898480415344\n",
      "Step: 1100  \tTraining loss: 0.5912889838218689\n",
      "Step: 1100  \tTraining accuracy: 0.659419059753418\n",
      "Step: 1100  \tValid loss: 0.5993360280990601\n",
      "Step: 1200  \tTraining loss: 0.589475154876709\n",
      "Step: 1200  \tTraining accuracy: 0.6618931889533997\n",
      "Step: 1200  \tValid loss: 0.5988039374351501\n",
      "Step: 1300  \tTraining loss: 0.5880571007728577\n",
      "Step: 1300  \tTraining accuracy: 0.6643995046615601\n",
      "Step: 1300  \tValid loss: 0.5973672270774841\n",
      "Step: 1400  \tTraining loss: 0.5867639780044556\n",
      "Step: 1400  \tTraining accuracy: 0.6665785908699036\n",
      "Step: 1400  \tValid loss: 0.5956599712371826\n",
      "Step: 1500  \tTraining loss: 0.5857338309288025\n",
      "Step: 1500  \tTraining accuracy: 0.6681700944900513\n",
      "Step: 1500  \tValid loss: 0.59410560131073\n",
      "Step: 1600  \tTraining loss: 0.584815263748169\n",
      "Step: 1600  \tTraining accuracy: 0.6696712970733643\n",
      "Step: 1600  \tValid loss: 0.5925896763801575\n",
      "Step: 1700  \tTraining loss: 0.5832505822181702\n",
      "Step: 1700  \tTraining accuracy: 0.6712067127227783\n",
      "Step: 1700  \tValid loss: 0.5908910632133484\n",
      "Step: 1800  \tTraining loss: 0.5818068385124207\n",
      "Step: 1800  \tTraining accuracy: 0.6726685762405396\n",
      "Step: 1800  \tValid loss: 0.5898903608322144\n",
      "Step: 1900  \tTraining loss: 0.5807802081108093\n",
      "Step: 1900  \tTraining accuracy: 0.674068808555603\n",
      "Step: 1900  \tValid loss: 0.5880383253097534\n",
      "Step: 2000  \tTraining loss: 0.580134391784668\n",
      "Step: 2000  \tTraining accuracy: 0.675477921962738\n",
      "Step: 2000  \tValid loss: 0.5866895914077759\n",
      "Step: 2100  \tTraining loss: 0.5796268582344055\n",
      "Step: 2100  \tTraining accuracy: 0.6767204999923706\n",
      "Step: 2100  \tValid loss: 0.5859415531158447\n",
      "Step: 2200  \tTraining loss: 0.579264760017395\n",
      "Step: 2200  \tTraining accuracy: 0.677930474281311\n",
      "Step: 2200  \tValid loss: 0.5856630802154541\n",
      "Step: 2300  \tTraining loss: 0.5789412260055542\n",
      "Step: 2300  \tTraining accuracy: 0.6790593266487122\n",
      "Step: 2300  \tValid loss: 0.5853041410446167\n",
      "Step: 2400  \tTraining loss: 0.5786911249160767\n",
      "Step: 2400  \tTraining accuracy: 0.6800667643547058\n",
      "Step: 2400  \tValid loss: 0.5851626992225647\n",
      "Step: 2500  \tTraining loss: 0.5784839987754822\n",
      "Step: 2500  \tTraining accuracy: 0.6810162663459778\n",
      "Step: 2500  \tValid loss: 0.5851855874061584\n",
      "Step: 2600  \tTraining loss: 0.5783050060272217\n",
      "Step: 2600  \tTraining accuracy: 0.6818446516990662\n",
      "Step: 2600  \tValid loss: 0.585257887840271\n",
      "Step: 2700  \tTraining loss: 0.5781456828117371\n",
      "Step: 2700  \tTraining accuracy: 0.6825881004333496\n",
      "Step: 2700  \tValid loss: 0.5854570865631104\n",
      "Step: 2800  \tTraining loss: 0.5779978632926941\n",
      "Step: 2800  \tTraining accuracy: 0.6832126379013062\n",
      "Step: 2800  \tValid loss: 0.5855851173400879\n",
      "Step: 2900  \tTraining loss: 0.5778584480285645\n",
      "Step: 2900  \tTraining accuracy: 0.6838141679763794\n",
      "Step: 2900  \tValid loss: 0.5857551693916321\n",
      "Step: 3000  \tTraining loss: 0.5777289271354675\n",
      "Step: 3000  \tTraining accuracy: 0.6843749284744263\n",
      "Step: 3000  \tValid loss: 0.5860357880592346\n",
      "Step: 3100  \tTraining loss: 0.5776059031486511\n",
      "Step: 3100  \tTraining accuracy: 0.6848989129066467\n",
      "Step: 3100  \tValid loss: 0.586226224899292\n",
      "Step: 3200  \tTraining loss: 0.5774885416030884\n",
      "Step: 3200  \tTraining accuracy: 0.6852952837944031\n",
      "Step: 3200  \tValid loss: 0.5864623785018921\n",
      "Step: 3300  \tTraining loss: 0.5773752331733704\n",
      "Step: 3300  \tTraining accuracy: 0.6856672167778015\n",
      "Step: 3300  \tValid loss: 0.5866724252700806\n",
      "Step: 3400  \tTraining loss: 0.5772660374641418\n",
      "Step: 3400  \tTraining accuracy: 0.6860347390174866\n",
      "Step: 3400  \tValid loss: 0.5868685245513916\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.68643266\n",
      "Precision: 0.70669293\n",
      "Recall: 0.75738394\n",
      "F1 score: 0.7101991\n",
      "AUC: 0.67569476\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.686433   0.706693  0.757384  0.710199  0.675695  0.577226      0.686438   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.585105       0.686165   0.628487      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3437.0  \n",
      "6\n",
      "(1131, 5)\n",
      "(1131, 1)\n",
      "(624, 5)\n",
      "(624, 1)\n",
      "(507, 5)\n",
      "(507, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5665883421897888\n",
      "Step: 100  \tTraining accuracy: 0.8116710782051086\n",
      "Step: 100  \tValid loss: 0.5682497024536133\n",
      "Step: 200  \tTraining loss: 0.44422170519828796\n",
      "Step: 200  \tTraining accuracy: 0.8240495324134827\n",
      "Step: 200  \tValid loss: 0.46036383509635925\n",
      "Step: 300  \tTraining loss: 0.4156931936740875\n",
      "Step: 300  \tTraining accuracy: 0.8304155468940735\n",
      "Step: 300  \tValid loss: 0.44072067737579346\n",
      "Step: 400  \tTraining loss: 0.4056931138038635\n",
      "Step: 400  \tTraining accuracy: 0.8330175280570984\n",
      "Step: 400  \tValid loss: 0.43539848923683167\n",
      "Step: 500  \tTraining loss: 0.3987559378147125\n",
      "Step: 500  \tTraining accuracy: 0.8341683745384216\n",
      "Step: 500  \tValid loss: 0.43179526925086975\n",
      "Step: 600  \tTraining loss: 0.3934141993522644\n",
      "Step: 600  \tTraining accuracy: 0.8353026509284973\n",
      "Step: 600  \tValid loss: 0.42955055832862854\n",
      "Step: 700  \tTraining loss: 0.3892863690853119\n",
      "Step: 700  \tTraining accuracy: 0.8363599181175232\n",
      "Step: 700  \tValid loss: 0.42831793427467346\n",
      "Step: 800  \tTraining loss: 0.3860293924808502\n",
      "Step: 800  \tTraining accuracy: 0.8371352553367615\n",
      "Step: 800  \tValid loss: 0.4275663197040558\n",
      "Step: 900  \tTraining loss: 0.38331571221351624\n",
      "Step: 900  \tTraining accuracy: 0.8379362225532532\n",
      "Step: 900  \tValid loss: 0.4271608889102936\n",
      "Step: 1000  \tTraining loss: 0.38101428747177124\n",
      "Step: 1000  \tTraining accuracy: 0.8385685682296753\n",
      "Step: 1000  \tValid loss: 0.4269634187221527\n",
      "Step: 1100  \tTraining loss: 0.3790213465690613\n",
      "Step: 1100  \tTraining accuracy: 0.8393330574035645\n",
      "Step: 1100  \tValid loss: 0.4268525540828705\n",
      "Step: 1200  \tTraining loss: 0.37726885080337524\n",
      "Step: 1200  \tTraining accuracy: 0.8400030732154846\n",
      "Step: 1200  \tValid loss: 0.42677628993988037\n",
      "Step: 1300  \tTraining loss: 0.37570518255233765\n",
      "Step: 1300  \tTraining accuracy: 0.8407427072525024\n",
      "Step: 1300  \tValid loss: 0.42672157287597656\n",
      "Step: 1400  \tTraining loss: 0.37429699301719666\n",
      "Step: 1400  \tTraining accuracy: 0.8413072824478149\n",
      "Step: 1400  \tValid loss: 0.42673951387405396\n",
      "Step: 1500  \tTraining loss: 0.373016893863678\n",
      "Step: 1500  \tTraining accuracy: 0.8418854475021362\n",
      "Step: 1500  \tValid loss: 0.42680397629737854\n",
      "Step: 1600  \tTraining loss: 0.37184908986091614\n",
      "Step: 1600  \tTraining accuracy: 0.8425030708312988\n",
      "Step: 1600  \tValid loss: 0.42690160870552063\n",
      "Step: 1700  \tTraining loss: 0.3707771599292755\n",
      "Step: 1700  \tTraining accuracy: 0.8430994153022766\n",
      "Step: 1700  \tValid loss: 0.4270423352718353\n",
      "Step: 1800  \tTraining loss: 0.3697887063026428\n",
      "Step: 1800  \tTraining accuracy: 0.8436529040336609\n",
      "Step: 1800  \tValid loss: 0.42724815011024475\n",
      "Step: 1900  \tTraining loss: 0.36887046694755554\n",
      "Step: 1900  \tTraining accuracy: 0.8441704511642456\n",
      "Step: 1900  \tValid loss: 0.4275358021259308\n",
      "Step: 2000  \tTraining loss: 0.3680065870285034\n",
      "Step: 2000  \tTraining accuracy: 0.8446802496910095\n",
      "Step: 2000  \tValid loss: 0.42790427803993225\n",
      "Step: 2100  \tTraining loss: 0.36719274520874023\n",
      "Step: 2100  \tTraining accuracy: 0.845140278339386\n",
      "Step: 2100  \tValid loss: 0.4282853901386261\n",
      "Step: 2200  \tTraining loss: 0.3664243817329407\n",
      "Step: 2200  \tTraining accuracy: 0.845537006855011\n",
      "Step: 2200  \tValid loss: 0.428730309009552\n",
      "Step: 2300  \tTraining loss: 0.365665465593338\n",
      "Step: 2300  \tTraining accuracy: 0.8459180593490601\n",
      "Step: 2300  \tValid loss: 0.42921584844589233\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8462479\n",
      "Precision: 0.8054968\n",
      "Recall: 0.83006537\n",
      "F1 score: 0.8589598\n",
      "AUC: 0.8465803\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.846248   0.805497  0.830065   0.85896  0.84658  0.365658      0.846173   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.426722       0.846212   0.364448      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2300.0  \n",
      "7\n",
      "(986, 5)\n",
      "(986, 1)\n",
      "(544, 5)\n",
      "(544, 1)\n",
      "(442, 5)\n",
      "(442, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6629462838172913\n",
      "Step: 100  \tTraining accuracy: 0.6227180361747742\n",
      "Step: 100  \tValid loss: 0.6571734547615051\n",
      "Step: 200  \tTraining loss: 0.6458719372749329\n",
      "Step: 200  \tTraining accuracy: 0.6260986924171448\n",
      "Step: 200  \tValid loss: 0.6346043348312378\n",
      "Step: 300  \tTraining loss: 0.6226199269294739\n",
      "Step: 300  \tTraining accuracy: 0.6348884105682373\n",
      "Step: 300  \tValid loss: 0.6057413816452026\n",
      "Step: 400  \tTraining loss: 0.5953784584999084\n",
      "Step: 400  \tTraining accuracy: 0.6466241478919983\n",
      "Step: 400  \tValid loss: 0.5718510150909424\n",
      "Step: 500  \tTraining loss: 0.5739323496818542\n",
      "Step: 500  \tTraining accuracy: 0.6591165065765381\n",
      "Step: 500  \tValid loss: 0.5430329442024231\n",
      "Step: 600  \tTraining loss: 0.5616341233253479\n",
      "Step: 600  \tTraining accuracy: 0.6699243783950806\n",
      "Step: 600  \tValid loss: 0.524419367313385\n",
      "Step: 700  \tTraining loss: 0.5557051301002502\n",
      "Step: 700  \tTraining accuracy: 0.6789670586585999\n",
      "Step: 700  \tValid loss: 0.5137228965759277\n",
      "Step: 800  \tTraining loss: 0.5529306530952454\n",
      "Step: 800  \tTraining accuracy: 0.6864097118377686\n",
      "Step: 800  \tValid loss: 0.5078152418136597\n",
      "Step: 900  \tTraining loss: 0.5515701770782471\n",
      "Step: 900  \tTraining accuracy: 0.6923398375511169\n",
      "Step: 900  \tValid loss: 0.504439651966095\n",
      "Step: 1000  \tTraining loss: 0.5508256554603577\n",
      "Step: 1000  \tTraining accuracy: 0.6973417401313782\n",
      "Step: 1000  \tValid loss: 0.5025184750556946\n",
      "Step: 1100  \tTraining loss: 0.550367534160614\n",
      "Step: 1100  \tTraining accuracy: 0.7014392018318176\n",
      "Step: 1100  \tValid loss: 0.5013295412063599\n",
      "Step: 1200  \tTraining loss: 0.5500413775444031\n",
      "Step: 1200  \tTraining accuracy: 0.7048681378364563\n",
      "Step: 1200  \tValid loss: 0.5005851984024048\n",
      "Step: 1300  \tTraining loss: 0.5497754812240601\n",
      "Step: 1300  \tTraining accuracy: 0.7078295946121216\n",
      "Step: 1300  \tValid loss: 0.5001052021980286\n",
      "Step: 1400  \tTraining loss: 0.5495363473892212\n",
      "Step: 1400  \tTraining accuracy: 0.71035236120224\n",
      "Step: 1400  \tValid loss: 0.499783456325531\n",
      "Step: 1500  \tTraining loss: 0.5493047833442688\n",
      "Step: 1500  \tTraining accuracy: 0.712562084197998\n",
      "Step: 1500  \tValid loss: 0.49957796931266785\n",
      "Step: 1600  \tTraining loss: 0.5490694642066956\n",
      "Step: 1600  \tTraining accuracy: 0.714552104473114\n",
      "Step: 1600  \tValid loss: 0.49945545196533203\n",
      "Step: 1700  \tTraining loss: 0.5488097071647644\n",
      "Step: 1700  \tTraining accuracy: 0.7162702083587646\n",
      "Step: 1700  \tValid loss: 0.499331533908844\n",
      "Step: 1800  \tTraining loss: 0.5485118627548218\n",
      "Step: 1800  \tTraining accuracy: 0.7177629470825195\n",
      "Step: 1800  \tValid loss: 0.499252587556839\n",
      "Step: 1900  \tTraining loss: 0.5481875538825989\n",
      "Step: 1900  \tTraining accuracy: 0.7191491723060608\n",
      "Step: 1900  \tValid loss: 0.49921339750289917\n",
      "Step: 2000  \tTraining loss: 0.5478535294532776\n",
      "Step: 2000  \tTraining accuracy: 0.720393180847168\n",
      "Step: 2000  \tValid loss: 0.49921590089797974\n",
      "Step: 2100  \tTraining loss: 0.5475513339042664\n",
      "Step: 2100  \tTraining accuracy: 0.7215158343315125\n",
      "Step: 2100  \tValid loss: 0.49932849407196045\n",
      "Step: 2200  \tTraining loss: 0.5472614765167236\n",
      "Step: 2200  \tTraining accuracy: 0.7225340604782104\n",
      "Step: 2200  \tValid loss: 0.4993908703327179\n",
      "Step: 2300  \tTraining loss: 0.5469797849655151\n",
      "Step: 2300  \tTraining accuracy: 0.7234167456626892\n",
      "Step: 2300  \tValid loss: 0.499482661485672\n",
      "Step: 2400  \tTraining loss: 0.5467221736907959\n",
      "Step: 2400  \tTraining accuracy: 0.7242458462715149\n",
      "Step: 2400  \tValid loss: 0.4994731843471527\n",
      "Step: 2500  \tTraining loss: 0.5464799404144287\n",
      "Step: 2500  \tTraining accuracy: 0.7250072360038757\n",
      "Step: 2500  \tValid loss: 0.4994621276855469\n",
      "Step: 2600  \tTraining loss: 0.5462530255317688\n",
      "Step: 2600  \tTraining accuracy: 0.7257686257362366\n",
      "Step: 2600  \tValid loss: 0.49939677119255066\n",
      "Step: 2700  \tTraining loss: 0.5460351705551147\n",
      "Step: 2700  \tTraining accuracy: 0.7264916300773621\n",
      "Step: 2700  \tValid loss: 0.49938392639160156\n",
      "Step: 2800  \tTraining loss: 0.5458247661590576\n",
      "Step: 2800  \tTraining accuracy: 0.7271989583969116\n",
      "Step: 2800  \tValid loss: 0.4993806779384613\n",
      "Step: 2900  \tTraining loss: 0.5456215739250183\n",
      "Step: 2900  \tTraining accuracy: 0.7278566360473633\n",
      "Step: 2900  \tValid loss: 0.49933159351348877\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7284698\n",
      "Precision: 0.6993007\n",
      "Recall: 0.53763443\n",
      "F1 score: 0.6332595\n",
      "AUC: 0.6987846\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0   0.72847   0.699301  0.537634  0.633259  0.698785  0.545552        0.7283   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.499118       0.727897   0.539685      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2934.0  \n",
      "8\n",
      "(2668, 5)\n",
      "(2668, 1)\n",
      "(1472, 5)\n",
      "(1472, 1)\n",
      "(1196, 5)\n",
      "(1196, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6479490995407104\n",
      "Step: 100  \tTraining accuracy: 0.633058488368988\n",
      "Step: 100  \tValid loss: 0.6607733964920044\n",
      "Step: 200  \tTraining loss: 0.5030567646026611\n",
      "Step: 200  \tTraining accuracy: 0.6826586723327637\n",
      "Step: 200  \tValid loss: 0.5084670186042786\n",
      "Step: 300  \tTraining loss: 0.38220471143722534\n",
      "Step: 300  \tTraining accuracy: 0.7411544322967529\n",
      "Step: 300  \tValid loss: 0.37239426374435425\n",
      "Step: 400  \tTraining loss: 0.3337234556674957\n",
      "Step: 400  \tTraining accuracy: 0.7754337191581726\n",
      "Step: 400  \tValid loss: 0.3191215991973877\n",
      "Step: 500  \tTraining loss: 0.32252389192581177\n",
      "Step: 500  \tTraining accuracy: 0.7944777607917786\n",
      "Step: 500  \tValid loss: 0.3053319454193115\n",
      "Step: 600  \tTraining loss: 0.31907665729522705\n",
      "Step: 600  \tTraining accuracy: 0.8071078062057495\n",
      "Step: 600  \tValid loss: 0.3017297089099884\n",
      "Step: 700  \tTraining loss: 0.31749215722084045\n",
      "Step: 700  \tTraining accuracy: 0.8159670233726501\n",
      "Step: 700  \tValid loss: 0.29970094561576843\n",
      "Step: 800  \tTraining loss: 0.3164588212966919\n",
      "Step: 800  \tTraining accuracy: 0.8224637508392334\n",
      "Step: 800  \tValid loss: 0.29831382632255554\n",
      "Step: 900  \tTraining loss: 0.3156377077102661\n",
      "Step: 900  \tTraining accuracy: 0.8276082277297974\n",
      "Step: 900  \tValid loss: 0.2973824739456177\n",
      "Step: 1000  \tTraining loss: 0.31494972109794617\n",
      "Step: 1000  \tTraining accuracy: 0.8317880630493164\n",
      "Step: 1000  \tValid loss: 0.29646626114845276\n",
      "Step: 1100  \tTraining loss: 0.31434565782546997\n",
      "Step: 1100  \tTraining accuracy: 0.8351716995239258\n",
      "Step: 1100  \tValid loss: 0.2957216203212738\n",
      "Step: 1200  \tTraining loss: 0.3137957751750946\n",
      "Step: 1200  \tTraining accuracy: 0.8378528356552124\n",
      "Step: 1200  \tValid loss: 0.2949715554714203\n",
      "Step: 1300  \tTraining loss: 0.31328046321868896\n",
      "Step: 1300  \tTraining accuracy: 0.8400899767875671\n",
      "Step: 1300  \tValid loss: 0.2942003607749939\n",
      "Step: 1400  \tTraining loss: 0.31278860569000244\n",
      "Step: 1400  \tTraining accuracy: 0.8419817686080933\n",
      "Step: 1400  \tValid loss: 0.29350823163986206\n",
      "Step: 1500  \tTraining loss: 0.3122981786727905\n",
      "Step: 1500  \tTraining accuracy: 0.8435609936714172\n",
      "Step: 1500  \tValid loss: 0.29280605912208557\n",
      "Step: 1600  \tTraining loss: 0.31181517243385315\n",
      "Step: 1600  \tTraining accuracy: 0.8449243307113647\n",
      "Step: 1600  \tValid loss: 0.2921757996082306\n",
      "Step: 1700  \tTraining loss: 0.3113775849342346\n",
      "Step: 1700  \tTraining accuracy: 0.8461110591888428\n",
      "Step: 1700  \tValid loss: 0.2915450930595398\n",
      "Step: 1800  \tTraining loss: 0.3109566569328308\n",
      "Step: 1800  \tTraining accuracy: 0.8471086025238037\n",
      "Step: 1800  \tValid loss: 0.29089170694351196\n",
      "Step: 1900  \tTraining loss: 0.31057026982307434\n",
      "Step: 1900  \tTraining accuracy: 0.8480185866355896\n",
      "Step: 1900  \tValid loss: 0.290291965007782\n",
      "Step: 2000  \tTraining loss: 0.3102024495601654\n",
      "Step: 2000  \tTraining accuracy: 0.8488544225692749\n",
      "Step: 2000  \tValid loss: 0.28977879881858826\n",
      "Step: 2100  \tTraining loss: 0.30985912680625916\n",
      "Step: 2100  \tTraining accuracy: 0.8495904207229614\n",
      "Step: 2100  \tValid loss: 0.28919240832328796\n",
      "Step: 2200  \tTraining loss: 0.30951085686683655\n",
      "Step: 2200  \tTraining accuracy: 0.8502667546272278\n",
      "Step: 2200  \tValid loss: 0.2886780798435211\n",
      "Step: 2300  \tTraining loss: 0.3091876208782196\n",
      "Step: 2300  \tTraining accuracy: 0.8508912324905396\n",
      "Step: 2300  \tValid loss: 0.2882733643054962\n",
      "Step: 2400  \tTraining loss: 0.308851420879364\n",
      "Step: 2400  \tTraining accuracy: 0.8514546155929565\n",
      "Step: 2400  \tValid loss: 0.2879365384578705\n",
      "Step: 2500  \tTraining loss: 0.30850106477737427\n",
      "Step: 2500  \tTraining accuracy: 0.852010190486908\n",
      "Step: 2500  \tValid loss: 0.28766071796417236\n",
      "Step: 2600  \tTraining loss: 0.30814167857170105\n",
      "Step: 2600  \tTraining accuracy: 0.8525516390800476\n",
      "Step: 2600  \tValid loss: 0.2873499095439911\n",
      "Step: 2700  \tTraining loss: 0.3073898255825043\n",
      "Step: 2700  \tTraining accuracy: 0.8530239462852478\n",
      "Step: 2700  \tValid loss: 0.28700610995292664\n",
      "Step: 2800  \tTraining loss: 0.30683186650276184\n",
      "Step: 2800  \tTraining accuracy: 0.8534550666809082\n",
      "Step: 2800  \tValid loss: 0.2866714894771576\n",
      "Step: 2900  \tTraining loss: 0.3063898980617523\n",
      "Step: 2900  \tTraining accuracy: 0.8538494110107422\n",
      "Step: 2900  \tValid loss: 0.28639328479766846\n",
      "Step: 3000  \tTraining loss: 0.3059754967689514\n",
      "Step: 3000  \tTraining accuracy: 0.8542296886444092\n",
      "Step: 3000  \tValid loss: 0.2861013114452362\n",
      "Step: 3100  \tTraining loss: 0.3053528964519501\n",
      "Step: 3100  \tTraining accuracy: 0.8545849919319153\n",
      "Step: 3100  \tValid loss: 0.28534621000289917\n",
      "Step: 3200  \tTraining loss: 0.30416297912597656\n",
      "Step: 3200  \tTraining accuracy: 0.8549118041992188\n",
      "Step: 3200  \tValid loss: 0.285883367061615\n",
      "Step: 3300  \tTraining loss: 0.30364349484443665\n",
      "Step: 3300  \tTraining accuracy: 0.8552243113517761\n",
      "Step: 3300  \tValid loss: 0.2858163118362427\n",
      "Step: 3400  \tTraining loss: 0.30321481823921204\n",
      "Step: 3400  \tTraining accuracy: 0.8555293083190918\n",
      "Step: 3400  \tValid loss: 0.2856767177581787\n",
      "Step: 3500  \tTraining loss: 0.302824467420578\n",
      "Step: 3500  \tTraining accuracy: 0.8558058142662048\n",
      "Step: 3500  \tValid loss: 0.28559717535972595\n",
      "Step: 3600  \tTraining loss: 0.3024384081363678\n",
      "Step: 3600  \tTraining accuracy: 0.8560613989830017\n",
      "Step: 3600  \tValid loss: 0.2857365310192108\n",
      "Step: 3700  \tTraining loss: 0.3021095097064972\n",
      "Step: 3700  \tTraining accuracy: 0.8563286662101746\n",
      "Step: 3700  \tValid loss: 0.2858617603778839\n",
      "Step: 3800  \tTraining loss: 0.30182331800460815\n",
      "Step: 3800  \tTraining accuracy: 0.8565617203712463\n",
      "Step: 3800  \tValid loss: 0.28576868772506714\n",
      "Step: 3900  \tTraining loss: 0.30157169699668884\n",
      "Step: 3900  \tTraining accuracy: 0.8567777872085571\n",
      "Step: 3900  \tValid loss: 0.2857203483581543\n",
      "Step: 4000  \tTraining loss: 0.3013452887535095\n",
      "Step: 4000  \tTraining accuracy: 0.856978178024292\n",
      "Step: 4000  \tValid loss: 0.2856159508228302\n",
      "Step: 4100  \tTraining loss: 0.30113816261291504\n",
      "Step: 4100  \tTraining accuracy: 0.8571686148643494\n",
      "Step: 4100  \tValid loss: 0.2855628728866577\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.857359\n",
      "Precision: 0.89114267\n",
      "Recall: 0.8693931\n",
      "F1 score: 0.84676725\n",
      "AUC: 0.8648181\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.857359   0.891143  0.869393  0.846767  0.864818  0.301136       0.85726   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.285346       0.857126   0.332786      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4100.0  \n",
      "9\n",
      "(754, 5)\n",
      "(754, 1)\n",
      "(400, 5)\n",
      "(400, 1)\n",
      "(325, 5)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6004961729049683\n",
      "Step: 100  \tTraining accuracy: 0.6366047859191895\n",
      "Step: 100  \tValid loss: 0.6967414617538452\n",
      "Step: 200  \tTraining loss: 0.5350450873374939\n",
      "Step: 200  \tTraining accuracy: 0.6681594252586365\n",
      "Step: 200  \tValid loss: 0.7026770114898682\n",
      "Step: 300  \tTraining loss: 0.514971137046814\n",
      "Step: 300  \tTraining accuracy: 0.7130926847457886\n",
      "Step: 300  \tValid loss: 0.6914703249931335\n",
      "Step: 400  \tTraining loss: 0.502849280834198\n",
      "Step: 400  \tTraining accuracy: 0.7324215173721313\n",
      "Step: 400  \tValid loss: 0.6823550462722778\n",
      "Step: 500  \tTraining loss: 0.49337589740753174\n",
      "Step: 500  \tTraining accuracy: 0.7431784272193909\n",
      "Step: 500  \tValid loss: 0.671190619468689\n",
      "Step: 600  \tTraining loss: 0.48531147837638855\n",
      "Step: 600  \tTraining accuracy: 0.7500306963920593\n",
      "Step: 600  \tValid loss: 0.6598750352859497\n",
      "Step: 700  \tTraining loss: 0.4782990515232086\n",
      "Step: 700  \tTraining accuracy: 0.754777729511261\n",
      "Step: 700  \tValid loss: 0.6493911743164062\n",
      "Step: 800  \tTraining loss: 0.47208142280578613\n",
      "Step: 800  \tTraining accuracy: 0.7582605481147766\n",
      "Step: 800  \tValid loss: 0.6391124129295349\n",
      "Step: 900  \tTraining loss: 0.46674951910972595\n",
      "Step: 900  \tTraining accuracy: 0.7609248161315918\n",
      "Step: 900  \tValid loss: 0.6302046179771423\n",
      "Step: 1000  \tTraining loss: 0.46216094493865967\n",
      "Step: 1000  \tTraining accuracy: 0.7630288004875183\n",
      "Step: 1000  \tValid loss: 0.6215541362762451\n",
      "Step: 1100  \tTraining loss: 0.45828545093536377\n",
      "Step: 1100  \tTraining accuracy: 0.7647323608398438\n",
      "Step: 1100  \tValid loss: 0.6142772436141968\n",
      "Step: 1200  \tTraining loss: 0.4549664258956909\n",
      "Step: 1200  \tTraining accuracy: 0.7661399245262146\n",
      "Step: 1200  \tValid loss: 0.6076486706733704\n",
      "Step: 1300  \tTraining loss: 0.4520803987979889\n",
      "Step: 1300  \tTraining accuracy: 0.7673224806785583\n",
      "Step: 1300  \tValid loss: 0.6017887592315674\n",
      "Step: 1400  \tTraining loss: 0.4493965804576874\n",
      "Step: 1400  \tTraining accuracy: 0.768329918384552\n",
      "Step: 1400  \tValid loss: 0.5962161421775818\n",
      "Step: 1500  \tTraining loss: 0.4452247619628906\n",
      "Step: 1500  \tTraining accuracy: 0.7691985368728638\n",
      "Step: 1500  \tValid loss: 0.5874318480491638\n",
      "Step: 1600  \tTraining loss: 0.44124752283096313\n",
      "Step: 1600  \tTraining accuracy: 0.7699550986289978\n",
      "Step: 1600  \tValid loss: 0.5783941149711609\n",
      "Step: 1700  \tTraining loss: 0.4383814334869385\n",
      "Step: 1700  \tTraining accuracy: 0.7706200480461121\n",
      "Step: 1700  \tValid loss: 0.5713544487953186\n",
      "Step: 1800  \tTraining loss: 0.436212420463562\n",
      "Step: 1800  \tTraining accuracy: 0.7712090015411377\n",
      "Step: 1800  \tValid loss: 0.5654619932174683\n",
      "Step: 1900  \tTraining loss: 0.43451398611068726\n",
      "Step: 1900  \tTraining accuracy: 0.771734356880188\n",
      "Step: 1900  \tValid loss: 0.5607861876487732\n",
      "Step: 2000  \tTraining loss: 0.4331514537334442\n",
      "Step: 2000  \tTraining accuracy: 0.7722058296203613\n",
      "Step: 2000  \tValid loss: 0.5567446351051331\n",
      "Step: 2100  \tTraining loss: 0.43204987049102783\n",
      "Step: 2100  \tTraining accuracy: 0.7726643085479736\n",
      "Step: 2100  \tValid loss: 0.55339115858078\n",
      "Step: 2200  \tTraining loss: 0.4311245083808899\n",
      "Step: 2200  \tTraining accuracy: 0.7730801701545715\n",
      "Step: 2200  \tValid loss: 0.5506507754325867\n",
      "Step: 2300  \tTraining loss: 0.4303624927997589\n",
      "Step: 2300  \tTraining accuracy: 0.7734891176223755\n",
      "Step: 2300  \tValid loss: 0.5481210947036743\n",
      "Step: 2400  \tTraining loss: 0.4297560155391693\n",
      "Step: 2400  \tTraining accuracy: 0.7739495635032654\n",
      "Step: 2400  \tValid loss: 0.5458926558494568\n",
      "Step: 2600  \tTraining loss: 0.4288084805011749\n",
      "Step: 2600  \tTraining accuracy: 0.7748681306838989\n",
      "Step: 2600  \tValid loss: 0.5426955819129944\n",
      "Step: 2700  \tTraining loss: 0.4284733831882477\n",
      "Step: 2700  \tTraining accuracy: 0.7754029631614685\n",
      "Step: 2700  \tValid loss: 0.5415651798248291\n",
      "Step: 2800  \tTraining loss: 0.4282139539718628\n",
      "Step: 2800  \tTraining accuracy: 0.7758743762969971\n",
      "Step: 2800  \tValid loss: 0.540626049041748\n",
      "Step: 2900  \tTraining loss: 0.4280100166797638\n",
      "Step: 2900  \tTraining accuracy: 0.7763363718986511\n",
      "Step: 2900  \tValid loss: 0.5399887561798096\n",
      "Step: 3000  \tTraining loss: 0.4278346598148346\n",
      "Step: 3000  \tTraining accuracy: 0.7767670750617981\n",
      "Step: 3000  \tValid loss: 0.5393633246421814\n",
      "Step: 3100  \tTraining loss: 0.42767298221588135\n",
      "Step: 3100  \tTraining accuracy: 0.7771917581558228\n",
      "Step: 3100  \tValid loss: 0.5388996005058289\n",
      "Step: 3200  \tTraining loss: 0.4275219142436981\n",
      "Step: 3200  \tTraining accuracy: 0.7776323556900024\n",
      "Step: 3200  \tValid loss: 0.53849858045578\n",
      "Step: 3300  \tTraining loss: 0.42737525701522827\n",
      "Step: 3300  \tTraining accuracy: 0.7780666351318359\n",
      "Step: 3300  \tValid loss: 0.5381673574447632\n",
      "Step: 3400  \tTraining loss: 0.42722392082214355\n",
      "Step: 3400  \tTraining accuracy: 0.7784548401832581\n",
      "Step: 3400  \tValid loss: 0.5379149913787842\n",
      "Step: 3500  \tTraining loss: 0.42705342173576355\n",
      "Step: 3500  \tTraining accuracy: 0.7788401246070862\n",
      "Step: 3500  \tValid loss: 0.5378480553627014\n",
      "Step: 3600  \tTraining loss: 0.4268619418144226\n",
      "Step: 3600  \tTraining accuracy: 0.7791846990585327\n",
      "Step: 3600  \tValid loss: 0.5379482507705688\n",
      "Step: 3700  \tTraining loss: 0.42666590213775635\n",
      "Step: 3700  \tTraining accuracy: 0.7795103788375854\n",
      "Step: 3700  \tValid loss: 0.5379770994186401\n",
      "Step: 3800  \tTraining loss: 0.4264652132987976\n",
      "Step: 3800  \tTraining accuracy: 0.7798186540603638\n",
      "Step: 3800  \tValid loss: 0.5380100011825562\n",
      "Step: 3900  \tTraining loss: 0.4262619614601135\n",
      "Step: 3900  \tTraining accuracy: 0.7800758481025696\n",
      "Step: 3900  \tValid loss: 0.5379891991615295\n",
      "Step: 4000  \tTraining loss: 0.4260583221912384\n",
      "Step: 4000  \tTraining accuracy: 0.780302882194519\n",
      "Step: 4000  \tValid loss: 0.537879467010498\n",
      "Step: 4100  \tTraining loss: 0.4258510172367096\n",
      "Step: 4100  \tTraining accuracy: 0.7805020809173584\n",
      "Step: 4100  \tValid loss: 0.5377681851387024\n",
      "Step: 4200  \tTraining loss: 0.4256399869918823\n",
      "Step: 4200  \tTraining accuracy: 0.7807078957557678\n",
      "Step: 4200  \tValid loss: 0.5376869440078735\n",
      "Step: 4300  \tTraining loss: 0.42542383074760437\n",
      "Step: 4300  \tTraining accuracy: 0.7809040546417236\n",
      "Step: 4300  \tValid loss: 0.5375939607620239\n",
      "Step: 4400  \tTraining loss: 0.42519983649253845\n",
      "Step: 4400  \tTraining accuracy: 0.7811067700386047\n",
      "Step: 4400  \tValid loss: 0.5375246405601501\n",
      "Step: 4500  \tTraining loss: 0.42496439814567566\n",
      "Step: 4500  \tTraining accuracy: 0.7813003063201904\n",
      "Step: 4500  \tValid loss: 0.537394106388092\n",
      "Step: 4600  \tTraining loss: 0.424710750579834\n",
      "Step: 4600  \tTraining accuracy: 0.7815002202987671\n",
      "Step: 4600  \tValid loss: 0.5372309684753418\n",
      "Step: 4700  \tTraining loss: 0.4244386851787567\n",
      "Step: 4700  \tTraining accuracy: 0.7817060947418213\n",
      "Step: 4700  \tValid loss: 0.5370074510574341\n",
      "Step: 4800  \tTraining loss: 0.42414456605911255\n",
      "Step: 4800  \tTraining accuracy: 0.7819033265113831\n",
      "Step: 4800  \tValid loss: 0.5367258787155151\n",
      "Step: 4900  \tTraining loss: 0.4238356947898865\n",
      "Step: 4900  \tTraining accuracy: 0.782106339931488\n",
      "Step: 4900  \tValid loss: 0.5365148782730103\n",
      "Step: 5000  \tTraining loss: 0.4235278367996216\n",
      "Step: 5000  \tTraining accuracy: 0.782301127910614\n",
      "Step: 5000  \tValid loss: 0.5359052419662476\n",
      "Step: 5100  \tTraining loss: 0.42322295904159546\n",
      "Step: 5100  \tTraining accuracy: 0.782488226890564\n",
      "Step: 5100  \tValid loss: 0.5354849100112915\n",
      "Step: 5200  \tTraining loss: 0.42292433977127075\n",
      "Step: 5200  \tTraining accuracy: 0.7826680541038513\n",
      "Step: 5200  \tValid loss: 0.535109281539917\n",
      "Step: 5300  \tTraining loss: 0.42263224720954895\n",
      "Step: 5300  \tTraining accuracy: 0.7828410267829895\n",
      "Step: 5300  \tValid loss: 0.5348169803619385\n",
      "Step: 5400  \tTraining loss: 0.4223465919494629\n",
      "Step: 5400  \tTraining accuracy: 0.7830201983451843\n",
      "Step: 5400  \tValid loss: 0.5346050262451172\n",
      "Step: 5500  \tTraining loss: 0.42206600308418274\n",
      "Step: 5500  \tTraining accuracy: 0.7831927537918091\n",
      "Step: 5500  \tValid loss: 0.5342612266540527\n",
      "Step: 5600  \tTraining loss: 0.4217895269393921\n",
      "Step: 5600  \tTraining accuracy: 0.7833591103553772\n",
      "Step: 5600  \tValid loss: 0.5340012907981873\n",
      "Step: 5700  \tTraining loss: 0.4215165972709656\n",
      "Step: 5700  \tTraining accuracy: 0.7835435271263123\n",
      "Step: 5700  \tValid loss: 0.5338153839111328\n",
      "Step: 5800  \tTraining loss: 0.4212520122528076\n",
      "Step: 5800  \tTraining accuracy: 0.7837332487106323\n",
      "Step: 5800  \tValid loss: 0.5336011648178101\n",
      "Step: 5900  \tTraining loss: 0.4209901988506317\n",
      "Step: 5900  \tTraining accuracy: 0.7839165329933167\n",
      "Step: 5900  \tValid loss: 0.5334161520004272\n",
      "Step: 6000  \tTraining loss: 0.4207315742969513\n",
      "Step: 6000  \tTraining accuracy: 0.7840822339057922\n",
      "Step: 6000  \tValid loss: 0.5332844853401184\n",
      "Step: 6100  \tTraining loss: 0.42047616839408875\n",
      "Step: 6100  \tTraining accuracy: 0.784253716468811\n",
      "Step: 6100  \tValid loss: 0.533156156539917\n",
      "Step: 6200  \tTraining loss: 0.42022523283958435\n",
      "Step: 6200  \tTraining accuracy: 0.7844195365905762\n",
      "Step: 6200  \tValid loss: 0.5329739451408386\n",
      "Step: 6300  \tTraining loss: 0.419976145029068\n",
      "Step: 6300  \tTraining accuracy: 0.7845801115036011\n",
      "Step: 6300  \tValid loss: 0.5328983068466187\n",
      "Step: 6400  \tTraining loss: 0.4197334349155426\n",
      "Step: 6400  \tTraining accuracy: 0.7847462296485901\n",
      "Step: 6400  \tValid loss: 0.5325940847396851\n",
      "Step: 6500  \tTraining loss: 0.4194914698600769\n",
      "Step: 6500  \tTraining accuracy: 0.7849282026290894\n",
      "Step: 6500  \tValid loss: 0.532491147518158\n",
      "Step: 6600  \tTraining loss: 0.41925355792045593\n",
      "Step: 6600  \tTraining accuracy: 0.7851046323776245\n",
      "Step: 6600  \tValid loss: 0.5323891639709473\n",
      "Step: 6700  \tTraining loss: 0.41902145743370056\n",
      "Step: 6700  \tTraining accuracy: 0.7852756977081299\n",
      "Step: 6700  \tValid loss: 0.5322254300117493\n",
      "Step: 6800  \tTraining loss: 0.4187915623188019\n",
      "Step: 6800  \tTraining accuracy: 0.7854517698287964\n",
      "Step: 6800  \tValid loss: 0.5321542620658875\n",
      "Step: 6900  \tTraining loss: 0.4185680150985718\n",
      "Step: 6900  \tTraining accuracy: 0.7856226563453674\n",
      "Step: 6900  \tValid loss: 0.5319144129753113\n",
      "Step: 7000  \tTraining loss: 0.4183458983898163\n",
      "Step: 7000  \tTraining accuracy: 0.7857983708381653\n",
      "Step: 7000  \tValid loss: 0.5319092273712158\n",
      "Step: 7100  \tTraining loss: 0.4181306064128876\n",
      "Step: 7100  \tTraining accuracy: 0.7859594821929932\n",
      "Step: 7100  \tValid loss: 0.5317233800888062\n",
      "Step: 7200  \tTraining loss: 0.4179195463657379\n",
      "Step: 7200  \tTraining accuracy: 0.7861161231994629\n",
      "Step: 7200  \tValid loss: 0.5316263437271118\n",
      "Step: 7300  \tTraining loss: 0.4177146852016449\n",
      "Step: 7300  \tTraining accuracy: 0.786268413066864\n",
      "Step: 7300  \tValid loss: 0.5313568711280823\n",
      "Step: 7400  \tTraining loss: 0.41751542687416077\n",
      "Step: 7400  \tTraining accuracy: 0.7864258289337158\n",
      "Step: 7400  \tValid loss: 0.5311674475669861\n",
      "Step: 7500  \tTraining loss: 0.4173160493373871\n",
      "Step: 7500  \tTraining accuracy: 0.7865789532661438\n",
      "Step: 7500  \tValid loss: 0.5313093662261963\n",
      "Step: 7600  \tTraining loss: 0.4171239733695984\n",
      "Step: 7600  \tTraining accuracy: 0.7867459654808044\n",
      "Step: 7600  \tValid loss: 0.5310554504394531\n",
      "Step: 7700  \tTraining loss: 0.4169330894947052\n",
      "Step: 7700  \tTraining accuracy: 0.7869173884391785\n",
      "Step: 7700  \tValid loss: 0.5310290455818176\n",
      "Step: 7800  \tTraining loss: 0.4167478084564209\n",
      "Step: 7800  \tTraining accuracy: 0.7870844602584839\n",
      "Step: 7800  \tValid loss: 0.530862033367157\n",
      "Step: 7900  \tTraining loss: 0.41656550765037537\n",
      "Step: 7900  \tTraining accuracy: 0.7872472405433655\n",
      "Step: 7900  \tValid loss: 0.5309258103370667\n",
      "Step: 8000  \tTraining loss: 0.4163881540298462\n",
      "Step: 8000  \tTraining accuracy: 0.7874059081077576\n",
      "Step: 8000  \tValid loss: 0.5306464433670044\n",
      "Step: 8100  \tTraining loss: 0.4162130057811737\n",
      "Step: 8100  \tTraining accuracy: 0.7875607013702393\n",
      "Step: 8100  \tValid loss: 0.5306203365325928\n",
      "Step: 8200  \tTraining loss: 0.4160412549972534\n",
      "Step: 8200  \tTraining accuracy: 0.7877116203308105\n",
      "Step: 8200  \tValid loss: 0.530246376991272\n",
      "Step: 8300  \tTraining loss: 0.41587018966674805\n",
      "Step: 8300  \tTraining accuracy: 0.7878589034080505\n",
      "Step: 8300  \tValid loss: 0.5298037528991699\n",
      "Step: 8400  \tTraining loss: 0.415698379278183\n",
      "Step: 8400  \tTraining accuracy: 0.7880107760429382\n",
      "Step: 8400  \tValid loss: 0.5300552845001221\n",
      "Step: 8500  \tTraining loss: 0.4155294895172119\n",
      "Step: 8500  \tTraining accuracy: 0.7881590723991394\n",
      "Step: 8500  \tValid loss: 0.529811680316925\n",
      "Step: 8600  \tTraining loss: 0.4153631031513214\n",
      "Step: 8600  \tTraining accuracy: 0.7883038520812988\n",
      "Step: 8600  \tValid loss: 0.5294078588485718\n",
      "Step: 8700  \tTraining loss: 0.4151946008205414\n",
      "Step: 8700  \tTraining accuracy: 0.7884452939033508\n",
      "Step: 8700  \tValid loss: 0.5296182632446289\n",
      "Step: 8800  \tTraining loss: 0.415029376745224\n",
      "Step: 8800  \tTraining accuracy: 0.788583517074585\n",
      "Step: 8800  \tValid loss: 0.529451310634613\n",
      "Step: 8900  \tTraining loss: 0.4148712456226349\n",
      "Step: 8900  \tTraining accuracy: 0.788726270198822\n",
      "Step: 8900  \tValid loss: 0.5293040871620178\n",
      "Step: 9000  \tTraining loss: 0.41471701860427856\n",
      "Step: 9000  \tTraining accuracy: 0.7888658046722412\n",
      "Step: 9000  \tValid loss: 0.5291510820388794\n",
      "Step: 9100  \tTraining loss: 0.4145648181438446\n",
      "Step: 9100  \tTraining accuracy: 0.7890022993087769\n",
      "Step: 9100  \tValid loss: 0.5289854407310486\n",
      "Step: 9200  \tTraining loss: 0.4144132435321808\n",
      "Step: 9200  \tTraining accuracy: 0.789135754108429\n",
      "Step: 9200  \tValid loss: 0.528807520866394\n",
      "Step: 9300  \tTraining loss: 0.41426321864128113\n",
      "Step: 9300  \tTraining accuracy: 0.7892663478851318\n",
      "Step: 9300  \tValid loss: 0.5286364555358887\n",
      "Step: 9400  \tTraining loss: 0.41411346197128296\n",
      "Step: 9400  \tTraining accuracy: 0.7893941402435303\n",
      "Step: 9400  \tValid loss: 0.5284414291381836\n",
      "Step: 9500  \tTraining loss: 0.41396644711494446\n",
      "Step: 9500  \tTraining accuracy: 0.7895192503929138\n",
      "Step: 9500  \tValid loss: 0.5282288193702698\n",
      "Step: 9600  \tTraining loss: 0.4138209819793701\n",
      "Step: 9600  \tTraining accuracy: 0.7896488308906555\n",
      "Step: 9600  \tValid loss: 0.5280314683914185\n",
      "Step: 9700  \tTraining loss: 0.41367676854133606\n",
      "Step: 9700  \tTraining accuracy: 0.7897756695747375\n",
      "Step: 9700  \tValid loss: 0.5278332233428955\n",
      "Step: 9800  \tTraining loss: 0.4135352075099945\n",
      "Step: 9800  \tTraining accuracy: 0.7898999452590942\n",
      "Step: 9800  \tValid loss: 0.5276406407356262\n",
      "Step: 9900  \tTraining loss: 0.41339677572250366\n",
      "Step: 9900  \tTraining accuracy: 0.7900217175483704\n",
      "Step: 9900  \tValid loss: 0.5274448394775391\n",
      "Step: 10000  \tTraining loss: 0.413260817527771\n",
      "Step: 10000  \tTraining accuracy: 0.7901341915130615\n",
      "Step: 10000  \tValid loss: 0.5273035168647766\n",
      "Step: 10100  \tTraining loss: 0.41312694549560547\n",
      "Step: 10100  \tTraining accuracy: 0.790244460105896\n",
      "Step: 10100  \tValid loss: 0.5271486043930054\n",
      "Step: 10200  \tTraining loss: 0.41299504041671753\n",
      "Step: 10200  \tTraining accuracy: 0.7903525829315186\n",
      "Step: 10200  \tValid loss: 0.526980459690094\n",
      "Step: 10300  \tTraining loss: 0.41286394000053406\n",
      "Step: 10300  \tTraining accuracy: 0.7904519438743591\n",
      "Step: 10300  \tValid loss: 0.5268451571464539\n",
      "Step: 10400  \tTraining loss: 0.41273483633995056\n",
      "Step: 10400  \tTraining accuracy: 0.7905493974685669\n",
      "Step: 10400  \tValid loss: 0.5267069339752197\n",
      "Step: 10500  \tTraining loss: 0.41260114312171936\n",
      "Step: 10500  \tTraining accuracy: 0.7906450033187866\n",
      "Step: 10500  \tValid loss: 0.5265068411827087\n",
      "Step: 10600  \tTraining loss: 0.4124675691127777\n",
      "Step: 10600  \tTraining accuracy: 0.7907388210296631\n",
      "Step: 10600  \tValid loss: 0.5262165665626526\n",
      "Step: 10700  \tTraining loss: 0.4123372435569763\n",
      "Step: 10700  \tTraining accuracy: 0.7908435463905334\n",
      "Step: 10700  \tValid loss: 0.5260191559791565\n",
      "Step: 10800  \tTraining loss: 0.4122079312801361\n",
      "Step: 10800  \tTraining accuracy: 0.7909400463104248\n",
      "Step: 10800  \tValid loss: 0.525870144367218\n",
      "Step: 10900  \tTraining loss: 0.41205546259880066\n",
      "Step: 10900  \tTraining accuracy: 0.7910347580909729\n",
      "Step: 10900  \tValid loss: 0.5257132053375244\n",
      "Step: 11000  \tTraining loss: 0.4119114577770233\n",
      "Step: 11000  \tTraining accuracy: 0.7911338806152344\n",
      "Step: 11000  \tValid loss: 0.5254639387130737\n",
      "Step: 11100  \tTraining loss: 0.4117768704891205\n",
      "Step: 11100  \tTraining accuracy: 0.7912312746047974\n",
      "Step: 11100  \tValid loss: 0.5252355337142944\n",
      "Step: 11200  \tTraining loss: 0.41164517402648926\n",
      "Step: 11200  \tTraining accuracy: 0.79132080078125\n",
      "Step: 11200  \tValid loss: 0.5250774621963501\n",
      "Step: 11300  \tTraining loss: 0.41151103377342224\n",
      "Step: 11300  \tTraining accuracy: 0.7914087772369385\n",
      "Step: 11300  \tValid loss: 0.5246521234512329\n",
      "Step: 11400  \tTraining loss: 0.4113803207874298\n",
      "Step: 11400  \tTraining accuracy: 0.791495144367218\n",
      "Step: 11400  \tValid loss: 0.5244829058647156\n",
      "Step: 11500  \tTraining loss: 0.4112343192100525\n",
      "Step: 11500  \tTraining accuracy: 0.7915741801261902\n",
      "Step: 11500  \tValid loss: 0.5243626236915588\n",
      "Step: 11600  \tTraining loss: 0.4110778868198395\n",
      "Step: 11600  \tTraining accuracy: 0.7916517853736877\n",
      "Step: 11600  \tValid loss: 0.5241309404373169\n",
      "Step: 11700  \tTraining loss: 0.4109143614768982\n",
      "Step: 11700  \tTraining accuracy: 0.7917280793190002\n",
      "Step: 11700  \tValid loss: 0.5239971280097961\n",
      "Step: 11800  \tTraining loss: 0.41071265935897827\n",
      "Step: 11800  \tTraining accuracy: 0.7918088436126709\n",
      "Step: 11800  \tValid loss: 0.5237753987312317\n",
      "Step: 11900  \tTraining loss: 0.41056767106056213\n",
      "Step: 11900  \tTraining accuracy: 0.7918938994407654\n",
      "Step: 11900  \tValid loss: 0.523472011089325\n",
      "Step: 12000  \tTraining loss: 0.4104374647140503\n",
      "Step: 12000  \tTraining accuracy: 0.7919719219207764\n",
      "Step: 12000  \tValid loss: 0.5233544707298279\n",
      "Step: 12100  \tTraining loss: 0.41031068563461304\n",
      "Step: 12100  \tTraining accuracy: 0.7920486330986023\n",
      "Step: 12100  \tValid loss: 0.5232425928115845\n",
      "Step: 12200  \tTraining loss: 0.4101860821247101\n",
      "Step: 12200  \tTraining accuracy: 0.7921240925788879\n",
      "Step: 12200  \tValid loss: 0.5230735540390015\n",
      "Step: 12300  \tTraining loss: 0.4100634455680847\n",
      "Step: 12300  \tTraining accuracy: 0.7921872735023499\n",
      "Step: 12300  \tValid loss: 0.5229005217552185\n",
      "Step: 12400  \tTraining loss: 0.409941703081131\n",
      "Step: 12400  \tTraining accuracy: 0.7922439575195312\n",
      "Step: 12400  \tValid loss: 0.5227018594741821\n",
      "Step: 12500  \tTraining loss: 0.4098217785358429\n",
      "Step: 12500  \tTraining accuracy: 0.792299747467041\n",
      "Step: 12500  \tValid loss: 0.5225036144256592\n",
      "Step: 12600  \tTraining loss: 0.4096927344799042\n",
      "Step: 12600  \tTraining accuracy: 0.7923492789268494\n",
      "Step: 12600  \tValid loss: 0.5222840309143066\n",
      "Step: 12700  \tTraining loss: 0.4095643162727356\n",
      "Step: 12700  \tTraining accuracy: 0.7924033403396606\n",
      "Step: 12700  \tValid loss: 0.5219420790672302\n",
      "Step: 12800  \tTraining loss: 0.4094310998916626\n",
      "Step: 12800  \tTraining accuracy: 0.7924512028694153\n",
      "Step: 12800  \tValid loss: 0.5216323733329773\n",
      "Step: 12900  \tTraining loss: 0.4093015193939209\n",
      "Step: 12900  \tTraining accuracy: 0.7924984097480774\n",
      "Step: 12900  \tValid loss: 0.5213433504104614\n",
      "Step: 13000  \tTraining loss: 0.40917572379112244\n",
      "Step: 13000  \tTraining accuracy: 0.7925448417663574\n",
      "Step: 13000  \tValid loss: 0.5211176872253418\n",
      "Step: 13100  \tTraining loss: 0.4090353846549988\n",
      "Step: 13100  \tTraining accuracy: 0.7925905585289001\n",
      "Step: 13100  \tValid loss: 0.5209425091743469\n",
      "Step: 13200  \tTraining loss: 0.4089045524597168\n",
      "Step: 13200  \tTraining accuracy: 0.7926355600357056\n",
      "Step: 13200  \tValid loss: 0.5208261013031006\n",
      "Step: 13300  \tTraining loss: 0.40877965092658997\n",
      "Step: 13300  \tTraining accuracy: 0.7926799654960632\n",
      "Step: 13300  \tValid loss: 0.5208075046539307\n",
      "Step: 13400  \tTraining loss: 0.40866100788116455\n",
      "Step: 13400  \tTraining accuracy: 0.7927236557006836\n",
      "Step: 13400  \tValid loss: 0.5207445621490479\n",
      "Step: 13500  \tTraining loss: 0.4085465967655182\n",
      "Step: 13500  \tTraining accuracy: 0.7927716970443726\n",
      "Step: 13500  \tValid loss: 0.5207517147064209\n",
      "Step: 13600  \tTraining loss: 0.4084378778934479\n",
      "Step: 13600  \tTraining accuracy: 0.7928190231323242\n",
      "Step: 13600  \tValid loss: 0.5206786394119263\n",
      "Step: 13700  \tTraining loss: 0.4083315432071686\n",
      "Step: 13700  \tTraining accuracy: 0.7928656935691833\n",
      "Step: 13700  \tValid loss: 0.5207250118255615\n",
      "Step: 13800  \tTraining loss: 0.40822893381118774\n",
      "Step: 13800  \tTraining accuracy: 0.79291170835495\n",
      "Step: 13800  \tValid loss: 0.5208104848861694\n",
      "Step: 13900  \tTraining loss: 0.4081308841705322\n",
      "Step: 13900  \tTraining accuracy: 0.7929570078849792\n",
      "Step: 13900  \tValid loss: 0.5207920670509338\n",
      "Step: 14000  \tTraining loss: 0.40803393721580505\n",
      "Step: 14000  \tTraining accuracy: 0.7929968237876892\n",
      "Step: 14000  \tValid loss: 0.5209525227546692\n",
      "Step: 14100  \tTraining loss: 0.407941997051239\n",
      "Step: 14100  \tTraining accuracy: 0.7930312752723694\n",
      "Step: 14100  \tValid loss: 0.5208804607391357\n",
      "Step: 14200  \tTraining loss: 0.407850444316864\n",
      "Step: 14200  \tTraining accuracy: 0.7930652499198914\n",
      "Step: 14200  \tValid loss: 0.5210770964622498\n",
      "Step: 14300  \tTraining loss: 0.40776318311691284\n",
      "Step: 14300  \tTraining accuracy: 0.7930986881256104\n",
      "Step: 14300  \tValid loss: 0.5210185050964355\n",
      "Step: 14400  \tTraining loss: 0.4076763987541199\n",
      "Step: 14400  \tTraining accuracy: 0.7931317090988159\n",
      "Step: 14400  \tValid loss: 0.5211648344993591\n",
      "Step: 14500  \tTraining loss: 0.4075917601585388\n",
      "Step: 14500  \tTraining accuracy: 0.7931642532348633\n",
      "Step: 14500  \tValid loss: 0.5212969183921814\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7931964\n",
      "Precision: 0.8533917\n",
      "Recall: 0.864745\n",
      "F1 score: 0.7984377\n",
      "AUC: 0.8218114\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.793196   0.853392  0.864745  0.798438  0.821811  0.40758      0.793066   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.520625       0.793119   0.558197      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  14514.0  \n",
      "10\n",
      "(957, 5)\n",
      "(957, 1)\n",
      "(528, 5)\n",
      "(528, 1)\n",
      "(429, 5)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.62528395652771\n",
      "Step: 100  \tTraining accuracy: 0.6259143352508545\n",
      "Step: 100  \tValid loss: 0.6463369727134705\n",
      "Step: 200  \tTraining loss: 0.5525144338607788\n",
      "Step: 200  \tTraining accuracy: 0.6562173366546631\n",
      "Step: 200  \tValid loss: 0.5764093399047852\n",
      "Step: 300  \tTraining loss: 0.4839932322502136\n",
      "Step: 300  \tTraining accuracy: 0.7015674114227295\n",
      "Step: 300  \tValid loss: 0.4940495491027832\n",
      "Step: 400  \tTraining loss: 0.43850788474082947\n",
      "Step: 400  \tTraining accuracy: 0.7323480844497681\n",
      "Step: 400  \tValid loss: 0.4345221519470215\n",
      "Step: 500  \tTraining loss: 0.41400185227394104\n",
      "Step: 500  \tTraining accuracy: 0.7522349953651428\n",
      "Step: 500  \tValid loss: 0.3997677266597748\n",
      "Step: 600  \tTraining loss: 0.40310433506965637\n",
      "Step: 600  \tTraining accuracy: 0.7655552625656128\n",
      "Step: 600  \tValid loss: 0.38270899653434753\n",
      "Step: 700  \tTraining loss: 0.39766648411750793\n",
      "Step: 700  \tTraining accuracy: 0.7749376893043518\n",
      "Step: 700  \tValid loss: 0.3740760385990143\n",
      "Step: 800  \tTraining loss: 0.39440855383872986\n",
      "Step: 800  \tTraining accuracy: 0.7824451327323914\n",
      "Step: 800  \tValid loss: 0.36927470564842224\n",
      "Step: 900  \tTraining loss: 0.3921935558319092\n",
      "Step: 900  \tTraining accuracy: 0.7885549068450928\n",
      "Step: 900  \tValid loss: 0.36632052063941956\n",
      "Step: 1000  \tTraining loss: 0.3905162215232849\n",
      "Step: 1000  \tTraining accuracy: 0.793213427066803\n",
      "Step: 1000  \tValid loss: 0.36435234546661377\n",
      "Step: 1100  \tTraining loss: 0.38902002573013306\n",
      "Step: 1100  \tTraining accuracy: 0.7969846129417419\n",
      "Step: 1100  \tValid loss: 0.3628471791744232\n",
      "Step: 1200  \tTraining loss: 0.3874797224998474\n",
      "Step: 1200  \tTraining accuracy: 0.8001453876495361\n",
      "Step: 1200  \tValid loss: 0.36160415410995483\n",
      "Step: 1300  \tTraining loss: 0.3857388496398926\n",
      "Step: 1300  \tTraining accuracy: 0.8029258251190186\n",
      "Step: 1300  \tValid loss: 0.360494464635849\n",
      "Step: 1400  \tTraining loss: 0.38382062315940857\n",
      "Step: 1400  \tTraining accuracy: 0.8051782250404358\n",
      "Step: 1400  \tValid loss: 0.3595896065235138\n",
      "Step: 1500  \tTraining loss: 0.38226571679115295\n",
      "Step: 1500  \tTraining accuracy: 0.8073000907897949\n",
      "Step: 1500  \tValid loss: 0.3585073947906494\n",
      "Step: 1600  \tTraining loss: 0.38085320591926575\n",
      "Step: 1600  \tTraining accuracy: 0.8091481924057007\n",
      "Step: 1600  \tValid loss: 0.35761401057243347\n",
      "Step: 1700  \tTraining loss: 0.3795829117298126\n",
      "Step: 1700  \tTraining accuracy: 0.8108673095703125\n",
      "Step: 1700  \tValid loss: 0.3568771183490753\n",
      "Step: 1800  \tTraining loss: 0.37847477197647095\n",
      "Step: 1800  \tTraining accuracy: 0.8124197721481323\n",
      "Step: 1800  \tValid loss: 0.3562222123146057\n",
      "Step: 1900  \tTraining loss: 0.3774755299091339\n",
      "Step: 1900  \tTraining accuracy: 0.8136914372444153\n",
      "Step: 1900  \tValid loss: 0.35566288232803345\n",
      "Step: 2000  \tTraining loss: 0.37657809257507324\n",
      "Step: 2000  \tTraining accuracy: 0.8148594498634338\n",
      "Step: 2000  \tValid loss: 0.3550543785095215\n",
      "Step: 2100  \tTraining loss: 0.3757624626159668\n",
      "Step: 2100  \tTraining accuracy: 0.8159645199775696\n",
      "Step: 2100  \tValid loss: 0.3545417785644531\n",
      "Step: 2200  \tTraining loss: 0.37502673268318176\n",
      "Step: 2200  \tTraining accuracy: 0.8169424533843994\n",
      "Step: 2200  \tValid loss: 0.3540799021720886\n",
      "Step: 2300  \tTraining loss: 0.3743496835231781\n",
      "Step: 2300  \tTraining accuracy: 0.8178334832191467\n",
      "Step: 2300  \tValid loss: 0.35363179445266724\n",
      "Step: 2400  \tTraining loss: 0.37366363406181335\n",
      "Step: 2400  \tTraining accuracy: 0.8186486959457397\n",
      "Step: 2400  \tValid loss: 0.3534899652004242\n",
      "Step: 2500  \tTraining loss: 0.3730955719947815\n",
      "Step: 2500  \tTraining accuracy: 0.8193973302841187\n",
      "Step: 2500  \tValid loss: 0.35310137271881104\n",
      "Step: 2600  \tTraining loss: 0.37258777022361755\n",
      "Step: 2600  \tTraining accuracy: 0.820148766040802\n",
      "Step: 2600  \tValid loss: 0.3528098165988922\n",
      "Step: 2700  \tTraining loss: 0.3721368908882141\n",
      "Step: 2700  \tTraining accuracy: 0.8208631277084351\n",
      "Step: 2700  \tValid loss: 0.3524308502674103\n",
      "Step: 2800  \tTraining loss: 0.3717270493507385\n",
      "Step: 2800  \tTraining accuracy: 0.8215255737304688\n",
      "Step: 2800  \tValid loss: 0.3522324860095978\n",
      "Step: 2900  \tTraining loss: 0.3713545799255371\n",
      "Step: 2900  \tTraining accuracy: 0.8221232295036316\n",
      "Step: 2900  \tValid loss: 0.3520124554634094\n",
      "Step: 3000  \tTraining loss: 0.3710212707519531\n",
      "Step: 3000  \tTraining accuracy: 0.8226803541183472\n",
      "Step: 3000  \tValid loss: 0.351681113243103\n",
      "Step: 3100  \tTraining loss: 0.37071695923805237\n",
      "Step: 3100  \tTraining accuracy: 0.8231837749481201\n",
      "Step: 3100  \tValid loss: 0.35139375925064087\n",
      "Step: 3200  \tTraining loss: 0.3704345226287842\n",
      "Step: 3200  \tTraining accuracy: 0.8236386775970459\n",
      "Step: 3200  \tValid loss: 0.35111483931541443\n",
      "Step: 3300  \tTraining loss: 0.37016966938972473\n",
      "Step: 3300  \tTraining accuracy: 0.8240655660629272\n",
      "Step: 3300  \tValid loss: 0.350888192653656\n",
      "Step: 3400  \tTraining loss: 0.3699204921722412\n",
      "Step: 3400  \tTraining accuracy: 0.8244670033454895\n",
      "Step: 3400  \tValid loss: 0.3506612479686737\n",
      "Step: 3500  \tTraining loss: 0.3696812689304352\n",
      "Step: 3500  \tTraining accuracy: 0.8248299956321716\n",
      "Step: 3500  \tValid loss: 0.35057830810546875\n",
      "Step: 3600  \tTraining loss: 0.3694537878036499\n",
      "Step: 3600  \tTraining accuracy: 0.8251430988311768\n",
      "Step: 3600  \tValid loss: 0.3503386378288269\n",
      "Step: 3700  \tTraining loss: 0.3692343235015869\n",
      "Step: 3700  \tTraining accuracy: 0.8254390954971313\n",
      "Step: 3700  \tValid loss: 0.35018429160118103\n",
      "Step: 3800  \tTraining loss: 0.36901918053627014\n",
      "Step: 3800  \tTraining accuracy: 0.8257192373275757\n",
      "Step: 3800  \tValid loss: 0.3500615060329437\n",
      "Step: 3900  \tTraining loss: 0.3688107132911682\n",
      "Step: 3900  \tTraining accuracy: 0.8259713053703308\n",
      "Step: 3900  \tValid loss: 0.3500145375728607\n",
      "Step: 4000  \tTraining loss: 0.3686046004295349\n",
      "Step: 4000  \tTraining accuracy: 0.8262238502502441\n",
      "Step: 4000  \tValid loss: 0.3498365581035614\n",
      "Step: 4100  \tTraining loss: 0.368399441242218\n",
      "Step: 4100  \tTraining accuracy: 0.8264638781547546\n",
      "Step: 4100  \tValid loss: 0.34966129064559937\n",
      "Step: 4200  \tTraining loss: 0.3681977391242981\n",
      "Step: 4200  \tTraining accuracy: 0.8267049193382263\n",
      "Step: 4200  \tValid loss: 0.34952589869499207\n",
      "Step: 4300  \tTraining loss: 0.36799612641334534\n",
      "Step: 4300  \tTraining accuracy: 0.8269346356391907\n",
      "Step: 4300  \tValid loss: 0.34944307804107666\n",
      "Step: 4400  \tTraining loss: 0.3677908182144165\n",
      "Step: 4400  \tTraining accuracy: 0.8271418213844299\n",
      "Step: 4400  \tValid loss: 0.34926629066467285\n",
      "Step: 4500  \tTraining loss: 0.36758390069007874\n",
      "Step: 4500  \tTraining accuracy: 0.8273279070854187\n",
      "Step: 4500  \tValid loss: 0.3491044342517853\n",
      "Step: 4600  \tTraining loss: 0.36737197637557983\n",
      "Step: 4600  \tTraining accuracy: 0.8275402784347534\n",
      "Step: 4600  \tValid loss: 0.3488592207431793\n",
      "Step: 4700  \tTraining loss: 0.3671550750732422\n",
      "Step: 4700  \tTraining accuracy: 0.827732264995575\n",
      "Step: 4700  \tValid loss: 0.34871479868888855\n",
      "Step: 4800  \tTraining loss: 0.3669341504573822\n",
      "Step: 4800  \tTraining accuracy: 0.8279162049293518\n",
      "Step: 4800  \tValid loss: 0.3484759032726288\n",
      "Step: 4900  \tTraining loss: 0.36670735478401184\n",
      "Step: 4900  \tTraining accuracy: 0.8281033039093018\n",
      "Step: 4900  \tValid loss: 0.3483356237411499\n",
      "Step: 5000  \tTraining loss: 0.3664761483669281\n",
      "Step: 5000  \tTraining accuracy: 0.8282828330993652\n",
      "Step: 5000  \tValid loss: 0.34817737340927124\n",
      "Step: 5100  \tTraining loss: 0.36623984575271606\n",
      "Step: 5100  \tTraining accuracy: 0.8284552693367004\n",
      "Step: 5100  \tValid loss: 0.347978800535202\n",
      "Step: 5200  \tTraining loss: 0.36599794030189514\n",
      "Step: 5200  \tTraining accuracy: 0.828620970249176\n",
      "Step: 5200  \tValid loss: 0.3477671146392822\n",
      "Step: 5300  \tTraining loss: 0.36575308442115784\n",
      "Step: 5300  \tTraining accuracy: 0.8288003206253052\n",
      "Step: 5300  \tValid loss: 0.3476080298423767\n",
      "Step: 5400  \tTraining loss: 0.36550429463386536\n",
      "Step: 5400  \tTraining accuracy: 0.8289827108383179\n",
      "Step: 5400  \tValid loss: 0.3474057614803314\n",
      "Step: 5500  \tTraining loss: 0.3652503788471222\n",
      "Step: 5500  \tTraining accuracy: 0.8291679620742798\n",
      "Step: 5500  \tValid loss: 0.34728309512138367\n",
      "Step: 5600  \tTraining loss: 0.3649791181087494\n",
      "Step: 5600  \tTraining accuracy: 0.8293465971946716\n",
      "Step: 5600  \tValid loss: 0.34698817133903503\n",
      "Step: 5700  \tTraining loss: 0.3647105395793915\n",
      "Step: 5700  \tTraining accuracy: 0.8295280933380127\n",
      "Step: 5700  \tValid loss: 0.3468872904777527\n",
      "Step: 5800  \tTraining loss: 0.36443984508514404\n",
      "Step: 5800  \tTraining accuracy: 0.8297033309936523\n",
      "Step: 5800  \tValid loss: 0.34669825434684753\n",
      "Step: 5900  \tTraining loss: 0.36416158080101013\n",
      "Step: 5900  \tTraining accuracy: 0.8298725485801697\n",
      "Step: 5900  \tValid loss: 0.34643757343292236\n",
      "Step: 6000  \tTraining loss: 0.36387383937835693\n",
      "Step: 6000  \tTraining accuracy: 0.8300448656082153\n",
      "Step: 6000  \tValid loss: 0.3462846279144287\n",
      "Step: 6100  \tTraining loss: 0.3635633587837219\n",
      "Step: 6100  \tTraining accuracy: 0.8302115201950073\n",
      "Step: 6100  \tValid loss: 0.3461654782295227\n",
      "Step: 6200  \tTraining loss: 0.3632708191871643\n",
      "Step: 6200  \tTraining accuracy: 0.8303641676902771\n",
      "Step: 6200  \tValid loss: 0.3459782600402832\n",
      "Step: 6300  \tTraining loss: 0.3629828691482544\n",
      "Step: 6300  \tTraining accuracy: 0.8305119872093201\n",
      "Step: 6300  \tValid loss: 0.34574031829833984\n",
      "Step: 6400  \tTraining loss: 0.36269086599349976\n",
      "Step: 6400  \tTraining accuracy: 0.8306551575660706\n",
      "Step: 6400  \tValid loss: 0.3455611765384674\n",
      "Step: 6500  \tTraining loss: 0.3623972535133362\n",
      "Step: 6500  \tTraining accuracy: 0.8307858109474182\n",
      "Step: 6500  \tValid loss: 0.34529292583465576\n",
      "Step: 6600  \tTraining loss: 0.3621037006378174\n",
      "Step: 6600  \tTraining accuracy: 0.8309124708175659\n",
      "Step: 6600  \tValid loss: 0.3450179696083069\n",
      "Step: 6700  \tTraining loss: 0.36179766058921814\n",
      "Step: 6700  \tTraining accuracy: 0.8310352563858032\n",
      "Step: 6700  \tValid loss: 0.34464073181152344\n",
      "Step: 6800  \tTraining loss: 0.3612779676914215\n",
      "Step: 6800  \tTraining accuracy: 0.8311312198638916\n",
      "Step: 6800  \tValid loss: 0.34451472759246826\n",
      "Step: 6900  \tTraining loss: 0.3609408736228943\n",
      "Step: 6900  \tTraining accuracy: 0.831239640712738\n",
      "Step: 6900  \tValid loss: 0.34434711933135986\n",
      "Step: 7000  \tTraining loss: 0.3606216609477997\n",
      "Step: 7000  \tTraining accuracy: 0.8313299417495728\n",
      "Step: 7000  \tValid loss: 0.3441251218318939\n",
      "Step: 7100  \tTraining loss: 0.3603140115737915\n",
      "Step: 7100  \tTraining accuracy: 0.8314102292060852\n",
      "Step: 7100  \tValid loss: 0.34391242265701294\n",
      "Step: 7200  \tTraining loss: 0.3600177764892578\n",
      "Step: 7200  \tTraining accuracy: 0.8314736485481262\n",
      "Step: 7200  \tValid loss: 0.3436567783355713\n",
      "Step: 7300  \tTraining loss: 0.3597300350666046\n",
      "Step: 7300  \tTraining accuracy: 0.8315425515174866\n",
      "Step: 7300  \tValid loss: 0.3434370458126068\n",
      "Step: 7400  \tTraining loss: 0.35945236682891846\n",
      "Step: 7400  \tTraining accuracy: 0.8316024541854858\n",
      "Step: 7400  \tValid loss: 0.3432258367538452\n",
      "Step: 7500  \tTraining loss: 0.35918477177619934\n",
      "Step: 7500  \tTraining accuracy: 0.8316677808761597\n",
      "Step: 7500  \tValid loss: 0.3430330157279968\n",
      "Step: 7600  \tTraining loss: 0.35892605781555176\n",
      "Step: 7600  \tTraining accuracy: 0.8317313194274902\n",
      "Step: 7600  \tValid loss: 0.3428967297077179\n",
      "Step: 7700  \tTraining loss: 0.35868147015571594\n",
      "Step: 7700  \tTraining accuracy: 0.8317932486534119\n",
      "Step: 7700  \tValid loss: 0.3426811397075653\n",
      "Step: 7800  \tTraining loss: 0.3584441542625427\n",
      "Step: 7800  \tTraining accuracy: 0.8318535685539246\n",
      "Step: 7800  \tValid loss: 0.34254905581474304\n",
      "Step: 7900  \tTraining loss: 0.3582196831703186\n",
      "Step: 7900  \tTraining accuracy: 0.8319190144538879\n",
      "Step: 7900  \tValid loss: 0.3423905670642853\n",
      "Step: 8000  \tTraining loss: 0.3580079972743988\n",
      "Step: 8000  \tTraining accuracy: 0.831969678401947\n",
      "Step: 8000  \tValid loss: 0.34224948287010193\n",
      "Step: 8100  \tTraining loss: 0.3578071594238281\n",
      "Step: 8100  \tTraining accuracy: 0.8320125937461853\n",
      "Step: 8100  \tValid loss: 0.3421076536178589\n",
      "Step: 8200  \tTraining loss: 0.3576173782348633\n",
      "Step: 8200  \tTraining accuracy: 0.8320544362068176\n",
      "Step: 8200  \tValid loss: 0.3419713079929352\n",
      "Step: 8300  \tTraining loss: 0.3574385344982147\n",
      "Step: 8300  \tTraining accuracy: 0.832101583480835\n",
      "Step: 8300  \tValid loss: 0.34183329343795776\n",
      "Step: 8400  \tTraining loss: 0.3572688400745392\n",
      "Step: 8400  \tTraining accuracy: 0.8321475982666016\n",
      "Step: 8400  \tValid loss: 0.3417353928089142\n",
      "Step: 8500  \tTraining loss: 0.35710829496383667\n",
      "Step: 8500  \tTraining accuracy: 0.8321987390518188\n",
      "Step: 8500  \tValid loss: 0.3416282832622528\n",
      "Step: 8600  \tTraining loss: 0.3569546639919281\n",
      "Step: 8600  \tTraining accuracy: 0.8322486877441406\n",
      "Step: 8600  \tValid loss: 0.34151896834373474\n",
      "Step: 8700  \tTraining loss: 0.35680657625198364\n",
      "Step: 8700  \tTraining accuracy: 0.8322974443435669\n",
      "Step: 8700  \tValid loss: 0.3414294719696045\n",
      "Step: 8800  \tTraining loss: 0.35665440559387207\n",
      "Step: 8800  \tTraining accuracy: 0.8323451280593872\n",
      "Step: 8800  \tValid loss: 0.34134426712989807\n",
      "Step: 8900  \tTraining loss: 0.3565025329589844\n",
      "Step: 8900  \tTraining accuracy: 0.8323917388916016\n",
      "Step: 8900  \tValid loss: 0.3413229286670685\n",
      "Step: 9000  \tTraining loss: 0.3563139736652374\n",
      "Step: 9000  \tTraining accuracy: 0.83243727684021\n",
      "Step: 9000  \tValid loss: 0.3411276340484619\n",
      "Step: 9100  \tTraining loss: 0.35607215762138367\n",
      "Step: 9100  \tTraining accuracy: 0.8324818015098572\n",
      "Step: 9100  \tValid loss: 0.34088727831840515\n",
      "Step: 9200  \tTraining loss: 0.35586994886398315\n",
      "Step: 9200  \tTraining accuracy: 0.8325139284133911\n",
      "Step: 9200  \tValid loss: 0.3407770097255707\n",
      "Step: 9300  \tTraining loss: 0.35568156838417053\n",
      "Step: 9300  \tTraining accuracy: 0.8325397372245789\n",
      "Step: 9300  \tValid loss: 0.34070974588394165\n",
      "Step: 9400  \tTraining loss: 0.3555099070072174\n",
      "Step: 9400  \tTraining accuracy: 0.8325650095939636\n",
      "Step: 9400  \tValid loss: 0.3406601548194885\n",
      "Step: 9500  \tTraining loss: 0.3553473949432373\n",
      "Step: 9500  \tTraining accuracy: 0.8325897455215454\n",
      "Step: 9500  \tValid loss: 0.3405996561050415\n",
      "Step: 9600  \tTraining loss: 0.3551884889602661\n",
      "Step: 9600  \tTraining accuracy: 0.8326139450073242\n",
      "Step: 9600  \tValid loss: 0.340520441532135\n",
      "Step: 9700  \tTraining loss: 0.3550325036048889\n",
      "Step: 9700  \tTraining accuracy: 0.8326376080513\n",
      "Step: 9700  \tValid loss: 0.3404800593852997\n",
      "Step: 9800  \tTraining loss: 0.35487934947013855\n",
      "Step: 9800  \tTraining accuracy: 0.8326608538627625\n",
      "Step: 9800  \tValid loss: 0.34044215083122253\n",
      "Step: 9900  \tTraining loss: 0.35472846031188965\n",
      "Step: 9900  \tTraining accuracy: 0.8326941728591919\n",
      "Step: 9900  \tValid loss: 0.340388685464859\n",
      "Step: 10000  \tTraining loss: 0.35457858443260193\n",
      "Step: 10000  \tTraining accuracy: 0.8327215909957886\n",
      "Step: 10000  \tValid loss: 0.3403824269771576\n",
      "Step: 10100  \tTraining loss: 0.35442978143692017\n",
      "Step: 10100  \tTraining accuracy: 0.8327432870864868\n",
      "Step: 10100  \tValid loss: 0.3403947949409485\n",
      "Step: 10200  \tTraining loss: 0.3542829155921936\n",
      "Step: 10200  \tTraining accuracy: 0.8327696919441223\n",
      "Step: 10200  \tValid loss: 0.3403792083263397\n",
      "Step: 10300  \tTraining loss: 0.35413703322410583\n",
      "Step: 10300  \tTraining accuracy: 0.8327955603599548\n",
      "Step: 10300  \tValid loss: 0.34038108587265015\n",
      "Step: 10400  \tTraining loss: 0.3539924621582031\n",
      "Step: 10400  \tTraining accuracy: 0.8328209519386292\n",
      "Step: 10400  \tValid loss: 0.34042683243751526\n",
      "Step: 10500  \tTraining loss: 0.35385003685951233\n",
      "Step: 10500  \tTraining accuracy: 0.8328508734703064\n",
      "Step: 10500  \tValid loss: 0.34042248129844666\n",
      "Step: 10600  \tTraining loss: 0.3537099063396454\n",
      "Step: 10600  \tTraining accuracy: 0.8328801989555359\n",
      "Step: 10600  \tValid loss: 0.3403811454772949\n",
      "Step: 10700  \tTraining loss: 0.35357198119163513\n",
      "Step: 10700  \tTraining accuracy: 0.8328991532325745\n",
      "Step: 10700  \tValid loss: 0.3403647243976593\n",
      "Step: 10800  \tTraining loss: 0.3534373342990875\n",
      "Step: 10800  \tTraining accuracy: 0.8329129219055176\n",
      "Step: 10800  \tValid loss: 0.3403468728065491\n",
      "Step: 10900  \tTraining loss: 0.3533061444759369\n",
      "Step: 10900  \tTraining accuracy: 0.8329264521598816\n",
      "Step: 10900  \tValid loss: 0.34031417965888977\n",
      "Step: 11000  \tTraining loss: 0.35317838191986084\n",
      "Step: 11000  \tTraining accuracy: 0.8329444527626038\n",
      "Step: 11000  \tValid loss: 0.34025800228118896\n",
      "Step: 11100  \tTraining loss: 0.3530530333518982\n",
      "Step: 11100  \tTraining accuracy: 0.832962155342102\n",
      "Step: 11100  \tValid loss: 0.34021347761154175\n",
      "Step: 11200  \tTraining loss: 0.3529294729232788\n",
      "Step: 11200  \tTraining accuracy: 0.8329842686653137\n",
      "Step: 11200  \tValid loss: 0.3401816785335541\n",
      "Step: 11300  \tTraining loss: 0.3528078496456146\n",
      "Step: 11300  \tTraining accuracy: 0.8330059051513672\n",
      "Step: 11300  \tValid loss: 0.3401619791984558\n",
      "Step: 11400  \tTraining loss: 0.35268813371658325\n",
      "Step: 11400  \tTraining accuracy: 0.8330272436141968\n",
      "Step: 11400  \tValid loss: 0.3401334881782532\n",
      "Step: 11500  \tTraining loss: 0.3525693714618683\n",
      "Step: 11500  \tTraining accuracy: 0.8330435752868652\n",
      "Step: 11500  \tValid loss: 0.3401302695274353\n",
      "Step: 11600  \tTraining loss: 0.3524514138698578\n",
      "Step: 11600  \tTraining accuracy: 0.8330596685409546\n",
      "Step: 11600  \tValid loss: 0.34013819694519043\n",
      "Step: 11700  \tTraining loss: 0.35233360528945923\n",
      "Step: 11700  \tTraining accuracy: 0.8330754637718201\n",
      "Step: 11700  \tValid loss: 0.34017321467399597\n",
      "Step: 11800  \tTraining loss: 0.35221609473228455\n",
      "Step: 11800  \tTraining accuracy: 0.8330910205841064\n",
      "Step: 11800  \tValid loss: 0.3402012288570404\n",
      "Step: 11900  \tTraining loss: 0.352098673582077\n",
      "Step: 11900  \tTraining accuracy: 0.8330974578857422\n",
      "Step: 11900  \tValid loss: 0.34023186564445496\n",
      "Step: 12000  \tTraining loss: 0.3519804775714874\n",
      "Step: 12000  \tTraining accuracy: 0.8331037759780884\n",
      "Step: 12000  \tValid loss: 0.3402603566646576\n",
      "Step: 12100  \tTraining loss: 0.35186219215393066\n",
      "Step: 12100  \tTraining accuracy: 0.833118736743927\n",
      "Step: 12100  \tValid loss: 0.340290367603302\n",
      "Step: 12200  \tTraining loss: 0.35174429416656494\n",
      "Step: 12200  \tTraining accuracy: 0.8331333994865417\n",
      "Step: 12200  \tValid loss: 0.3403152823448181\n",
      "Step: 12300  \tTraining loss: 0.35162752866744995\n",
      "Step: 12300  \tTraining accuracy: 0.8331478238105774\n",
      "Step: 12300  \tValid loss: 0.3403414487838745\n",
      "Step: 12400  \tTraining loss: 0.35151207447052\n",
      "Step: 12400  \tTraining accuracy: 0.8331620097160339\n",
      "Step: 12400  \tValid loss: 0.34038597345352173\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.83317596\n",
      "Precision: 0.8452769\n",
      "Recall: 0.88869864\n",
      "F1 score: 0.85404015\n",
      "AUC: 0.81700337\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.833176   0.845277  0.888699   0.85404  0.817003  0.351457      0.833177   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.340115       0.833148   0.389876      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  12447.0  \n",
      "11\n",
      "(754, 5)\n",
      "(754, 1)\n",
      "(416, 5)\n",
      "(416, 1)\n",
      "(338, 5)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.550464928150177\n",
      "Step: 100  \tTraining accuracy: 0.7692307829856873\n",
      "Step: 100  \tValid loss: 0.5353225469589233\n",
      "Step: 200  \tTraining loss: 0.41606637835502625\n",
      "Step: 200  \tTraining accuracy: 0.7988505959510803\n",
      "Step: 200  \tValid loss: 0.4098581075668335\n",
      "Step: 300  \tTraining loss: 0.3734813630580902\n",
      "Step: 300  \tTraining accuracy: 0.8129973411560059\n",
      "Step: 300  \tValid loss: 0.37070757150650024\n",
      "Step: 400  \tTraining loss: 0.3625223636627197\n",
      "Step: 400  \tTraining accuracy: 0.8183023929595947\n",
      "Step: 400  \tValid loss: 0.3609483540058136\n",
      "Step: 500  \tTraining loss: 0.3571179509162903\n",
      "Step: 500  \tTraining accuracy: 0.8211022615432739\n",
      "Step: 500  \tValid loss: 0.35601791739463806\n",
      "Step: 600  \tTraining loss: 0.3533121645450592\n",
      "Step: 600  \tTraining accuracy: 0.8227634429931641\n",
      "Step: 600  \tValid loss: 0.3522999882698059\n",
      "Step: 700  \tTraining loss: 0.350231409072876\n",
      "Step: 700  \tTraining accuracy: 0.8234033584594727\n",
      "Step: 700  \tValid loss: 0.34911081194877625\n",
      "Step: 800  \tTraining loss: 0.34758293628692627\n",
      "Step: 800  \tTraining accuracy: 0.8238726854324341\n",
      "Step: 800  \tValid loss: 0.3462788760662079\n",
      "Step: 900  \tTraining loss: 0.34523189067840576\n",
      "Step: 900  \tTraining accuracy: 0.8244655728340149\n",
      "Step: 900  \tValid loss: 0.34373635053634644\n",
      "Step: 1000  \tTraining loss: 0.3430991470813751\n",
      "Step: 1000  \tTraining accuracy: 0.8248639106750488\n",
      "Step: 1000  \tValid loss: 0.3414337933063507\n",
      "Step: 1100  \tTraining loss: 0.3411318063735962\n",
      "Step: 1100  \tTraining accuracy: 0.824996829032898\n",
      "Step: 1100  \tValid loss: 0.3393357992172241\n",
      "Step: 1200  \tTraining loss: 0.3392850458621979\n",
      "Step: 1200  \tTraining accuracy: 0.825106680393219\n",
      "Step: 1200  \tValid loss: 0.3374088704586029\n",
      "Step: 1300  \tTraining loss: 0.3375087082386017\n",
      "Step: 1300  \tTraining accuracy: 0.8251989483833313\n",
      "Step: 1300  \tValid loss: 0.33561772108078003\n",
      "Step: 1400  \tTraining loss: 0.3358248770236969\n",
      "Step: 1400  \tTraining accuracy: 0.8252775073051453\n",
      "Step: 1400  \tValid loss: 0.3339616656303406\n",
      "Step: 1500  \tTraining loss: 0.3342180848121643\n",
      "Step: 1500  \tTraining accuracy: 0.8254824876785278\n",
      "Step: 1500  \tValid loss: 0.33242636919021606\n",
      "Step: 1600  \tTraining loss: 0.3326801657676697\n",
      "Step: 1600  \tTraining accuracy: 0.8258321285247803\n",
      "Step: 1600  \tValid loss: 0.3310014009475708\n",
      "Step: 1700  \tTraining loss: 0.3312055766582489\n",
      "Step: 1700  \tTraining accuracy: 0.826179563999176\n",
      "Step: 1700  \tValid loss: 0.32967573404312134\n",
      "Step: 1800  \tTraining loss: 0.32979127764701843\n",
      "Step: 1800  \tTraining accuracy: 0.8265631198883057\n",
      "Step: 1800  \tValid loss: 0.328439861536026\n",
      "Step: 1900  \tTraining loss: 0.32843613624572754\n",
      "Step: 1900  \tTraining accuracy: 0.8269410133361816\n",
      "Step: 1900  \tValid loss: 0.32728445529937744\n",
      "Step: 2000  \tTraining loss: 0.32713985443115234\n",
      "Step: 2000  \tTraining accuracy: 0.827450156211853\n",
      "Step: 2000  \tValid loss: 0.3262004256248474\n",
      "Step: 2100  \tTraining loss: 0.3259029984474182\n",
      "Step: 2100  \tTraining accuracy: 0.8280390501022339\n",
      "Step: 2100  \tValid loss: 0.32517778873443604\n",
      "Step: 2200  \tTraining loss: 0.32472559809684753\n",
      "Step: 2200  \tTraining accuracy: 0.8286348581314087\n",
      "Step: 2200  \tValid loss: 0.32420679926872253\n",
      "Step: 2300  \tTraining loss: 0.3236067295074463\n",
      "Step: 2300  \tTraining accuracy: 0.8292661309242249\n",
      "Step: 2300  \tValid loss: 0.32327720522880554\n",
      "Step: 2400  \tTraining loss: 0.32254454493522644\n",
      "Step: 2400  \tTraining accuracy: 0.8299283385276794\n",
      "Step: 2400  \tValid loss: 0.3223794102668762\n",
      "Step: 2500  \tTraining loss: 0.3215367794036865\n",
      "Step: 2500  \tTraining accuracy: 0.8305906057357788\n",
      "Step: 2500  \tValid loss: 0.32150474190711975\n",
      "Step: 2600  \tTraining loss: 0.3205803334712982\n",
      "Step: 2600  \tTraining accuracy: 0.831096887588501\n",
      "Step: 2600  \tValid loss: 0.32064640522003174\n",
      "Step: 2700  \tTraining loss: 0.3196723759174347\n",
      "Step: 2700  \tTraining accuracy: 0.8315649628639221\n",
      "Step: 2700  \tValid loss: 0.3197995722293854\n",
      "Step: 2800  \tTraining loss: 0.3188098073005676\n",
      "Step: 2800  \tTraining accuracy: 0.8320231437683105\n",
      "Step: 2800  \tValid loss: 0.3189612925052643\n",
      "Step: 2900  \tTraining loss: 0.31799036264419556\n",
      "Step: 2900  \tTraining accuracy: 0.8324491381645203\n",
      "Step: 2900  \tValid loss: 0.3181303143501282\n",
      "Step: 3000  \tTraining loss: 0.31721171736717224\n",
      "Step: 3000  \tTraining accuracy: 0.8328238129615784\n",
      "Step: 3000  \tValid loss: 0.31730717420578003\n",
      "Step: 3100  \tTraining loss: 0.31647229194641113\n",
      "Step: 3100  \tTraining accuracy: 0.8331956267356873\n",
      "Step: 3100  \tValid loss: 0.3164933919906616\n",
      "Step: 3200  \tTraining loss: 0.3157704472541809\n",
      "Step: 3200  \tTraining accuracy: 0.8335648775100708\n",
      "Step: 3200  \tValid loss: 0.31569114327430725\n",
      "Step: 3300  \tTraining loss: 0.3151050806045532\n",
      "Step: 3300  \tTraining accuracy: 0.8339318633079529\n",
      "Step: 3300  \tValid loss: 0.3149030804634094\n",
      "Step: 3400  \tTraining loss: 0.3144749104976654\n",
      "Step: 3400  \tTraining accuracy: 0.8342769145965576\n",
      "Step: 3400  \tValid loss: 0.3141316771507263\n",
      "Step: 3500  \tTraining loss: 0.3138791024684906\n",
      "Step: 3500  \tTraining accuracy: 0.8345634937286377\n",
      "Step: 3500  \tValid loss: 0.3133792281150818\n",
      "Step: 3600  \tTraining loss: 0.313316285610199\n",
      "Step: 3600  \tTraining accuracy: 0.834815263748169\n",
      "Step: 3600  \tValid loss: 0.3126479685306549\n",
      "Step: 3700  \tTraining loss: 0.31278565526008606\n",
      "Step: 3700  \tTraining accuracy: 0.8350350856781006\n",
      "Step: 3700  \tValid loss: 0.311939537525177\n",
      "Step: 3800  \tTraining loss: 0.3122859597206116\n",
      "Step: 3800  \tTraining accuracy: 0.8352431654930115\n",
      "Step: 3800  \tValid loss: 0.31125515699386597\n",
      "Step: 3900  \tTraining loss: 0.31181615591049194\n",
      "Step: 3900  \tTraining accuracy: 0.8354576230049133\n",
      "Step: 3900  \tValid loss: 0.31059587001800537\n",
      "Step: 4000  \tTraining loss: 0.3113747835159302\n",
      "Step: 4000  \tTraining accuracy: 0.8356444835662842\n",
      "Step: 4000  \tValid loss: 0.3099622130393982\n",
      "Step: 4100  \tTraining loss: 0.3109607398509979\n",
      "Step: 4100  \tTraining accuracy: 0.8358057141304016\n",
      "Step: 4100  \tValid loss: 0.3093542754650116\n",
      "Step: 4200  \tTraining loss: 0.31057262420654297\n",
      "Step: 4200  \tTraining accuracy: 0.8359752297401428\n",
      "Step: 4200  \tValid loss: 0.3087720274925232\n",
      "Step: 4300  \tTraining loss: 0.31020915508270264\n",
      "Step: 4300  \tTraining accuracy: 0.8361523151397705\n",
      "Step: 4300  \tValid loss: 0.3082151710987091\n",
      "Step: 4400  \tTraining loss: 0.3098689615726471\n",
      "Step: 4400  \tTraining accuracy: 0.836321234703064\n",
      "Step: 4400  \tValid loss: 0.3076832890510559\n",
      "Step: 4500  \tTraining loss: 0.30955076217651367\n",
      "Step: 4500  \tTraining accuracy: 0.836482584476471\n",
      "Step: 4500  \tValid loss: 0.30717551708221436\n",
      "Step: 4600  \tTraining loss: 0.30925312638282776\n",
      "Step: 4600  \tTraining accuracy: 0.8366368412971497\n",
      "Step: 4600  \tValid loss: 0.30669137835502625\n",
      "Step: 4700  \tTraining loss: 0.30897513031959534\n",
      "Step: 4700  \tTraining accuracy: 0.8367844820022583\n",
      "Step: 4700  \tValid loss: 0.30622994899749756\n",
      "Step: 4800  \tTraining loss: 0.30871516466140747\n",
      "Step: 4800  \tTraining accuracy: 0.836939811706543\n",
      "Step: 4800  \tValid loss: 0.3057902157306671\n",
      "Step: 4900  \tTraining loss: 0.30847227573394775\n",
      "Step: 4900  \tTraining accuracy: 0.8370887637138367\n",
      "Step: 4900  \tValid loss: 0.30537131428718567\n",
      "Step: 5000  \tTraining loss: 0.3082452118396759\n",
      "Step: 5000  \tTraining accuracy: 0.8372317552566528\n",
      "Step: 5000  \tValid loss: 0.3049722909927368\n",
      "Step: 5100  \tTraining loss: 0.3080331087112427\n",
      "Step: 5100  \tTraining accuracy: 0.8373690247535706\n",
      "Step: 5100  \tValid loss: 0.3045922517776489\n",
      "Step: 5200  \tTraining loss: 0.30783456563949585\n",
      "Step: 5200  \tTraining accuracy: 0.8375009894371033\n",
      "Step: 5200  \tValid loss: 0.3042302429676056\n",
      "Step: 5300  \tTraining loss: 0.3076489269733429\n",
      "Step: 5300  \tTraining accuracy: 0.8376152515411377\n",
      "Step: 5300  \tValid loss: 0.3038853704929352\n",
      "Step: 5400  \tTraining loss: 0.307475209236145\n",
      "Step: 5400  \tTraining accuracy: 0.8377376794815063\n",
      "Step: 5400  \tValid loss: 0.30355674028396606\n",
      "Step: 5500  \tTraining loss: 0.307312548160553\n",
      "Step: 5500  \tTraining accuracy: 0.8378677368164062\n",
      "Step: 5500  \tValid loss: 0.30324357748031616\n",
      "Step: 5600  \tTraining loss: 0.30716007947921753\n",
      "Step: 5600  \tTraining accuracy: 0.8380051255226135\n",
      "Step: 5600  \tValid loss: 0.30294492840766907\n",
      "Step: 5700  \tTraining loss: 0.3070172369480133\n",
      "Step: 5700  \tTraining accuracy: 0.83814936876297\n",
      "Step: 5700  \tValid loss: 0.30266010761260986\n",
      "Step: 5800  \tTraining loss: 0.30688315629959106\n",
      "Step: 5800  \tTraining accuracy: 0.8382770419120789\n",
      "Step: 5800  \tValid loss: 0.30238837003707886\n",
      "Step: 5900  \tTraining loss: 0.3067571818828583\n",
      "Step: 5900  \tTraining accuracy: 0.8384003043174744\n",
      "Step: 5900  \tValid loss: 0.30212897062301636\n",
      "Step: 6000  \tTraining loss: 0.30663883686065674\n",
      "Step: 6000  \tTraining accuracy: 0.8385195136070251\n",
      "Step: 6000  \tValid loss: 0.3018812835216522\n",
      "Step: 6100  \tTraining loss: 0.3065274655818939\n",
      "Step: 6100  \tTraining accuracy: 0.838634729385376\n",
      "Step: 6100  \tValid loss: 0.30164459347724915\n",
      "Step: 6200  \tTraining loss: 0.306422621011734\n",
      "Step: 6200  \tTraining accuracy: 0.8387569785118103\n",
      "Step: 6200  \tValid loss: 0.3014184236526489\n",
      "Step: 6300  \tTraining loss: 0.306323766708374\n",
      "Step: 6300  \tTraining accuracy: 0.8388753533363342\n",
      "Step: 6300  \tValid loss: 0.30120208859443665\n",
      "Step: 6400  \tTraining loss: 0.30623045563697815\n",
      "Step: 6400  \tTraining accuracy: 0.8389794826507568\n",
      "Step: 6400  \tValid loss: 0.3009951412677765\n",
      "Step: 6500  \tTraining loss: 0.3061424195766449\n",
      "Step: 6500  \tTraining accuracy: 0.8390804529190063\n",
      "Step: 6500  \tValid loss: 0.3007970452308655\n",
      "Step: 6600  \tTraining loss: 0.30605897307395935\n",
      "Step: 6600  \tTraining accuracy: 0.8391985893249512\n",
      "Step: 6600  \tValid loss: 0.3006073236465454\n",
      "Step: 6700  \tTraining loss: 0.3059800863265991\n",
      "Step: 6700  \tTraining accuracy: 0.8393031358718872\n",
      "Step: 6700  \tValid loss: 0.3004254698753357\n",
      "Step: 6800  \tTraining loss: 0.30590522289276123\n",
      "Step: 6800  \tTraining accuracy: 0.8394144773483276\n",
      "Step: 6800  \tValid loss: 0.3002511262893677\n",
      "Step: 6900  \tTraining loss: 0.3058340847492218\n",
      "Step: 6900  \tTraining accuracy: 0.8395225405693054\n",
      "Step: 6900  \tValid loss: 0.3000839650630951\n",
      "Step: 7000  \tTraining loss: 0.30576661229133606\n",
      "Step: 7000  \tTraining accuracy: 0.8396275043487549\n",
      "Step: 7000  \tValid loss: 0.2999234199523926\n",
      "Step: 7100  \tTraining loss: 0.30570223927497864\n",
      "Step: 7100  \tTraining accuracy: 0.8397200703620911\n",
      "Step: 7100  \tValid loss: 0.2997693717479706\n",
      "Step: 7200  \tTraining loss: 0.3056408762931824\n",
      "Step: 7200  \tTraining accuracy: 0.8398100733757019\n",
      "Step: 7200  \tValid loss: 0.2996213138103485\n",
      "Step: 7300  \tTraining loss: 0.3055824339389801\n",
      "Step: 7300  \tTraining accuracy: 0.8398975729942322\n",
      "Step: 7300  \tValid loss: 0.2994789481163025\n",
      "Step: 7400  \tTraining loss: 0.30552637577056885\n",
      "Step: 7400  \tTraining accuracy: 0.8399916887283325\n",
      "Step: 7400  \tValid loss: 0.29934194684028625\n",
      "Step: 7500  \tTraining loss: 0.30547279119491577\n",
      "Step: 7500  \tTraining accuracy: 0.8400833010673523\n",
      "Step: 7500  \tValid loss: 0.29921016097068787\n",
      "Step: 7600  \tTraining loss: 0.3054213523864746\n",
      "Step: 7600  \tTraining accuracy: 0.840172529220581\n",
      "Step: 7600  \tValid loss: 0.2990832030773163\n",
      "Step: 7700  \tTraining loss: 0.3053721487522125\n",
      "Step: 7700  \tTraining accuracy: 0.8402593731880188\n",
      "Step: 7700  \tValid loss: 0.2989608943462372\n",
      "Step: 7800  \tTraining loss: 0.30532461404800415\n",
      "Step: 7800  \tTraining accuracy: 0.8403439521789551\n",
      "Step: 7800  \tValid loss: 0.2988430857658386\n",
      "Step: 7900  \tTraining loss: 0.30527883768081665\n",
      "Step: 7900  \tTraining accuracy: 0.8404264450073242\n",
      "Step: 7900  \tValid loss: 0.2987292408943176\n",
      "Step: 8000  \tTraining loss: 0.30523476004600525\n",
      "Step: 8000  \tTraining accuracy: 0.8405067920684814\n",
      "Step: 8000  \tValid loss: 0.29861947894096375\n",
      "Step: 8100  \tTraining loss: 0.30519217252731323\n",
      "Step: 8100  \tTraining accuracy: 0.8405851721763611\n",
      "Step: 8100  \tValid loss: 0.29851335287094116\n",
      "Step: 8200  \tTraining loss: 0.30515095591545105\n",
      "Step: 8200  \tTraining accuracy: 0.8406616449356079\n",
      "Step: 8200  \tValid loss: 0.2984108030796051\n",
      "Step: 8300  \tTraining loss: 0.3051110506057739\n",
      "Step: 8300  \tTraining accuracy: 0.8407362699508667\n",
      "Step: 8300  \tValid loss: 0.29831168055534363\n",
      "Step: 8400  \tTraining loss: 0.30507224798202515\n",
      "Step: 8400  \tTraining accuracy: 0.8408091068267822\n",
      "Step: 8400  \tValid loss: 0.29821568727493286\n",
      "Step: 8500  \tTraining loss: 0.3050345778465271\n",
      "Step: 8500  \tTraining accuracy: 0.8408802151679993\n",
      "Step: 8500  \tValid loss: 0.29812270402908325\n",
      "Step: 8600  \tTraining loss: 0.30499789118766785\n",
      "Step: 8600  \tTraining accuracy: 0.8409574031829834\n",
      "Step: 8600  \tValid loss: 0.2980327010154724\n",
      "Step: 8700  \tTraining loss: 0.3049621880054474\n",
      "Step: 8700  \tTraining accuracy: 0.8410328030586243\n",
      "Step: 8700  \tValid loss: 0.2979453206062317\n",
      "Step: 8800  \tTraining loss: 0.3049273192882538\n",
      "Step: 8800  \tTraining accuracy: 0.8411064743995667\n",
      "Step: 8800  \tValid loss: 0.2978605628013611\n",
      "Step: 8900  \tTraining loss: 0.30489325523376465\n",
      "Step: 8900  \tTraining accuracy: 0.8411784768104553\n",
      "Step: 8900  \tValid loss: 0.2977781593799591\n",
      "Step: 9000  \tTraining loss: 0.30485978722572327\n",
      "Step: 9000  \tTraining accuracy: 0.8412489295005798\n",
      "Step: 9000  \tValid loss: 0.29769814014434814\n",
      "Step: 9100  \tTraining loss: 0.30482712388038635\n",
      "Step: 9100  \tTraining accuracy: 0.8413177728652954\n",
      "Step: 9100  \tValid loss: 0.2976202368736267\n",
      "Step: 9200  \tTraining loss: 0.3047950267791748\n",
      "Step: 9200  \tTraining accuracy: 0.8413851261138916\n",
      "Step: 9200  \tValid loss: 0.2975445091724396\n",
      "Step: 9300  \tTraining loss: 0.3047634959220886\n",
      "Step: 9300  \tTraining accuracy: 0.8414581418037415\n",
      "Step: 9300  \tValid loss: 0.2974707782268524\n",
      "Step: 9400  \tTraining loss: 0.30473244190216064\n",
      "Step: 9400  \tTraining accuracy: 0.8415225744247437\n",
      "Step: 9400  \tValid loss: 0.29739874601364136\n",
      "Step: 9500  \tTraining loss: 0.30470195412635803\n",
      "Step: 9500  \tTraining accuracy: 0.841585636138916\n",
      "Step: 9500  \tValid loss: 0.29732853174209595\n",
      "Step: 9600  \tTraining loss: 0.3046717345714569\n",
      "Step: 9600  \tTraining accuracy: 0.8416473269462585\n",
      "Step: 9600  \tValid loss: 0.29726001620292664\n",
      "Step: 9700  \tTraining loss: 0.3046419322490692\n",
      "Step: 9700  \tTraining accuracy: 0.8417077660560608\n",
      "Step: 9700  \tValid loss: 0.2971930205821991\n",
      "Step: 9800  \tTraining loss: 0.30461254715919495\n",
      "Step: 9800  \tTraining accuracy: 0.8417670130729675\n",
      "Step: 9800  \tValid loss: 0.29712754487991333\n",
      "Step: 9900  \tTraining loss: 0.3045835494995117\n",
      "Step: 9900  \tTraining accuracy: 0.841825008392334\n",
      "Step: 9900  \tValid loss: 0.2970633804798126\n",
      "Step: 10000  \tTraining loss: 0.3045547902584076\n",
      "Step: 10000  \tTraining accuracy: 0.8418818116188049\n",
      "Step: 10000  \tValid loss: 0.29700061678886414\n",
      "Step: 10100  \tTraining loss: 0.304526150226593\n",
      "Step: 10100  \tTraining accuracy: 0.8419309258460999\n",
      "Step: 10100  \tValid loss: 0.29693910479545593\n",
      "Step: 10200  \tTraining loss: 0.3044978678226471\n",
      "Step: 10200  \tTraining accuracy: 0.8419790863990784\n",
      "Step: 10200  \tValid loss: 0.2968786656856537\n",
      "Step: 10300  \tTraining loss: 0.3044698238372803\n",
      "Step: 10300  \tTraining accuracy: 0.8420262932777405\n",
      "Step: 10300  \tValid loss: 0.2968193590641022\n",
      "Step: 10400  \tTraining loss: 0.30444180965423584\n",
      "Step: 10400  \tTraining accuracy: 0.8420725464820862\n",
      "Step: 10400  \tValid loss: 0.29676109552383423\n",
      "Step: 10500  \tTraining loss: 0.30441394448280334\n",
      "Step: 10500  \tTraining accuracy: 0.8421242833137512\n",
      "Step: 10500  \tValid loss: 0.2967037558555603\n",
      "Step: 10600  \tTraining loss: 0.30438628792762756\n",
      "Step: 10600  \tTraining accuracy: 0.8421813249588013\n",
      "Step: 10600  \tValid loss: 0.2966473400592804\n",
      "Step: 10700  \tTraining loss: 0.3043588101863861\n",
      "Step: 10700  \tTraining accuracy: 0.8422373533248901\n",
      "Step: 10700  \tValid loss: 0.29659178853034973\n",
      "Step: 10800  \tTraining loss: 0.3043312728404999\n",
      "Step: 10800  \tTraining accuracy: 0.8422861099243164\n",
      "Step: 10800  \tValid loss: 0.29653701186180115\n",
      "Step: 10900  \tTraining loss: 0.3043038249015808\n",
      "Step: 10900  \tTraining accuracy: 0.842333972454071\n",
      "Step: 10900  \tValid loss: 0.29648298025131226\n",
      "Step: 11000  \tTraining loss: 0.30427655577659607\n",
      "Step: 11000  \tTraining accuracy: 0.8423749208450317\n",
      "Step: 11000  \tValid loss: 0.2964296042919159\n",
      "Step: 11100  \tTraining loss: 0.30424925684928894\n",
      "Step: 11100  \tTraining accuracy: 0.8424150943756104\n",
      "Step: 11100  \tValid loss: 0.29637691378593445\n",
      "Step: 11200  \tTraining loss: 0.3042219281196594\n",
      "Step: 11200  \tTraining accuracy: 0.8424546122550964\n",
      "Step: 11200  \tValid loss: 0.29632478952407837\n",
      "Step: 11300  \tTraining loss: 0.3041945695877075\n",
      "Step: 11300  \tTraining accuracy: 0.8424933552742004\n",
      "Step: 11300  \tValid loss: 0.29627326130867004\n",
      "Step: 11400  \tTraining loss: 0.30416733026504517\n",
      "Step: 11400  \tTraining accuracy: 0.8425314426422119\n",
      "Step: 11400  \tValid loss: 0.2962222695350647\n",
      "Step: 11500  \tTraining loss: 0.30414003133773804\n",
      "Step: 11500  \tTraining accuracy: 0.8425688743591309\n",
      "Step: 11500  \tValid loss: 0.29617172479629517\n",
      "Step: 11600  \tTraining loss: 0.3041127622127533\n",
      "Step: 11600  \tTraining accuracy: 0.8426056504249573\n",
      "Step: 11600  \tValid loss: 0.29612162709236145\n",
      "Step: 11700  \tTraining loss: 0.304085373878479\n",
      "Step: 11700  \tTraining accuracy: 0.8426418304443359\n",
      "Step: 11700  \tValid loss: 0.29607200622558594\n",
      "Step: 11800  \tTraining loss: 0.3040579557418823\n",
      "Step: 11800  \tTraining accuracy: 0.8426830172538757\n",
      "Step: 11800  \tValid loss: 0.2960226833820343\n",
      "Step: 11900  \tTraining loss: 0.30403050780296326\n",
      "Step: 11900  \tTraining accuracy: 0.8427234888076782\n",
      "Step: 11900  \tValid loss: 0.29597386717796326\n",
      "Step: 12000  \tTraining loss: 0.304002970457077\n",
      "Step: 12000  \tTraining accuracy: 0.8427633047103882\n",
      "Step: 12000  \tValid loss: 0.2959253191947937\n",
      "Step: 12100  \tTraining loss: 0.303975373506546\n",
      "Step: 12100  \tTraining accuracy: 0.8428024053573608\n",
      "Step: 12100  \tValid loss: 0.2958770990371704\n",
      "Step: 12200  \tTraining loss: 0.30394768714904785\n",
      "Step: 12200  \tTraining accuracy: 0.8428409099578857\n",
      "Step: 12200  \tValid loss: 0.295829176902771\n",
      "Step: 12300  \tTraining loss: 0.3039199113845825\n",
      "Step: 12300  \tTraining accuracy: 0.8428788185119629\n",
      "Step: 12300  \tValid loss: 0.29578158259391785\n",
      "Step: 12400  \tTraining loss: 0.3038921058177948\n",
      "Step: 12400  \tTraining accuracy: 0.8429268002510071\n",
      "Step: 12400  \tValid loss: 0.2957341969013214\n",
      "Step: 12500  \tTraining loss: 0.30386418104171753\n",
      "Step: 12500  \tTraining accuracy: 0.8429740071296692\n",
      "Step: 12500  \tValid loss: 0.29568707942962646\n",
      "Step: 12600  \tTraining loss: 0.3038361370563507\n",
      "Step: 12600  \tTraining accuracy: 0.843025803565979\n",
      "Step: 12600  \tValid loss: 0.295640230178833\n",
      "Step: 12700  \tTraining loss: 0.30380794405937195\n",
      "Step: 12700  \tTraining accuracy: 0.8430767059326172\n",
      "Step: 12700  \tValid loss: 0.2955937385559082\n",
      "Step: 12800  \tTraining loss: 0.3037797808647156\n",
      "Step: 12800  \tTraining accuracy: 0.8431320786476135\n",
      "Step: 12800  \tValid loss: 0.29554733633995056\n",
      "Step: 12900  \tTraining loss: 0.30375149846076965\n",
      "Step: 12900  \tTraining accuracy: 0.8431865572929382\n",
      "Step: 12900  \tValid loss: 0.2955012619495392\n",
      "Step: 13000  \tTraining loss: 0.3037230670452118\n",
      "Step: 13000  \tTraining accuracy: 0.8432401418685913\n",
      "Step: 13000  \tValid loss: 0.2954554855823517\n",
      "Step: 13100  \tTraining loss: 0.303694486618042\n",
      "Step: 13100  \tTraining accuracy: 0.8432930111885071\n",
      "Step: 13100  \tValid loss: 0.29540982842445374\n",
      "Step: 13200  \tTraining loss: 0.3036659359931946\n",
      "Step: 13200  \tTraining accuracy: 0.8433449864387512\n",
      "Step: 13200  \tValid loss: 0.2953643202781677\n",
      "Step: 13300  \tTraining loss: 0.30363714694976807\n",
      "Step: 13300  \tTraining accuracy: 0.8434012532234192\n",
      "Step: 13300  \tValid loss: 0.295319139957428\n",
      "Step: 13400  \tTraining loss: 0.30360835790634155\n",
      "Step: 13400  \tTraining accuracy: 0.8434566259384155\n",
      "Step: 13400  \tValid loss: 0.2952742576599121\n",
      "Step: 13500  \tTraining loss: 0.3035793900489807\n",
      "Step: 13500  \tTraining accuracy: 0.8435161113739014\n",
      "Step: 13500  \tValid loss: 0.2952294647693634\n",
      "Step: 13600  \tTraining loss: 0.3035503625869751\n",
      "Step: 13600  \tTraining accuracy: 0.8435747623443604\n",
      "Step: 13600  \tValid loss: 0.29518502950668335\n",
      "Step: 13700  \tTraining loss: 0.30352118611335754\n",
      "Step: 13700  \tTraining accuracy: 0.8436373472213745\n",
      "Step: 13700  \tValid loss: 0.29514092206954956\n",
      "Step: 13800  \tTraining loss: 0.3034919798374176\n",
      "Step: 13800  \tTraining accuracy: 0.843699038028717\n",
      "Step: 13800  \tValid loss: 0.29509708285331726\n",
      "Step: 13900  \tTraining loss: 0.3034626543521881\n",
      "Step: 13900  \tTraining accuracy: 0.8437598943710327\n",
      "Step: 13900  \tValid loss: 0.29505330324172974\n",
      "Step: 14000  \tTraining loss: 0.30343326926231384\n",
      "Step: 14000  \tTraining accuracy: 0.843819797039032\n",
      "Step: 14000  \tValid loss: 0.2950098514556885\n",
      "Step: 14100  \tTraining loss: 0.3034038245677948\n",
      "Step: 14100  \tTraining accuracy: 0.8438836336135864\n",
      "Step: 14100  \tValid loss: 0.2949668765068054\n",
      "Step: 14200  \tTraining loss: 0.3033742308616638\n",
      "Step: 14200  \tTraining accuracy: 0.8439465165138245\n",
      "Step: 14200  \tValid loss: 0.2949241101741791\n",
      "Step: 14300  \tTraining loss: 0.30334463715553284\n",
      "Step: 14300  \tTraining accuracy: 0.8440085649490356\n",
      "Step: 14300  \tValid loss: 0.29488158226013184\n",
      "Step: 14400  \tTraining loss: 0.3033148944377899\n",
      "Step: 14400  \tTraining accuracy: 0.8440697193145752\n",
      "Step: 14400  \tValid loss: 0.29483941197395325\n",
      "Step: 14500  \tTraining loss: 0.3032851815223694\n",
      "Step: 14500  \tTraining accuracy: 0.8441254496574402\n",
      "Step: 14500  \tValid loss: 0.2947975695133209\n",
      "Step: 14600  \tTraining loss: 0.3032553493976593\n",
      "Step: 14600  \tTraining accuracy: 0.8441804051399231\n",
      "Step: 14600  \tValid loss: 0.29475608468055725\n",
      "Step: 14700  \tTraining loss: 0.30322545766830444\n",
      "Step: 14700  \tTraining accuracy: 0.8442346453666687\n",
      "Step: 14700  \tValid loss: 0.2947150766849518\n",
      "Step: 14800  \tTraining loss: 0.3031955063343048\n",
      "Step: 14800  \tTraining accuracy: 0.8442835807800293\n",
      "Step: 14800  \tValid loss: 0.29467451572418213\n",
      "Step: 14900  \tTraining loss: 0.30316561460494995\n",
      "Step: 14900  \tTraining accuracy: 0.8443319201469421\n",
      "Step: 14900  \tValid loss: 0.2946341931819916\n",
      "Step: 15000  \tTraining loss: 0.3031357228755951\n",
      "Step: 15000  \tTraining accuracy: 0.8443751335144043\n",
      "Step: 15000  \tValid loss: 0.29459431767463684\n",
      "Step: 15100  \tTraining loss: 0.3031056821346283\n",
      "Step: 15100  \tTraining accuracy: 0.8444178104400635\n",
      "Step: 15100  \tValid loss: 0.29455482959747314\n",
      "Step: 15200  \tTraining loss: 0.30307576060295105\n",
      "Step: 15200  \tTraining accuracy: 0.8444598913192749\n",
      "Step: 15200  \tValid loss: 0.29451581835746765\n",
      "Step: 15300  \tTraining loss: 0.30304574966430664\n",
      "Step: 15300  \tTraining accuracy: 0.8445014357566833\n",
      "Step: 15300  \tValid loss: 0.29447734355926514\n",
      "Step: 15400  \tTraining loss: 0.3030157685279846\n",
      "Step: 15400  \tTraining accuracy: 0.844538152217865\n",
      "Step: 15400  \tValid loss: 0.2944394648075104\n",
      "Step: 15500  \tTraining loss: 0.3029857575893402\n",
      "Step: 15500  \tTraining accuracy: 0.8445743322372437\n",
      "Step: 15500  \tValid loss: 0.2944019138813019\n",
      "Step: 15600  \tTraining loss: 0.30295583605766296\n",
      "Step: 15600  \tTraining accuracy: 0.8446100950241089\n",
      "Step: 15600  \tValid loss: 0.2943648099899292\n",
      "Step: 15700  \tTraining loss: 0.30292579531669617\n",
      "Step: 15700  \tTraining accuracy: 0.8446453809738159\n",
      "Step: 15700  \tValid loss: 0.2943282723426819\n",
      "Step: 15800  \tTraining loss: 0.3028958737850189\n",
      "Step: 15800  \tTraining accuracy: 0.8446802496910095\n",
      "Step: 15800  \tValid loss: 0.29429230093955994\n",
      "Step: 15900  \tTraining loss: 0.30286601185798645\n",
      "Step: 15900  \tTraining accuracy: 0.8447146415710449\n",
      "Step: 15900  \tValid loss: 0.29425686597824097\n",
      "Step: 16000  \tTraining loss: 0.30283620953559875\n",
      "Step: 16000  \tTraining accuracy: 0.8447527289390564\n",
      "Step: 16000  \tValid loss: 0.29422202706336975\n",
      "Step: 16100  \tTraining loss: 0.30280640721321106\n",
      "Step: 16100  \tTraining accuracy: 0.8447903990745544\n",
      "Step: 16100  \tValid loss: 0.29418760538101196\n",
      "Step: 16200  \tTraining loss: 0.30277666449546814\n",
      "Step: 16200  \tTraining accuracy: 0.8448275923728943\n",
      "Step: 16200  \tValid loss: 0.29415372014045715\n",
      "Step: 16300  \tTraining loss: 0.3027469515800476\n",
      "Step: 16300  \tTraining accuracy: 0.8448643088340759\n",
      "Step: 16300  \tValid loss: 0.2941204309463501\n",
      "Step: 16400  \tTraining loss: 0.3027174472808838\n",
      "Step: 16400  \tTraining accuracy: 0.8448965549468994\n",
      "Step: 16400  \tValid loss: 0.29408788681030273\n",
      "Step: 16500  \tTraining loss: 0.3026879131793976\n",
      "Step: 16500  \tTraining accuracy: 0.8449283838272095\n",
      "Step: 16500  \tValid loss: 0.29405587911605835\n",
      "Step: 16600  \tTraining loss: 0.3026584982872009\n",
      "Step: 16600  \tTraining accuracy: 0.8449597954750061\n",
      "Step: 16600  \tValid loss: 0.29402443766593933\n",
      "Step: 16700  \tTraining loss: 0.3026292026042938\n",
      "Step: 16700  \tTraining accuracy: 0.8449909090995789\n",
      "Step: 16700  \tValid loss: 0.2939937114715576\n",
      "Step: 16800  \tTraining loss: 0.30259984731674194\n",
      "Step: 16800  \tTraining accuracy: 0.8450216054916382\n",
      "Step: 16800  \tValid loss: 0.29396361112594604\n",
      "Step: 16900  \tTraining loss: 0.30257073044776917\n",
      "Step: 16900  \tTraining accuracy: 0.8450518846511841\n",
      "Step: 16900  \tValid loss: 0.2939338684082031\n",
      "Step: 17000  \tTraining loss: 0.30254173278808594\n",
      "Step: 17000  \tTraining accuracy: 0.8450818657875061\n",
      "Step: 17000  \tValid loss: 0.2939048409461975\n",
      "Step: 17100  \tTraining loss: 0.3025128245353699\n",
      "Step: 17100  \tTraining accuracy: 0.8451154232025146\n",
      "Step: 17100  \tValid loss: 0.29387643933296204\n",
      "Step: 17200  \tTraining loss: 0.30248400568962097\n",
      "Step: 17200  \tTraining accuracy: 0.8451523780822754\n",
      "Step: 17200  \tValid loss: 0.29384857416152954\n",
      "Step: 17300  \tTraining loss: 0.3024553954601288\n",
      "Step: 17300  \tTraining accuracy: 0.8451889157295227\n",
      "Step: 17300  \tValid loss: 0.29382139444351196\n",
      "Step: 17400  \tTraining loss: 0.30242690443992615\n",
      "Step: 17400  \tTraining accuracy: 0.8452212810516357\n",
      "Step: 17400  \tValid loss: 0.29379481077194214\n",
      "Step: 17500  \tTraining loss: 0.3023984730243683\n",
      "Step: 17500  \tTraining accuracy: 0.8452569842338562\n",
      "Step: 17500  \tValid loss: 0.29376909136772156\n",
      "Step: 17600  \tTraining loss: 0.30237022042274475\n",
      "Step: 17600  \tTraining accuracy: 0.845292329788208\n",
      "Step: 17600  \tValid loss: 0.29374396800994873\n",
      "Step: 17700  \tTraining loss: 0.30234211683273315\n",
      "Step: 17700  \tTraining accuracy: 0.8453272581100464\n",
      "Step: 17700  \tValid loss: 0.29371926188468933\n",
      "Step: 17800  \tTraining loss: 0.3023141622543335\n",
      "Step: 17800  \tTraining accuracy: 0.8453580737113953\n",
      "Step: 17800  \tValid loss: 0.2936951518058777\n",
      "Step: 17900  \tTraining loss: 0.3022863566875458\n",
      "Step: 17900  \tTraining accuracy: 0.8453885316848755\n",
      "Step: 17900  \tValid loss: 0.29367178678512573\n",
      "Step: 18000  \tTraining loss: 0.3022587299346924\n",
      "Step: 18000  \tTraining accuracy: 0.8454186916351318\n",
      "Step: 18000  \tValid loss: 0.29364898800849915\n",
      "Step: 18100  \tTraining loss: 0.3022311329841614\n",
      "Step: 18100  \tTraining accuracy: 0.8454521298408508\n",
      "Step: 18100  \tValid loss: 0.2936268448829651\n",
      "Step: 18200  \tTraining loss: 0.3022037744522095\n",
      "Step: 18200  \tTraining accuracy: 0.8454815745353699\n",
      "Step: 18200  \tValid loss: 0.29360532760620117\n",
      "Step: 18300  \tTraining loss: 0.30217650532722473\n",
      "Step: 18300  \tTraining accuracy: 0.845510721206665\n",
      "Step: 18300  \tValid loss: 0.2935843765735626\n",
      "Step: 18400  \tTraining loss: 0.30214953422546387\n",
      "Step: 18400  \tTraining accuracy: 0.8455395102500916\n",
      "Step: 18400  \tValid loss: 0.2935639023780823\n",
      "Step: 18500  \tTraining loss: 0.3021226227283478\n",
      "Step: 18500  \tTraining accuracy: 0.8455715775489807\n",
      "Step: 18500  \tValid loss: 0.2935441732406616\n",
      "Step: 18600  \tTraining loss: 0.3020959794521332\n",
      "Step: 18600  \tTraining accuracy: 0.845603346824646\n",
      "Step: 18600  \tValid loss: 0.29352492094039917\n",
      "Step: 18700  \tTraining loss: 0.30206942558288574\n",
      "Step: 18700  \tTraining accuracy: 0.8456346988677979\n",
      "Step: 18700  \tValid loss: 0.29350632429122925\n",
      "Step: 18800  \tTraining loss: 0.3020431101322174\n",
      "Step: 18800  \tTraining accuracy: 0.8456657528877258\n",
      "Step: 18800  \tValid loss: 0.2934882938861847\n",
      "Step: 18900  \tTraining loss: 0.30201685428619385\n",
      "Step: 18900  \tTraining accuracy: 0.8456965088844299\n",
      "Step: 18900  \tValid loss: 0.2934706211090088\n",
      "Step: 19000  \tTraining loss: 0.3019907772541046\n",
      "Step: 19000  \tTraining accuracy: 0.8457269072532654\n",
      "Step: 19000  \tValid loss: 0.2934536635875702\n",
      "Step: 19100  \tTraining loss: 0.3019649088382721\n",
      "Step: 19100  \tTraining accuracy: 0.845757007598877\n",
      "Step: 19100  \tValid loss: 0.29343724250793457\n",
      "Step: 19200  \tTraining loss: 0.3019392490386963\n",
      "Step: 19200  \tTraining accuracy: 0.8457868099212646\n",
      "Step: 19200  \tValid loss: 0.2934214174747467\n",
      "Step: 19300  \tTraining loss: 0.30191370844841003\n",
      "Step: 19300  \tTraining accuracy: 0.8458162546157837\n",
      "Step: 19300  \tValid loss: 0.2934059202671051\n",
      "Step: 19400  \tTraining loss: 0.3018883764743805\n",
      "Step: 19400  \tTraining accuracy: 0.8458420038223267\n",
      "Step: 19400  \tValid loss: 0.29339104890823364\n",
      "Step: 19500  \tTraining loss: 0.3018631339073181\n",
      "Step: 19500  \tTraining accuracy: 0.8458674550056458\n",
      "Step: 19500  \tValid loss: 0.2933768033981323\n",
      "Step: 19600  \tTraining loss: 0.3018381595611572\n",
      "Step: 19600  \tTraining accuracy: 0.8458926677703857\n",
      "Step: 19600  \tValid loss: 0.29336291551589966\n",
      "Step: 19700  \tTraining loss: 0.3018132746219635\n",
      "Step: 19700  \tTraining accuracy: 0.8459176421165466\n",
      "Step: 19700  \tValid loss: 0.29334962368011475\n",
      "Step: 19800  \tTraining loss: 0.3017886281013489\n",
      "Step: 19800  \tTraining accuracy: 0.8459423184394836\n",
      "Step: 19800  \tValid loss: 0.29333677887916565\n",
      "Step: 19900  \tTraining loss: 0.3017641603946686\n",
      "Step: 19900  \tTraining accuracy: 0.8459667563438416\n",
      "Step: 19900  \tValid loss: 0.29332441091537476\n",
      "Step: 20000  \tTraining loss: 0.30173981189727783\n",
      "Step: 20000  \tTraining accuracy: 0.8459909558296204\n",
      "Step: 20000  \tValid loss: 0.2933126986026764\n",
      "Step: 20100  \tTraining loss: 0.3017156422138214\n",
      "Step: 20100  \tTraining accuracy: 0.8460149168968201\n",
      "Step: 20100  \tValid loss: 0.2933012545108795\n",
      "Step: 20200  \tTraining loss: 0.3016916513442993\n",
      "Step: 20200  \tTraining accuracy: 0.8460386395454407\n",
      "Step: 20200  \tValid loss: 0.2932901680469513\n",
      "Step: 20300  \tTraining loss: 0.30166780948638916\n",
      "Step: 20300  \tTraining accuracy: 0.846062183380127\n",
      "Step: 20300  \tValid loss: 0.2932797074317932\n",
      "Step: 20400  \tTraining loss: 0.30164408683776855\n",
      "Step: 20400  \tTraining accuracy: 0.8460854291915894\n",
      "Step: 20400  \tValid loss: 0.2932696044445038\n",
      "Step: 20500  \tTraining loss: 0.30162063241004944\n",
      "Step: 20500  \tTraining accuracy: 0.8461117148399353\n",
      "Step: 20500  \tValid loss: 0.2932601273059845\n",
      "Step: 20600  \tTraining loss: 0.3015972077846527\n",
      "Step: 20600  \tTraining accuracy: 0.8461377024650574\n",
      "Step: 20600  \tValid loss: 0.2932509481906891\n",
      "Step: 20700  \tTraining loss: 0.30157411098480225\n",
      "Step: 20700  \tTraining accuracy: 0.8461634516716003\n",
      "Step: 20700  \tValid loss: 0.2932421863079071\n",
      "Step: 20800  \tTraining loss: 0.30155104398727417\n",
      "Step: 20800  \tTraining accuracy: 0.846189022064209\n",
      "Step: 20800  \tValid loss: 0.29323384165763855\n",
      "Step: 20900  \tTraining loss: 0.3015281558036804\n",
      "Step: 20900  \tTraining accuracy: 0.8462142944335938\n",
      "Step: 20900  \tValid loss: 0.29322588443756104\n",
      "Step: 21000  \tTraining loss: 0.30150550603866577\n",
      "Step: 21000  \tTraining accuracy: 0.8462424874305725\n",
      "Step: 21000  \tValid loss: 0.29321837425231934\n",
      "Step: 21100  \tTraining loss: 0.3014828860759735\n",
      "Step: 21100  \tTraining accuracy: 0.8462703824043274\n",
      "Step: 21100  \tValid loss: 0.2932112216949463\n",
      "Step: 21200  \tTraining loss: 0.30146047472953796\n",
      "Step: 21200  \tTraining accuracy: 0.846298098564148\n",
      "Step: 21200  \tValid loss: 0.29320457577705383\n",
      "Step: 21300  \tTraining loss: 0.30143824219703674\n",
      "Step: 21300  \tTraining accuracy: 0.8463254570960999\n",
      "Step: 21300  \tValid loss: 0.2931981682777405\n",
      "Step: 21400  \tTraining loss: 0.30141615867614746\n",
      "Step: 21400  \tTraining accuracy: 0.8463526368141174\n",
      "Step: 21400  \tValid loss: 0.29319217801094055\n",
      "Step: 21500  \tTraining loss: 0.30139416456222534\n",
      "Step: 21500  \tTraining accuracy: 0.8463795185089111\n",
      "Step: 21500  \tValid loss: 0.2931865155696869\n",
      "Step: 21600  \tTraining loss: 0.30137234926223755\n",
      "Step: 21600  \tTraining accuracy: 0.8464031219482422\n",
      "Step: 21600  \tValid loss: 0.2931813895702362\n",
      "Step: 21700  \tTraining loss: 0.3013507127761841\n",
      "Step: 21700  \tTraining accuracy: 0.8464356660842896\n",
      "Step: 21700  \tValid loss: 0.293176531791687\n",
      "Step: 21800  \tTraining loss: 0.30132919549942017\n",
      "Step: 21800  \tTraining accuracy: 0.8464678525924683\n",
      "Step: 21800  \tValid loss: 0.2931720018386841\n",
      "Step: 21900  \tTraining loss: 0.30130764842033386\n",
      "Step: 21900  \tTraining accuracy: 0.8464998006820679\n",
      "Step: 21900  \tValid loss: 0.29316771030426025\n",
      "Step: 22000  \tTraining loss: 0.301286518573761\n",
      "Step: 22000  \tTraining accuracy: 0.8465315103530884\n",
      "Step: 22000  \tValid loss: 0.29316380620002747\n",
      "Step: 22100  \tTraining loss: 0.3012653589248657\n",
      "Step: 22100  \tTraining accuracy: 0.8465628623962402\n",
      "Step: 22100  \tValid loss: 0.29316022992134094\n",
      "Step: 22200  \tTraining loss: 0.3012444078922272\n",
      "Step: 22200  \tTraining accuracy: 0.8465939164161682\n",
      "Step: 22200  \tValid loss: 0.29315677285194397\n",
      "Step: 22300  \tTraining loss: 0.3012235462665558\n",
      "Step: 22300  \tTraining accuracy: 0.8466247320175171\n",
      "Step: 22300  \tValid loss: 0.2931537628173828\n",
      "Step: 22400  \tTraining loss: 0.3012027442455292\n",
      "Step: 22400  \tTraining accuracy: 0.8466552495956421\n",
      "Step: 22400  \tValid loss: 0.2931511104106903\n",
      "Step: 22500  \tTraining loss: 0.30118224024772644\n",
      "Step: 22500  \tTraining accuracy: 0.846685528755188\n",
      "Step: 22500  \tValid loss: 0.29314887523651123\n",
      "Step: 22600  \tTraining loss: 0.30116167664527893\n",
      "Step: 22600  \tTraining accuracy: 0.8467214107513428\n",
      "Step: 22600  \tValid loss: 0.29314669966697693\n",
      "Step: 22700  \tTraining loss: 0.3011413812637329\n",
      "Step: 22700  \tTraining accuracy: 0.8467598557472229\n",
      "Step: 22700  \tValid loss: 0.29314473271369934\n",
      "Step: 22800  \tTraining loss: 0.30112117528915405\n",
      "Step: 22800  \tTraining accuracy: 0.8467980027198792\n",
      "Step: 22800  \tValid loss: 0.2931431233882904\n",
      "Step: 22900  \tTraining loss: 0.30110108852386475\n",
      "Step: 22900  \tTraining accuracy: 0.8468358516693115\n",
      "Step: 22900  \tValid loss: 0.2931419014930725\n",
      "Step: 23000  \tTraining loss: 0.3010810315608978\n",
      "Step: 23000  \tTraining accuracy: 0.8468733429908752\n",
      "Step: 23000  \tValid loss: 0.2931410074234009\n",
      "Step: 23100  \tTraining loss: 0.3010612428188324\n",
      "Step: 23100  \tTraining accuracy: 0.8469104766845703\n",
      "Step: 23100  \tValid loss: 0.2931402027606964\n",
      "Step: 23200  \tTraining loss: 0.3010413646697998\n",
      "Step: 23200  \tTraining accuracy: 0.8469473123550415\n",
      "Step: 23200  \tValid loss: 0.29313957691192627\n",
      "Step: 23300  \tTraining loss: 0.3010218143463135\n",
      "Step: 23300  \tTraining accuracy: 0.8469838500022888\n",
      "Step: 23300  \tValid loss: 0.2931392788887024\n",
      "Step: 23400  \tTraining loss: 0.30100223422050476\n",
      "Step: 23400  \tTraining accuracy: 0.8470200300216675\n",
      "Step: 23400  \tValid loss: 0.2931394875049591\n",
      "Step: 23500  \tTraining loss: 0.30098286271095276\n",
      "Step: 23500  \tTraining accuracy: 0.8470559120178223\n",
      "Step: 23500  \tValid loss: 0.2931397557258606\n",
      "Step: 23600  \tTraining loss: 0.30096349120140076\n",
      "Step: 23600  \tTraining accuracy: 0.8470914959907532\n",
      "Step: 23600  \tValid loss: 0.29314008355140686\n",
      "Step: 23700  \tTraining loss: 0.30094432830810547\n",
      "Step: 23700  \tTraining accuracy: 0.8471267819404602\n",
      "Step: 23700  \tValid loss: 0.29314082860946655\n",
      "Step: 23800  \tTraining loss: 0.30092519521713257\n",
      "Step: 23800  \tTraining accuracy: 0.8471618294715881\n",
      "Step: 23800  \tValid loss: 0.29314178228378296\n",
      "Step: 23900  \tTraining loss: 0.3009062111377716\n",
      "Step: 23900  \tTraining accuracy: 0.8471965193748474\n",
      "Step: 23900  \tValid loss: 0.29314297437667847\n",
      "Step: 24000  \tTraining loss: 0.3008872866630554\n",
      "Step: 24000  \tTraining accuracy: 0.8472309112548828\n",
      "Step: 24000  \tValid loss: 0.2931442856788635\n",
      "Step: 24100  \tTraining loss: 0.3008684813976288\n",
      "Step: 24100  \tTraining accuracy: 0.8472650647163391\n",
      "Step: 24100  \tValid loss: 0.2931458055973053\n",
      "Step: 24200  \tTraining loss: 0.3008497953414917\n",
      "Step: 24200  \tTraining accuracy: 0.8472988605499268\n",
      "Step: 24200  \tValid loss: 0.29314762353897095\n",
      "Step: 24300  \tTraining loss: 0.3008311688899994\n",
      "Step: 24300  \tTraining accuracy: 0.8473324179649353\n",
      "Step: 24300  \tValid loss: 0.2931496798992157\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.84736574\n",
      "Precision: 0.68421054\n",
      "Recall: 0.67241377\n",
      "F1 score: 0.8399973\n",
      "AUC: 0.7896552\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.847366   0.684211  0.672414  0.839997  0.789655  0.300829      0.847355   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.293139        0.84734   0.273728      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  24313.0  \n",
      "12\n",
      "(754, 5)\n",
      "(754, 1)\n",
      "(400, 5)\n",
      "(400, 1)\n",
      "(325, 5)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5886756777763367\n",
      "Step: 100  \tTraining accuracy: 0.7334217429161072\n",
      "Step: 100  \tValid loss: 0.6029013991355896\n",
      "Step: 200  \tTraining loss: 0.4562666118144989\n",
      "Step: 200  \tTraining accuracy: 0.7451858520507812\n",
      "Step: 200  \tValid loss: 0.5016122460365295\n",
      "Step: 300  \tTraining loss: 0.4330308437347412\n",
      "Step: 300  \tTraining accuracy: 0.7551185488700867\n",
      "Step: 300  \tValid loss: 0.48692700266838074\n",
      "Step: 400  \tTraining loss: 0.42323312163352966\n",
      "Step: 400  \tTraining accuracy: 0.7617029547691345\n",
      "Step: 400  \tValid loss: 0.47975975275039673\n",
      "Step: 500  \tTraining loss: 0.41384559869766235\n",
      "Step: 500  \tTraining accuracy: 0.7661169171333313\n",
      "Step: 500  \tValid loss: 0.4708558917045593\n",
      "Step: 600  \tTraining loss: 0.4049822688102722\n",
      "Step: 600  \tTraining accuracy: 0.771137535572052\n",
      "Step: 600  \tValid loss: 0.46257054805755615\n",
      "Step: 700  \tTraining loss: 0.39743751287460327\n",
      "Step: 700  \tTraining accuracy: 0.7755504846572876\n",
      "Step: 700  \tValid loss: 0.45473727583885193\n",
      "Step: 800  \tTraining loss: 0.39152514934539795\n",
      "Step: 800  \tTraining accuracy: 0.7795084118843079\n",
      "Step: 800  \tValid loss: 0.45065978169441223\n",
      "Step: 900  \tTraining loss: 0.3872041702270508\n",
      "Step: 900  \tTraining accuracy: 0.782615602016449\n",
      "Step: 900  \tValid loss: 0.4469314217567444\n",
      "Step: 1000  \tTraining loss: 0.38383328914642334\n",
      "Step: 1000  \tTraining accuracy: 0.785495936870575\n",
      "Step: 1000  \tValid loss: 0.44381004571914673\n",
      "Step: 1100  \tTraining loss: 0.380991131067276\n",
      "Step: 1100  \tTraining accuracy: 0.7881497740745544\n",
      "Step: 1100  \tValid loss: 0.4411114454269409\n",
      "Step: 1200  \tTraining loss: 0.37847185134887695\n",
      "Step: 1200  \tTraining accuracy: 0.7906361818313599\n",
      "Step: 1200  \tValid loss: 0.4387979805469513\n",
      "Step: 1300  \tTraining loss: 0.37603017687797546\n",
      "Step: 1300  \tTraining accuracy: 0.7929413318634033\n",
      "Step: 1300  \tValid loss: 0.4366306960582733\n",
      "Step: 1400  \tTraining loss: 0.37365037202835083\n",
      "Step: 1400  \tTraining accuracy: 0.7948551177978516\n",
      "Step: 1400  \tValid loss: 0.43453288078308105\n",
      "Step: 1500  \tTraining loss: 0.37117844820022583\n",
      "Step: 1500  \tTraining accuracy: 0.7964585423469543\n",
      "Step: 1500  \tValid loss: 0.43262192606925964\n",
      "Step: 1600  \tTraining loss: 0.3683156371116638\n",
      "Step: 1600  \tTraining accuracy: 0.7976372241973877\n",
      "Step: 1600  \tValid loss: 0.430991530418396\n",
      "Step: 1700  \tTraining loss: 0.36664924025535583\n",
      "Step: 1700  \tTraining accuracy: 0.7986321449279785\n",
      "Step: 1700  \tValid loss: 0.429168701171875\n",
      "Step: 1800  \tTraining loss: 0.3653532564640045\n",
      "Step: 1800  \tTraining accuracy: 0.799629271030426\n",
      "Step: 1800  \tValid loss: 0.427653968334198\n",
      "Step: 1900  \tTraining loss: 0.3642013967037201\n",
      "Step: 1900  \tTraining accuracy: 0.8006283044815063\n",
      "Step: 1900  \tValid loss: 0.42680948972702026\n",
      "Step: 2000  \tTraining loss: 0.3631507158279419\n",
      "Step: 2000  \tTraining accuracy: 0.8016981482505798\n",
      "Step: 2000  \tValid loss: 0.4257051944732666\n",
      "Step: 2100  \tTraining loss: 0.3624188303947449\n",
      "Step: 2100  \tTraining accuracy: 0.802564799785614\n",
      "Step: 2100  \tValid loss: 0.42493048310279846\n",
      "Step: 2200  \tTraining loss: 0.36184263229370117\n",
      "Step: 2200  \tTraining accuracy: 0.8033193945884705\n",
      "Step: 2200  \tValid loss: 0.4243272542953491\n",
      "Step: 2300  \tTraining loss: 0.3613797426223755\n",
      "Step: 2300  \tTraining accuracy: 0.804097056388855\n",
      "Step: 2300  \tValid loss: 0.4238574206829071\n",
      "Step: 2400  \tTraining loss: 0.36095568537712097\n",
      "Step: 2400  \tTraining accuracy: 0.8048373460769653\n",
      "Step: 2400  \tValid loss: 0.4234831929206848\n",
      "Step: 2500  \tTraining loss: 0.36060047149658203\n",
      "Step: 2500  \tTraining accuracy: 0.8055723905563354\n",
      "Step: 2500  \tValid loss: 0.42321768403053284\n",
      "Step: 2600  \tTraining loss: 0.3602985441684723\n",
      "Step: 2600  \tTraining accuracy: 0.8061968088150024\n",
      "Step: 2600  \tValid loss: 0.42289847135543823\n",
      "Step: 2700  \tTraining loss: 0.3599427342414856\n",
      "Step: 2700  \tTraining accuracy: 0.8067741394042969\n",
      "Step: 2700  \tValid loss: 0.4229135811328888\n",
      "Step: 2800  \tTraining loss: 0.3596974313259125\n",
      "Step: 2800  \tTraining accuracy: 0.8073094487190247\n",
      "Step: 2800  \tValid loss: 0.42264464497566223\n",
      "Step: 2900  \tTraining loss: 0.35943517088890076\n",
      "Step: 2900  \tTraining accuracy: 0.8077835440635681\n",
      "Step: 2900  \tValid loss: 0.42239460349082947\n",
      "Step: 3000  \tTraining loss: 0.35909613966941833\n",
      "Step: 3000  \tTraining accuracy: 0.8082254528999329\n",
      "Step: 3000  \tValid loss: 0.4222477674484253\n",
      "Step: 3100  \tTraining loss: 0.3588636517524719\n",
      "Step: 3100  \tTraining accuracy: 0.8086383938789368\n",
      "Step: 3100  \tValid loss: 0.42207375168800354\n",
      "Step: 3200  \tTraining loss: 0.35867223143577576\n",
      "Step: 3200  \tTraining accuracy: 0.8090251684188843\n",
      "Step: 3200  \tValid loss: 0.4218706786632538\n",
      "Step: 3300  \tTraining loss: 0.35850539803504944\n",
      "Step: 3300  \tTraining accuracy: 0.8093673586845398\n",
      "Step: 3300  \tValid loss: 0.4216902256011963\n",
      "Step: 3400  \tTraining loss: 0.3583452105522156\n",
      "Step: 3400  \tTraining accuracy: 0.8096890449523926\n",
      "Step: 3400  \tValid loss: 0.4215250015258789\n",
      "Step: 3500  \tTraining loss: 0.3581869304180145\n",
      "Step: 3500  \tTraining accuracy: 0.8099921345710754\n",
      "Step: 3500  \tValid loss: 0.4213712215423584\n",
      "Step: 3600  \tTraining loss: 0.35802948474884033\n",
      "Step: 3600  \tTraining accuracy: 0.810316264629364\n",
      "Step: 3600  \tValid loss: 0.4211960732936859\n",
      "Step: 3700  \tTraining loss: 0.3578709065914154\n",
      "Step: 3700  \tTraining accuracy: 0.8106411099433899\n",
      "Step: 3700  \tValid loss: 0.42100924253463745\n",
      "Step: 3800  \tTraining loss: 0.3577105700969696\n",
      "Step: 3800  \tTraining accuracy: 0.8109486699104309\n",
      "Step: 3800  \tValid loss: 0.4208514392375946\n",
      "Step: 3900  \tTraining loss: 0.35754644870758057\n",
      "Step: 3900  \tTraining accuracy: 0.8112578392028809\n",
      "Step: 3900  \tValid loss: 0.42066094279289246\n",
      "Step: 4000  \tTraining loss: 0.35737335681915283\n",
      "Step: 4000  \tTraining accuracy: 0.8115512728691101\n",
      "Step: 4000  \tValid loss: 0.4203702509403229\n",
      "Step: 4100  \tTraining loss: 0.35719332098960876\n",
      "Step: 4100  \tTraining accuracy: 0.8118302822113037\n",
      "Step: 4100  \tValid loss: 0.42020389437675476\n",
      "Step: 4200  \tTraining loss: 0.3570096492767334\n",
      "Step: 4200  \tTraining accuracy: 0.8121121525764465\n",
      "Step: 4200  \tValid loss: 0.41998574137687683\n",
      "Step: 4300  \tTraining loss: 0.3567982614040375\n",
      "Step: 4300  \tTraining accuracy: 0.8123807311058044\n",
      "Step: 4300  \tValid loss: 0.41954344511032104\n",
      "Step: 4400  \tTraining loss: 0.35655519366264343\n",
      "Step: 4400  \tTraining accuracy: 0.8126369714736938\n",
      "Step: 4400  \tValid loss: 0.4192431569099426\n",
      "Step: 4500  \tTraining loss: 0.35628020763397217\n",
      "Step: 4500  \tTraining accuracy: 0.8128968477249146\n",
      "Step: 4500  \tValid loss: 0.41874054074287415\n",
      "Step: 4600  \tTraining loss: 0.355935662984848\n",
      "Step: 4600  \tTraining accuracy: 0.8131304979324341\n",
      "Step: 4600  \tValid loss: 0.4183650314807892\n",
      "Step: 4700  \tTraining loss: 0.35567182302474976\n",
      "Step: 4700  \tTraining accuracy: 0.813383162021637\n",
      "Step: 4700  \tValid loss: 0.41798728704452515\n",
      "Step: 4800  \tTraining loss: 0.3553546667098999\n",
      "Step: 4800  \tTraining accuracy: 0.813625156879425\n",
      "Step: 4800  \tValid loss: 0.4175020158290863\n",
      "Step: 4900  \tTraining loss: 0.35505571961402893\n",
      "Step: 4900  \tTraining accuracy: 0.8138571977615356\n",
      "Step: 4900  \tValid loss: 0.4170597493648529\n",
      "Step: 5000  \tTraining loss: 0.35475292801856995\n",
      "Step: 5000  \tTraining accuracy: 0.8140662312507629\n",
      "Step: 5000  \tValid loss: 0.4166279733181\n",
      "Step: 5100  \tTraining loss: 0.3544481098651886\n",
      "Step: 5100  \tTraining accuracy: 0.8142937421798706\n",
      "Step: 5100  \tValid loss: 0.4162043333053589\n",
      "Step: 5200  \tTraining loss: 0.3541560471057892\n",
      "Step: 5200  \tTraining accuracy: 0.8144861459732056\n",
      "Step: 5200  \tValid loss: 0.4158465564250946\n",
      "Step: 5300  \tTraining loss: 0.35386648774147034\n",
      "Step: 5300  \tTraining accuracy: 0.8146712779998779\n",
      "Step: 5300  \tValid loss: 0.4154266119003296\n",
      "Step: 5400  \tTraining loss: 0.35358601808547974\n",
      "Step: 5400  \tTraining accuracy: 0.8148747086524963\n",
      "Step: 5400  \tValid loss: 0.4151723384857178\n",
      "Step: 5500  \tTraining loss: 0.353315144777298\n",
      "Step: 5500  \tTraining accuracy: 0.8150706887245178\n",
      "Step: 5500  \tValid loss: 0.4148576259613037\n",
      "Step: 5600  \tTraining loss: 0.3530483841896057\n",
      "Step: 5600  \tTraining accuracy: 0.8152474164962769\n",
      "Step: 5600  \tValid loss: 0.41459032893180847\n",
      "Step: 5700  \tTraining loss: 0.35278934240341187\n",
      "Step: 5700  \tTraining accuracy: 0.8154299259185791\n",
      "Step: 5700  \tValid loss: 0.41431763768196106\n",
      "Step: 5800  \tTraining loss: 0.35253679752349854\n",
      "Step: 5800  \tTraining accuracy: 0.8156177401542664\n",
      "Step: 5800  \tValid loss: 0.4141554534435272\n",
      "Step: 5900  \tTraining loss: 0.35228878259658813\n",
      "Step: 5900  \tTraining accuracy: 0.8157991766929626\n",
      "Step: 5900  \tValid loss: 0.41395556926727295\n",
      "Step: 6000  \tTraining loss: 0.35204464197158813\n",
      "Step: 6000  \tTraining accuracy: 0.8159745335578918\n",
      "Step: 6000  \tValid loss: 0.4137606918811798\n",
      "Step: 6100  \tTraining loss: 0.3518046438694\n",
      "Step: 6100  \tTraining accuracy: 0.8161441087722778\n",
      "Step: 6100  \tValid loss: 0.4135482907295227\n",
      "Step: 6200  \tTraining loss: 0.35157060623168945\n",
      "Step: 6200  \tTraining accuracy: 0.8163081407546997\n",
      "Step: 6200  \tValid loss: 0.413385272026062\n",
      "Step: 6300  \tTraining loss: 0.3513335883617401\n",
      "Step: 6300  \tTraining accuracy: 0.8164669275283813\n",
      "Step: 6300  \tValid loss: 0.4131002426147461\n",
      "Step: 6400  \tTraining loss: 0.351103276014328\n",
      "Step: 6400  \tTraining accuracy: 0.8166207075119019\n",
      "Step: 6400  \tValid loss: 0.41289305686950684\n",
      "Step: 6500  \tTraining loss: 0.3508780896663666\n",
      "Step: 6500  \tTraining accuracy: 0.8167697191238403\n",
      "Step: 6500  \tValid loss: 0.4126625061035156\n",
      "Step: 6600  \tTraining loss: 0.35066157579421997\n",
      "Step: 6600  \tTraining accuracy: 0.8169142007827759\n",
      "Step: 6600  \tValid loss: 0.4125112295150757\n",
      "Step: 6700  \tTraining loss: 0.3504282534122467\n",
      "Step: 6700  \tTraining accuracy: 0.8170644640922546\n",
      "Step: 6700  \tValid loss: 0.41189831495285034\n",
      "Step: 6800  \tTraining loss: 0.3501259386539459\n",
      "Step: 6800  \tTraining accuracy: 0.8172003030776978\n",
      "Step: 6800  \tValid loss: 0.41143858432769775\n",
      "Step: 6900  \tTraining loss: 0.3497629761695862\n",
      "Step: 6900  \tTraining accuracy: 0.8173321485519409\n",
      "Step: 6900  \tValid loss: 0.4116509258747101\n",
      "Step: 7000  \tTraining loss: 0.34948980808258057\n",
      "Step: 7000  \tTraining accuracy: 0.8174602389335632\n",
      "Step: 7000  \tValid loss: 0.4121193587779999\n",
      "Step: 7100  \tTraining loss: 0.3492374122142792\n",
      "Step: 7100  \tTraining accuracy: 0.8176038265228271\n",
      "Step: 7100  \tValid loss: 0.41256386041641235\n",
      "Step: 7200  \tTraining loss: 0.3490023910999298\n",
      "Step: 7200  \tTraining accuracy: 0.8177434206008911\n",
      "Step: 7200  \tValid loss: 0.4129667580127716\n",
      "Step: 7300  \tTraining loss: 0.3487774133682251\n",
      "Step: 7300  \tTraining accuracy: 0.8178698420524597\n",
      "Step: 7300  \tValid loss: 0.413371205329895\n",
      "Step: 7400  \tTraining loss: 0.34856221079826355\n",
      "Step: 7400  \tTraining accuracy: 0.8179836273193359\n",
      "Step: 7400  \tValid loss: 0.41362953186035156\n",
      "Step: 7500  \tTraining loss: 0.3483595848083496\n",
      "Step: 7500  \tTraining accuracy: 0.8180943727493286\n",
      "Step: 7500  \tValid loss: 0.4139561057090759\n",
      "Step: 7600  \tTraining loss: 0.34816795587539673\n",
      "Step: 7600  \tTraining accuracy: 0.8181931972503662\n",
      "Step: 7600  \tValid loss: 0.4141807556152344\n",
      "Step: 7700  \tTraining loss: 0.3479827046394348\n",
      "Step: 7700  \tTraining accuracy: 0.8182894587516785\n",
      "Step: 7700  \tValid loss: 0.41444575786590576\n",
      "Step: 7800  \tTraining loss: 0.3478105068206787\n",
      "Step: 7800  \tTraining accuracy: 0.8183832168579102\n",
      "Step: 7800  \tValid loss: 0.414722740650177\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.81847465\n",
      "Precision: 0.8586207\n",
      "Recall: 0.9005425\n",
      "F1 score: 0.8379794\n",
      "AUC: 0.74629116\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.818475   0.858621  0.900542  0.837979  0.746291  0.347772      0.818476   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.411073       0.818497   0.390187      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  7822.0  \n",
      "13\n",
      "(957, 5)\n",
      "(957, 1)\n",
      "(528, 5)\n",
      "(528, 1)\n",
      "(429, 5)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6318134665489197\n",
      "Step: 100  \tTraining accuracy: 0.6823406219482422\n",
      "Step: 100  \tValid loss: 0.6587933301925659\n",
      "Step: 200  \tTraining loss: 0.609355092048645\n",
      "Step: 200  \tTraining accuracy: 0.6729362607002258\n",
      "Step: 200  \tValid loss: 0.643034040927887\n",
      "Step: 300  \tTraining loss: 0.5447461009025574\n",
      "Step: 300  \tTraining accuracy: 0.6802507638931274\n",
      "Step: 300  \tValid loss: 0.5861818790435791\n",
      "Step: 400  \tTraining loss: 0.4776788651943207\n",
      "Step: 400  \tTraining accuracy: 0.6972682476043701\n",
      "Step: 400  \tValid loss: 0.5161033868789673\n",
      "Step: 500  \tTraining loss: 0.423697829246521\n",
      "Step: 500  \tTraining accuracy: 0.7184488773345947\n",
      "Step: 500  \tValid loss: 0.4533304274082184\n",
      "Step: 600  \tTraining loss: 0.37927812337875366\n",
      "Step: 600  \tTraining accuracy: 0.7364871501922607\n",
      "Step: 600  \tValid loss: 0.40028437972068787\n",
      "Step: 700  \tTraining loss: 0.3542836904525757\n",
      "Step: 700  \tTraining accuracy: 0.7525118589401245\n",
      "Step: 700  \tValid loss: 0.3697202205657959\n",
      "Step: 800  \tTraining loss: 0.34142374992370605\n",
      "Step: 800  \tTraining accuracy: 0.7658655643463135\n",
      "Step: 800  \tValid loss: 0.35336607694625854\n",
      "Step: 900  \tTraining loss: 0.33455389738082886\n",
      "Step: 900  \tTraining accuracy: 0.776753306388855\n",
      "Step: 900  \tValid loss: 0.34413570165634155\n",
      "Step: 1000  \tTraining loss: 0.330660343170166\n",
      "Step: 1000  \tTraining accuracy: 0.7856789231300354\n",
      "Step: 1000  \tValid loss: 0.3385435938835144\n",
      "Step: 1100  \tTraining loss: 0.3282873034477234\n",
      "Step: 1100  \tTraining accuracy: 0.7932029366493225\n",
      "Step: 1100  \tValid loss: 0.334754079580307\n",
      "Step: 1200  \tTraining loss: 0.32674333453178406\n",
      "Step: 1200  \tTraining accuracy: 0.7995547652244568\n",
      "Step: 1200  \tValid loss: 0.33221760392189026\n",
      "Step: 1300  \tTraining loss: 0.3256617784500122\n",
      "Step: 1300  \tTraining accuracy: 0.8048067092895508\n",
      "Step: 1300  \tValid loss: 0.33031654357910156\n",
      "Step: 1400  \tTraining loss: 0.32487741112709045\n",
      "Step: 1400  \tTraining accuracy: 0.8092031478881836\n",
      "Step: 1400  \tValid loss: 0.3288916349411011\n",
      "Step: 1500  \tTraining loss: 0.32427796721458435\n",
      "Step: 1500  \tTraining accuracy: 0.8129571676254272\n",
      "Step: 1500  \tValid loss: 0.32773762941360474\n",
      "Step: 1600  \tTraining loss: 0.3238027095794678\n",
      "Step: 1600  \tTraining accuracy: 0.8162941932678223\n",
      "Step: 1600  \tValid loss: 0.32682934403419495\n",
      "Step: 1700  \tTraining loss: 0.32341286540031433\n",
      "Step: 1700  \tTraining accuracy: 0.8192267417907715\n",
      "Step: 1700  \tValid loss: 0.3260924220085144\n",
      "Step: 1800  \tTraining loss: 0.32308828830718994\n",
      "Step: 1800  \tTraining accuracy: 0.8218539953231812\n",
      "Step: 1800  \tValid loss: 0.3254876136779785\n",
      "Step: 1900  \tTraining loss: 0.322815477848053\n",
      "Step: 1900  \tTraining accuracy: 0.8241689801216125\n",
      "Step: 1900  \tValid loss: 0.32501503825187683\n",
      "Step: 2000  \tTraining loss: 0.3225840628147125\n",
      "Step: 2000  \tTraining accuracy: 0.8262197375297546\n",
      "Step: 2000  \tValid loss: 0.3246094584465027\n",
      "Step: 2100  \tTraining loss: 0.3223893642425537\n",
      "Step: 2100  \tTraining accuracy: 0.8280704617500305\n",
      "Step: 2100  \tValid loss: 0.32429230213165283\n",
      "Step: 2200  \tTraining loss: 0.32221782207489014\n",
      "Step: 2200  \tTraining accuracy: 0.8297003507614136\n",
      "Step: 2200  \tValid loss: 0.32408079504966736\n",
      "Step: 2300  \tTraining loss: 0.32206547260284424\n",
      "Step: 2300  \tTraining accuracy: 0.8312086462974548\n",
      "Step: 2300  \tValid loss: 0.3238831162452698\n",
      "Step: 2400  \tTraining loss: 0.32193076610565186\n",
      "Step: 2400  \tTraining accuracy: 0.8326552510261536\n",
      "Step: 2400  \tValid loss: 0.32374751567840576\n",
      "Step: 2500  \tTraining loss: 0.3218088448047638\n",
      "Step: 2500  \tTraining accuracy: 0.8340263962745667\n",
      "Step: 2500  \tValid loss: 0.3236375153064728\n",
      "Step: 2600  \tTraining loss: 0.3216979205608368\n",
      "Step: 2600  \tTraining accuracy: 0.8352285623550415\n",
      "Step: 2600  \tValid loss: 0.32357117533683777\n",
      "Step: 2700  \tTraining loss: 0.3215942084789276\n",
      "Step: 2700  \tTraining accuracy: 0.8363399505615234\n",
      "Step: 2700  \tValid loss: 0.32352206110954285\n",
      "Step: 2800  \tTraining loss: 0.3214969336986542\n",
      "Step: 2800  \tTraining accuracy: 0.8373705744743347\n",
      "Step: 2800  \tValid loss: 0.32351210713386536\n",
      "Step: 2900  \tTraining loss: 0.32140448689460754\n",
      "Step: 2900  \tTraining accuracy: 0.8383471965789795\n",
      "Step: 2900  \tValid loss: 0.3235248923301697\n",
      "Step: 3000  \tTraining loss: 0.3213162422180176\n",
      "Step: 3000  \tTraining accuracy: 0.8392398357391357\n",
      "Step: 3000  \tValid loss: 0.3235568404197693\n",
      "Step: 3100  \tTraining loss: 0.32123157382011414\n",
      "Step: 3100  \tTraining accuracy: 0.8400911092758179\n",
      "Step: 3100  \tValid loss: 0.3236047625541687\n",
      "Step: 3200  \tTraining loss: 0.3211516737937927\n",
      "Step: 3200  \tTraining accuracy: 0.840904951095581\n",
      "Step: 3200  \tValid loss: 0.3236430883407593\n",
      "Step: 3300  \tTraining loss: 0.3210758864879608\n",
      "Step: 3300  \tTraining accuracy: 0.8416686654090881\n",
      "Step: 3300  \tValid loss: 0.32368502020835876\n",
      "Step: 3400  \tTraining loss: 0.3210028111934662\n",
      "Step: 3400  \tTraining accuracy: 0.8424023985862732\n",
      "Step: 3400  \tValid loss: 0.3237241208553314\n",
      "Step: 3500  \tTraining loss: 0.3209317922592163\n",
      "Step: 3500  \tTraining accuracy: 0.8430784344673157\n",
      "Step: 3500  \tValid loss: 0.32376956939697266\n",
      "Step: 3600  \tTraining loss: 0.3208628296852112\n",
      "Step: 3600  \tTraining accuracy: 0.8437164425849915\n",
      "Step: 3600  \tValid loss: 0.3238094747066498\n",
      "Step: 3700  \tTraining loss: 0.3207967281341553\n",
      "Step: 3700  \tTraining accuracy: 0.8443337678909302\n",
      "Step: 3700  \tValid loss: 0.32384270429611206\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8449321\n",
      "Precision: 0.8825257\n",
      "Recall: 0.92036754\n",
      "F1 score: 0.8626668\n",
      "AUC: 0.8286048\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.844932   0.882526  0.920368  0.862667  0.828605  0.320748      0.844701   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.323507       0.844587   0.285778      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3775.0  \n",
      "14\n",
      "(1798, 5)\n",
      "(1798, 1)\n",
      "(992, 5)\n",
      "(992, 1)\n",
      "(806, 5)\n",
      "(806, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6091681122779846\n",
      "Step: 100  \tTraining accuracy: 0.6779755353927612\n",
      "Step: 100  \tValid loss: 0.6213738322257996\n",
      "Step: 200  \tTraining loss: 0.5568536520004272\n",
      "Step: 200  \tTraining accuracy: 0.688357412815094\n",
      "Step: 200  \tValid loss: 0.5946346521377563\n",
      "Step: 300  \tTraining loss: 0.5388767123222351\n",
      "Step: 300  \tTraining accuracy: 0.7021134495735168\n",
      "Step: 300  \tValid loss: 0.5825710296630859\n",
      "Step: 400  \tTraining loss: 0.5204810500144958\n",
      "Step: 400  \tTraining accuracy: 0.7110280990600586\n",
      "Step: 400  \tValid loss: 0.5659034252166748\n",
      "Step: 500  \tTraining loss: 0.4985214173793793\n",
      "Step: 500  \tTraining accuracy: 0.7172166705131531\n",
      "Step: 500  \tValid loss: 0.5443954467773438\n",
      "Step: 600  \tTraining loss: 0.4735097885131836\n",
      "Step: 600  \tTraining accuracy: 0.722570538520813\n",
      "Step: 600  \tValid loss: 0.5191317796707153\n",
      "Step: 700  \tTraining loss: 0.4498502016067505\n",
      "Step: 700  \tTraining accuracy: 0.7289723753929138\n",
      "Step: 700  \tValid loss: 0.49610215425491333\n",
      "Step: 800  \tTraining loss: 0.4325215518474579\n",
      "Step: 800  \tTraining accuracy: 0.735558032989502\n",
      "Step: 800  \tValid loss: 0.48031729459762573\n",
      "Step: 900  \tTraining loss: 0.4208087921142578\n",
      "Step: 900  \tTraining accuracy: 0.7419682145118713\n",
      "Step: 900  \tValid loss: 0.4704069197177887\n",
      "Step: 1000  \tTraining loss: 0.41291680932044983\n",
      "Step: 1000  \tTraining accuracy: 0.7477021217346191\n",
      "Step: 1000  \tValid loss: 0.4641800820827484\n",
      "Step: 1100  \tTraining loss: 0.4075232148170471\n",
      "Step: 1100  \tTraining accuracy: 0.7527411580085754\n",
      "Step: 1100  \tValid loss: 0.4600307047367096\n",
      "Step: 1200  \tTraining loss: 0.40377238392829895\n",
      "Step: 1200  \tTraining accuracy: 0.7574115991592407\n",
      "Step: 1200  \tValid loss: 0.4570448398590088\n",
      "Step: 1300  \tTraining loss: 0.4011230766773224\n",
      "Step: 1300  \tTraining accuracy: 0.7614682912826538\n",
      "Step: 1300  \tValid loss: 0.454743891954422\n",
      "Step: 1400  \tTraining loss: 0.3992590010166168\n",
      "Step: 1400  \tTraining accuracy: 0.764841616153717\n",
      "Step: 1400  \tValid loss: 0.4530094563961029\n",
      "Step: 1500  \tTraining loss: 0.3979421854019165\n",
      "Step: 1500  \tTraining accuracy: 0.7678263187408447\n",
      "Step: 1500  \tValid loss: 0.4516792297363281\n",
      "Step: 1600  \tTraining loss: 0.3969985246658325\n",
      "Step: 1600  \tTraining accuracy: 0.7706232666969299\n",
      "Step: 1600  \tValid loss: 0.4506375193595886\n",
      "Step: 1700  \tTraining loss: 0.3963046967983246\n",
      "Step: 1700  \tTraining accuracy: 0.7730306386947632\n",
      "Step: 1700  \tValid loss: 0.44979655742645264\n",
      "Step: 1800  \tTraining loss: 0.3957776427268982\n",
      "Step: 1800  \tTraining accuracy: 0.7752582430839539\n",
      "Step: 1800  \tValid loss: 0.4490935504436493\n",
      "Step: 1900  \tTraining loss: 0.39536237716674805\n",
      "Step: 1900  \tTraining accuracy: 0.7772901058197021\n",
      "Step: 1900  \tValid loss: 0.448486328125\n",
      "Step: 2000  \tTraining loss: 0.39502376317977905\n",
      "Step: 2000  \tTraining accuracy: 0.7791563272476196\n",
      "Step: 2000  \tValid loss: 0.44794750213623047\n",
      "Step: 2100  \tTraining loss: 0.3947382867336273\n",
      "Step: 2100  \tTraining accuracy: 0.7808405160903931\n",
      "Step: 2100  \tValid loss: 0.44745904207229614\n",
      "Step: 2200  \tTraining loss: 0.39449089765548706\n",
      "Step: 2200  \tTraining accuracy: 0.7823550701141357\n",
      "Step: 2200  \tValid loss: 0.4470096826553345\n",
      "Step: 2300  \tTraining loss: 0.3942703306674957\n",
      "Step: 2300  \tTraining accuracy: 0.7837226390838623\n",
      "Step: 2300  \tValid loss: 0.4465915560722351\n",
      "Step: 2400  \tTraining loss: 0.3940698504447937\n",
      "Step: 2400  \tTraining accuracy: 0.7850093245506287\n",
      "Step: 2400  \tValid loss: 0.44619911909103394\n",
      "Step: 2500  \tTraining loss: 0.3938833475112915\n",
      "Step: 2500  \tTraining accuracy: 0.7861682772636414\n",
      "Step: 2500  \tValid loss: 0.44582852721214294\n",
      "Step: 2600  \tTraining loss: 0.3937070965766907\n",
      "Step: 2600  \tTraining accuracy: 0.7872472405433655\n",
      "Step: 2600  \tValid loss: 0.4454767405986786\n",
      "Step: 2700  \tTraining loss: 0.39353761076927185\n",
      "Step: 2700  \tTraining accuracy: 0.7882447838783264\n",
      "Step: 2700  \tValid loss: 0.445141464471817\n",
      "Step: 2800  \tTraining loss: 0.393372505903244\n",
      "Step: 2800  \tTraining accuracy: 0.7891596555709839\n",
      "Step: 2800  \tValid loss: 0.4448210299015045\n",
      "Step: 2900  \tTraining loss: 0.3932100236415863\n",
      "Step: 2900  \tTraining accuracy: 0.7900103330612183\n",
      "Step: 2900  \tValid loss: 0.44451332092285156\n",
      "Step: 3000  \tTraining loss: 0.39304816722869873\n",
      "Step: 3000  \tTraining accuracy: 0.7907938957214355\n",
      "Step: 3000  \tValid loss: 0.44421762228012085\n",
      "Step: 3100  \tTraining loss: 0.39288580417633057\n",
      "Step: 3100  \tTraining accuracy: 0.7915260791778564\n",
      "Step: 3100  \tValid loss: 0.4439326524734497\n",
      "Step: 3200  \tTraining loss: 0.39272212982177734\n",
      "Step: 3200  \tTraining accuracy: 0.7922118306159973\n",
      "Step: 3200  \tValid loss: 0.4436572194099426\n",
      "Step: 3300  \tTraining loss: 0.3925556540489197\n",
      "Step: 3300  \tTraining accuracy: 0.7928553223609924\n",
      "Step: 3300  \tValid loss: 0.44339069724082947\n",
      "Step: 3400  \tTraining loss: 0.3923858404159546\n",
      "Step: 3400  \tTraining accuracy: 0.7934603691101074\n",
      "Step: 3400  \tValid loss: 0.44313210248947144\n",
      "Step: 3500  \tTraining loss: 0.39221152663230896\n",
      "Step: 3500  \tTraining accuracy: 0.7940384745597839\n",
      "Step: 3500  \tValid loss: 0.4428805112838745\n",
      "Step: 3600  \tTraining loss: 0.3920322060585022\n",
      "Step: 3600  \tTraining accuracy: 0.7945917844772339\n",
      "Step: 3600  \tValid loss: 0.4426349401473999\n",
      "Step: 3800  \tTraining loss: 0.39165395498275757\n",
      "Step: 3800  \tTraining accuracy: 0.7956470251083374\n",
      "Step: 3800  \tValid loss: 0.44215983152389526\n",
      "Step: 3900  \tTraining loss: 0.39145317673683167\n",
      "Step: 3900  \tTraining accuracy: 0.7961443662643433\n",
      "Step: 3900  \tValid loss: 0.4419286549091339\n",
      "Step: 4000  \tTraining loss: 0.39124321937561035\n",
      "Step: 4000  \tTraining accuracy: 0.7966375946998596\n",
      "Step: 4000  \tValid loss: 0.4417007267475128\n",
      "Step: 4100  \tTraining loss: 0.3910229504108429\n",
      "Step: 4100  \tTraining accuracy: 0.7970996499061584\n",
      "Step: 4100  \tValid loss: 0.4414755403995514\n",
      "Step: 4200  \tTraining loss: 0.39079129695892334\n",
      "Step: 4200  \tTraining accuracy: 0.7975394129753113\n",
      "Step: 4200  \tValid loss: 0.44125276803970337\n",
      "Step: 4300  \tTraining loss: 0.39054739475250244\n",
      "Step: 4300  \tTraining accuracy: 0.797958493232727\n",
      "Step: 4300  \tValid loss: 0.441032350063324\n",
      "Step: 4400  \tTraining loss: 0.39029020071029663\n",
      "Step: 4400  \tTraining accuracy: 0.7983391284942627\n",
      "Step: 4400  \tValid loss: 0.44081369042396545\n",
      "Step: 4500  \tTraining loss: 0.3900192379951477\n",
      "Step: 4500  \tTraining accuracy: 0.7987026572227478\n",
      "Step: 4500  \tValid loss: 0.4405978322029114\n",
      "Step: 4600  \tTraining loss: 0.3897343873977661\n",
      "Step: 4600  \tTraining accuracy: 0.799044132232666\n",
      "Step: 4600  \tValid loss: 0.44038495421409607\n",
      "Step: 4700  \tTraining loss: 0.3894355893135071\n",
      "Step: 4700  \tTraining accuracy: 0.7993768453598022\n",
      "Step: 4700  \tValid loss: 0.44017675518989563\n",
      "Step: 4800  \tTraining loss: 0.38912326097488403\n",
      "Step: 4800  \tTraining accuracy: 0.7996897101402283\n",
      "Step: 4800  \tValid loss: 0.43997499346733093\n",
      "Step: 4900  \tTraining loss: 0.38879862427711487\n",
      "Step: 4900  \tTraining accuracy: 0.7999954223632812\n",
      "Step: 4900  \tValid loss: 0.43978190422058105\n",
      "Step: 5000  \tTraining loss: 0.38846293091773987\n",
      "Step: 5000  \tTraining accuracy: 0.8002831339836121\n",
      "Step: 5000  \tValid loss: 0.4396011531352997\n",
      "Step: 5100  \tTraining loss: 0.3881184160709381\n",
      "Step: 5100  \tTraining accuracy: 0.8005594611167908\n",
      "Step: 5100  \tValid loss: 0.43943628668785095\n",
      "Step: 5200  \tTraining loss: 0.38776740431785583\n",
      "Step: 5200  \tTraining accuracy: 0.8008196949958801\n",
      "Step: 5200  \tValid loss: 0.4392922818660736\n",
      "Step: 5300  \tTraining loss: 0.3874123990535736\n",
      "Step: 5300  \tTraining accuracy: 0.801064670085907\n",
      "Step: 5300  \tValid loss: 0.4391728639602661\n",
      "Step: 5400  \tTraining loss: 0.38705307245254517\n",
      "Step: 5400  \tTraining accuracy: 0.8013005256652832\n",
      "Step: 5400  \tValid loss: 0.439097136259079\n",
      "Step: 5500  \tTraining loss: 0.38668179512023926\n",
      "Step: 5500  \tTraining accuracy: 0.8015226125717163\n",
      "Step: 5500  \tValid loss: 0.43906155228614807\n",
      "Step: 5600  \tTraining loss: 0.38630953431129456\n",
      "Step: 5600  \tTraining accuracy: 0.801746666431427\n",
      "Step: 5600  \tValid loss: 0.43897080421447754\n",
      "Step: 5700  \tTraining loss: 0.3859487771987915\n",
      "Step: 5700  \tTraining accuracy: 0.8019530177116394\n",
      "Step: 5700  \tValid loss: 0.43891045451164246\n",
      "Step: 5800  \tTraining loss: 0.3856008052825928\n",
      "Step: 5800  \tTraining accuracy: 0.802152156829834\n",
      "Step: 5800  \tValid loss: 0.4388681948184967\n",
      "Step: 5900  \tTraining loss: 0.3852701783180237\n",
      "Step: 5900  \tTraining accuracy: 0.8023445010185242\n",
      "Step: 5900  \tValid loss: 0.43883395195007324\n",
      "Step: 6000  \tTraining loss: 0.3849557936191559\n",
      "Step: 6000  \tTraining accuracy: 0.802544355392456\n",
      "Step: 6000  \tValid loss: 0.43883559107780457\n",
      "Step: 6100  \tTraining loss: 0.3846537470817566\n",
      "Step: 6100  \tTraining accuracy: 0.8027376532554626\n",
      "Step: 6100  \tValid loss: 0.43885695934295654\n",
      "Step: 6200  \tTraining loss: 0.38435864448547363\n",
      "Step: 6200  \tTraining accuracy: 0.802929162979126\n",
      "Step: 6200  \tValid loss: 0.43888771533966064\n",
      "Step: 6300  \tTraining loss: 0.38407590985298157\n",
      "Step: 6300  \tTraining accuracy: 0.8031190037727356\n",
      "Step: 6300  \tValid loss: 0.4389117658138275\n",
      "Step: 6400  \tTraining loss: 0.38380855321884155\n",
      "Step: 6400  \tTraining accuracy: 0.8032984733581543\n",
      "Step: 6400  \tValid loss: 0.4389580190181732\n",
      "Step: 6500  \tTraining loss: 0.383549302816391\n",
      "Step: 6500  \tTraining accuracy: 0.8034594655036926\n",
      "Step: 6500  \tValid loss: 0.4390176832675934\n",
      "Step: 6600  \tTraining loss: 0.3832946717739105\n",
      "Step: 6600  \tTraining accuracy: 0.8036155700683594\n",
      "Step: 6600  \tValid loss: 0.4390539824962616\n",
      "Step: 6700  \tTraining loss: 0.38304999470710754\n",
      "Step: 6700  \tTraining accuracy: 0.8037585616111755\n",
      "Step: 6700  \tValid loss: 0.4391140341758728\n",
      "Step: 6800  \tTraining loss: 0.3828130066394806\n",
      "Step: 6800  \tTraining accuracy: 0.8038932085037231\n",
      "Step: 6800  \tValid loss: 0.43916547298431396\n",
      "Step: 6900  \tTraining loss: 0.382584810256958\n",
      "Step: 6900  \tTraining accuracy: 0.8040239214897156\n",
      "Step: 6900  \tValid loss: 0.4392436146736145\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8041549\n",
      "Precision: 0.8333333\n",
      "Recall: 0.85287845\n",
      "F1 score: 0.81347597\n",
      "AUC: 0.833416\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.804155   0.833333  0.852878  0.813476  0.833416  0.382501      0.803937   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.438832       0.803947   0.557395      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  6937.0  \n",
      "15\n",
      "(870, 5)\n",
      "(870, 1)\n",
      "(480, 5)\n",
      "(480, 1)\n",
      "(390, 5)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5667997002601624\n",
      "Step: 100  \tTraining accuracy: 0.7103448510169983\n",
      "Step: 100  \tValid loss: 0.5691296458244324\n",
      "Step: 200  \tTraining loss: 0.5285241603851318\n",
      "Step: 200  \tTraining accuracy: 0.7249042391777039\n",
      "Step: 200  \tValid loss: 0.5387311577796936\n",
      "Step: 300  \tTraining loss: 0.5145759582519531\n",
      "Step: 300  \tTraining accuracy: 0.7326436638832092\n",
      "Step: 300  \tValid loss: 0.5246039628982544\n",
      "Step: 400  \tTraining loss: 0.5017849802970886\n",
      "Step: 400  \tTraining accuracy: 0.7402299046516418\n",
      "Step: 400  \tValid loss: 0.5090781450271606\n",
      "Step: 500  \tTraining loss: 0.48889994621276855\n",
      "Step: 500  \tTraining accuracy: 0.7455938458442688\n",
      "Step: 500  \tValid loss: 0.49325239658355713\n",
      "Step: 600  \tTraining loss: 0.4760885536670685\n",
      "Step: 600  \tTraining accuracy: 0.7502612471580505\n",
      "Step: 600  \tValid loss: 0.47747331857681274\n",
      "Step: 700  \tTraining loss: 0.4639512896537781\n",
      "Step: 700  \tTraining accuracy: 0.7534924745559692\n",
      "Step: 700  \tValid loss: 0.46277859807014465\n",
      "Step: 800  \tTraining loss: 0.45332810282707214\n",
      "Step: 800  \tTraining accuracy: 0.7564750909805298\n",
      "Step: 800  \tValid loss: 0.45054981112480164\n",
      "Step: 900  \tTraining loss: 0.4460771083831787\n",
      "Step: 900  \tTraining accuracy: 0.7592291831970215\n",
      "Step: 900  \tValid loss: 0.44129323959350586\n",
      "Step: 1000  \tTraining loss: 0.4413546919822693\n",
      "Step: 1000  \tTraining accuracy: 0.7618269920349121\n",
      "Step: 1000  \tValid loss: 0.4357938766479492\n",
      "Step: 1100  \tTraining loss: 0.43823572993278503\n",
      "Step: 1100  \tTraining accuracy: 0.7643678188323975\n",
      "Step: 1100  \tValid loss: 0.4321446120738983\n",
      "Step: 1200  \tTraining loss: 0.4358779489994049\n",
      "Step: 1200  \tTraining accuracy: 0.7665666937828064\n",
      "Step: 1200  \tValid loss: 0.4297214448451996\n",
      "Step: 1300  \tTraining loss: 0.43325275182724\n",
      "Step: 1300  \tTraining accuracy: 0.7685517072677612\n",
      "Step: 1300  \tValid loss: 0.42829686403274536\n",
      "Step: 1400  \tTraining loss: 0.43073445558547974\n",
      "Step: 1400  \tTraining accuracy: 0.770370364189148\n",
      "Step: 1400  \tValid loss: 0.4267527461051941\n",
      "Step: 1500  \tTraining loss: 0.4278509318828583\n",
      "Step: 1500  \tTraining accuracy: 0.7720174193382263\n",
      "Step: 1500  \tValid loss: 0.4250381886959076\n",
      "Step: 1600  \tTraining loss: 0.42476966977119446\n",
      "Step: 1600  \tTraining accuracy: 0.7736373543739319\n",
      "Step: 1600  \tValid loss: 0.423324853181839\n",
      "Step: 1700  \tTraining loss: 0.42185118794441223\n",
      "Step: 1700  \tTraining accuracy: 0.7750957608222961\n",
      "Step: 1700  \tValid loss: 0.4220582842826843\n",
      "Step: 1800  \tTraining loss: 0.4191271960735321\n",
      "Step: 1800  \tTraining accuracy: 0.7765188813209534\n",
      "Step: 1800  \tValid loss: 0.42182648181915283\n",
      "Step: 1900  \tTraining loss: 0.4167984426021576\n",
      "Step: 1900  \tTraining accuracy: 0.7777259945869446\n",
      "Step: 1900  \tValid loss: 0.4216950237751007\n",
      "Step: 2000  \tTraining loss: 0.41479894518852234\n",
      "Step: 2000  \tTraining accuracy: 0.7787503600120544\n",
      "Step: 2000  \tValid loss: 0.4219071567058563\n",
      "Step: 2100  \tTraining loss: 0.41301336884498596\n",
      "Step: 2100  \tTraining accuracy: 0.7797589302062988\n",
      "Step: 2100  \tValid loss: 0.42238929867744446\n",
      "Step: 2200  \tTraining loss: 0.41114088892936707\n",
      "Step: 2200  \tTraining accuracy: 0.780673623085022\n",
      "Step: 2200  \tValid loss: 0.422627717256546\n",
      "Step: 2300  \tTraining loss: 0.40966325998306274\n",
      "Step: 2300  \tTraining accuracy: 0.7816858291625977\n",
      "Step: 2300  \tValid loss: 0.4228982925415039\n",
      "Step: 2400  \tTraining loss: 0.40831640362739563\n",
      "Step: 2400  \tTraining accuracy: 0.7825874090194702\n",
      "Step: 2400  \tValid loss: 0.4231704771518707\n",
      "Step: 2500  \tTraining loss: 0.4070754051208496\n",
      "Step: 2500  \tTraining accuracy: 0.7833216190338135\n",
      "Step: 2500  \tValid loss: 0.42357587814331055\n",
      "Step: 2600  \tTraining loss: 0.4057118594646454\n",
      "Step: 2600  \tTraining accuracy: 0.7839756608009338\n",
      "Step: 2600  \tValid loss: 0.42317965626716614\n",
      "Step: 2700  \tTraining loss: 0.40455639362335205\n",
      "Step: 2700  \tTraining accuracy: 0.7846020460128784\n",
      "Step: 2700  \tValid loss: 0.4236481487751007\n",
      "Step: 2800  \tTraining loss: 0.40346089005470276\n",
      "Step: 2800  \tTraining accuracy: 0.7851410508155823\n",
      "Step: 2800  \tValid loss: 0.4242820143699646\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7856624\n",
      "Precision: 0.8504532\n",
      "Recall: 0.91100323\n",
      "F1 score: 0.8126695\n",
      "AUC: 0.759073\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.785662   0.850453  0.911003   0.81267  0.759073  0.402601      0.784996   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.421671       0.784909   0.497681      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2881.0  \n",
      "16\n",
      "(1624, 5)\n",
      "(1624, 1)\n",
      "(880, 5)\n",
      "(880, 1)\n",
      "(715, 5)\n",
      "(715, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6530390977859497\n",
      "Step: 100  \tTraining accuracy: 0.6293103694915771\n",
      "Step: 100  \tValid loss: 0.6493300795555115\n",
      "Step: 200  \tTraining loss: 0.5919397473335266\n",
      "Step: 200  \tTraining accuracy: 0.6520751714706421\n",
      "Step: 200  \tValid loss: 0.5859529376029968\n",
      "Step: 300  \tTraining loss: 0.4805091917514801\n",
      "Step: 300  \tTraining accuracy: 0.6946167349815369\n",
      "Step: 300  \tValid loss: 0.47204291820526123\n",
      "Step: 400  \tTraining loss: 0.4113795757293701\n",
      "Step: 400  \tTraining accuracy: 0.736282229423523\n",
      "Step: 400  \tValid loss: 0.3986043334007263\n",
      "Step: 500  \tTraining loss: 0.38056403398513794\n",
      "Step: 500  \tTraining accuracy: 0.7620000243186951\n",
      "Step: 500  \tValid loss: 0.3635864853858948\n",
      "Step: 600  \tTraining loss: 0.3672652244567871\n",
      "Step: 600  \tTraining accuracy: 0.7782606482505798\n",
      "Step: 600  \tValid loss: 0.34766748547554016\n",
      "Step: 700  \tTraining loss: 0.3607150912284851\n",
      "Step: 700  \tTraining accuracy: 0.7896169424057007\n",
      "Step: 700  \tValid loss: 0.33965209126472473\n",
      "Step: 800  \tTraining loss: 0.3568979501724243\n",
      "Step: 800  \tTraining accuracy: 0.7981951236724854\n",
      "Step: 800  \tValid loss: 0.3349604904651642\n",
      "Step: 900  \tTraining loss: 0.35437673330307007\n",
      "Step: 900  \tTraining accuracy: 0.8048655986785889\n",
      "Step: 900  \tValid loss: 0.33193954825401306\n",
      "Step: 1000  \tTraining loss: 0.35236847400665283\n",
      "Step: 1000  \tTraining accuracy: 0.810328483581543\n",
      "Step: 1000  \tValid loss: 0.3299291133880615\n",
      "Step: 1100  \tTraining loss: 0.3508051335811615\n",
      "Step: 1100  \tTraining accuracy: 0.8148400187492371\n",
      "Step: 1100  \tValid loss: 0.3285216689109802\n",
      "Step: 1200  \tTraining loss: 0.34955722093582153\n",
      "Step: 1200  \tTraining accuracy: 0.8187562227249146\n",
      "Step: 1200  \tValid loss: 0.3273485600948334\n",
      "Step: 1300  \tTraining loss: 0.34847888350486755\n",
      "Step: 1300  \tTraining accuracy: 0.8220461010932922\n",
      "Step: 1300  \tValid loss: 0.3265050947666168\n",
      "Step: 1400  \tTraining loss: 0.3475969731807709\n",
      "Step: 1400  \tTraining accuracy: 0.8248487710952759\n",
      "Step: 1400  \tValid loss: 0.32568541169166565\n",
      "Step: 1500  \tTraining loss: 0.3468097150325775\n",
      "Step: 1500  \tTraining accuracy: 0.8272863626480103\n",
      "Step: 1500  \tValid loss: 0.32505494356155396\n",
      "Step: 1600  \tTraining loss: 0.34606045484542847\n",
      "Step: 1600  \tTraining accuracy: 0.8293895125389099\n",
      "Step: 1600  \tValid loss: 0.32462242245674133\n",
      "Step: 1700  \tTraining loss: 0.34515073895454407\n",
      "Step: 1700  \tTraining accuracy: 0.8312754034996033\n",
      "Step: 1700  \tValid loss: 0.32463759183883667\n",
      "Step: 1800  \tTraining loss: 0.34429630637168884\n",
      "Step: 1800  \tTraining accuracy: 0.8329635858535767\n",
      "Step: 1800  \tValid loss: 0.32457050681114197\n",
      "Step: 1900  \tTraining loss: 0.34353092312812805\n",
      "Step: 1900  \tTraining accuracy: 0.8344693183898926\n",
      "Step: 1900  \tValid loss: 0.3242376744747162\n",
      "Step: 2000  \tTraining loss: 0.34288257360458374\n",
      "Step: 2000  \tTraining accuracy: 0.8358525037765503\n",
      "Step: 2000  \tValid loss: 0.3239946663379669\n",
      "Step: 2100  \tTraining loss: 0.3422740697860718\n",
      "Step: 2100  \tTraining accuracy: 0.8371310830116272\n",
      "Step: 2100  \tValid loss: 0.32371464371681213\n",
      "Step: 2200  \tTraining loss: 0.34169337153434753\n",
      "Step: 2200  \tTraining accuracy: 0.8382762670516968\n",
      "Step: 2200  \tValid loss: 0.32335183024406433\n",
      "Step: 2300  \tTraining loss: 0.34117111563682556\n",
      "Step: 2300  \tTraining accuracy: 0.8393059372901917\n",
      "Step: 2300  \tValid loss: 0.3230859339237213\n",
      "Step: 2400  \tTraining loss: 0.34068071842193604\n",
      "Step: 2400  \tTraining accuracy: 0.8402611613273621\n",
      "Step: 2400  \tValid loss: 0.32283785939216614\n",
      "Step: 2500  \tTraining loss: 0.3402194380760193\n",
      "Step: 2500  \tTraining accuracy: 0.8411257863044739\n",
      "Step: 2500  \tValid loss: 0.322636216878891\n",
      "Step: 2600  \tTraining loss: 0.3397701382637024\n",
      "Step: 2600  \tTraining accuracy: 0.8419225811958313\n",
      "Step: 2600  \tValid loss: 0.322487473487854\n",
      "Step: 2700  \tTraining loss: 0.3393131494522095\n",
      "Step: 2700  \tTraining accuracy: 0.8426592350006104\n",
      "Step: 2700  \tValid loss: 0.3224200904369354\n",
      "Step: 2800  \tTraining loss: 0.33885350823402405\n",
      "Step: 2800  \tTraining accuracy: 0.8433310389518738\n",
      "Step: 2800  \tValid loss: 0.32233378291130066\n",
      "Step: 2900  \tTraining loss: 0.3384241461753845\n",
      "Step: 2900  \tTraining accuracy: 0.8439556956291199\n",
      "Step: 2900  \tValid loss: 0.3222143352031708\n",
      "Step: 3000  \tTraining loss: 0.33800607919692993\n",
      "Step: 3000  \tTraining accuracy: 0.8445485830307007\n",
      "Step: 3000  \tValid loss: 0.32208874821662903\n",
      "Step: 3100  \tTraining loss: 0.33758893609046936\n",
      "Step: 3100  \tTraining accuracy: 0.8450923562049866\n",
      "Step: 3100  \tValid loss: 0.321990042924881\n",
      "Step: 3200  \tTraining loss: 0.33715203404426575\n",
      "Step: 3200  \tTraining accuracy: 0.8455917835235596\n",
      "Step: 3200  \tValid loss: 0.3219856917858124\n",
      "Step: 3300  \tTraining loss: 0.3367289900779724\n",
      "Step: 3300  \tTraining accuracy: 0.8460413813591003\n",
      "Step: 3300  \tValid loss: 0.3217895030975342\n",
      "Step: 3400  \tTraining loss: 0.3363034725189209\n",
      "Step: 3400  \tTraining accuracy: 0.8464548587799072\n",
      "Step: 3400  \tValid loss: 0.32179319858551025\n",
      "Step: 3500  \tTraining loss: 0.3357257544994354\n",
      "Step: 3500  \tTraining accuracy: 0.846880316734314\n",
      "Step: 3500  \tValid loss: 0.3223757743835449\n",
      "Step: 3600  \tTraining loss: 0.3352023661136627\n",
      "Step: 3600  \tTraining accuracy: 0.8472644090652466\n",
      "Step: 3600  \tValid loss: 0.32232117652893066\n",
      "Step: 3700  \tTraining loss: 0.33473655581474304\n",
      "Step: 3700  \tTraining accuracy: 0.8476274013519287\n",
      "Step: 3700  \tValid loss: 0.32211726903915405\n",
      "Step: 3800  \tTraining loss: 0.3342960774898529\n",
      "Step: 3800  \tTraining accuracy: 0.8479461669921875\n",
      "Step: 3800  \tValid loss: 0.3219926357269287\n",
      "Step: 3900  \tTraining loss: 0.33387425541877747\n",
      "Step: 3900  \tTraining accuracy: 0.8482403755187988\n",
      "Step: 3900  \tValid loss: 0.32201191782951355\n",
      "Step: 4000  \tTraining loss: 0.3334006369113922\n",
      "Step: 4000  \tTraining accuracy: 0.8485117554664612\n",
      "Step: 4000  \tValid loss: 0.32225170731544495\n",
      "Step: 4100  \tTraining loss: 0.3330361545085907\n",
      "Step: 4100  \tTraining accuracy: 0.8487697839736938\n",
      "Step: 4100  \tValid loss: 0.32223227620124817\n",
      "Step: 4200  \tTraining loss: 0.33270105719566345\n",
      "Step: 4200  \tTraining accuracy: 0.8490303158760071\n",
      "Step: 4200  \tValid loss: 0.32220324873924255\n",
      "Step: 4300  \tTraining loss: 0.3321501612663269\n",
      "Step: 4300  \tTraining accuracy: 0.8492859601974487\n",
      "Step: 4300  \tValid loss: 0.3228451907634735\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8495369\n",
      "Precision: 0.8537931\n",
      "Recall: 0.83648646\n",
      "F1 score: 0.8408386\n",
      "AUC: 0.85828847\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.849537   0.853793  0.836486  0.840839  0.858288  0.331976      0.849412   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.321728       0.849306   0.342307      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4356.0  \n",
      "17\n",
      "(783, 5)\n",
      "(783, 1)\n",
      "(432, 5)\n",
      "(432, 1)\n",
      "(351, 5)\n",
      "(351, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4055570662021637\n",
      "Step: 100  \tTraining accuracy: 0.8339719176292419\n",
      "Step: 100  \tValid loss: 0.5310985445976257\n",
      "Step: 200  \tTraining loss: 0.3997143805027008\n",
      "Step: 200  \tTraining accuracy: 0.8152405023574829\n",
      "Step: 200  \tValid loss: 0.5380524396896362\n",
      "Step: 300  \tTraining loss: 0.39612650871276855\n",
      "Step: 300  \tTraining accuracy: 0.8114942312240601\n",
      "Step: 300  \tValid loss: 0.5380955934524536\n",
      "Step: 400  \tTraining loss: 0.3934963047504425\n",
      "Step: 400  \tTraining accuracy: 0.8098887205123901\n",
      "Step: 400  \tValid loss: 0.5381892919540405\n",
      "Step: 500  \tTraining loss: 0.39126142859458923\n",
      "Step: 500  \tTraining accuracy: 0.8089967370033264\n",
      "Step: 500  \tValid loss: 0.5375196933746338\n",
      "Step: 600  \tTraining loss: 0.38897666335105896\n",
      "Step: 600  \tTraining accuracy: 0.8084291219711304\n",
      "Step: 600  \tValid loss: 0.5356229543685913\n",
      "Step: 700  \tTraining loss: 0.3870469629764557\n",
      "Step: 700  \tTraining accuracy: 0.8090185523033142\n",
      "Step: 700  \tValid loss: 0.5337852239608765\n",
      "Step: 800  \tTraining loss: 0.3852798342704773\n",
      "Step: 800  \tTraining accuracy: 0.8097062706947327\n",
      "Step: 800  \tValid loss: 0.5320301055908203\n",
      "Step: 900  \tTraining loss: 0.383653461933136\n",
      "Step: 900  \tTraining accuracy: 0.8106828927993774\n",
      "Step: 900  \tValid loss: 0.5307009816169739\n",
      "Step: 1000  \tTraining loss: 0.38187000155448914\n",
      "Step: 1000  \tTraining accuracy: 0.8114539384841919\n",
      "Step: 1000  \tValid loss: 0.5289881825447083\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8121389\n",
      "Precision: 0.85542166\n",
      "Recall: 0.9785605\n",
      "F1 score: 0.8666682\n",
      "AUC: 0.57389563\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.812139   0.855422  0.978561  0.866668  0.573896  0.380309      0.810536   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.521076       0.811597   0.441861      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1072.0  \n",
      "18\n",
      "(1189, 5)\n",
      "(1189, 1)\n",
      "(640, 5)\n",
      "(640, 1)\n",
      "(520, 5)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.517483115196228\n",
      "Step: 100  \tTraining accuracy: 0.7846930027008057\n",
      "Step: 100  \tValid loss: 0.5829556584358215\n",
      "Step: 200  \tTraining loss: 0.47688770294189453\n",
      "Step: 200  \tTraining accuracy: 0.7685132622718811\n",
      "Step: 200  \tValid loss: 0.5382167100906372\n",
      "Step: 300  \tTraining loss: 0.4581378996372223\n",
      "Step: 300  \tTraining accuracy: 0.7652454376220703\n",
      "Step: 300  \tValid loss: 0.5120005011558533\n",
      "Step: 400  \tTraining loss: 0.452431321144104\n",
      "Step: 400  \tTraining accuracy: 0.7638416886329651\n",
      "Step: 400  \tValid loss: 0.5014597177505493\n",
      "Step: 500  \tTraining loss: 0.4491533637046814\n",
      "Step: 500  \tTraining accuracy: 0.7630609273910522\n",
      "Step: 500  \tValid loss: 0.49574556946754456\n",
      "Step: 600  \tTraining loss: 0.4466921389102936\n",
      "Step: 600  \tTraining accuracy: 0.7646512985229492\n",
      "Step: 600  \tValid loss: 0.49220171570777893\n",
      "Step: 700  \tTraining loss: 0.44444552063941956\n",
      "Step: 700  \tTraining accuracy: 0.7683700919151306\n",
      "Step: 700  \tValid loss: 0.4897051453590393\n",
      "Step: 800  \tTraining loss: 0.44222110509872437\n",
      "Step: 800  \tTraining accuracy: 0.7722322940826416\n",
      "Step: 800  \tValid loss: 0.48705416917800903\n",
      "Step: 900  \tTraining loss: 0.4398031234741211\n",
      "Step: 900  \tTraining accuracy: 0.7754366397857666\n",
      "Step: 900  \tValid loss: 0.4846794605255127\n",
      "Step: 1000  \tTraining loss: 0.4375174939632416\n",
      "Step: 1000  \tTraining accuracy: 0.7778772711753845\n",
      "Step: 1000  \tValid loss: 0.48272234201431274\n",
      "Step: 1100  \tTraining loss: 0.4353829026222229\n",
      "Step: 1100  \tTraining accuracy: 0.7798938155174255\n",
      "Step: 1100  \tValid loss: 0.4809468686580658\n",
      "Step: 1200  \tTraining loss: 0.43378254771232605\n",
      "Step: 1200  \tTraining accuracy: 0.7816338539123535\n",
      "Step: 1200  \tValid loss: 0.47960957884788513\n",
      "Step: 1300  \tTraining loss: 0.43250975012779236\n",
      "Step: 1300  \tTraining accuracy: 0.7831637263298035\n",
      "Step: 1300  \tValid loss: 0.4775771200656891\n",
      "Step: 1400  \tTraining loss: 0.4315681457519531\n",
      "Step: 1400  \tTraining accuracy: 0.7844669818878174\n",
      "Step: 1400  \tValid loss: 0.4747651517391205\n",
      "Step: 1500  \tTraining loss: 0.43082600831985474\n",
      "Step: 1500  \tTraining accuracy: 0.785796046257019\n",
      "Step: 1500  \tValid loss: 0.4727729856967926\n",
      "Step: 1600  \tTraining loss: 0.4302908480167389\n",
      "Step: 1600  \tTraining accuracy: 0.787063479423523\n",
      "Step: 1600  \tValid loss: 0.4706502854824066\n",
      "Step: 1700  \tTraining loss: 0.429881751537323\n",
      "Step: 1700  \tTraining accuracy: 0.7882547378540039\n",
      "Step: 1700  \tValid loss: 0.46913427114486694\n",
      "Step: 1800  \tTraining loss: 0.429532915353775\n",
      "Step: 1800  \tTraining accuracy: 0.7893341779708862\n",
      "Step: 1800  \tValid loss: 0.4681984484195709\n",
      "Step: 1900  \tTraining loss: 0.42907848954200745\n",
      "Step: 1900  \tTraining accuracy: 0.7902739644050598\n",
      "Step: 1900  \tValid loss: 0.467515766620636\n",
      "Step: 2000  \tTraining loss: 0.4288189113140106\n",
      "Step: 2000  \tTraining accuracy: 0.7912265658378601\n",
      "Step: 2000  \tValid loss: 0.4664788246154785\n",
      "Step: 2100  \tTraining loss: 0.4285861551761627\n",
      "Step: 2100  \tTraining accuracy: 0.792065441608429\n",
      "Step: 2100  \tValid loss: 0.46585017442703247\n",
      "Step: 2200  \tTraining loss: 0.4283381998538971\n",
      "Step: 2200  \tTraining accuracy: 0.792846143245697\n",
      "Step: 2200  \tValid loss: 0.46519413590431213\n",
      "Step: 2300  \tTraining loss: 0.4280489683151245\n",
      "Step: 2300  \tTraining accuracy: 0.7935574054718018\n",
      "Step: 2300  \tValid loss: 0.4648566246032715\n",
      "Step: 2400  \tTraining loss: 0.4276912212371826\n",
      "Step: 2400  \tTraining accuracy: 0.7942082285881042\n",
      "Step: 2400  \tValid loss: 0.46460968255996704\n",
      "Step: 2500  \tTraining loss: 0.42731067538261414\n",
      "Step: 2500  \tTraining accuracy: 0.7948753833770752\n",
      "Step: 2500  \tValid loss: 0.4642600119113922\n",
      "Step: 2600  \tTraining loss: 0.4267849326133728\n",
      "Step: 2600  \tTraining accuracy: 0.7954902052879333\n",
      "Step: 2600  \tValid loss: 0.4638832211494446\n",
      "Step: 2700  \tTraining loss: 0.4260913133621216\n",
      "Step: 2700  \tTraining accuracy: 0.7960746884346008\n",
      "Step: 2700  \tValid loss: 0.4631677269935608\n",
      "Step: 2800  \tTraining loss: 0.4254662096500397\n",
      "Step: 2800  \tTraining accuracy: 0.7965857982635498\n",
      "Step: 2800  \tValid loss: 0.4624973237514496\n",
      "Step: 2900  \tTraining loss: 0.4248412251472473\n",
      "Step: 2900  \tTraining accuracy: 0.7971206903457642\n",
      "Step: 2900  \tValid loss: 0.4618452191352844\n",
      "Step: 3000  \tTraining loss: 0.4242106080055237\n",
      "Step: 3000  \tTraining accuracy: 0.7976194024085999\n",
      "Step: 3000  \tValid loss: 0.46157312393188477\n",
      "Step: 3100  \tTraining loss: 0.42365801334381104\n",
      "Step: 3100  \tTraining accuracy: 0.7980853915214539\n",
      "Step: 3100  \tValid loss: 0.4613518714904785\n",
      "Step: 3200  \tTraining loss: 0.42314112186431885\n",
      "Step: 3200  \tTraining accuracy: 0.7984136939048767\n",
      "Step: 3200  \tValid loss: 0.46108025312423706\n",
      "Step: 3300  \tTraining loss: 0.4226332902908325\n",
      "Step: 3300  \tTraining accuracy: 0.7987610697746277\n",
      "Step: 3300  \tValid loss: 0.46065959334373474\n",
      "Step: 3400  \tTraining loss: 0.42210328578948975\n",
      "Step: 3400  \tTraining accuracy: 0.7991385459899902\n",
      "Step: 3400  \tValid loss: 0.4600751996040344\n",
      "Step: 3500  \tTraining loss: 0.42149555683135986\n",
      "Step: 3500  \tTraining accuracy: 0.7994818091392517\n",
      "Step: 3500  \tValid loss: 0.45982393622398376\n",
      "Step: 3600  \tTraining loss: 0.4209328293800354\n",
      "Step: 3600  \tTraining accuracy: 0.7998297214508057\n",
      "Step: 3600  \tValid loss: 0.45967498421669006\n",
      "Step: 3700  \tTraining loss: 0.4203559458255768\n",
      "Step: 3700  \tTraining accuracy: 0.8001469373703003\n",
      "Step: 3700  \tValid loss: 0.4596622586250305\n",
      "Step: 3800  \tTraining loss: 0.4197745621204376\n",
      "Step: 3800  \tTraining accuracy: 0.800458550453186\n",
      "Step: 3800  \tValid loss: 0.4598531126976013\n",
      "Step: 3900  \tTraining loss: 0.4192159175872803\n",
      "Step: 3900  \tTraining accuracy: 0.8007429242134094\n",
      "Step: 3900  \tValid loss: 0.4601692259311676\n",
      "Step: 4000  \tTraining loss: 0.4186796247959137\n",
      "Step: 4000  \tTraining accuracy: 0.8010129332542419\n",
      "Step: 4000  \tValid loss: 0.4604988694190979\n",
      "Step: 4100  \tTraining loss: 0.4181423783302307\n",
      "Step: 4100  \tTraining accuracy: 0.8012800812721252\n",
      "Step: 4100  \tValid loss: 0.4607323706150055\n",
      "Step: 4200  \tTraining loss: 0.41760188341140747\n",
      "Step: 4200  \tTraining accuracy: 0.8015138506889343\n",
      "Step: 4200  \tValid loss: 0.46099719405174255\n",
      "Step: 4300  \tTraining loss: 0.41710343956947327\n",
      "Step: 4300  \tTraining accuracy: 0.8017366528511047\n",
      "Step: 4300  \tValid loss: 0.46152782440185547\n",
      "Step: 4400  \tTraining loss: 0.416628360748291\n",
      "Step: 4400  \tTraining accuracy: 0.8019198179244995\n",
      "Step: 4400  \tValid loss: 0.4618615508079529\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8020948\n",
      "Precision: 0.8429518\n",
      "Recall: 0.95498395\n",
      "F1 score: 0.8520746\n",
      "AUC: 0.6532732\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.802095   0.842952  0.954984  0.852075  0.653273  0.416397      0.801831   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.459517       0.801969   0.439567      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4443.0  \n",
      "19\n",
      "(899, 5)\n",
      "(899, 1)\n",
      "(480, 5)\n",
      "(480, 1)\n",
      "(390, 5)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4391751289367676\n",
      "Step: 100  \tTraining accuracy: 0.8264738321304321\n",
      "Step: 100  \tValid loss: 0.45206859707832336\n",
      "Step: 200  \tTraining loss: 0.4367688298225403\n",
      "Step: 200  \tTraining accuracy: 0.8294602632522583\n",
      "Step: 200  \tValid loss: 0.44892024993896484\n",
      "Step: 300  \tTraining loss: 0.43516936898231506\n",
      "Step: 300  \tTraining accuracy: 0.8300653696060181\n",
      "Step: 300  \tValid loss: 0.44766202569007874\n",
      "Step: 400  \tTraining loss: 0.43383222818374634\n",
      "Step: 400  \tTraining accuracy: 0.8303254842758179\n",
      "Step: 400  \tValid loss: 0.44656848907470703\n",
      "Step: 500  \tTraining loss: 0.4324764907360077\n",
      "Step: 500  \tTraining accuracy: 0.8309717774391174\n",
      "Step: 500  \tValid loss: 0.44571515917778015\n",
      "Step: 600  \tTraining loss: 0.4309777617454529\n",
      "Step: 600  \tTraining accuracy: 0.8314860463142395\n",
      "Step: 600  \tValid loss: 0.445001482963562\n",
      "Step: 700  \tTraining loss: 0.4293701946735382\n",
      "Step: 700  \tTraining accuracy: 0.8317553997039795\n",
      "Step: 700  \tValid loss: 0.44449031352996826\n",
      "Step: 800  \tTraining loss: 0.42713138461112976\n",
      "Step: 800  \tTraining accuracy: 0.8319530487060547\n",
      "Step: 800  \tValid loss: 0.4430515468120575\n",
      "Step: 900  \tTraining loss: 0.4254792332649231\n",
      "Step: 900  \tTraining accuracy: 0.831971287727356\n",
      "Step: 900  \tValid loss: 0.4422062635421753\n",
      "Step: 1000  \tTraining loss: 0.42412346601486206\n",
      "Step: 1000  \tTraining accuracy: 0.8320451974868774\n",
      "Step: 1000  \tValid loss: 0.4421711564064026\n",
      "Step: 1100  \tTraining loss: 0.4229718744754791\n",
      "Step: 1100  \tTraining accuracy: 0.8321588039398193\n",
      "Step: 1100  \tValid loss: 0.44220319390296936\n",
      "Step: 1200  \tTraining loss: 0.4220833480358124\n",
      "Step: 1200  \tTraining accuracy: 0.8323509097099304\n",
      "Step: 1200  \tValid loss: 0.4421497881412506\n",
      "Step: 1300  \tTraining loss: 0.4213656783103943\n",
      "Step: 1300  \tTraining accuracy: 0.8324218988418579\n",
      "Step: 1300  \tValid loss: 0.44214895367622375\n",
      "Step: 1400  \tTraining loss: 0.4208044409751892\n",
      "Step: 1400  \tTraining accuracy: 0.8324823975563049\n",
      "Step: 1400  \tValid loss: 0.4424990117549896\n",
      "Step: 1500  \tTraining loss: 0.42036673426628113\n",
      "Step: 1500  \tTraining accuracy: 0.8325345516204834\n",
      "Step: 1500  \tValid loss: 0.44278016686439514\n",
      "Step: 1600  \tTraining loss: 0.4200032353401184\n",
      "Step: 1600  \tTraining accuracy: 0.832580029964447\n",
      "Step: 1600  \tValid loss: 0.44306713342666626\n",
      "Step: 1700  \tTraining loss: 0.41968852281570435\n",
      "Step: 1700  \tTraining accuracy: 0.8325856924057007\n",
      "Step: 1700  \tValid loss: 0.4433865249156952\n",
      "Step: 1800  \tTraining loss: 0.41940420866012573\n",
      "Step: 1800  \tTraining accuracy: 0.8326230049133301\n",
      "Step: 1800  \tValid loss: 0.4435804486274719\n",
      "Step: 1900  \tTraining loss: 0.41913270950317383\n",
      "Step: 1900  \tTraining accuracy: 0.8326257467269897\n",
      "Step: 1900  \tValid loss: 0.4437776505947113\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8325992\n",
      "Precision: 0.8329545\n",
      "Recall: 0.98654103\n",
      "F1 score: 0.90288025\n",
      "AUC: 0.52211666\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.832599   0.832955  0.986541   0.90288  0.522117  0.418993      0.832793   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.442088       0.832936   0.406141      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1951.0  \n",
      "20\n",
      "(899, 5)\n",
      "(899, 1)\n",
      "(496, 5)\n",
      "(496, 1)\n",
      "(403, 5)\n",
      "(403, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6274666786193848\n",
      "Step: 100  \tTraining accuracy: 0.6685205698013306\n",
      "Step: 100  \tValid loss: 0.6171715259552002\n",
      "Step: 200  \tTraining loss: 0.574384331703186\n",
      "Step: 200  \tTraining accuracy: 0.6848350167274475\n",
      "Step: 200  \tValid loss: 0.5642232298851013\n",
      "Step: 300  \tTraining loss: 0.5242854952812195\n",
      "Step: 300  \tTraining accuracy: 0.6985539197921753\n",
      "Step: 300  \tValid loss: 0.5168418288230896\n",
      "Step: 400  \tTraining loss: 0.4741319417953491\n",
      "Step: 400  \tTraining accuracy: 0.7142857313156128\n",
      "Step: 400  \tValid loss: 0.47365957498550415\n",
      "Step: 500  \tTraining loss: 0.442256361246109\n",
      "Step: 500  \tTraining accuracy: 0.7259918451309204\n",
      "Step: 500  \tValid loss: 0.45122626423835754\n",
      "Step: 600  \tTraining loss: 0.42987221479415894\n",
      "Step: 600  \tTraining accuracy: 0.7359692454338074\n",
      "Step: 600  \tValid loss: 0.4461856484413147\n",
      "Step: 700  \tTraining loss: 0.4255641996860504\n",
      "Step: 700  \tTraining accuracy: 0.7427055835723877\n",
      "Step: 700  \tValid loss: 0.4460564851760864\n",
      "Step: 800  \tTraining loss: 0.4236067533493042\n",
      "Step: 800  \tTraining accuracy: 0.747868001461029\n",
      "Step: 800  \tValid loss: 0.44599905610084534\n",
      "Step: 900  \tTraining loss: 0.4221687614917755\n",
      "Step: 900  \tTraining accuracy: 0.7520774602890015\n",
      "Step: 900  \tValid loss: 0.44544005393981934\n",
      "Step: 1000  \tTraining loss: 0.42104372382164\n",
      "Step: 1000  \tTraining accuracy: 0.7554007172584534\n",
      "Step: 1000  \tValid loss: 0.4443400800228119\n",
      "Step: 1100  \tTraining loss: 0.4200044274330139\n",
      "Step: 1100  \tTraining accuracy: 0.7579850554466248\n",
      "Step: 1100  \tValid loss: 0.4429977834224701\n",
      "Step: 1200  \tTraining loss: 0.4190020263195038\n",
      "Step: 1200  \tTraining accuracy: 0.7602166533470154\n",
      "Step: 1200  \tValid loss: 0.4414561986923218\n",
      "Step: 1300  \tTraining loss: 0.4180586338043213\n",
      "Step: 1300  \tTraining accuracy: 0.7621356844902039\n",
      "Step: 1300  \tValid loss: 0.43996143341064453\n",
      "Step: 1400  \tTraining loss: 0.4170830547809601\n",
      "Step: 1400  \tTraining accuracy: 0.7637704610824585\n",
      "Step: 1400  \tValid loss: 0.4383285939693451\n",
      "Step: 1500  \tTraining loss: 0.41609030961990356\n",
      "Step: 1500  \tTraining accuracy: 0.7652180790901184\n",
      "Step: 1500  \tValid loss: 0.43644261360168457\n",
      "Step: 1600  \tTraining loss: 0.4151018261909485\n",
      "Step: 1600  \tTraining accuracy: 0.766514778137207\n",
      "Step: 1600  \tValid loss: 0.4346820116043091\n",
      "Step: 1700  \tTraining loss: 0.41382041573524475\n",
      "Step: 1700  \tTraining accuracy: 0.7677217125892639\n",
      "Step: 1700  \tValid loss: 0.43231406807899475\n",
      "Step: 1800  \tTraining loss: 0.4125424325466156\n",
      "Step: 1800  \tTraining accuracy: 0.7687589526176453\n",
      "Step: 1800  \tValid loss: 0.430844247341156\n",
      "Step: 1900  \tTraining loss: 0.41139790415763855\n",
      "Step: 1900  \tTraining accuracy: 0.7697141170501709\n",
      "Step: 1900  \tValid loss: 0.4304168224334717\n",
      "Step: 2000  \tTraining loss: 0.4100772440433502\n",
      "Step: 2000  \tTraining accuracy: 0.7704001665115356\n",
      "Step: 2000  \tValid loss: 0.4303698241710663\n",
      "Step: 2100  \tTraining loss: 0.4091333746910095\n",
      "Step: 2100  \tTraining accuracy: 0.770965039730072\n",
      "Step: 2100  \tValid loss: 0.4295154809951782\n",
      "Step: 2200  \tTraining loss: 0.40838363766670227\n",
      "Step: 2200  \tTraining accuracy: 0.7715549468994141\n",
      "Step: 2200  \tValid loss: 0.4289172887802124\n",
      "Step: 2300  \tTraining loss: 0.407714307308197\n",
      "Step: 2300  \tTraining accuracy: 0.7721418738365173\n",
      "Step: 2300  \tValid loss: 0.4286268949508667\n",
      "Step: 2400  \tTraining loss: 0.40710580348968506\n",
      "Step: 2400  \tTraining accuracy: 0.7727025151252747\n",
      "Step: 2400  \tValid loss: 0.4283600449562073\n",
      "Step: 2500  \tTraining loss: 0.4065345227718353\n",
      "Step: 2500  \tTraining accuracy: 0.7731947302818298\n",
      "Step: 2500  \tValid loss: 0.428340882062912\n",
      "Step: 2600  \tTraining loss: 0.4060031473636627\n",
      "Step: 2600  \tTraining accuracy: 0.773495614528656\n",
      "Step: 2600  \tValid loss: 0.4280018210411072\n",
      "Step: 2700  \tTraining loss: 0.40551358461380005\n",
      "Step: 2700  \tTraining accuracy: 0.7737947702407837\n",
      "Step: 2700  \tValid loss: 0.4277849495410919\n",
      "Step: 2800  \tTraining loss: 0.40507277846336365\n",
      "Step: 2800  \tTraining accuracy: 0.7740722298622131\n",
      "Step: 2800  \tValid loss: 0.4274654984474182\n",
      "Step: 2900  \tTraining loss: 0.4046800136566162\n",
      "Step: 2900  \tTraining accuracy: 0.7743496894836426\n",
      "Step: 2900  \tValid loss: 0.4273013472557068\n",
      "Step: 3000  \tTraining loss: 0.4043223559856415\n",
      "Step: 3000  \tTraining accuracy: 0.774589478969574\n",
      "Step: 3000  \tValid loss: 0.4274432361125946\n",
      "Step: 3100  \tTraining loss: 0.40398329496383667\n",
      "Step: 3100  \tTraining accuracy: 0.7748682498931885\n",
      "Step: 3100  \tValid loss: 0.4273909032344818\n",
      "Step: 3200  \tTraining loss: 0.4036839008331299\n",
      "Step: 3200  \tTraining accuracy: 0.7751469612121582\n",
      "Step: 3200  \tValid loss: 0.4272422194480896\n",
      "Step: 3300  \tTraining loss: 0.40341314673423767\n",
      "Step: 3300  \tTraining accuracy: 0.7753914594650269\n",
      "Step: 3300  \tValid loss: 0.4271169602870941\n",
      "Step: 3400  \tTraining loss: 0.4031658470630646\n",
      "Step: 3400  \tTraining accuracy: 0.7756213545799255\n",
      "Step: 3400  \tValid loss: 0.42705512046813965\n",
      "Step: 3500  \tTraining loss: 0.40293851494789124\n",
      "Step: 3500  \tTraining accuracy: 0.7758539915084839\n",
      "Step: 3500  \tValid loss: 0.4269556701183319\n",
      "Step: 3600  \tTraining loss: 0.4027262330055237\n",
      "Step: 3600  \tTraining accuracy: 0.7760735750198364\n",
      "Step: 3600  \tValid loss: 0.4269258975982666\n",
      "Step: 3700  \tTraining loss: 0.4025300145149231\n",
      "Step: 3700  \tTraining accuracy: 0.7762963175773621\n",
      "Step: 3700  \tValid loss: 0.4269132912158966\n",
      "Step: 3800  \tTraining loss: 0.40234681963920593\n",
      "Step: 3800  \tTraining accuracy: 0.7765368819236755\n",
      "Step: 3800  \tValid loss: 0.42688220739364624\n",
      "Step: 3900  \tTraining loss: 0.40217554569244385\n",
      "Step: 3900  \tTraining accuracy: 0.7767649292945862\n",
      "Step: 3900  \tValid loss: 0.42688560485839844\n",
      "Step: 4000  \tTraining loss: 0.40201130509376526\n",
      "Step: 4000  \tTraining accuracy: 0.7770096063613892\n",
      "Step: 4000  \tValid loss: 0.42690715193748474\n",
      "Step: 4100  \tTraining loss: 0.40185874700546265\n",
      "Step: 4100  \tTraining accuracy: 0.7772559523582458\n",
      "Step: 4100  \tValid loss: 0.42688536643981934\n",
      "Step: 4200  \tTraining loss: 0.40171149373054504\n",
      "Step: 4200  \tTraining accuracy: 0.7775306105613708\n",
      "Step: 4200  \tValid loss: 0.42687928676605225\n",
      "Step: 4300  \tTraining loss: 0.40157079696655273\n",
      "Step: 4300  \tTraining accuracy: 0.7777923345565796\n",
      "Step: 4300  \tValid loss: 0.42692676186561584\n",
      "Step: 4400  \tTraining loss: 0.40143755078315735\n",
      "Step: 4400  \tTraining accuracy: 0.7780547738075256\n",
      "Step: 4400  \tValid loss: 0.42690426111221313\n",
      "Step: 4500  \tTraining loss: 0.4013080596923828\n",
      "Step: 4500  \tTraining accuracy: 0.7782930135726929\n",
      "Step: 4500  \tValid loss: 0.4269435703754425\n",
      "Step: 4600  \tTraining loss: 0.40118229389190674\n",
      "Step: 4600  \tTraining accuracy: 0.7785329222679138\n",
      "Step: 4600  \tValid loss: 0.42697253823280334\n",
      "Step: 4700  \tTraining loss: 0.4010646641254425\n",
      "Step: 4700  \tTraining accuracy: 0.7787505984306335\n",
      "Step: 4700  \tValid loss: 0.4269513785839081\n",
      "Step: 4800  \tTraining loss: 0.4009495675563812\n",
      "Step: 4800  \tTraining accuracy: 0.7789473533630371\n",
      "Step: 4800  \tValid loss: 0.4269656836986542\n",
      "Step: 4900  \tTraining loss: 0.4008355140686035\n",
      "Step: 4900  \tTraining accuracy: 0.7791245579719543\n",
      "Step: 4900  \tValid loss: 0.42703285813331604\n",
      "Step: 5000  \tTraining loss: 0.40072786808013916\n",
      "Step: 5000  \tTraining accuracy: 0.7792834043502808\n",
      "Step: 5000  \tValid loss: 0.4270600974559784\n",
      "Step: 5100  \tTraining loss: 0.40062227845191956\n",
      "Step: 5100  \tTraining accuracy: 0.7794358730316162\n",
      "Step: 5100  \tValid loss: 0.4270634353160858\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.77956086\n",
      "Precision: 0.84549356\n",
      "Recall: 0.78642714\n",
      "F1 score: 0.7513451\n",
      "AUC: 0.8027613\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.779561   0.845494  0.786427  0.751345  0.802761  0.400557      0.779352   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.426809       0.779424   0.487504      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5162.0  \n",
      "21\n",
      "(957, 5)\n",
      "(957, 1)\n",
      "(528, 5)\n",
      "(528, 1)\n",
      "(429, 5)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6362144947052002\n",
      "Step: 100  \tTraining accuracy: 0.676071047782898\n",
      "Step: 100  \tValid loss: 0.647972583770752\n",
      "Step: 200  \tTraining loss: 0.5575227737426758\n",
      "Step: 200  \tTraining accuracy: 0.6854754686355591\n",
      "Step: 200  \tValid loss: 0.5782185792922974\n",
      "Step: 300  \tTraining loss: 0.46762195229530334\n",
      "Step: 300  \tTraining accuracy: 0.7201671600341797\n",
      "Step: 300  \tValid loss: 0.4851527214050293\n",
      "Step: 400  \tTraining loss: 0.3792286217212677\n",
      "Step: 400  \tTraining accuracy: 0.7548887729644775\n",
      "Step: 400  \tValid loss: 0.3944554328918457\n",
      "Step: 500  \tTraining loss: 0.32465896010398865\n",
      "Step: 500  \tTraining accuracy: 0.7832346558570862\n",
      "Step: 500  \tValid loss: 0.3386410176753998\n",
      "Step: 600  \tTraining loss: 0.29410502314567566\n",
      "Step: 600  \tTraining accuracy: 0.8026028275489807\n",
      "Step: 600  \tValid loss: 0.3075293302536011\n",
      "Step: 700  \tTraining loss: 0.2761833071708679\n",
      "Step: 700  \tTraining accuracy: 0.8163331151008606\n",
      "Step: 700  \tValid loss: 0.2894314229488373\n",
      "Step: 800  \tTraining loss: 0.2649904787540436\n",
      "Step: 800  \tTraining accuracy: 0.8260536193847656\n",
      "Step: 800  \tValid loss: 0.2782449424266815\n",
      "Step: 900  \tTraining loss: 0.25759652256965637\n",
      "Step: 900  \tTraining accuracy: 0.833609938621521\n",
      "Step: 900  \tValid loss: 0.27094218134880066\n",
      "Step: 1000  \tTraining loss: 0.2524736225605011\n",
      "Step: 1000  \tTraining accuracy: 0.8395754098892212\n",
      "Step: 1000  \tValid loss: 0.2659528851509094\n",
      "Step: 1100  \tTraining loss: 0.24877320230007172\n",
      "Step: 1100  \tTraining accuracy: 0.8444046378135681\n",
      "Step: 1100  \tValid loss: 0.2624056935310364\n",
      "Step: 1200  \tTraining loss: 0.24599528312683105\n",
      "Step: 1200  \tTraining accuracy: 0.8484393954277039\n",
      "Step: 1200  \tValid loss: 0.25979340076446533\n",
      "Step: 1300  \tTraining loss: 0.2438291311264038\n",
      "Step: 1300  \tTraining accuracy: 0.8518286347389221\n",
      "Step: 1300  \tValid loss: 0.2578001916408539\n",
      "Step: 1400  \tTraining loss: 0.24207307398319244\n",
      "Step: 1400  \tTraining accuracy: 0.8547544479370117\n",
      "Step: 1400  \tValid loss: 0.2562229335308075\n",
      "Step: 1500  \tTraining loss: 0.24059194326400757\n",
      "Step: 1500  \tTraining accuracy: 0.8573127388954163\n",
      "Step: 1500  \tValid loss: 0.254923939704895\n",
      "Step: 1600  \tTraining loss: 0.23929524421691895\n",
      "Step: 1600  \tTraining accuracy: 0.8596082925796509\n",
      "Step: 1600  \tValid loss: 0.25380703806877136\n",
      "Step: 1700  \tTraining loss: 0.23812896013259888\n",
      "Step: 1700  \tTraining accuracy: 0.8616889715194702\n",
      "Step: 1700  \tValid loss: 0.2528058588504791\n",
      "Step: 1800  \tTraining loss: 0.23706822097301483\n",
      "Step: 1800  \tTraining accuracy: 0.8635915517807007\n",
      "Step: 1800  \tValid loss: 0.2518792748451233\n",
      "Step: 1900  \tTraining loss: 0.2361091673374176\n",
      "Step: 1900  \tTraining accuracy: 0.865288496017456\n",
      "Step: 1900  \tValid loss: 0.2510097324848175\n",
      "Step: 2000  \tTraining loss: 0.23525474965572357\n",
      "Step: 2000  \tTraining accuracy: 0.8668113350868225\n",
      "Step: 2000  \tValid loss: 0.2501961588859558\n",
      "Step: 2100  \tTraining loss: 0.23450474441051483\n",
      "Step: 2100  \tTraining accuracy: 0.8682111501693726\n",
      "Step: 2100  \tValid loss: 0.24944616854190826\n",
      "Step: 2200  \tTraining loss: 0.23385226726531982\n",
      "Step: 2200  \tTraining accuracy: 0.8695293068885803\n",
      "Step: 2200  \tValid loss: 0.24876698851585388\n",
      "Step: 2300  \tTraining loss: 0.23328624665737152\n",
      "Step: 2300  \tTraining accuracy: 0.8707535266876221\n",
      "Step: 2300  \tValid loss: 0.24816209077835083\n",
      "Step: 2400  \tTraining loss: 0.23279397189617157\n",
      "Step: 2400  \tTraining accuracy: 0.8719402551651001\n",
      "Step: 2400  \tValid loss: 0.2476305514574051\n",
      "Step: 2500  \tTraining loss: 0.23236387968063354\n",
      "Step: 2500  \tTraining accuracy: 0.8730514049530029\n",
      "Step: 2500  \tValid loss: 0.24716833233833313\n",
      "Step: 2600  \tTraining loss: 0.2319858819246292\n",
      "Step: 2600  \tTraining accuracy: 0.8741164207458496\n",
      "Step: 2600  \tValid loss: 0.24677008390426636\n",
      "Step: 2700  \tTraining loss: 0.23165147006511688\n",
      "Step: 2700  \tTraining accuracy: 0.8751404881477356\n",
      "Step: 2700  \tValid loss: 0.24642978608608246\n",
      "Step: 2800  \tTraining loss: 0.23135370016098022\n",
      "Step: 2800  \tTraining accuracy: 0.876071035861969\n",
      "Step: 2800  \tValid loss: 0.24614207446575165\n",
      "Step: 2900  \tTraining loss: 0.23108679056167603\n",
      "Step: 2900  \tTraining accuracy: 0.8768813610076904\n",
      "Step: 2900  \tValid loss: 0.24590101838111877\n",
      "Step: 3000  \tTraining loss: 0.23084582388401031\n",
      "Step: 3000  \tTraining accuracy: 0.8776189684867859\n",
      "Step: 3000  \tValid loss: 0.24570123851299286\n",
      "Step: 3100  \tTraining loss: 0.2306266725063324\n",
      "Step: 3100  \tTraining accuracy: 0.878291130065918\n",
      "Step: 3100  \tValid loss: 0.24553824961185455\n",
      "Step: 3200  \tTraining loss: 0.23042599856853485\n",
      "Step: 3200  \tTraining accuracy: 0.8789371252059937\n",
      "Step: 3200  \tValid loss: 0.2454073429107666\n",
      "Step: 3300  \tTraining loss: 0.23024103045463562\n",
      "Step: 3300  \tTraining accuracy: 0.8795434236526489\n",
      "Step: 3300  \tValid loss: 0.24530445039272308\n",
      "Step: 3400  \tTraining loss: 0.23006929457187653\n",
      "Step: 3400  \tTraining accuracy: 0.8801291584968567\n",
      "Step: 3400  \tValid loss: 0.24522602558135986\n",
      "Step: 3500  \tTraining loss: 0.22990897297859192\n",
      "Step: 3500  \tTraining accuracy: 0.8806808590888977\n",
      "Step: 3500  \tValid loss: 0.24516868591308594\n",
      "Step: 3600  \tTraining loss: 0.22975848615169525\n",
      "Step: 3600  \tTraining accuracy: 0.8812015056610107\n",
      "Step: 3600  \tValid loss: 0.24512979388237\n",
      "Step: 3700  \tTraining loss: 0.22961638867855072\n",
      "Step: 3700  \tTraining accuracy: 0.8816649913787842\n",
      "Step: 3700  \tValid loss: 0.24510660767555237\n",
      "Step: 3800  \tTraining loss: 0.22948147356510162\n",
      "Step: 3800  \tTraining accuracy: 0.8821038007736206\n",
      "Step: 3800  \tValid loss: 0.24509719014167786\n",
      "Step: 3900  \tTraining loss: 0.22935296595096588\n",
      "Step: 3900  \tTraining accuracy: 0.8825333714485168\n",
      "Step: 3900  \tValid loss: 0.24509955942630768\n",
      "Step: 4000  \tTraining loss: 0.22923000156879425\n",
      "Step: 4000  \tTraining accuracy: 0.8829543590545654\n",
      "Step: 4000  \tValid loss: 0.24511224031448364\n",
      "Step: 4100  \tTraining loss: 0.2291119545698166\n",
      "Step: 4100  \tTraining accuracy: 0.8833546042442322\n",
      "Step: 4100  \tValid loss: 0.2451339215040207\n",
      "Step: 4200  \tTraining loss: 0.22899824380874634\n",
      "Step: 4200  \tTraining accuracy: 0.8837355971336365\n",
      "Step: 4200  \tValid loss: 0.24516330659389496\n",
      "Step: 4300  \tTraining loss: 0.22888849675655365\n",
      "Step: 4300  \tTraining accuracy: 0.8840985894203186\n",
      "Step: 4300  \tValid loss: 0.2451992630958557\n",
      "Step: 4400  \tTraining loss: 0.22878223657608032\n",
      "Step: 4400  \tTraining accuracy: 0.8844569325447083\n",
      "Step: 4400  \tValid loss: 0.2452409863471985\n",
      "Step: 4500  \tTraining loss: 0.22867923974990845\n",
      "Step: 4500  \tTraining accuracy: 0.8847991824150085\n",
      "Step: 4500  \tValid loss: 0.24528807401657104\n",
      "Step: 4600  \tTraining loss: 0.22857922315597534\n",
      "Step: 4600  \tTraining accuracy: 0.8851149082183838\n",
      "Step: 4600  \tValid loss: 0.24533936381340027\n",
      "Step: 4700  \tTraining loss: 0.22848184406757355\n",
      "Step: 4700  \tTraining accuracy: 0.8854057788848877\n",
      "Step: 4700  \tValid loss: 0.24539467692375183\n",
      "Step: 4800  \tTraining loss: 0.22838710248470306\n",
      "Step: 4800  \tTraining accuracy: 0.8856844305992126\n",
      "Step: 4800  \tValid loss: 0.24545302987098694\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8859516\n",
      "Precision: 0.90654206\n",
      "Recall: 0.88787186\n",
      "F1 score: 0.8767336\n",
      "AUC: 0.9054744\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.885952   0.906542  0.887872  0.876734  0.905474  0.22836      0.885732   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.245097       0.885696   0.309669      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4828.0  \n",
      "22\n",
      "(1015, 5)\n",
      "(1015, 1)\n",
      "(560, 5)\n",
      "(560, 1)\n",
      "(455, 5)\n",
      "(455, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6490102410316467\n",
      "Step: 100  \tTraining accuracy: 0.7182266116142273\n",
      "Step: 100  \tValid loss: 0.6640981435775757\n",
      "Step: 200  \tTraining loss: 0.5861162543296814\n",
      "Step: 200  \tTraining accuracy: 0.7267652153968811\n",
      "Step: 200  \tValid loss: 0.6283369660377502\n",
      "Step: 300  \tTraining loss: 0.5669608116149902\n",
      "Step: 300  \tTraining accuracy: 0.7314285635948181\n",
      "Step: 300  \tValid loss: 0.6169068217277527\n",
      "Step: 400  \tTraining loss: 0.5466698408126831\n",
      "Step: 400  \tTraining accuracy: 0.7345531582832336\n",
      "Step: 400  \tValid loss: 0.5976269841194153\n",
      "Step: 500  \tTraining loss: 0.5215205550193787\n",
      "Step: 500  \tTraining accuracy: 0.7370553016662598\n",
      "Step: 500  \tValid loss: 0.5729463696479797\n",
      "Step: 600  \tTraining loss: 0.4963913559913635\n",
      "Step: 600  \tTraining accuracy: 0.7402597665786743\n",
      "Step: 600  \tValid loss: 0.5487667918205261\n",
      "Step: 700  \tTraining loss: 0.4787156581878662\n",
      "Step: 700  \tTraining accuracy: 0.7427055835723877\n",
      "Step: 700  \tValid loss: 0.532746434211731\n",
      "Step: 800  \tTraining loss: 0.46853235363960266\n",
      "Step: 800  \tTraining accuracy: 0.7452873587608337\n",
      "Step: 800  \tValid loss: 0.5238879323005676\n",
      "Step: 900  \tTraining loss: 0.46281445026397705\n",
      "Step: 900  \tTraining accuracy: 0.7469719052314758\n",
      "Step: 900  \tValid loss: 0.5185188055038452\n",
      "Step: 1000  \tTraining loss: 0.4596630930900574\n",
      "Step: 1000  \tTraining accuracy: 0.7485610842704773\n",
      "Step: 1000  \tValid loss: 0.5157114267349243\n",
      "Step: 1100  \tTraining loss: 0.45779260993003845\n",
      "Step: 1100  \tTraining accuracy: 0.7500820755958557\n",
      "Step: 1100  \tValid loss: 0.513811469078064\n",
      "Step: 1200  \tTraining loss: 0.4565528333187103\n",
      "Step: 1200  \tTraining accuracy: 0.7513386011123657\n",
      "Step: 1200  \tValid loss: 0.5125121474266052\n",
      "Step: 1300  \tTraining loss: 0.45562776923179626\n",
      "Step: 1300  \tTraining accuracy: 0.7523546814918518\n",
      "Step: 1300  \tValid loss: 0.5115118026733398\n",
      "Step: 1400  \tTraining loss: 0.4548724889755249\n",
      "Step: 1400  \tTraining accuracy: 0.7532202005386353\n",
      "Step: 1400  \tValid loss: 0.5106490254402161\n",
      "Step: 1500  \tTraining loss: 0.4542127549648285\n",
      "Step: 1500  \tTraining accuracy: 0.7538984417915344\n",
      "Step: 1500  \tValid loss: 0.5099880695343018\n",
      "Step: 1600  \tTraining loss: 0.45359355211257935\n",
      "Step: 1600  \tTraining accuracy: 0.7545208930969238\n",
      "Step: 1600  \tValid loss: 0.5094124674797058\n",
      "Step: 1700  \tTraining loss: 0.45290273427963257\n",
      "Step: 1700  \tTraining accuracy: 0.754978358745575\n",
      "Step: 1700  \tValid loss: 0.5091198086738586\n",
      "Step: 1800  \tTraining loss: 0.4522903859615326\n",
      "Step: 1800  \tTraining accuracy: 0.7553553581237793\n",
      "Step: 1800  \tValid loss: 0.5086641907691956\n",
      "Step: 1900  \tTraining loss: 0.4516828656196594\n",
      "Step: 1900  \tTraining accuracy: 0.7557182908058167\n",
      "Step: 1900  \tValid loss: 0.5081086754798889\n",
      "Step: 2000  \tTraining loss: 0.4510878026485443\n",
      "Step: 2000  \tTraining accuracy: 0.7560944557189941\n",
      "Step: 2000  \tValid loss: 0.5075870752334595\n",
      "Step: 2100  \tTraining loss: 0.45051896572113037\n",
      "Step: 2100  \tTraining accuracy: 0.7564820647239685\n",
      "Step: 2100  \tValid loss: 0.5070566534996033\n",
      "Step: 2200  \tTraining loss: 0.4499768316745758\n",
      "Step: 2200  \tTraining accuracy: 0.7568564414978027\n",
      "Step: 2200  \tValid loss: 0.5066167712211609\n",
      "Step: 2300  \tTraining loss: 0.44946858286857605\n",
      "Step: 2300  \tTraining accuracy: 0.7570662498474121\n",
      "Step: 2300  \tValid loss: 0.5061853528022766\n",
      "Step: 2400  \tTraining loss: 0.44898831844329834\n",
      "Step: 2400  \tTraining accuracy: 0.7573419809341431\n",
      "Step: 2400  \tValid loss: 0.5057802200317383\n",
      "Step: 2500  \tTraining loss: 0.4485335350036621\n",
      "Step: 2500  \tTraining accuracy: 0.7574746012687683\n",
      "Step: 2500  \tValid loss: 0.5053516626358032\n",
      "Step: 2600  \tTraining loss: 0.4480988681316376\n",
      "Step: 2600  \tTraining accuracy: 0.7576161623001099\n",
      "Step: 2600  \tValid loss: 0.505009114742279\n",
      "Step: 2700  \tTraining loss: 0.44768381118774414\n",
      "Step: 2700  \tTraining accuracy: 0.7577469944953918\n",
      "Step: 2700  \tValid loss: 0.5047322511672974\n",
      "Step: 2800  \tTraining loss: 0.4472813904285431\n",
      "Step: 2800  \tTraining accuracy: 0.7578504085540771\n",
      "Step: 2800  \tValid loss: 0.5045522451400757\n",
      "Step: 2900  \tTraining loss: 0.44687509536743164\n",
      "Step: 2900  \tTraining accuracy: 0.7579466104507446\n",
      "Step: 2900  \tValid loss: 0.5044766068458557\n",
      "Step: 3000  \tTraining loss: 0.44647544622421265\n",
      "Step: 3000  \tTraining accuracy: 0.7580362558364868\n",
      "Step: 3000  \tValid loss: 0.5044242143630981\n",
      "Step: 3100  \tTraining loss: 0.4460853338241577\n",
      "Step: 3100  \tTraining accuracy: 0.7581038475036621\n",
      "Step: 3100  \tValid loss: 0.504457950592041\n",
      "Step: 3200  \tTraining loss: 0.44570672512054443\n",
      "Step: 3200  \tTraining accuracy: 0.7582610249519348\n",
      "Step: 3200  \tValid loss: 0.504472553730011\n",
      "Step: 3300  \tTraining loss: 0.4453486502170563\n",
      "Step: 3300  \tTraining accuracy: 0.7584388256072998\n",
      "Step: 3300  \tValid loss: 0.5045021176338196\n",
      "Step: 3400  \tTraining loss: 0.4450053572654724\n",
      "Step: 3400  \tTraining accuracy: 0.7585765719413757\n",
      "Step: 3400  \tValid loss: 0.5045146346092224\n",
      "Step: 3500  \tTraining loss: 0.44467997550964355\n",
      "Step: 3500  \tTraining accuracy: 0.7587491869926453\n",
      "Step: 3500  \tValid loss: 0.5045480728149414\n",
      "Step: 3600  \tTraining loss: 0.4443719685077667\n",
      "Step: 3600  \tTraining accuracy: 0.7589259743690491\n",
      "Step: 3600  \tValid loss: 0.5045883059501648\n",
      "Step: 3700  \tTraining loss: 0.4440777003765106\n",
      "Step: 3700  \tTraining accuracy: 0.759133517742157\n",
      "Step: 3700  \tValid loss: 0.5046133995056152\n",
      "Step: 3800  \tTraining loss: 0.44379740953445435\n",
      "Step: 3800  \tTraining accuracy: 0.7593300342559814\n",
      "Step: 3800  \tValid loss: 0.5046553015708923\n",
      "Step: 3900  \tTraining loss: 0.4435253441333771\n",
      "Step: 3900  \tTraining accuracy: 0.7595291137695312\n",
      "Step: 3900  \tValid loss: 0.5047386884689331\n",
      "Step: 4000  \tTraining loss: 0.4432660937309265\n",
      "Step: 4000  \tTraining accuracy: 0.7597306370735168\n",
      "Step: 4000  \tValid loss: 0.5047867298126221\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.75991\n",
      "Precision: 0.75632185\n",
      "Recall: 0.73273945\n",
      "F1 score: 0.7478752\n",
      "AUC: 0.7727301\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0   0.75991   0.756322  0.732739  0.747875  0.77273  0.443193      0.759692   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.504381       0.759834   0.437522      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4031.0  \n",
      "23\n",
      "(841, 5)\n",
      "(841, 1)\n",
      "(464, 5)\n",
      "(464, 1)\n",
      "(377, 5)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5683342814445496\n",
      "Step: 100  \tTraining accuracy: 0.7241379022598267\n",
      "Step: 100  \tValid loss: 0.5979965329170227\n",
      "Step: 200  \tTraining loss: 0.560059130191803\n",
      "Step: 200  \tTraining accuracy: 0.7213634848594666\n",
      "Step: 200  \tValid loss: 0.590753972530365\n",
      "Step: 300  \tTraining loss: 0.5523927211761475\n",
      "Step: 300  \tTraining accuracy: 0.7210463881492615\n",
      "Step: 300  \tValid loss: 0.5819897055625916\n",
      "Step: 400  \tTraining loss: 0.5443413257598877\n",
      "Step: 400  \tTraining accuracy: 0.7214200496673584\n",
      "Step: 400  \tValid loss: 0.5721421837806702\n",
      "Step: 500  \tTraining loss: 0.5367225408554077\n",
      "Step: 500  \tTraining accuracy: 0.7226846218109131\n",
      "Step: 500  \tValid loss: 0.5622169971466064\n",
      "Step: 600  \tTraining loss: 0.5299931764602661\n",
      "Step: 600  \tTraining accuracy: 0.7238136529922485\n",
      "Step: 600  \tValid loss: 0.553512692451477\n",
      "Step: 700  \tTraining loss: 0.5234978795051575\n",
      "Step: 700  \tTraining accuracy: 0.7266075015068054\n",
      "Step: 700  \tValid loss: 0.5458002686500549\n",
      "Step: 800  \tTraining loss: 0.5159070491790771\n",
      "Step: 800  \tTraining accuracy: 0.7300039529800415\n",
      "Step: 800  \tValid loss: 0.5377622842788696\n",
      "Step: 900  \tTraining loss: 0.5062596201896667\n",
      "Step: 900  \tTraining accuracy: 0.7335105538368225\n",
      "Step: 900  \tValid loss: 0.5272275805473328\n",
      "Step: 1000  \tTraining loss: 0.4952484369277954\n",
      "Step: 1000  \tTraining accuracy: 0.736779510974884\n",
      "Step: 1000  \tValid loss: 0.5159432888031006\n",
      "Step: 1100  \tTraining loss: 0.48486149311065674\n",
      "Step: 1100  \tTraining accuracy: 0.7402185797691345\n",
      "Step: 1100  \tValid loss: 0.5036690831184387\n",
      "Step: 1200  \tTraining loss: 0.4747997522354126\n",
      "Step: 1200  \tTraining accuracy: 0.7434213757514954\n",
      "Step: 1200  \tValid loss: 0.49145787954330444\n",
      "Step: 1300  \tTraining loss: 0.46632513403892517\n",
      "Step: 1300  \tTraining accuracy: 0.7467776536941528\n",
      "Step: 1300  \tValid loss: 0.48182374238967896\n",
      "Step: 1400  \tTraining loss: 0.4609363079071045\n",
      "Step: 1400  \tTraining accuracy: 0.7499009370803833\n",
      "Step: 1400  \tValid loss: 0.47546151280403137\n",
      "Step: 1500  \tTraining loss: 0.4568624198436737\n",
      "Step: 1500  \tTraining accuracy: 0.7527983784675598\n",
      "Step: 1500  \tValid loss: 0.47111690044403076\n",
      "Step: 1600  \tTraining loss: 0.45390743017196655\n",
      "Step: 1600  \tTraining accuracy: 0.7554754614830017\n",
      "Step: 1600  \tValid loss: 0.46787717938423157\n",
      "Step: 1700  \tTraining loss: 0.4515606462955475\n",
      "Step: 1700  \tTraining accuracy: 0.7577559351921082\n",
      "Step: 1700  \tValid loss: 0.46529725193977356\n",
      "Step: 1800  \tTraining loss: 0.44960418343544006\n",
      "Step: 1800  \tTraining accuracy: 0.7599116563796997\n",
      "Step: 1800  \tValid loss: 0.46308761835098267\n",
      "Step: 1900  \tTraining loss: 0.44720980525016785\n",
      "Step: 1900  \tTraining accuracy: 0.7618343830108643\n",
      "Step: 1900  \tValid loss: 0.46015363931655884\n",
      "Step: 2000  \tTraining loss: 0.44520533084869385\n",
      "Step: 2000  \tTraining accuracy: 0.7636818289756775\n",
      "Step: 2000  \tValid loss: 0.45754432678222656\n",
      "Step: 2100  \tTraining loss: 0.44420233368873596\n",
      "Step: 2100  \tTraining accuracy: 0.7653200030326843\n",
      "Step: 2100  \tValid loss: 0.4570789933204651\n",
      "Step: 2200  \tTraining loss: 0.443256676197052\n",
      "Step: 2200  \tTraining accuracy: 0.7667781710624695\n",
      "Step: 2200  \tValid loss: 0.4570048153400421\n",
      "Step: 2300  \tTraining loss: 0.44214555621147156\n",
      "Step: 2300  \tTraining accuracy: 0.7681067585945129\n",
      "Step: 2300  \tValid loss: 0.45738479495048523\n",
      "Step: 2400  \tTraining loss: 0.4412831664085388\n",
      "Step: 2400  \tTraining accuracy: 0.7694487571716309\n",
      "Step: 2400  \tValid loss: 0.45689037442207336\n",
      "Step: 2500  \tTraining loss: 0.4404938817024231\n",
      "Step: 2500  \tTraining accuracy: 0.7706811428070068\n",
      "Step: 2500  \tValid loss: 0.45633333921432495\n",
      "Step: 2600  \tTraining loss: 0.4397417902946472\n",
      "Step: 2600  \tTraining accuracy: 0.771863579750061\n",
      "Step: 2600  \tValid loss: 0.4559946060180664\n",
      "Step: 2700  \tTraining loss: 0.43910104036331177\n",
      "Step: 2700  \tTraining accuracy: 0.7730016112327576\n",
      "Step: 2700  \tValid loss: 0.45560699701309204\n",
      "Step: 2800  \tTraining loss: 0.43834388256073\n",
      "Step: 2800  \tTraining accuracy: 0.774100124835968\n",
      "Step: 2800  \tValid loss: 0.45537611842155457\n",
      "Step: 2900  \tTraining loss: 0.437775194644928\n",
      "Step: 2900  \tTraining accuracy: 0.7751423716545105\n",
      "Step: 2900  \tValid loss: 0.4549714922904968\n",
      "Step: 3000  \tTraining loss: 0.4372667670249939\n",
      "Step: 3000  \tTraining accuracy: 0.7760938405990601\n",
      "Step: 3000  \tValid loss: 0.4546807110309601\n",
      "Step: 3100  \tTraining loss: 0.43677958846092224\n",
      "Step: 3100  \tTraining accuracy: 0.7769439220428467\n",
      "Step: 3100  \tValid loss: 0.45454761385917664\n",
      "Step: 3200  \tTraining loss: 0.436259388923645\n",
      "Step: 3200  \tTraining accuracy: 0.7777777910232544\n",
      "Step: 3200  \tValid loss: 0.4546280801296234\n",
      "Step: 3300  \tTraining loss: 0.43576547503471375\n",
      "Step: 3300  \tTraining accuracy: 0.7785786390304565\n",
      "Step: 3300  \tValid loss: 0.45414555072784424\n",
      "Step: 3400  \tTraining loss: 0.4351843595504761\n",
      "Step: 3400  \tTraining accuracy: 0.779331624507904\n",
      "Step: 3400  \tValid loss: 0.4538835287094116\n",
      "Step: 3500  \tTraining loss: 0.4346303641796112\n",
      "Step: 3500  \tTraining accuracy: 0.780092716217041\n",
      "Step: 3500  \tValid loss: 0.4534462094306946\n",
      "Step: 3600  \tTraining loss: 0.4340835213661194\n",
      "Step: 3600  \tTraining accuracy: 0.7808276414871216\n",
      "Step: 3600  \tValid loss: 0.45284968614578247\n",
      "Step: 3700  \tTraining loss: 0.43355822563171387\n",
      "Step: 3700  \tTraining accuracy: 0.7815386056900024\n",
      "Step: 3700  \tValid loss: 0.4528975784778595\n",
      "Step: 3800  \tTraining loss: 0.43304306268692017\n",
      "Step: 3800  \tTraining accuracy: 0.7822116613388062\n",
      "Step: 3800  \tValid loss: 0.4529785215854645\n",
      "Step: 3900  \tTraining loss: 0.4325370192527771\n",
      "Step: 3900  \tTraining accuracy: 0.7828651666641235\n",
      "Step: 3900  \tValid loss: 0.45280030369758606\n",
      "Step: 4000  \tTraining loss: 0.4320376515388489\n",
      "Step: 4000  \tTraining accuracy: 0.7834855914115906\n",
      "Step: 4000  \tValid loss: 0.45273634791374207\n",
      "Step: 4100  \tTraining loss: 0.4315745532512665\n",
      "Step: 4100  \tTraining accuracy: 0.7840753793716431\n",
      "Step: 4100  \tValid loss: 0.45273053646087646\n",
      "Step: 4200  \tTraining loss: 0.4311213493347168\n",
      "Step: 4200  \tTraining accuracy: 0.7846224308013916\n",
      "Step: 4200  \tValid loss: 0.45273205637931824\n",
      "Step: 4300  \tTraining loss: 0.4306540787220001\n",
      "Step: 4300  \tTraining accuracy: 0.785185694694519\n",
      "Step: 4300  \tValid loss: 0.45275017619132996\n",
      "Step: 4400  \tTraining loss: 0.4301984906196594\n",
      "Step: 4400  \tTraining accuracy: 0.7856957316398621\n",
      "Step: 4400  \tValid loss: 0.45276352763175964\n",
      "Step: 4500  \tTraining loss: 0.42977073788642883\n",
      "Step: 4500  \tTraining accuracy: 0.7862095832824707\n",
      "Step: 4500  \tValid loss: 0.45276620984077454\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7867139\n",
      "Precision: 0.83187133\n",
      "Recall: 0.93431854\n",
      "F1 score: 0.832347\n",
      "AUC: 0.71931446\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.786714   0.831871  0.934319  0.832347  0.719314  0.429431      0.786392   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0    0.4526       0.786284   0.462546      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4579.0  \n",
      "24\n",
      "(1189, 5)\n",
      "(1189, 1)\n",
      "(640, 5)\n",
      "(640, 1)\n",
      "(520, 5)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6118110418319702\n",
      "Step: 100  \tTraining accuracy: 0.698906660079956\n",
      "Step: 100  \tValid loss: 0.6249998807907104\n",
      "Step: 200  \tTraining loss: 0.595756471157074\n",
      "Step: 200  \tTraining accuracy: 0.7052006721496582\n",
      "Step: 200  \tValid loss: 0.6165539026260376\n",
      "Step: 300  \tTraining loss: 0.5877171158790588\n",
      "Step: 300  \tTraining accuracy: 0.7059623003005981\n",
      "Step: 300  \tValid loss: 0.6077921986579895\n",
      "Step: 400  \tTraining loss: 0.5791510343551636\n",
      "Step: 400  \tTraining accuracy: 0.7076250314712524\n",
      "Step: 400  \tValid loss: 0.5985158085823059\n",
      "Step: 500  \tTraining loss: 0.571561872959137\n",
      "Step: 500  \tTraining accuracy: 0.7095890641212463\n",
      "Step: 500  \tValid loss: 0.5908905267715454\n",
      "Step: 600  \tTraining loss: 0.5656421780586243\n",
      "Step: 600  \tTraining accuracy: 0.7116901278495789\n",
      "Step: 600  \tValid loss: 0.5854988098144531\n",
      "Step: 700  \tTraining loss: 0.5615988373756409\n",
      "Step: 700  \tTraining accuracy: 0.7134724855422974\n",
      "Step: 700  \tValid loss: 0.5822846293449402\n",
      "Step: 800  \tTraining loss: 0.5591666102409363\n",
      "Step: 800  \tTraining accuracy: 0.715120255947113\n",
      "Step: 800  \tValid loss: 0.5806898474693298\n",
      "Step: 900  \tTraining loss: 0.5577748417854309\n",
      "Step: 900  \tTraining accuracy: 0.7159801721572876\n",
      "Step: 900  \tValid loss: 0.5800355076789856\n",
      "Step: 1000  \tTraining loss: 0.5569215416908264\n",
      "Step: 1000  \tTraining accuracy: 0.7169278860092163\n",
      "Step: 1000  \tValid loss: 0.5796786546707153\n",
      "Step: 1100  \tTraining loss: 0.5563163757324219\n",
      "Step: 1100  \tTraining accuracy: 0.7178167700767517\n",
      "Step: 1100  \tValid loss: 0.5794249176979065\n",
      "Step: 1200  \tTraining loss: 0.5556772947311401\n",
      "Step: 1200  \tTraining accuracy: 0.7186251282691956\n",
      "Step: 1200  \tValid loss: 0.5791326761245728\n",
      "Step: 1300  \tTraining loss: 0.5552653074264526\n",
      "Step: 1300  \tTraining accuracy: 0.7192361354827881\n",
      "Step: 1300  \tValid loss: 0.5790737867355347\n",
      "Step: 1400  \tTraining loss: 0.5549572706222534\n",
      "Step: 1400  \tTraining accuracy: 0.7197881937026978\n",
      "Step: 1400  \tValid loss: 0.5791252255439758\n",
      "Step: 1500  \tTraining loss: 0.554705798625946\n",
      "Step: 1500  \tTraining accuracy: 0.720381498336792\n",
      "Step: 1500  \tValid loss: 0.5791691541671753\n",
      "Step: 1600  \tTraining loss: 0.5544735193252563\n",
      "Step: 1600  \tTraining accuracy: 0.7208983302116394\n",
      "Step: 1600  \tValid loss: 0.5792428851127625\n",
      "Step: 1700  \tTraining loss: 0.5542480945587158\n",
      "Step: 1700  \tTraining accuracy: 0.7213524580001831\n",
      "Step: 1700  \tValid loss: 0.5792078971862793\n",
      "Step: 1800  \tTraining loss: 0.5540181398391724\n",
      "Step: 1800  \tTraining accuracy: 0.7217791080474854\n",
      "Step: 1800  \tValid loss: 0.5792120099067688\n",
      "Step: 1900  \tTraining loss: 0.5537782311439514\n",
      "Step: 1900  \tTraining accuracy: 0.7222055792808533\n",
      "Step: 1900  \tValid loss: 0.5792127847671509\n",
      "Step: 2000  \tTraining loss: 0.5535246133804321\n",
      "Step: 2000  \tTraining accuracy: 0.7225883603096008\n",
      "Step: 2000  \tValid loss: 0.5792440176010132\n",
      "Step: 2100  \tTraining loss: 0.5532550811767578\n",
      "Step: 2100  \tTraining accuracy: 0.7229545712471008\n",
      "Step: 2100  \tValid loss: 0.5792478322982788\n",
      "Step: 2200  \tTraining loss: 0.5529587268829346\n",
      "Step: 2200  \tTraining accuracy: 0.7232669591903687\n",
      "Step: 2200  \tValid loss: 0.5792310237884521\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.72357047\n",
      "Precision: 0.7542044\n",
      "Recall: 0.8052486\n",
      "F1 score: 0.7472545\n",
      "AUC: 0.69832325\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0   0.72357   0.754204  0.805249  0.747254  0.698323  0.552692      0.723615   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.578979       0.723872   0.493208      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2284.0  \n",
      "25\n",
      "(1421, 5)\n",
      "(1421, 1)\n",
      "(768, 5)\n",
      "(768, 1)\n",
      "(624, 5)\n",
      "(624, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6710468530654907\n",
      "Step: 100  \tTraining accuracy: 0.5890218019485474\n",
      "Step: 100  \tValid loss: 0.6614689230918884\n",
      "Step: 200  \tTraining loss: 0.608513593673706\n",
      "Step: 200  \tTraining accuracy: 0.6268303990364075\n",
      "Step: 200  \tValid loss: 0.5889366269111633\n",
      "Step: 300  \tTraining loss: 0.5709390640258789\n",
      "Step: 300  \tTraining accuracy: 0.6592876315116882\n",
      "Step: 300  \tValid loss: 0.5496732592582703\n",
      "Step: 400  \tTraining loss: 0.5642372965812683\n",
      "Step: 400  \tTraining accuracy: 0.6738336682319641\n",
      "Step: 400  \tValid loss: 0.5447273254394531\n",
      "Step: 500  \tTraining loss: 0.5626704096794128\n",
      "Step: 500  \tTraining accuracy: 0.6820800304412842\n",
      "Step: 500  \tValid loss: 0.5446224212646484\n",
      "Step: 600  \tTraining loss: 0.5617426037788391\n",
      "Step: 600  \tTraining accuracy: 0.6875888109207153\n",
      "Step: 600  \tValid loss: 0.544328510761261\n",
      "Step: 700  \tTraining loss: 0.5609850883483887\n",
      "Step: 700  \tTraining accuracy: 0.691458523273468\n",
      "Step: 700  \tValid loss: 0.5440046787261963\n",
      "Step: 800  \tTraining loss: 0.5602756142616272\n",
      "Step: 800  \tTraining accuracy: 0.6942023634910583\n",
      "Step: 800  \tValid loss: 0.5433321595191956\n",
      "Step: 900  \tTraining loss: 0.5595791339874268\n",
      "Step: 900  \tTraining accuracy: 0.6962591409683228\n",
      "Step: 900  \tValid loss: 0.5428679585456848\n",
      "Step: 1000  \tTraining loss: 0.5587995052337646\n",
      "Step: 1000  \tTraining accuracy: 0.6978831887245178\n",
      "Step: 1000  \tValid loss: 0.5421609282493591\n",
      "Step: 1100  \tTraining loss: 0.5578942894935608\n",
      "Step: 1100  \tTraining accuracy: 0.6992318630218506\n",
      "Step: 1100  \tValid loss: 0.5413568019866943\n",
      "Step: 1200  \tTraining loss: 0.5570594668388367\n",
      "Step: 1200  \tTraining accuracy: 0.7006241679191589\n",
      "Step: 1200  \tValid loss: 0.540671169757843\n",
      "Step: 1300  \tTraining loss: 0.5562857389450073\n",
      "Step: 1300  \tTraining accuracy: 0.7018506526947021\n",
      "Step: 1300  \tValid loss: 0.5401272773742676\n",
      "Step: 1400  \tTraining loss: 0.5556263327598572\n",
      "Step: 1400  \tTraining accuracy: 0.7028428316116333\n",
      "Step: 1400  \tValid loss: 0.5395835041999817\n",
      "Step: 1500  \tTraining loss: 0.5549762845039368\n",
      "Step: 1500  \tTraining accuracy: 0.7036737203598022\n",
      "Step: 1500  \tValid loss: 0.5391747355461121\n",
      "Step: 1600  \tTraining loss: 0.5544500946998596\n",
      "Step: 1600  \tTraining accuracy: 0.7044203877449036\n",
      "Step: 1600  \tValid loss: 0.5387911200523376\n",
      "Step: 1700  \tTraining loss: 0.553985595703125\n",
      "Step: 1700  \tTraining accuracy: 0.7051411867141724\n",
      "Step: 1700  \tValid loss: 0.5384755730628967\n",
      "Step: 1800  \tTraining loss: 0.5535665154457092\n",
      "Step: 1800  \tTraining accuracy: 0.70579993724823\n",
      "Step: 1800  \tValid loss: 0.5382013320922852\n",
      "Step: 1900  \tTraining loss: 0.5531867742538452\n",
      "Step: 1900  \tTraining accuracy: 0.7064835429191589\n",
      "Step: 1900  \tValid loss: 0.5380063056945801\n",
      "Step: 2000  \tTraining loss: 0.5527694821357727\n",
      "Step: 2000  \tTraining accuracy: 0.7070788145065308\n",
      "Step: 2000  \tValid loss: 0.5380528569221497\n",
      "Step: 2100  \tTraining loss: 0.5523963570594788\n",
      "Step: 2100  \tTraining accuracy: 0.707633376121521\n",
      "Step: 2100  \tValid loss: 0.5378209948539734\n",
      "Step: 2200  \tTraining loss: 0.5520162582397461\n",
      "Step: 2200  \tTraining accuracy: 0.7081032991409302\n",
      "Step: 2200  \tValid loss: 0.5376097559928894\n",
      "Step: 2300  \tTraining loss: 0.5516402721405029\n",
      "Step: 2300  \tTraining accuracy: 0.7084366679191589\n",
      "Step: 2300  \tValid loss: 0.5374295115470886\n",
      "Step: 2400  \tTraining loss: 0.5512808561325073\n",
      "Step: 2400  \tTraining accuracy: 0.7087719440460205\n",
      "Step: 2400  \tValid loss: 0.5372822880744934\n",
      "Step: 2500  \tTraining loss: 0.5509530901908875\n",
      "Step: 2500  \tTraining accuracy: 0.7091668844223022\n",
      "Step: 2500  \tValid loss: 0.5371479392051697\n",
      "Step: 2600  \tTraining loss: 0.5506501793861389\n",
      "Step: 2600  \tTraining accuracy: 0.7095168828964233\n",
      "Step: 2600  \tValid loss: 0.53706294298172\n",
      "Step: 2700  \tTraining loss: 0.5503698587417603\n",
      "Step: 2700  \tTraining accuracy: 0.7098137140274048\n",
      "Step: 2700  \tValid loss: 0.5370006561279297\n",
      "Step: 2800  \tTraining loss: 0.5501041412353516\n",
      "Step: 2800  \tTraining accuracy: 0.7100759744644165\n",
      "Step: 2800  \tValid loss: 0.5369935631752014\n",
      "Step: 2900  \tTraining loss: 0.5498519539833069\n",
      "Step: 2900  \tTraining accuracy: 0.7103448510169983\n",
      "Step: 2900  \tValid loss: 0.5369808077812195\n",
      "Step: 3000  \tTraining loss: 0.5496051907539368\n",
      "Step: 3000  \tTraining accuracy: 0.7105713486671448\n",
      "Step: 3000  \tValid loss: 0.5369904041290283\n",
      "Step: 3100  \tTraining loss: 0.549365222454071\n",
      "Step: 3100  \tTraining accuracy: 0.7107713222503662\n",
      "Step: 3100  \tValid loss: 0.5370217561721802\n",
      "Step: 3200  \tTraining loss: 0.5491316914558411\n",
      "Step: 3200  \tTraining accuracy: 0.7109925150871277\n",
      "Step: 3200  \tValid loss: 0.5370059609413147\n",
      "Step: 3300  \tTraining loss: 0.5489038825035095\n",
      "Step: 3300  \tTraining accuracy: 0.7112000584602356\n",
      "Step: 3300  \tValid loss: 0.5370447635650635\n",
      "Step: 3400  \tTraining loss: 0.548681914806366\n",
      "Step: 3400  \tTraining accuracy: 0.7114164233207703\n",
      "Step: 3400  \tValid loss: 0.537065327167511\n",
      "Step: 3500  \tTraining loss: 0.5484626889228821\n",
      "Step: 3500  \tTraining accuracy: 0.7115893959999084\n",
      "Step: 3500  \tValid loss: 0.5371442437171936\n",
      "Step: 3600  \tTraining loss: 0.548246443271637\n",
      "Step: 3600  \tTraining accuracy: 0.7117626070976257\n",
      "Step: 3600  \tValid loss: 0.5372247695922852\n",
      "Step: 3700  \tTraining loss: 0.5480334758758545\n",
      "Step: 3700  \tTraining accuracy: 0.7119165658950806\n",
      "Step: 3700  \tValid loss: 0.5372886061668396\n",
      "Step: 3800  \tTraining loss: 0.5478164553642273\n",
      "Step: 3800  \tTraining accuracy: 0.7120623588562012\n",
      "Step: 3800  \tValid loss: 0.537348210811615\n",
      "Step: 3900  \tTraining loss: 0.5476059913635254\n",
      "Step: 3900  \tTraining accuracy: 0.7121912837028503\n",
      "Step: 3900  \tValid loss: 0.5374610424041748\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7122957\n",
      "Precision: 0.6913767\n",
      "Recall: 0.6851574\n",
      "F1 score: 0.70907754\n",
      "AUC: 0.7073002\n",
      "   accuracy  precision    recall  f1_score     auc      loss  accuracy_val  \\\n",
      "0  0.712296   0.691377  0.685157  0.709078  0.7073  0.547508      0.712343   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.536966       0.712077   0.573795      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3946.0  \n",
      "26\n",
      "(870, 5)\n",
      "(870, 1)\n",
      "(464, 5)\n",
      "(464, 1)\n",
      "(377, 5)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6521859765052795\n",
      "Step: 100  \tTraining accuracy: 0.6275861859321594\n",
      "Step: 100  \tValid loss: 0.6553122401237488\n",
      "Step: 200  \tTraining loss: 0.6321596503257751\n",
      "Step: 200  \tTraining accuracy: 0.6303758025169373\n",
      "Step: 200  \tValid loss: 0.6365615129470825\n",
      "Step: 300  \tTraining loss: 0.6022683382034302\n",
      "Step: 300  \tTraining accuracy: 0.6372320652008057\n",
      "Step: 300  \tValid loss: 0.6080966591835022\n",
      "Step: 400  \tTraining loss: 0.5707675218582153\n",
      "Step: 400  \tTraining accuracy: 0.6491754055023193\n",
      "Step: 400  \tValid loss: 0.5777009129524231\n",
      "Step: 500  \tTraining loss: 0.5509875416755676\n",
      "Step: 500  \tTraining accuracy: 0.6600984930992126\n",
      "Step: 500  \tValid loss: 0.5581859946250916\n",
      "Step: 600  \tTraining loss: 0.5406011343002319\n",
      "Step: 600  \tTraining accuracy: 0.6701326370239258\n",
      "Step: 600  \tValid loss: 0.5462827086448669\n",
      "Step: 700  \tTraining loss: 0.5349771976470947\n",
      "Step: 700  \tTraining accuracy: 0.6782507300376892\n",
      "Step: 700  \tValid loss: 0.5393638610839844\n",
      "Step: 800  \tTraining loss: 0.5315190553665161\n",
      "Step: 800  \tTraining accuracy: 0.6842064261436462\n",
      "Step: 800  \tValid loss: 0.5348934531211853\n",
      "Step: 900  \tTraining loss: 0.5291075110435486\n",
      "Step: 900  \tTraining accuracy: 0.6887621879577637\n",
      "Step: 900  \tValid loss: 0.531781792640686\n",
      "Step: 1000  \tTraining loss: 0.5271979570388794\n",
      "Step: 1000  \tTraining accuracy: 0.6922982335090637\n",
      "Step: 1000  \tValid loss: 0.5293904542922974\n",
      "Step: 1100  \tTraining loss: 0.5255818963050842\n",
      "Step: 1100  \tTraining accuracy: 0.6952725052833557\n",
      "Step: 1100  \tValid loss: 0.5273609757423401\n",
      "Step: 1200  \tTraining loss: 0.5241413712501526\n",
      "Step: 1200  \tTraining accuracy: 0.6977299451828003\n",
      "Step: 1200  \tValid loss: 0.5256525278091431\n",
      "Step: 1300  \tTraining loss: 0.5228239893913269\n",
      "Step: 1300  \tTraining accuracy: 0.6997944116592407\n",
      "Step: 1300  \tValid loss: 0.5241671204566956\n",
      "Step: 1400  \tTraining loss: 0.5216214656829834\n",
      "Step: 1400  \tTraining accuracy: 0.7014234662055969\n",
      "Step: 1400  \tValid loss: 0.5228496193885803\n",
      "Step: 1500  \tTraining loss: 0.5204974412918091\n",
      "Step: 1500  \tTraining accuracy: 0.7028279304504395\n",
      "Step: 1500  \tValid loss: 0.5216615796089172\n",
      "Step: 1600  \tTraining loss: 0.519453227519989\n",
      "Step: 1600  \tTraining accuracy: 0.7039758563041687\n",
      "Step: 1600  \tValid loss: 0.5204870700836182\n",
      "Step: 1700  \tTraining loss: 0.5184943079948425\n",
      "Step: 1700  \tTraining accuracy: 0.7050555944442749\n",
      "Step: 1700  \tValid loss: 0.519446849822998\n",
      "Step: 1800  \tTraining loss: 0.5176161527633667\n",
      "Step: 1800  \tTraining accuracy: 0.7061454653739929\n",
      "Step: 1800  \tValid loss: 0.5184974074363708\n",
      "Step: 1900  \tTraining loss: 0.5167837142944336\n",
      "Step: 1900  \tTraining accuracy: 0.7071807384490967\n",
      "Step: 1900  \tValid loss: 0.517565131187439\n",
      "Step: 2000  \tTraining loss: 0.5159257054328918\n",
      "Step: 2000  \tTraining accuracy: 0.7081099152565002\n",
      "Step: 2000  \tValid loss: 0.5165680646896362\n",
      "Step: 2100  \tTraining loss: 0.5151527523994446\n",
      "Step: 2100  \tTraining accuracy: 0.709204912185669\n",
      "Step: 2100  \tValid loss: 0.5158527493476868\n",
      "Step: 2200  \tTraining loss: 0.5143887996673584\n",
      "Step: 2200  \tTraining accuracy: 0.7103067636489868\n",
      "Step: 2200  \tValid loss: 0.5150739550590515\n",
      "Step: 2300  \tTraining loss: 0.5135946273803711\n",
      "Step: 2300  \tTraining accuracy: 0.7112588286399841\n",
      "Step: 2300  \tValid loss: 0.5142351388931274\n",
      "Step: 2400  \tTraining loss: 0.5127475261688232\n",
      "Step: 2400  \tTraining accuracy: 0.7121050357818604\n",
      "Step: 2400  \tValid loss: 0.5134036540985107\n",
      "Step: 2500  \tTraining loss: 0.5118083953857422\n",
      "Step: 2500  \tTraining accuracy: 0.712906002998352\n",
      "Step: 2500  \tValid loss: 0.5124849081039429\n",
      "Step: 2600  \tTraining loss: 0.510747492313385\n",
      "Step: 2600  \tTraining accuracy: 0.7137129306793213\n",
      "Step: 2600  \tValid loss: 0.5114780068397522\n",
      "Step: 2700  \tTraining loss: 0.5095862150192261\n",
      "Step: 2700  \tTraining accuracy: 0.7145912051200867\n",
      "Step: 2700  \tValid loss: 0.5104230642318726\n",
      "Step: 2800  \tTraining loss: 0.5083796977996826\n",
      "Step: 2800  \tTraining accuracy: 0.7155119180679321\n",
      "Step: 2800  \tValid loss: 0.5093994736671448\n",
      "Step: 2900  \tTraining loss: 0.5071764588356018\n",
      "Step: 2900  \tTraining accuracy: 0.7164090275764465\n",
      "Step: 2900  \tValid loss: 0.5084713697433472\n",
      "Step: 3000  \tTraining loss: 0.5060088634490967\n",
      "Step: 3000  \tTraining accuracy: 0.7172849774360657\n",
      "Step: 3000  \tValid loss: 0.5076320767402649\n",
      "Step: 3100  \tTraining loss: 0.5048903822898865\n",
      "Step: 3100  \tTraining accuracy: 0.7180842757225037\n",
      "Step: 3100  \tValid loss: 0.5069145560264587\n",
      "Step: 3200  \tTraining loss: 0.5038275122642517\n",
      "Step: 3200  \tTraining accuracy: 0.7188143134117126\n",
      "Step: 3200  \tValid loss: 0.5062884092330933\n",
      "Step: 3300  \tTraining loss: 0.50282222032547\n",
      "Step: 3300  \tTraining accuracy: 0.7195714116096497\n",
      "Step: 3300  \tValid loss: 0.5057598352432251\n",
      "Step: 3400  \tTraining loss: 0.5018476247787476\n",
      "Step: 3400  \tTraining accuracy: 0.7202832698822021\n",
      "Step: 3400  \tValid loss: 0.5053926110267639\n",
      "Step: 3500  \tTraining loss: 0.5009018778800964\n",
      "Step: 3500  \tTraining accuracy: 0.7209369540214539\n",
      "Step: 3500  \tValid loss: 0.5050746202468872\n",
      "Step: 3600  \tTraining loss: 0.4999449551105499\n",
      "Step: 3600  \tTraining accuracy: 0.7216031551361084\n",
      "Step: 3600  \tValid loss: 0.504936933517456\n",
      "Step: 3700  \tTraining loss: 0.4989968240261078\n",
      "Step: 3700  \tTraining accuracy: 0.722248911857605\n",
      "Step: 3700  \tValid loss: 0.5047187805175781\n",
      "Step: 3800  \tTraining loss: 0.4981384575366974\n",
      "Step: 3800  \tTraining accuracy: 0.7227823138237\n",
      "Step: 3800  \tValid loss: 0.5044549703598022\n",
      "Step: 3900  \tTraining loss: 0.49735087156295776\n",
      "Step: 3900  \tTraining accuracy: 0.7233031988143921\n",
      "Step: 3900  \tValid loss: 0.5042729377746582\n",
      "Step: 4000  \tTraining loss: 0.4966112971305847\n",
      "Step: 4000  \tTraining accuracy: 0.7237976789474487\n",
      "Step: 4000  \tValid loss: 0.5041688680648804\n",
      "Step: 4100  \tTraining loss: 0.49590492248535156\n",
      "Step: 4100  \tTraining accuracy: 0.7242677807807922\n",
      "Step: 4100  \tValid loss: 0.5041319131851196\n",
      "Step: 4200  \tTraining loss: 0.49524566531181335\n",
      "Step: 4200  \tTraining accuracy: 0.7247715592384338\n",
      "Step: 4200  \tValid loss: 0.5040733218193054\n",
      "Step: 4300  \tTraining loss: 0.49460744857788086\n",
      "Step: 4300  \tTraining accuracy: 0.725265383720398\n",
      "Step: 4300  \tValid loss: 0.5040057897567749\n",
      "Step: 4400  \tTraining loss: 0.49398329854011536\n",
      "Step: 4400  \tTraining accuracy: 0.7256558537483215\n",
      "Step: 4400  \tValid loss: 0.5039874911308289\n",
      "Step: 4500  \tTraining loss: 0.4933694005012512\n",
      "Step: 4500  \tTraining accuracy: 0.72600257396698\n",
      "Step: 4500  \tValid loss: 0.5039522051811218\n",
      "Step: 4600  \tTraining loss: 0.4927613139152527\n",
      "Step: 4600  \tTraining accuracy: 0.7263597249984741\n",
      "Step: 4600  \tValid loss: 0.5039123892784119\n",
      "Step: 4700  \tTraining loss: 0.49215564131736755\n",
      "Step: 4700  \tTraining accuracy: 0.7267014980316162\n",
      "Step: 4700  \tValid loss: 0.5038121342658997\n",
      "Step: 4800  \tTraining loss: 0.491556853055954\n",
      "Step: 4800  \tTraining accuracy: 0.7270289063453674\n",
      "Step: 4800  \tValid loss: 0.5036709904670715\n",
      "Step: 4900  \tTraining loss: 0.4909715950489044\n",
      "Step: 4900  \tTraining accuracy: 0.7273187041282654\n",
      "Step: 4900  \tValid loss: 0.5035000443458557\n",
      "Step: 5000  \tTraining loss: 0.4904076159000397\n",
      "Step: 5000  \tTraining accuracy: 0.7276086211204529\n",
      "Step: 5000  \tValid loss: 0.5033661127090454\n",
      "Step: 5100  \tTraining loss: 0.4898708164691925\n",
      "Step: 5100  \tTraining accuracy: 0.7279102206230164\n",
      "Step: 5100  \tValid loss: 0.5032684206962585\n",
      "Step: 5200  \tTraining loss: 0.4893653392791748\n",
      "Step: 5200  \tTraining accuracy: 0.7282227873802185\n",
      "Step: 5200  \tValid loss: 0.5032411217689514\n",
      "Step: 5300  \tTraining loss: 0.48888644576072693\n",
      "Step: 5300  \tTraining accuracy: 0.7285011410713196\n",
      "Step: 5300  \tValid loss: 0.5032967329025269\n",
      "Step: 5400  \tTraining loss: 0.4884275496006012\n",
      "Step: 5400  \tTraining accuracy: 0.7287909984588623\n",
      "Step: 5400  \tValid loss: 0.5034050941467285\n",
      "Step: 5500  \tTraining loss: 0.4879792332649231\n",
      "Step: 5500  \tTraining accuracy: 0.7290809154510498\n",
      "Step: 5500  \tValid loss: 0.5035737752914429\n",
      "Step: 5600  \tTraining loss: 0.4875321686267853\n",
      "Step: 5600  \tTraining accuracy: 0.7293498516082764\n",
      "Step: 5600  \tValid loss: 0.5037875175476074\n",
      "Step: 5700  \tTraining loss: 0.4870843291282654\n",
      "Step: 5700  \tTraining accuracy: 0.7296196222305298\n",
      "Step: 5700  \tValid loss: 0.5040497183799744\n",
      "Step: 5800  \tTraining loss: 0.4866396486759186\n",
      "Step: 5800  \tTraining accuracy: 0.7298901677131653\n",
      "Step: 5800  \tValid loss: 0.5043628215789795\n",
      "Step: 5900  \tTraining loss: 0.48620328307151794\n",
      "Step: 5900  \tTraining accuracy: 0.7301514148712158\n",
      "Step: 5900  \tValid loss: 0.5047320127487183\n",
      "Step: 6000  \tTraining loss: 0.4857792258262634\n",
      "Step: 6000  \tTraining accuracy: 0.7304137945175171\n",
      "Step: 6000  \tValid loss: 0.5051321983337402\n",
      "Step: 6100  \tTraining loss: 0.48536720871925354\n",
      "Step: 6100  \tTraining accuracy: 0.7306481003761292\n",
      "Step: 6100  \tValid loss: 0.5055556893348694\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7309033\n",
      "Precision: 0.7275281\n",
      "Recall: 0.69251335\n",
      "F1 score: 0.712881\n",
      "AUC: 0.7484744\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.730903   0.727528  0.692513  0.712881  0.748474  0.485056      0.730691   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.503238       0.730673   0.523675      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  6177.0  \n",
      "27\n",
      "(870, 5)\n",
      "(870, 1)\n",
      "(480, 5)\n",
      "(480, 1)\n",
      "(390, 5)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6159904599189758\n",
      "Step: 100  \tTraining accuracy: 0.6735632419586182\n",
      "Step: 100  \tValid loss: 0.6341009140014648\n",
      "Step: 200  \tTraining loss: 0.5861669182777405\n",
      "Step: 200  \tTraining accuracy: 0.6708812117576599\n",
      "Step: 200  \tValid loss: 0.5950336456298828\n",
      "Step: 300  \tTraining loss: 0.5625975728034973\n",
      "Step: 300  \tTraining accuracy: 0.6845977306365967\n",
      "Step: 300  \tValid loss: 0.5626916885375977\n",
      "Step: 400  \tTraining loss: 0.5461381673812866\n",
      "Step: 400  \tTraining accuracy: 0.6958948969841003\n",
      "Step: 400  \tValid loss: 0.537420392036438\n",
      "Step: 500  \tTraining loss: 0.5375213027000427\n",
      "Step: 500  \tTraining accuracy: 0.7045977115631104\n",
      "Step: 500  \tValid loss: 0.5218997597694397\n",
      "Step: 600  \tTraining loss: 0.5333218574523926\n",
      "Step: 600  \tTraining accuracy: 0.7107627987861633\n",
      "Step: 600  \tValid loss: 0.5127325057983398\n",
      "Step: 700  \tTraining loss: 0.531208872795105\n",
      "Step: 700  \tTraining accuracy: 0.7153846025466919\n",
      "Step: 700  \tValid loss: 0.5071887373924255\n",
      "Step: 800  \tTraining loss: 0.5299991369247437\n",
      "Step: 800  \tTraining accuracy: 0.7196168303489685\n",
      "Step: 800  \tValid loss: 0.5036170482635498\n",
      "Step: 900  \tTraining loss: 0.5291469693183899\n",
      "Step: 900  \tTraining accuracy: 0.7226504683494568\n",
      "Step: 900  \tValid loss: 0.5011559724807739\n",
      "Step: 1000  \tTraining loss: 0.5283659100532532\n",
      "Step: 1000  \tTraining accuracy: 0.7254083752632141\n",
      "Step: 1000  \tValid loss: 0.4994106888771057\n",
      "Step: 1100  \tTraining loss: 0.5274835228919983\n",
      "Step: 1100  \tTraining accuracy: 0.7276957035064697\n",
      "Step: 1100  \tValid loss: 0.4980246126651764\n",
      "Step: 1200  \tTraining loss: 0.5265496373176575\n",
      "Step: 1200  \tTraining accuracy: 0.7295352220535278\n",
      "Step: 1200  \tValid loss: 0.4968790113925934\n",
      "Step: 1300  \tTraining loss: 0.5256465673446655\n",
      "Step: 1300  \tTraining accuracy: 0.7310344576835632\n",
      "Step: 1300  \tValid loss: 0.49605995416641235\n",
      "Step: 1400  \tTraining loss: 0.5248590111732483\n",
      "Step: 1400  \tTraining accuracy: 0.7325244545936584\n",
      "Step: 1400  \tValid loss: 0.4952815771102905\n",
      "Step: 1500  \tTraining loss: 0.5242040753364563\n",
      "Step: 1500  \tTraining accuracy: 0.7338882088661194\n",
      "Step: 1500  \tValid loss: 0.4946673810482025\n",
      "Step: 1600  \tTraining loss: 0.5232400298118591\n",
      "Step: 1600  \tTraining accuracy: 0.7350760102272034\n",
      "Step: 1600  \tValid loss: 0.49414804577827454\n",
      "Step: 1700  \tTraining loss: 0.5200016498565674\n",
      "Step: 1700  \tTraining accuracy: 0.7362242937088013\n",
      "Step: 1700  \tValid loss: 0.49712762236595154\n",
      "Step: 1800  \tTraining loss: 0.5188375115394592\n",
      "Step: 1800  \tTraining accuracy: 0.7371428608894348\n",
      "Step: 1800  \tValid loss: 0.49566295742988586\n",
      "Step: 1900  \tTraining loss: 0.5178998708724976\n",
      "Step: 1900  \tTraining accuracy: 0.7380552887916565\n",
      "Step: 1900  \tValid loss: 0.4943346679210663\n",
      "Step: 2000  \tTraining loss: 0.5171309113502502\n",
      "Step: 2000  \tTraining accuracy: 0.738815188407898\n",
      "Step: 2000  \tValid loss: 0.49329984188079834\n",
      "Step: 2100  \tTraining loss: 0.5164540410041809\n",
      "Step: 2100  \tTraining accuracy: 0.7395570278167725\n",
      "Step: 2100  \tValid loss: 0.4924800992012024\n",
      "Step: 2200  \tTraining loss: 0.5158575773239136\n",
      "Step: 2200  \tTraining accuracy: 0.7402566075325012\n",
      "Step: 2200  \tValid loss: 0.49179187417030334\n",
      "Step: 2300  \tTraining loss: 0.5153135657310486\n",
      "Step: 2300  \tTraining accuracy: 0.7408684492111206\n",
      "Step: 2300  \tValid loss: 0.4913630783557892\n",
      "Step: 2400  \tTraining loss: 0.5148079991340637\n",
      "Step: 2400  \tTraining accuracy: 0.7415015697479248\n",
      "Step: 2400  \tValid loss: 0.4911089539527893\n",
      "Step: 2500  \tTraining loss: 0.5143198370933533\n",
      "Step: 2500  \tTraining accuracy: 0.7420830130577087\n",
      "Step: 2500  \tValid loss: 0.4908508360385895\n",
      "Step: 2600  \tTraining loss: 0.5138592720031738\n",
      "Step: 2600  \tTraining accuracy: 0.7427090406417847\n",
      "Step: 2600  \tValid loss: 0.4906150698661804\n",
      "Step: 2700  \tTraining loss: 0.5134226083755493\n",
      "Step: 2700  \tTraining accuracy: 0.743309497833252\n",
      "Step: 2700  \tValid loss: 0.4904109239578247\n",
      "Step: 2800  \tTraining loss: 0.5130066275596619\n",
      "Step: 2800  \tTraining accuracy: 0.7438662648200989\n",
      "Step: 2800  \tValid loss: 0.4902039170265198\n",
      "Step: 2900  \tTraining loss: 0.5126137733459473\n",
      "Step: 2900  \tTraining accuracy: 0.744464635848999\n",
      "Step: 2900  \tValid loss: 0.4901925325393677\n",
      "Step: 3000  \tTraining loss: 0.5122426152229309\n",
      "Step: 3000  \tTraining accuracy: 0.7450224161148071\n",
      "Step: 3000  \tValid loss: 0.49002358317375183\n",
      "Step: 3100  \tTraining loss: 0.5118893980979919\n",
      "Step: 3100  \tTraining accuracy: 0.7455247640609741\n",
      "Step: 3100  \tValid loss: 0.4898373484611511\n",
      "Step: 3200  \tTraining loss: 0.5115565657615662\n",
      "Step: 3200  \tTraining accuracy: 0.745995283126831\n",
      "Step: 3200  \tValid loss: 0.4896734356880188\n",
      "Step: 3300  \tTraining loss: 0.5112280249595642\n",
      "Step: 3300  \tTraining accuracy: 0.7464014291763306\n",
      "Step: 3300  \tValid loss: 0.4896358549594879\n",
      "Step: 3400  \tTraining loss: 0.5108888745307922\n",
      "Step: 3400  \tTraining accuracy: 0.7468004822731018\n",
      "Step: 3400  \tValid loss: 0.4895035922527313\n",
      "Step: 3500  \tTraining loss: 0.510547399520874\n",
      "Step: 3500  \tTraining accuracy: 0.7472097277641296\n",
      "Step: 3500  \tValid loss: 0.48927223682403564\n",
      "Step: 3600  \tTraining loss: 0.5102131366729736\n",
      "Step: 3600  \tTraining accuracy: 0.7476121187210083\n",
      "Step: 3600  \tValid loss: 0.48895612359046936\n",
      "Step: 3700  \tTraining loss: 0.5098913311958313\n",
      "Step: 3700  \tTraining accuracy: 0.7480239272117615\n",
      "Step: 3700  \tValid loss: 0.4884980022907257\n",
      "Step: 3800  \tTraining loss: 0.5095755457878113\n",
      "Step: 3800  \tTraining accuracy: 0.7483677864074707\n",
      "Step: 3800  \tValid loss: 0.48810529708862305\n",
      "Step: 3900  \tTraining loss: 0.5092687606811523\n",
      "Step: 3900  \tTraining accuracy: 0.7486789226531982\n",
      "Step: 3900  \tValid loss: 0.4877115786075592\n",
      "Step: 4000  \tTraining loss: 0.5089722871780396\n",
      "Step: 4000  \tTraining accuracy: 0.7490033507347107\n",
      "Step: 4000  \tValid loss: 0.487282931804657\n",
      "Step: 4100  \tTraining loss: 0.5086800456047058\n",
      "Step: 4100  \tTraining accuracy: 0.7493685483932495\n",
      "Step: 4100  \tValid loss: 0.4866202175617218\n",
      "Step: 4200  \tTraining loss: 0.5083858370780945\n",
      "Step: 4200  \tTraining accuracy: 0.7497161030769348\n",
      "Step: 4200  \tValid loss: 0.48605263233184814\n",
      "Step: 4300  \tTraining loss: 0.508113443851471\n",
      "Step: 4300  \tTraining accuracy: 0.7500473260879517\n",
      "Step: 4300  \tValid loss: 0.4856695830821991\n",
      "Step: 4400  \tTraining loss: 0.5078452229499817\n",
      "Step: 4400  \tTraining accuracy: 0.7503633499145508\n",
      "Step: 4400  \tValid loss: 0.48538848757743835\n",
      "Step: 4500  \tTraining loss: 0.5075594782829285\n",
      "Step: 4500  \tTraining accuracy: 0.7506780028343201\n",
      "Step: 4500  \tValid loss: 0.48465242981910706\n",
      "Step: 4600  \tTraining loss: 0.5072847008705139\n",
      "Step: 4600  \tTraining accuracy: 0.7509788870811462\n",
      "Step: 4600  \tValid loss: 0.4842662811279297\n",
      "Step: 4700  \tTraining loss: 0.5070205330848694\n",
      "Step: 4700  \tTraining accuracy: 0.7512915730476379\n",
      "Step: 4700  \tValid loss: 0.48404571413993835\n",
      "Step: 4800  \tTraining loss: 0.5067644119262695\n",
      "Step: 4800  \tTraining accuracy: 0.7515910267829895\n",
      "Step: 4800  \tValid loss: 0.4838416874408722\n",
      "Step: 4900  \tTraining loss: 0.5065154433250427\n",
      "Step: 4900  \tTraining accuracy: 0.7518782019615173\n",
      "Step: 4900  \tValid loss: 0.4836088716983795\n",
      "Step: 5000  \tTraining loss: 0.5062729120254517\n",
      "Step: 5000  \tTraining accuracy: 0.7521885633468628\n",
      "Step: 5000  \tValid loss: 0.48340681195259094\n",
      "Step: 5100  \tTraining loss: 0.5060288310050964\n",
      "Step: 5100  \tTraining accuracy: 0.7524980306625366\n",
      "Step: 5100  \tValid loss: 0.48332998156547546\n",
      "Step: 5200  \tTraining loss: 0.5057495832443237\n",
      "Step: 5200  \tTraining accuracy: 0.7527843117713928\n",
      "Step: 5200  \tValid loss: 0.4833129942417145\n",
      "Step: 5300  \tTraining loss: 0.5054464340209961\n",
      "Step: 5300  \tTraining accuracy: 0.7530596852302551\n",
      "Step: 5300  \tValid loss: 0.4832822382450104\n",
      "Step: 5400  \tTraining loss: 0.5051960945129395\n",
      "Step: 5400  \tTraining accuracy: 0.7533354759216309\n",
      "Step: 5400  \tValid loss: 0.4830636978149414\n",
      "Step: 5500  \tTraining loss: 0.5049397349357605\n",
      "Step: 5500  \tTraining accuracy: 0.7535906434059143\n",
      "Step: 5500  \tValid loss: 0.4830050766468048\n",
      "Step: 5600  \tTraining loss: 0.5046828389167786\n",
      "Step: 5600  \tTraining accuracy: 0.7538365721702576\n",
      "Step: 5600  \tValid loss: 0.4828798174858093\n",
      "Step: 5700  \tTraining loss: 0.5044355988502502\n",
      "Step: 5700  \tTraining accuracy: 0.7541145086288452\n",
      "Step: 5700  \tValid loss: 0.48275429010391235\n",
      "Step: 5800  \tTraining loss: 0.5041988492012024\n",
      "Step: 5800  \tTraining accuracy: 0.7543827891349792\n",
      "Step: 5800  \tValid loss: 0.4826403260231018\n",
      "Step: 5900  \tTraining loss: 0.5039654970169067\n",
      "Step: 5900  \tTraining accuracy: 0.7546418905258179\n",
      "Step: 5900  \tValid loss: 0.4825754761695862\n",
      "Step: 6000  \tTraining loss: 0.5037275552749634\n",
      "Step: 6000  \tTraining accuracy: 0.7548633217811584\n",
      "Step: 6000  \tValid loss: 0.4825398027896881\n",
      "Step: 6100  \tTraining loss: 0.5034972429275513\n",
      "Step: 6100  \tTraining accuracy: 0.7551059126853943\n",
      "Step: 6100  \tValid loss: 0.48274073004722595\n",
      "Step: 6200  \tTraining loss: 0.5032739043235779\n",
      "Step: 6200  \tTraining accuracy: 0.7553032636642456\n",
      "Step: 6200  \tValid loss: 0.4827718734741211\n",
      "Step: 6300  \tTraining loss: 0.503053605556488\n",
      "Step: 6300  \tTraining accuracy: 0.7554850578308105\n",
      "Step: 6300  \tValid loss: 0.4827721416950226\n",
      "Step: 6400  \tTraining loss: 0.5028355717658997\n",
      "Step: 6400  \tTraining accuracy: 0.755661129951477\n",
      "Step: 6400  \tValid loss: 0.4827721416950226\n",
      "Step: 6500  \tTraining loss: 0.5026159286499023\n",
      "Step: 6500  \tTraining accuracy: 0.7558406591415405\n",
      "Step: 6500  \tValid loss: 0.48268985748291016\n",
      "Step: 6600  \tTraining loss: 0.5023852586746216\n",
      "Step: 6600  \tTraining accuracy: 0.7560322880744934\n",
      "Step: 6600  \tValid loss: 0.4826105535030365\n",
      "Step: 6700  \tTraining loss: 0.5021629333496094\n",
      "Step: 6700  \tTraining accuracy: 0.7562181353569031\n",
      "Step: 6700  \tValid loss: 0.48272860050201416\n",
      "Step: 6800  \tTraining loss: 0.5019450187683105\n",
      "Step: 6800  \tTraining accuracy: 0.7563984394073486\n",
      "Step: 6800  \tValid loss: 0.48284563422203064\n",
      "Step: 6900  \tTraining loss: 0.5017310380935669\n",
      "Step: 6900  \tTraining accuracy: 0.7565903067588806\n",
      "Step: 6900  \tValid loss: 0.4828951060771942\n",
      "Step: 7000  \tTraining loss: 0.5015194416046143\n",
      "Step: 7000  \tTraining accuracy: 0.7567766308784485\n",
      "Step: 7000  \tValid loss: 0.4829750061035156\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.75694954\n",
      "Precision: 0.7806216\n",
      "Recall: 0.8243243\n",
      "F1 score: 0.77756137\n",
      "AUC: 0.7417076\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0   0.75695   0.780622  0.824324  0.777561  0.741708  0.501431      0.756946   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.482527       0.756866   0.450333      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  7041.0  \n",
      "28\n",
      "(870, 5)\n",
      "(870, 1)\n",
      "(464, 5)\n",
      "(464, 1)\n",
      "(377, 5)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6542572975158691\n",
      "Step: 100  \tTraining accuracy: 0.6252873539924622\n",
      "Step: 100  \tValid loss: 0.6585514545440674\n",
      "Step: 200  \tTraining loss: 0.6216310858726501\n",
      "Step: 200  \tTraining accuracy: 0.6377373337745667\n",
      "Step: 200  \tValid loss: 0.6094731688499451\n",
      "Step: 300  \tTraining loss: 0.5999681353569031\n",
      "Step: 300  \tTraining accuracy: 0.6528425216674805\n",
      "Step: 300  \tValid loss: 0.5930774211883545\n",
      "Step: 400  \tTraining loss: 0.5785711407661438\n",
      "Step: 400  \tTraining accuracy: 0.6645010709762573\n",
      "Step: 400  \tValid loss: 0.5835906863212585\n",
      "Step: 500  \tTraining loss: 0.5661749243736267\n",
      "Step: 500  \tTraining accuracy: 0.673580527305603\n",
      "Step: 500  \tValid loss: 0.5811754465103149\n",
      "Step: 600  \tTraining loss: 0.5593565106391907\n",
      "Step: 600  \tTraining accuracy: 0.6802121996879578\n",
      "Step: 600  \tValid loss: 0.5817614793777466\n",
      "Step: 700  \tTraining loss: 0.555560827255249\n",
      "Step: 700  \tTraining accuracy: 0.6846264600753784\n",
      "Step: 700  \tValid loss: 0.5833919048309326\n",
      "Step: 800  \tTraining loss: 0.5532346367835999\n",
      "Step: 800  \tTraining accuracy: 0.6880205273628235\n",
      "Step: 800  \tValid loss: 0.5849272608757019\n",
      "Step: 900  \tTraining loss: 0.5515941977500916\n",
      "Step: 900  \tTraining accuracy: 0.6908916234970093\n",
      "Step: 900  \tValid loss: 0.5859875082969666\n",
      "Step: 1000  \tTraining loss: 0.5502423048019409\n",
      "Step: 1000  \tTraining accuracy: 0.6934046149253845\n",
      "Step: 1000  \tValid loss: 0.5864921808242798\n",
      "Step: 1100  \tTraining loss: 0.5490208268165588\n",
      "Step: 1100  \tTraining accuracy: 0.6956062316894531\n",
      "Step: 1100  \tValid loss: 0.5864787697792053\n",
      "Step: 1200  \tTraining loss: 0.547716498374939\n",
      "Step: 1200  \tTraining accuracy: 0.6975268125534058\n",
      "Step: 1200  \tValid loss: 0.5859596133232117\n",
      "Step: 1300  \tTraining loss: 0.5463127493858337\n",
      "Step: 1300  \tTraining accuracy: 0.6994206309318542\n",
      "Step: 1300  \tValid loss: 0.5849422812461853\n",
      "Step: 1400  \tTraining loss: 0.5447602868080139\n",
      "Step: 1400  \tTraining accuracy: 0.7009475231170654\n",
      "Step: 1400  \tValid loss: 0.5834660530090332\n",
      "Step: 1500  \tTraining loss: 0.5429763793945312\n",
      "Step: 1500  \tTraining accuracy: 0.7024653553962708\n",
      "Step: 1500  \tValid loss: 0.581543505191803\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7039005\n",
      "Precision: 0.753937\n",
      "Recall: 0.7962578\n",
      "F1 score: 0.72311723\n",
      "AUC: 0.7374605\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.703901   0.753937  0.796258  0.723117  0.73746  0.542689      0.702552   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.581153       0.702512    0.59084      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1514.0  \n",
      "29\n",
      "(1798, 5)\n",
      "(1798, 1)\n",
      "(992, 5)\n",
      "(992, 1)\n",
      "(806, 5)\n",
      "(806, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5707694292068481\n",
      "Step: 100  \tTraining accuracy: 0.7797552943229675\n",
      "Step: 100  \tValid loss: 0.5847905278205872\n",
      "Step: 200  \tTraining loss: 0.47864609956741333\n",
      "Step: 200  \tTraining accuracy: 0.7767890095710754\n",
      "Step: 200  \tValid loss: 0.5114195346832275\n",
      "Step: 300  \tTraining loss: 0.4555612802505493\n",
      "Step: 300  \tTraining accuracy: 0.7817575335502625\n",
      "Step: 300  \tValid loss: 0.49389469623565674\n",
      "Step: 400  \tTraining loss: 0.4338166415691376\n",
      "Step: 400  \tTraining accuracy: 0.7858731746673584\n",
      "Step: 400  \tValid loss: 0.47480571269989014\n",
      "Step: 500  \tTraining loss: 0.4103884696960449\n",
      "Step: 500  \tTraining accuracy: 0.789086639881134\n",
      "Step: 500  \tValid loss: 0.452406108379364\n",
      "Step: 600  \tTraining loss: 0.38749632239341736\n",
      "Step: 600  \tTraining accuracy: 0.7928506135940552\n",
      "Step: 600  \tValid loss: 0.43039581179618835\n",
      "Step: 700  \tTraining loss: 0.37089818716049194\n",
      "Step: 700  \tTraining accuracy: 0.7969966530799866\n",
      "Step: 700  \tValid loss: 0.4152309000492096\n",
      "Step: 800  \tTraining loss: 0.36109381914138794\n",
      "Step: 800  \tTraining accuracy: 0.8012235760688782\n",
      "Step: 800  \tValid loss: 0.4082733988761902\n",
      "Step: 900  \tTraining loss: 0.3557780981063843\n",
      "Step: 900  \tTraining accuracy: 0.8049793839454651\n",
      "Step: 900  \tValid loss: 0.4065121114253998\n",
      "Step: 1000  \tTraining loss: 0.3526459336280823\n",
      "Step: 1000  \tTraining accuracy: 0.8082079291343689\n",
      "Step: 1000  \tValid loss: 0.40638118982315063\n",
      "Step: 1100  \tTraining loss: 0.35057538747787476\n",
      "Step: 1100  \tTraining accuracy: 0.8110334277153015\n",
      "Step: 1100  \tValid loss: 0.406595915555954\n",
      "Step: 1200  \tTraining loss: 0.34902554750442505\n",
      "Step: 1200  \tTraining accuracy: 0.8135126233100891\n",
      "Step: 1200  \tValid loss: 0.40689098834991455\n",
      "Step: 1300  \tTraining loss: 0.3477427363395691\n",
      "Step: 1300  \tTraining accuracy: 0.8156618475914001\n",
      "Step: 1300  \tValid loss: 0.40684249997138977\n",
      "Step: 1400  \tTraining loss: 0.3467090427875519\n",
      "Step: 1400  \tTraining accuracy: 0.8176369071006775\n",
      "Step: 1400  \tValid loss: 0.4069550931453705\n",
      "Step: 1500  \tTraining loss: 0.34581664204597473\n",
      "Step: 1500  \tTraining accuracy: 0.8192819356918335\n",
      "Step: 1500  \tValid loss: 0.4069625735282898\n",
      "Step: 1600  \tTraining loss: 0.34500619769096375\n",
      "Step: 1600  \tTraining accuracy: 0.8206968307495117\n",
      "Step: 1600  \tValid loss: 0.40705570578575134\n",
      "Step: 1700  \tTraining loss: 0.34423041343688965\n",
      "Step: 1700  \tTraining accuracy: 0.8220075964927673\n",
      "Step: 1700  \tValid loss: 0.4070611894130707\n",
      "Step: 1800  \tTraining loss: 0.3434695303440094\n",
      "Step: 1800  \tTraining accuracy: 0.8231685757637024\n",
      "Step: 1800  \tValid loss: 0.40698808431625366\n",
      "Step: 1900  \tTraining loss: 0.3427269756793976\n",
      "Step: 1900  \tTraining accuracy: 0.8241890668869019\n",
      "Step: 1900  \tValid loss: 0.4070243239402771\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.82510483\n",
      "Precision: 0.86524063\n",
      "Recall: 0.8606383\n",
      "F1 score: 0.8229046\n",
      "AUC: 0.85689265\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.825105   0.865241  0.860638  0.822905  0.856893  0.342302      0.824264   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.406331        0.82417   0.361838      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1958.0  \n",
      "30\n",
      "(2378, 5)\n",
      "(2378, 1)\n",
      "(1312, 5)\n",
      "(1312, 1)\n",
      "(1066, 5)\n",
      "(1066, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6667696833610535\n",
      "Step: 100  \tTraining accuracy: 0.5984020233154297\n",
      "Step: 100  \tValid loss: 0.6592081785202026\n",
      "Step: 200  \tTraining loss: 0.646133542060852\n",
      "Step: 200  \tTraining accuracy: 0.6162040829658508\n",
      "Step: 200  \tValid loss: 0.6385664343833923\n",
      "Step: 300  \tTraining loss: 0.6069866418838501\n",
      "Step: 300  \tTraining accuracy: 0.6355761289596558\n",
      "Step: 300  \tValid loss: 0.597366213798523\n",
      "Step: 400  \tTraining loss: 0.585321843624115\n",
      "Step: 400  \tTraining accuracy: 0.6561936736106873\n",
      "Step: 400  \tValid loss: 0.5695375204086304\n",
      "Step: 500  \tTraining loss: 0.5749773383140564\n",
      "Step: 500  \tTraining accuracy: 0.6711989641189575\n",
      "Step: 500  \tValid loss: 0.5542319416999817\n",
      "Step: 600  \tTraining loss: 0.5687623620033264\n",
      "Step: 600  \tTraining accuracy: 0.6821240186691284\n",
      "Step: 600  \tValid loss: 0.5447973608970642\n",
      "Step: 700  \tTraining loss: 0.5646459460258484\n",
      "Step: 700  \tTraining accuracy: 0.6899139285087585\n",
      "Step: 700  \tValid loss: 0.5384770631790161\n",
      "Step: 800  \tTraining loss: 0.5622344017028809\n",
      "Step: 800  \tTraining accuracy: 0.6961872577667236\n",
      "Step: 800  \tValid loss: 0.5343678593635559\n",
      "Step: 900  \tTraining loss: 0.5607566833496094\n",
      "Step: 900  \tTraining accuracy: 0.7010092735290527\n",
      "Step: 900  \tValid loss: 0.5317896604537964\n",
      "Step: 1000  \tTraining loss: 0.5598248243331909\n",
      "Step: 1000  \tTraining accuracy: 0.7052366137504578\n",
      "Step: 1000  \tValid loss: 0.5302087068557739\n",
      "Step: 1100  \tTraining loss: 0.5591950416564941\n",
      "Step: 1100  \tTraining accuracy: 0.7087788581848145\n",
      "Step: 1100  \tValid loss: 0.5293623805046082\n",
      "Step: 1200  \tTraining loss: 0.5587059855461121\n",
      "Step: 1200  \tTraining accuracy: 0.7116320133209229\n",
      "Step: 1200  \tValid loss: 0.5287207365036011\n",
      "Step: 1300  \tTraining loss: 0.55828458070755\n",
      "Step: 1300  \tTraining accuracy: 0.7141631841659546\n",
      "Step: 1300  \tValid loss: 0.5282204151153564\n",
      "Step: 1400  \tTraining loss: 0.5578640699386597\n",
      "Step: 1400  \tTraining accuracy: 0.7163504958152771\n",
      "Step: 1400  \tValid loss: 0.5278268456459045\n",
      "Step: 1500  \tTraining loss: 0.5574272274971008\n",
      "Step: 1500  \tTraining accuracy: 0.7183086276054382\n",
      "Step: 1500  \tValid loss: 0.5274339318275452\n",
      "Step: 1600  \tTraining loss: 0.5570550560951233\n",
      "Step: 1600  \tTraining accuracy: 0.7199056148529053\n",
      "Step: 1600  \tValid loss: 0.5270468592643738\n",
      "Step: 1700  \tTraining loss: 0.5567205548286438\n",
      "Step: 1700  \tTraining accuracy: 0.721283495426178\n",
      "Step: 1700  \tValid loss: 0.5268110632896423\n",
      "Step: 1800  \tTraining loss: 0.556402325630188\n",
      "Step: 1800  \tTraining accuracy: 0.7225399613380432\n",
      "Step: 1800  \tValid loss: 0.5265325307846069\n",
      "Step: 1900  \tTraining loss: 0.5560907125473022\n",
      "Step: 1900  \tTraining accuracy: 0.7236719727516174\n",
      "Step: 1900  \tValid loss: 0.5263426899909973\n",
      "Step: 2000  \tTraining loss: 0.555808424949646\n",
      "Step: 2000  \tTraining accuracy: 0.7246662974357605\n",
      "Step: 2000  \tValid loss: 0.5262041687965393\n",
      "Step: 2100  \tTraining loss: 0.5555628538131714\n",
      "Step: 2100  \tTraining accuracy: 0.7255635857582092\n",
      "Step: 2100  \tValid loss: 0.5259853601455688\n",
      "Step: 2200  \tTraining loss: 0.555341362953186\n",
      "Step: 2200  \tTraining accuracy: 0.7263578772544861\n",
      "Step: 2200  \tValid loss: 0.5257518291473389\n",
      "Step: 2300  \tTraining loss: 0.5551345348358154\n",
      "Step: 2300  \tTraining accuracy: 0.7270442247390747\n",
      "Step: 2300  \tValid loss: 0.5254977345466614\n",
      "Step: 2400  \tTraining loss: 0.5549346804618835\n",
      "Step: 2400  \tTraining accuracy: 0.7276452779769897\n",
      "Step: 2400  \tValid loss: 0.5253123641014099\n",
      "Step: 2500  \tTraining loss: 0.5547375679016113\n",
      "Step: 2500  \tTraining accuracy: 0.7281972765922546\n",
      "Step: 2500  \tValid loss: 0.5250864624977112\n",
      "Step: 2600  \tTraining loss: 0.5545371770858765\n",
      "Step: 2600  \tTraining accuracy: 0.728689432144165\n",
      "Step: 2600  \tValid loss: 0.5248439311981201\n",
      "Step: 2700  \tTraining loss: 0.5543306469917297\n",
      "Step: 2700  \tTraining accuracy: 0.7291603684425354\n",
      "Step: 2700  \tValid loss: 0.5246340036392212\n",
      "Step: 2800  \tTraining loss: 0.5541228652000427\n",
      "Step: 2800  \tTraining accuracy: 0.7296047210693359\n",
      "Step: 2800  \tValid loss: 0.5244332551956177\n",
      "Step: 2900  \tTraining loss: 0.5539177060127258\n",
      "Step: 2900  \tTraining accuracy: 0.7300400137901306\n",
      "Step: 2900  \tValid loss: 0.5242637395858765\n",
      "Step: 3000  \tTraining loss: 0.5537190437316895\n",
      "Step: 3000  \tTraining accuracy: 0.730459988117218\n",
      "Step: 3000  \tValid loss: 0.5241352915763855\n",
      "Step: 3100  \tTraining loss: 0.5535203814506531\n",
      "Step: 3100  \tTraining accuracy: 0.73084557056427\n",
      "Step: 3100  \tValid loss: 0.5239680409431458\n",
      "Step: 3200  \tTraining loss: 0.5533189177513123\n",
      "Step: 3200  \tTraining accuracy: 0.7311866879463196\n",
      "Step: 3200  \tValid loss: 0.5238347053527832\n",
      "Step: 3300  \tTraining loss: 0.5531102418899536\n",
      "Step: 3300  \tTraining accuracy: 0.7315132021903992\n",
      "Step: 3300  \tValid loss: 0.5236595273017883\n",
      "Step: 3400  \tTraining loss: 0.5529037117958069\n",
      "Step: 3400  \tTraining accuracy: 0.7318077683448792\n",
      "Step: 3400  \tValid loss: 0.5235198140144348\n",
      "Step: 3500  \tTraining loss: 0.5526912212371826\n",
      "Step: 3500  \tTraining accuracy: 0.7320912480354309\n",
      "Step: 3500  \tValid loss: 0.5234383344650269\n",
      "Step: 3600  \tTraining loss: 0.552466630935669\n",
      "Step: 3600  \tTraining accuracy: 0.7323647737503052\n",
      "Step: 3600  \tValid loss: 0.5233380198478699\n",
      "Step: 3700  \tTraining loss: 0.5522395968437195\n",
      "Step: 3700  \tTraining accuracy: 0.7326347827911377\n",
      "Step: 3700  \tValid loss: 0.5232725143432617\n",
      "Step: 3800  \tTraining loss: 0.5520085096359253\n",
      "Step: 3800  \tTraining accuracy: 0.732867956161499\n",
      "Step: 3800  \tValid loss: 0.5232349038124084\n",
      "Step: 3900  \tTraining loss: 0.5517793297767639\n",
      "Step: 3900  \tTraining accuracy: 0.7330835461616516\n",
      "Step: 3900  \tValid loss: 0.5232142806053162\n",
      "Step: 4000  \tTraining loss: 0.5515682101249695\n",
      "Step: 4000  \tTraining accuracy: 0.7332988977432251\n",
      "Step: 4000  \tValid loss: 0.523179292678833\n",
      "Step: 4100  \tTraining loss: 0.5513642430305481\n",
      "Step: 4100  \tTraining accuracy: 0.7335036396980286\n",
      "Step: 4100  \tValid loss: 0.5231964588165283\n",
      "Step: 4200  \tTraining loss: 0.551164984703064\n",
      "Step: 4200  \tTraining accuracy: 0.7336934208869934\n",
      "Step: 4200  \tValid loss: 0.5232291221618652\n",
      "Step: 4300  \tTraining loss: 0.5509682297706604\n",
      "Step: 4300  \tTraining accuracy: 0.7338594198226929\n",
      "Step: 4300  \tValid loss: 0.5232053399085999\n",
      "Step: 4400  \tTraining loss: 0.5507730841636658\n",
      "Step: 4400  \tTraining accuracy: 0.7340274453163147\n",
      "Step: 4400  \tValid loss: 0.523201048374176\n",
      "Step: 4500  \tTraining loss: 0.5505582690238953\n",
      "Step: 4500  \tTraining accuracy: 0.7342446446418762\n",
      "Step: 4500  \tValid loss: 0.5232426524162292\n",
      "Step: 4600  \tTraining loss: 0.5503615140914917\n",
      "Step: 4600  \tTraining accuracy: 0.7344568967819214\n",
      "Step: 4600  \tValid loss: 0.5232665538787842\n",
      "Step: 4700  \tTraining loss: 0.5501731038093567\n",
      "Step: 4700  \tTraining accuracy: 0.7346509695053101\n",
      "Step: 4700  \tValid loss: 0.5232792496681213\n",
      "Step: 4800  \tTraining loss: 0.5499892234802246\n",
      "Step: 4800  \tTraining accuracy: 0.7348545789718628\n",
      "Step: 4800  \tValid loss: 0.5233196020126343\n",
      "Step: 4900  \tTraining loss: 0.5498117804527283\n",
      "Step: 4900  \tTraining accuracy: 0.7350584864616394\n",
      "Step: 4900  \tValid loss: 0.5233740210533142\n",
      "Step: 5000  \tTraining loss: 0.5496245622634888\n",
      "Step: 5000  \tTraining accuracy: 0.7352498769760132\n",
      "Step: 5000  \tValid loss: 0.5234278440475464\n",
      "Step: 5100  \tTraining loss: 0.5494490265846252\n",
      "Step: 5100  \tTraining accuracy: 0.7354462146759033\n",
      "Step: 5100  \tValid loss: 0.5234856009483337\n",
      "Step: 5200  \tTraining loss: 0.54928058385849\n",
      "Step: 5200  \tTraining accuracy: 0.7356349229812622\n",
      "Step: 5200  \tValid loss: 0.5235319137573242\n",
      "Step: 5300  \tTraining loss: 0.5491130948066711\n",
      "Step: 5300  \tTraining accuracy: 0.7358164191246033\n",
      "Step: 5300  \tValid loss: 0.5235722064971924\n",
      "Step: 5400  \tTraining loss: 0.5489460229873657\n",
      "Step: 5400  \tTraining accuracy: 0.7359871864318848\n",
      "Step: 5400  \tValid loss: 0.5236057043075562\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7361479\n",
      "Precision: 0.7061924\n",
      "Recall: 0.5612565\n",
      "F1 score: 0.6519676\n",
      "AUC: 0.70227265\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.736148   0.706192  0.561257  0.651968  0.702273  0.548863      0.736205   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.523157       0.736087   0.517619      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5450.0  \n",
      "31\n",
      "(1160, 5)\n",
      "(1160, 1)\n",
      "(624, 5)\n",
      "(624, 1)\n",
      "(507, 5)\n",
      "(507, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6249616146087646\n",
      "Step: 100  \tTraining accuracy: 0.7103448510169983\n",
      "Step: 100  \tValid loss: 0.6324434280395508\n",
      "Step: 200  \tTraining loss: 0.5197563171386719\n",
      "Step: 200  \tTraining accuracy: 0.726166307926178\n",
      "Step: 200  \tValid loss: 0.5556355714797974\n",
      "Step: 300  \tTraining loss: 0.46496298909187317\n",
      "Step: 300  \tTraining accuracy: 0.7441657781600952\n",
      "Step: 300  \tValid loss: 0.507118821144104\n",
      "Step: 400  \tTraining loss: 0.4013039469718933\n",
      "Step: 400  \tTraining accuracy: 0.7631021738052368\n",
      "Step: 400  \tValid loss: 0.43894684314727783\n",
      "Step: 500  \tTraining loss: 0.34794700145721436\n",
      "Step: 500  \tTraining accuracy: 0.7808988690376282\n",
      "Step: 500  \tValid loss: 0.3856860101222992\n",
      "Step: 600  \tTraining loss: 0.3220534026622772\n",
      "Step: 600  \tTraining accuracy: 0.7973840832710266\n",
      "Step: 600  \tValid loss: 0.3604518473148346\n",
      "Step: 700  \tTraining loss: 0.30986127257347107\n",
      "Step: 700  \tTraining accuracy: 0.8092714548110962\n",
      "Step: 700  \tValid loss: 0.3486502468585968\n",
      "Step: 800  \tTraining loss: 0.30328670144081116\n",
      "Step: 800  \tTraining accuracy: 0.8179333806037903\n",
      "Step: 800  \tValid loss: 0.34209227561950684\n",
      "Step: 900  \tTraining loss: 0.2990332841873169\n",
      "Step: 900  \tTraining accuracy: 0.8245074152946472\n",
      "Step: 900  \tValid loss: 0.3375607132911682\n",
      "Step: 1000  \tTraining loss: 0.2957621216773987\n",
      "Step: 1000  \tTraining accuracy: 0.8297442197799683\n",
      "Step: 1000  \tValid loss: 0.3337295949459076\n",
      "Step: 1100  \tTraining loss: 0.2927468717098236\n",
      "Step: 1100  \tTraining accuracy: 0.8339011073112488\n",
      "Step: 1100  \tValid loss: 0.3304251730442047\n",
      "Step: 1200  \tTraining loss: 0.2904655337333679\n",
      "Step: 1200  \tTraining accuracy: 0.8374872207641602\n",
      "Step: 1200  \tValid loss: 0.32770025730133057\n",
      "Step: 1300  \tTraining loss: 0.2885854244232178\n",
      "Step: 1300  \tTraining accuracy: 0.8405346870422363\n",
      "Step: 1300  \tValid loss: 0.32535097002983093\n",
      "Step: 1400  \tTraining loss: 0.2869315445423126\n",
      "Step: 1400  \tTraining accuracy: 0.8432278633117676\n",
      "Step: 1400  \tValid loss: 0.3232690989971161\n",
      "Step: 1500  \tTraining loss: 0.285459965467453\n",
      "Step: 1500  \tTraining accuracy: 0.8455798029899597\n",
      "Step: 1500  \tValid loss: 0.3213580846786499\n",
      "Step: 1600  \tTraining loss: 0.2841486930847168\n",
      "Step: 1600  \tTraining accuracy: 0.8476002812385559\n",
      "Step: 1600  \tValid loss: 0.3195986747741699\n",
      "Step: 1700  \tTraining loss: 0.28298425674438477\n",
      "Step: 1700  \tTraining accuracy: 0.8495610356330872\n",
      "Step: 1700  \tValid loss: 0.31798255443573\n",
      "Step: 1800  \tTraining loss: 0.28195661306381226\n",
      "Step: 1800  \tTraining accuracy: 0.8513476252555847\n",
      "Step: 1800  \tValid loss: 0.3165041208267212\n",
      "Step: 1900  \tTraining loss: 0.28105562925338745\n",
      "Step: 1900  \tTraining accuracy: 0.8530355095863342\n",
      "Step: 1900  \tValid loss: 0.3151582181453705\n",
      "Step: 2000  \tTraining loss: 0.28026896715164185\n",
      "Step: 2000  \tTraining accuracy: 0.8545727133750916\n",
      "Step: 2000  \tValid loss: 0.31393682956695557\n",
      "Step: 2100  \tTraining loss: 0.2795809209346771\n",
      "Step: 2100  \tTraining accuracy: 0.8559600114822388\n",
      "Step: 2100  \tValid loss: 0.3128271698951721\n",
      "Step: 2200  \tTraining loss: 0.27897384762763977\n",
      "Step: 2200  \tTraining accuracy: 0.8573400378227234\n",
      "Step: 2200  \tValid loss: 0.3118132948875427\n",
      "Step: 2300  \tTraining loss: 0.2784312665462494\n",
      "Step: 2300  \tTraining accuracy: 0.858636200428009\n",
      "Step: 2300  \tValid loss: 0.3108792006969452\n",
      "Step: 2400  \tTraining loss: 0.2779378890991211\n",
      "Step: 2400  \tTraining accuracy: 0.8598406910896301\n",
      "Step: 2400  \tValid loss: 0.3100118041038513\n",
      "Step: 2500  \tTraining loss: 0.2774812877178192\n",
      "Step: 2500  \tTraining accuracy: 0.8609468340873718\n",
      "Step: 2500  \tValid loss: 0.30920150876045227\n",
      "Step: 2600  \tTraining loss: 0.27705132961273193\n",
      "Step: 2600  \tTraining accuracy: 0.8619834184646606\n",
      "Step: 2600  \tValid loss: 0.30844223499298096\n",
      "Step: 2700  \tTraining loss: 0.2766397297382355\n",
      "Step: 2700  \tTraining accuracy: 0.8629581928253174\n",
      "Step: 2700  \tValid loss: 0.30773064494132996\n",
      "Step: 2800  \tTraining loss: 0.2762400805950165\n",
      "Step: 2800  \tTraining accuracy: 0.8638462424278259\n",
      "Step: 2800  \tValid loss: 0.3070652186870575\n",
      "Step: 2900  \tTraining loss: 0.275846928358078\n",
      "Step: 2900  \tTraining accuracy: 0.8646720051765442\n",
      "Step: 2900  \tValid loss: 0.30644509196281433\n",
      "Step: 3000  \tTraining loss: 0.275455504655838\n",
      "Step: 3000  \tTraining accuracy: 0.8654417991638184\n",
      "Step: 3000  \tValid loss: 0.3058699071407318\n",
      "Step: 3100  \tTraining loss: 0.27506157755851746\n",
      "Step: 3100  \tTraining accuracy: 0.8661611080169678\n",
      "Step: 3100  \tValid loss: 0.3053390681743622\n",
      "Step: 3200  \tTraining loss: 0.27466121315956116\n",
      "Step: 3200  \tTraining accuracy: 0.8668347597122192\n",
      "Step: 3200  \tValid loss: 0.3048519790172577\n",
      "Step: 3300  \tTraining loss: 0.27424973249435425\n",
      "Step: 3300  \tTraining accuracy: 0.8674669861793518\n",
      "Step: 3300  \tValid loss: 0.3044074475765228\n",
      "Step: 3400  \tTraining loss: 0.273823082447052\n",
      "Step: 3400  \tTraining accuracy: 0.8680614233016968\n",
      "Step: 3400  \tValid loss: 0.3040044605731964\n",
      "Step: 3500  \tTraining loss: 0.2733769714832306\n",
      "Step: 3500  \tTraining accuracy: 0.8686720728874207\n",
      "Step: 3500  \tValid loss: 0.3036419749259949\n",
      "Step: 3600  \tTraining loss: 0.27290797233581543\n",
      "Step: 3600  \tTraining accuracy: 0.8692482709884644\n",
      "Step: 3600  \tValid loss: 0.3033183813095093\n",
      "Step: 3700  \tTraining loss: 0.27241262793540955\n",
      "Step: 3700  \tTraining accuracy: 0.8697929382324219\n",
      "Step: 3700  \tValid loss: 0.3030320703983307\n",
      "Step: 3800  \tTraining loss: 0.27188947796821594\n",
      "Step: 3800  \tTraining accuracy: 0.870308518409729\n",
      "Step: 3800  \tValid loss: 0.3027803599834442\n",
      "Step: 3900  \tTraining loss: 0.27133774757385254\n",
      "Step: 3900  \tTraining accuracy: 0.8708313703536987\n",
      "Step: 3900  \tValid loss: 0.30255988240242004\n",
      "Step: 4000  \tTraining loss: 0.2707584500312805\n",
      "Step: 4000  \tTraining accuracy: 0.8713387846946716\n",
      "Step: 4000  \tValid loss: 0.30236557126045227\n",
      "Step: 4100  \tTraining loss: 0.2701537609100342\n",
      "Step: 4100  \tTraining accuracy: 0.8718103170394897\n",
      "Step: 4100  \tValid loss: 0.30219241976737976\n",
      "Step: 4200  \tTraining loss: 0.26952630281448364\n",
      "Step: 4200  \tTraining accuracy: 0.8722487092018127\n",
      "Step: 4200  \tValid loss: 0.3020353317260742\n",
      "Step: 4300  \tTraining loss: 0.2688792645931244\n",
      "Step: 4300  \tTraining accuracy: 0.8726972341537476\n",
      "Step: 4300  \tValid loss: 0.30189061164855957\n",
      "Step: 4400  \tTraining loss: 0.26821646094322205\n",
      "Step: 4400  \tTraining accuracy: 0.8731351494789124\n",
      "Step: 4400  \tValid loss: 0.3017560541629791\n",
      "Step: 4500  \tTraining loss: 0.2675420939922333\n",
      "Step: 4500  \tTraining accuracy: 0.8735533952713013\n",
      "Step: 4500  \tValid loss: 0.30163082480430603\n",
      "Step: 4600  \tTraining loss: 0.2668610215187073\n",
      "Step: 4600  \tTraining accuracy: 0.8739532828330994\n",
      "Step: 4600  \tValid loss: 0.30151447653770447\n",
      "Step: 4700  \tTraining loss: 0.266178697347641\n",
      "Step: 4700  \tTraining accuracy: 0.8743359446525574\n",
      "Step: 4700  \tValid loss: 0.30140653252601624\n",
      "Step: 4800  \tTraining loss: 0.2655007541179657\n",
      "Step: 4800  \tTraining accuracy: 0.8747117519378662\n",
      "Step: 4800  \tValid loss: 0.30130746960639954\n",
      "Step: 4900  \tTraining loss: 0.2648325562477112\n",
      "Step: 4900  \tTraining accuracy: 0.8750810027122498\n",
      "Step: 4900  \tValid loss: 0.3012181222438812\n",
      "Step: 5000  \tTraining loss: 0.2641791105270386\n",
      "Step: 5000  \tTraining accuracy: 0.8754353523254395\n",
      "Step: 5000  \tValid loss: 0.30114006996154785\n",
      "Step: 5100  \tTraining loss: 0.2635447084903717\n",
      "Step: 5100  \tTraining accuracy: 0.8757669925689697\n",
      "Step: 5100  \tValid loss: 0.301074743270874\n",
      "Step: 5200  \tTraining loss: 0.26293283700942993\n",
      "Step: 5200  \tTraining accuracy: 0.8760942816734314\n",
      "Step: 5200  \tValid loss: 0.3010229170322418\n",
      "Step: 5300  \tTraining loss: 0.2623462975025177\n",
      "Step: 5300  \tTraining accuracy: 0.8764090538024902\n",
      "Step: 5300  \tValid loss: 0.3009850084781647\n",
      "Step: 5400  \tTraining loss: 0.26178693771362305\n",
      "Step: 5400  \tTraining accuracy: 0.8767120838165283\n",
      "Step: 5400  \tValid loss: 0.30096107721328735\n",
      "Step: 5500  \tTraining loss: 0.2612558901309967\n",
      "Step: 5500  \tTraining accuracy: 0.8769960403442383\n",
      "Step: 5500  \tValid loss: 0.3009510934352875\n",
      "Step: 5600  \tTraining loss: 0.2607535123825073\n",
      "Step: 5600  \tTraining accuracy: 0.8772696852684021\n",
      "Step: 5600  \tValid loss: 0.30095580220222473\n",
      "Step: 5700  \tTraining loss: 0.2602798342704773\n",
      "Step: 5700  \tTraining accuracy: 0.8775414228439331\n",
      "Step: 5700  \tValid loss: 0.30097541213035583\n",
      "Step: 5800  \tTraining loss: 0.25983449816703796\n",
      "Step: 5800  \tTraining accuracy: 0.8778188228607178\n",
      "Step: 5800  \tValid loss: 0.3010103404521942\n",
      "Step: 5900  \tTraining loss: 0.2594165802001953\n",
      "Step: 5900  \tTraining accuracy: 0.8780942559242249\n",
      "Step: 5900  \tValid loss: 0.30106064677238464\n",
      "Step: 6000  \tTraining loss: 0.2590254545211792\n",
      "Step: 6000  \tTraining accuracy: 0.8783677816390991\n",
      "Step: 6000  \tValid loss: 0.30112600326538086\n",
      "Step: 6100  \tTraining loss: 0.25866010785102844\n",
      "Step: 6100  \tTraining accuracy: 0.8786394596099854\n",
      "Step: 6100  \tValid loss: 0.30120596289634705\n",
      "Step: 6200  \tTraining loss: 0.25831925868988037\n",
      "Step: 6200  \tTraining accuracy: 0.8788809776306152\n",
      "Step: 6200  \tValid loss: 0.301299512386322\n",
      "Step: 6300  \tTraining loss: 0.2580021023750305\n",
      "Step: 6300  \tTraining accuracy: 0.8791148066520691\n",
      "Step: 6300  \tValid loss: 0.3014056384563446\n",
      "Step: 6400  \tTraining loss: 0.2577070891857147\n",
      "Step: 6400  \tTraining accuracy: 0.8793343901634216\n",
      "Step: 6400  \tValid loss: 0.30152276158332825\n",
      "Step: 6500  \tTraining loss: 0.257433146238327\n",
      "Step: 6500  \tTraining accuracy: 0.8795471787452698\n",
      "Step: 6500  \tValid loss: 0.30164968967437744\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8797535\n",
      "Precision: 0.8696581\n",
      "Recall: 0.86595744\n",
      "F1 score: 0.8778777\n",
      "AUC: 0.8887758\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.879753   0.869658  0.865957  0.877878  0.888776  0.257396      0.879649   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.300951       0.879629   0.279165      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  6513.0  \n",
      "32\n",
      "(841, 5)\n",
      "(841, 1)\n",
      "(448, 5)\n",
      "(448, 1)\n",
      "(364, 5)\n",
      "(364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6371537446975708\n",
      "Step: 100  \tTraining accuracy: 0.6492270827293396\n",
      "Step: 100  \tValid loss: 0.6855302453041077\n",
      "Step: 200  \tTraining loss: 0.5823842287063599\n",
      "Step: 200  \tTraining accuracy: 0.6335204243659973\n",
      "Step: 200  \tValid loss: 0.6382428407669067\n",
      "Step: 300  \tTraining loss: 0.5128071904182434\n",
      "Step: 300  \tTraining accuracy: 0.6566192507743835\n",
      "Step: 300  \tValid loss: 0.5625342726707458\n",
      "Step: 400  \tTraining loss: 0.45971718430519104\n",
      "Step: 400  \tTraining accuracy: 0.6829310059547424\n",
      "Step: 400  \tValid loss: 0.5050930380821228\n",
      "Step: 500  \tTraining loss: 0.4251788854598999\n",
      "Step: 500  \tTraining accuracy: 0.7038776278495789\n",
      "Step: 500  \tValid loss: 0.46935513615608215\n",
      "Step: 600  \tTraining loss: 0.40178027749061584\n",
      "Step: 600  \tTraining accuracy: 0.7212826609611511\n",
      "Step: 600  \tValid loss: 0.4464443325996399\n",
      "Step: 700  \tTraining loss: 0.38478508591651917\n",
      "Step: 700  \tTraining accuracy: 0.7346407771110535\n",
      "Step: 700  \tValid loss: 0.43066903948783875\n",
      "Step: 800  \tTraining loss: 0.3719639778137207\n",
      "Step: 800  \tTraining accuracy: 0.7458105087280273\n",
      "Step: 800  \tValid loss: 0.4192045032978058\n",
      "Step: 900  \tTraining loss: 0.36191049218177795\n",
      "Step: 900  \tTraining accuracy: 0.7548524737358093\n",
      "Step: 900  \tValid loss: 0.4101950526237488\n",
      "Step: 1000  \tTraining loss: 0.3537938892841339\n",
      "Step: 1000  \tTraining accuracy: 0.7621834874153137\n",
      "Step: 1000  \tValid loss: 0.4028531014919281\n",
      "Step: 1100  \tTraining loss: 0.3470921516418457\n",
      "Step: 1100  \tTraining accuracy: 0.7682344317436218\n",
      "Step: 1100  \tValid loss: 0.3967345058917999\n",
      "Step: 1200  \tTraining loss: 0.3414851725101471\n",
      "Step: 1200  \tTraining accuracy: 0.7732338309288025\n",
      "Step: 1200  \tValid loss: 0.3915911316871643\n",
      "Step: 1300  \tTraining loss: 0.3367653489112854\n",
      "Step: 1300  \tTraining accuracy: 0.7775306105613708\n",
      "Step: 1300  \tValid loss: 0.38729599118232727\n",
      "Step: 1400  \tTraining loss: 0.33278048038482666\n",
      "Step: 1400  \tTraining accuracy: 0.7811912298202515\n",
      "Step: 1400  \tValid loss: 0.38374465703964233\n",
      "Step: 1500  \tTraining loss: 0.329407274723053\n",
      "Step: 1500  \tTraining accuracy: 0.7843889594078064\n",
      "Step: 1500  \tValid loss: 0.3808208107948303\n",
      "Step: 1600  \tTraining loss: 0.32654571533203125\n",
      "Step: 1600  \tTraining accuracy: 0.7872523069381714\n",
      "Step: 1600  \tValid loss: 0.37839776277542114\n",
      "Step: 1700  \tTraining loss: 0.3241104185581207\n",
      "Step: 1700  \tTraining accuracy: 0.7899519801139832\n",
      "Step: 1700  \tValid loss: 0.3764200806617737\n",
      "Step: 1800  \tTraining loss: 0.32203200459480286\n",
      "Step: 1800  \tTraining accuracy: 0.7925160527229309\n",
      "Step: 1800  \tValid loss: 0.37481072545051575\n",
      "Step: 1900  \tTraining loss: 0.320253849029541\n",
      "Step: 1900  \tTraining accuracy: 0.7948030829429626\n",
      "Step: 1900  \tValid loss: 0.37350377440452576\n",
      "Step: 2000  \tTraining loss: 0.31872862577438354\n",
      "Step: 2000  \tTraining accuracy: 0.7969176173210144\n",
      "Step: 2000  \tValid loss: 0.3724507689476013\n",
      "Step: 2100  \tTraining loss: 0.3174164891242981\n",
      "Step: 2100  \tTraining accuracy: 0.7988259792327881\n",
      "Step: 2100  \tValid loss: 0.37160855531692505\n",
      "Step: 2200  \tTraining loss: 0.31628552079200745\n",
      "Step: 2200  \tTraining accuracy: 0.8005287647247314\n",
      "Step: 2200  \tValid loss: 0.370938241481781\n",
      "Step: 2300  \tTraining loss: 0.3153090178966522\n",
      "Step: 2300  \tTraining accuracy: 0.8021339774131775\n",
      "Step: 2300  \tValid loss: 0.3704238533973694\n",
      "Step: 2400  \tTraining loss: 0.3144650161266327\n",
      "Step: 2400  \tTraining accuracy: 0.8036026954650879\n",
      "Step: 2400  \tValid loss: 0.3700294494628906\n",
      "Step: 2500  \tTraining loss: 0.31373491883277893\n",
      "Step: 2500  \tTraining accuracy: 0.8049514889717102\n",
      "Step: 2500  \tValid loss: 0.3697337508201599\n",
      "Step: 2600  \tTraining loss: 0.313102662563324\n",
      "Step: 2600  \tTraining accuracy: 0.8062182664871216\n",
      "Step: 2600  \tValid loss: 0.36953696608543396\n",
      "Step: 2700  \tTraining loss: 0.3125549852848053\n",
      "Step: 2700  \tTraining accuracy: 0.807389497756958\n",
      "Step: 2700  \tValid loss: 0.36942562460899353\n",
      "Step: 2800  \tTraining loss: 0.3120802342891693\n",
      "Step: 2800  \tTraining accuracy: 0.8084975481033325\n",
      "Step: 2800  \tValid loss: 0.36936092376708984\n",
      "Step: 2900  \tTraining loss: 0.3116677403450012\n",
      "Step: 2900  \tTraining accuracy: 0.80954909324646\n",
      "Step: 2900  \tValid loss: 0.36932530999183655\n",
      "Step: 3000  \tTraining loss: 0.3113093078136444\n",
      "Step: 3000  \tTraining accuracy: 0.810529351234436\n",
      "Step: 3000  \tValid loss: 0.3693006932735443\n",
      "Step: 3100  \tTraining loss: 0.3109963536262512\n",
      "Step: 3100  \tTraining accuracy: 0.8114453554153442\n",
      "Step: 3100  \tValid loss: 0.36928674578666687\n",
      "Step: 3200  \tTraining loss: 0.3107229769229889\n",
      "Step: 3200  \tTraining accuracy: 0.8123223781585693\n",
      "Step: 3200  \tValid loss: 0.3692823052406311\n",
      "Step: 3300  \tTraining loss: 0.31048327684402466\n",
      "Step: 3300  \tTraining accuracy: 0.8131641149520874\n",
      "Step: 3300  \tValid loss: 0.3692921996116638\n",
      "Step: 3400  \tTraining loss: 0.31027156114578247\n",
      "Step: 3400  \tTraining accuracy: 0.8139556050300598\n",
      "Step: 3400  \tValid loss: 0.36931467056274414\n",
      "Step: 3500  \tTraining loss: 0.3100844621658325\n",
      "Step: 3500  \tTraining accuracy: 0.8147011995315552\n",
      "Step: 3500  \tValid loss: 0.3693405091762543\n",
      "Step: 3600  \tTraining loss: 0.30991801619529724\n",
      "Step: 3600  \tTraining accuracy: 0.8154218196868896\n",
      "Step: 3600  \tValid loss: 0.36937084794044495\n",
      "Step: 3700  \tTraining loss: 0.30976879596710205\n",
      "Step: 3700  \tTraining accuracy: 0.8161361217498779\n",
      "Step: 3700  \tValid loss: 0.36940738558769226\n",
      "Step: 3800  \tTraining loss: 0.30963438749313354\n",
      "Step: 3800  \tTraining accuracy: 0.8167962431907654\n",
      "Step: 3800  \tValid loss: 0.36944642663002014\n",
      "Step: 3900  \tTraining loss: 0.3095124065876007\n",
      "Step: 3900  \tTraining accuracy: 0.8174220323562622\n",
      "Step: 3900  \tValid loss: 0.36948445439338684\n",
      "Step: 4000  \tTraining loss: 0.3094009459018707\n",
      "Step: 4000  \tTraining accuracy: 0.8180314898490906\n",
      "Step: 4000  \tValid loss: 0.3695206940174103\n",
      "Step: 4100  \tTraining loss: 0.3092978000640869\n",
      "Step: 4100  \tTraining accuracy: 0.8186108469963074\n",
      "Step: 4100  \tValid loss: 0.36956363916397095\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.81916225\n",
      "Precision: 0.85130113\n",
      "Recall: 0.77627116\n",
      "F1 score: 0.7813994\n",
      "AUC: 0.8515055\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.819162   0.851301  0.776271  0.781399  0.851506  0.309218      0.818482   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.369276       0.818433   0.527855      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4181.0  \n",
      "33\n",
      "(928, 5)\n",
      "(928, 1)\n",
      "(512, 5)\n",
      "(512, 1)\n",
      "(416, 5)\n",
      "(416, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5996932983398438\n",
      "Step: 100  \tTraining accuracy: 0.7230603694915771\n",
      "Step: 100  \tValid loss: 0.5942906141281128\n",
      "Step: 200  \tTraining loss: 0.5281842947006226\n",
      "Step: 200  \tTraining accuracy: 0.7363505959510803\n",
      "Step: 200  \tValid loss: 0.5305202007293701\n",
      "Step: 300  \tTraining loss: 0.5177743434906006\n",
      "Step: 300  \tTraining accuracy: 0.7439655065536499\n",
      "Step: 300  \tValid loss: 0.5195278525352478\n",
      "Step: 400  \tTraining loss: 0.5105767846107483\n",
      "Step: 400  \tTraining accuracy: 0.7490763664245605\n",
      "Step: 400  \tValid loss: 0.5127567052841187\n",
      "Step: 500  \tTraining loss: 0.5045425295829773\n",
      "Step: 500  \tTraining accuracy: 0.7534722089767456\n",
      "Step: 500  \tValid loss: 0.5074691772460938\n",
      "Step: 600  \tTraining loss: 0.49929991364479065\n",
      "Step: 600  \tTraining accuracy: 0.7566614151000977\n",
      "Step: 600  \tValid loss: 0.5027219653129578\n",
      "Step: 700  \tTraining loss: 0.49476557970046997\n",
      "Step: 700  \tTraining accuracy: 0.7596982717514038\n",
      "Step: 700  \tValid loss: 0.49884286522865295\n",
      "Step: 800  \tTraining loss: 0.49085375666618347\n",
      "Step: 800  \tTraining accuracy: 0.7624281644821167\n",
      "Step: 800  \tValid loss: 0.49546629190444946\n",
      "Step: 900  \tTraining loss: 0.48757514357566833\n",
      "Step: 900  \tTraining accuracy: 0.7645791172981262\n",
      "Step: 900  \tValid loss: 0.4925996661186218\n",
      "Step: 1000  \tTraining loss: 0.4849241077899933\n",
      "Step: 1000  \tTraining accuracy: 0.7663339376449585\n",
      "Step: 1000  \tValid loss: 0.49038732051849365\n",
      "Step: 1100  \tTraining loss: 0.4828321635723114\n",
      "Step: 1100  \tTraining accuracy: 0.7678571343421936\n",
      "Step: 1100  \tValid loss: 0.4887693226337433\n",
      "Step: 1200  \tTraining loss: 0.4812082350254059\n",
      "Step: 1200  \tTraining accuracy: 0.7692091464996338\n",
      "Step: 1200  \tValid loss: 0.48765212297439575\n",
      "Step: 1300  \tTraining loss: 0.4799528419971466\n",
      "Step: 1300  \tTraining accuracy: 0.7703879475593567\n",
      "Step: 1300  \tValid loss: 0.4869186282157898\n",
      "Step: 1400  \tTraining loss: 0.4789651036262512\n",
      "Step: 1400  \tTraining accuracy: 0.7714319825172424\n",
      "Step: 1400  \tValid loss: 0.4864691197872162\n",
      "Step: 1500  \tTraining loss: 0.4781631529331207\n",
      "Step: 1500  \tTraining accuracy: 0.7723692059516907\n",
      "Step: 1500  \tValid loss: 0.48619794845581055\n",
      "Step: 1600  \tTraining loss: 0.47748616337776184\n",
      "Step: 1600  \tTraining accuracy: 0.7731854915618896\n",
      "Step: 1600  \tValid loss: 0.4860312044620514\n",
      "Step: 1700  \tTraining loss: 0.4768955707550049\n",
      "Step: 1700  \tTraining accuracy: 0.7739028334617615\n",
      "Step: 1700  \tValid loss: 0.48593002557754517\n",
      "Step: 1800  \tTraining loss: 0.4763686954975128\n",
      "Step: 1800  \tTraining accuracy: 0.7745381593704224\n",
      "Step: 1800  \tValid loss: 0.48583346605300903\n",
      "Step: 1900  \tTraining loss: 0.47589346766471863\n",
      "Step: 1900  \tTraining accuracy: 0.7750757336616516\n",
      "Step: 1900  \tValid loss: 0.48580530285835266\n",
      "Step: 2000  \tTraining loss: 0.4754510819911957\n",
      "Step: 2000  \tTraining accuracy: 0.7756133675575256\n",
      "Step: 2000  \tValid loss: 0.48561590909957886\n",
      "Step: 2100  \tTraining loss: 0.4750291109085083\n",
      "Step: 2100  \tTraining accuracy: 0.7760986089706421\n",
      "Step: 2100  \tValid loss: 0.4857083857059479\n",
      "Step: 2200  \tTraining loss: 0.4746318757534027\n",
      "Step: 2200  \tTraining accuracy: 0.7765887975692749\n",
      "Step: 2200  \tValid loss: 0.4856443405151367\n",
      "Step: 2300  \tTraining loss: 0.47425201535224915\n",
      "Step: 2300  \tTraining accuracy: 0.7770354151725769\n",
      "Step: 2300  \tValid loss: 0.4856167435646057\n",
      "Step: 2400  \tTraining loss: 0.47388458251953125\n",
      "Step: 2400  \tTraining accuracy: 0.777444064617157\n",
      "Step: 2400  \tValid loss: 0.4855499863624573\n",
      "Step: 2500  \tTraining loss: 0.473528116941452\n",
      "Step: 2500  \tTraining accuracy: 0.7777753472328186\n",
      "Step: 2500  \tValid loss: 0.48548778891563416\n",
      "Step: 2600  \tTraining loss: 0.47318196296691895\n",
      "Step: 2600  \tTraining accuracy: 0.7780806422233582\n",
      "Step: 2600  \tValid loss: 0.48541805148124695\n",
      "Step: 2700  \tTraining loss: 0.4728449881076813\n",
      "Step: 2700  \tTraining accuracy: 0.7783628702163696\n",
      "Step: 2700  \tValid loss: 0.48535043001174927\n",
      "Step: 2800  \tTraining loss: 0.47251635789871216\n",
      "Step: 2800  \tTraining accuracy: 0.778605043888092\n",
      "Step: 2800  \tValid loss: 0.4853016138076782\n",
      "Step: 2900  \tTraining loss: 0.47219669818878174\n",
      "Step: 2900  \tTraining accuracy: 0.7788301706314087\n",
      "Step: 2900  \tValid loss: 0.48522841930389404\n",
      "Step: 3000  \tTraining loss: 0.4718816578388214\n",
      "Step: 3000  \tTraining accuracy: 0.7790217995643616\n",
      "Step: 3000  \tValid loss: 0.48515450954437256\n",
      "Step: 3100  \tTraining loss: 0.4715687930583954\n",
      "Step: 3100  \tTraining accuracy: 0.7792184948921204\n",
      "Step: 3100  \tValid loss: 0.48508787155151367\n",
      "Step: 3200  \tTraining loss: 0.4712553918361664\n",
      "Step: 3200  \tTraining accuracy: 0.7794027328491211\n",
      "Step: 3200  \tValid loss: 0.4850311875343323\n",
      "Step: 3300  \tTraining loss: 0.47093746066093445\n",
      "Step: 3300  \tTraining accuracy: 0.7795755863189697\n",
      "Step: 3300  \tValid loss: 0.48497137427330017\n",
      "Step: 3400  \tTraining loss: 0.4706127643585205\n",
      "Step: 3400  \tTraining accuracy: 0.7797864079475403\n",
      "Step: 3400  \tValid loss: 0.4848960340023041\n",
      "Step: 3500  \tTraining loss: 0.4702807664871216\n",
      "Step: 3500  \tTraining accuracy: 0.7799850106239319\n",
      "Step: 3500  \tValid loss: 0.4848473072052002\n",
      "Step: 3600  \tTraining loss: 0.46991053223609924\n",
      "Step: 3600  \tTraining accuracy: 0.7801724076271057\n",
      "Step: 3600  \tValid loss: 0.4848310053348541\n",
      "Step: 3700  \tTraining loss: 0.469544917345047\n",
      "Step: 3700  \tTraining accuracy: 0.7803643345832825\n",
      "Step: 3700  \tValid loss: 0.48473411798477173\n",
      "Step: 3800  \tTraining loss: 0.469163715839386\n",
      "Step: 3800  \tTraining accuracy: 0.7805459499359131\n",
      "Step: 3800  \tValid loss: 0.4846559464931488\n",
      "Step: 3900  \tTraining loss: 0.46876639127731323\n",
      "Step: 3900  \tTraining accuracy: 0.7807462215423584\n",
      "Step: 3900  \tValid loss: 0.48461776971817017\n",
      "Step: 4000  \tTraining loss: 0.4683544933795929\n",
      "Step: 4000  \tTraining accuracy: 0.7809363007545471\n",
      "Step: 4000  \tValid loss: 0.48456087708473206\n",
      "Step: 4100  \tTraining loss: 0.46793654561042786\n",
      "Step: 4100  \tTraining accuracy: 0.7811302542686462\n",
      "Step: 4100  \tValid loss: 0.48440808057785034\n",
      "Step: 4200  \tTraining loss: 0.46750786900520325\n",
      "Step: 4200  \tTraining accuracy: 0.7813149094581604\n",
      "Step: 4200  \tValid loss: 0.48439717292785645\n",
      "Step: 4300  \tTraining loss: 0.4670644998550415\n",
      "Step: 4300  \tTraining accuracy: 0.7814908623695374\n",
      "Step: 4300  \tValid loss: 0.48437613248825073\n",
      "Step: 4400  \tTraining loss: 0.4665383994579315\n",
      "Step: 4400  \tTraining accuracy: 0.7816587686538696\n",
      "Step: 4400  \tValid loss: 0.484699547290802\n",
      "Step: 4500  \tTraining loss: 0.46599704027175903\n",
      "Step: 4500  \tTraining accuracy: 0.7818311452865601\n",
      "Step: 4500  \tValid loss: 0.48460304737091064\n",
      "Step: 4600  \tTraining loss: 0.4654809236526489\n",
      "Step: 4600  \tTraining accuracy: 0.7820078730583191\n",
      "Step: 4600  \tValid loss: 0.48465973138809204\n",
      "Step: 4700  \tTraining loss: 0.4649730920791626\n",
      "Step: 4700  \tTraining accuracy: 0.7821885347366333\n",
      "Step: 4700  \tValid loss: 0.4848162531852722\n",
      "Step: 4800  \tTraining loss: 0.46446436643600464\n",
      "Step: 4800  \tTraining accuracy: 0.7823503017425537\n",
      "Step: 4800  \tValid loss: 0.4850768446922302\n",
      "Step: 4900  \tTraining loss: 0.46395570039749146\n",
      "Step: 4900  \tTraining accuracy: 0.7824942469596863\n",
      "Step: 4900  \tValid loss: 0.4853406846523285\n",
      "Step: 5000  \tTraining loss: 0.4634475111961365\n",
      "Step: 5000  \tTraining accuracy: 0.7826215028762817\n",
      "Step: 5000  \tValid loss: 0.48567795753479004\n",
      "Step: 5100  \tTraining loss: 0.4629417955875397\n",
      "Step: 5100  \tTraining accuracy: 0.7827223539352417\n",
      "Step: 5100  \tValid loss: 0.48611000180244446\n",
      "Step: 5200  \tTraining loss: 0.46243858337402344\n",
      "Step: 5200  \tTraining accuracy: 0.7828088402748108\n",
      "Step: 5200  \tValid loss: 0.486518919467926\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7829023\n",
      "Precision: 0.81702125\n",
      "Recall: 0.77575755\n",
      "F1 score: 0.76261985\n",
      "AUC: 0.78857166\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.782902   0.817021  0.775758   0.76262  0.788572  0.462204      0.782856   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.484329       0.782885   0.451892      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5246.0  \n",
      "34\n",
      "(986, 5)\n",
      "(986, 1)\n",
      "(544, 5)\n",
      "(544, 1)\n",
      "(442, 5)\n",
      "(442, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5430371761322021\n",
      "Step: 100  \tTraining accuracy: 0.8316429853439331\n",
      "Step: 100  \tValid loss: 0.5554499626159668\n",
      "Step: 200  \tTraining loss: 0.3983464241027832\n",
      "Step: 200  \tTraining accuracy: 0.8299526572227478\n",
      "Step: 200  \tValid loss: 0.4578074514865875\n",
      "Step: 300  \tTraining loss: 0.3713687062263489\n",
      "Step: 300  \tTraining accuracy: 0.8334685564041138\n",
      "Step: 300  \tValid loss: 0.44260886311531067\n",
      "Step: 400  \tTraining loss: 0.3585689663887024\n",
      "Step: 400  \tTraining accuracy: 0.8355548977851868\n",
      "Step: 400  \tValid loss: 0.43044978380203247\n",
      "Step: 500  \tTraining loss: 0.35037875175476074\n",
      "Step: 500  \tTraining accuracy: 0.8378408551216125\n",
      "Step: 500  \tValid loss: 0.42204800248146057\n",
      "Step: 600  \tTraining loss: 0.3444254994392395\n",
      "Step: 600  \tTraining accuracy: 0.8388345837593079\n",
      "Step: 600  \tValid loss: 0.41650891304016113\n",
      "Step: 700  \tTraining loss: 0.3404620885848999\n",
      "Step: 700  \tTraining accuracy: 0.8395225405693054\n",
      "Step: 700  \tValid loss: 0.41396573185920715\n",
      "Step: 800  \tTraining loss: 0.3378586769104004\n",
      "Step: 800  \tTraining accuracy: 0.839891791343689\n",
      "Step: 800  \tValid loss: 0.41235172748565674\n",
      "Step: 900  \tTraining loss: 0.3359564542770386\n",
      "Step: 900  \tTraining accuracy: 0.8404725193977356\n",
      "Step: 900  \tValid loss: 0.4111824035644531\n",
      "Step: 1000  \tTraining loss: 0.33441147208213806\n",
      "Step: 1000  \tTraining accuracy: 0.8408775329589844\n",
      "Step: 1000  \tValid loss: 0.41029345989227295\n",
      "Step: 1100  \tTraining loss: 0.33292537927627563\n",
      "Step: 1100  \tTraining accuracy: 0.8411088585853577\n",
      "Step: 1100  \tValid loss: 0.4088901877403259\n",
      "Step: 1200  \tTraining loss: 0.3313473165035248\n",
      "Step: 1200  \tTraining accuracy: 0.8413440585136414\n",
      "Step: 1200  \tValid loss: 0.4069613218307495\n",
      "Step: 1300  \tTraining loss: 0.3297021985054016\n",
      "Step: 1300  \tTraining accuracy: 0.841582179069519\n",
      "Step: 1300  \tValid loss: 0.40427419543266296\n",
      "Step: 1400  \tTraining loss: 0.3281806409358978\n",
      "Step: 1400  \tTraining accuracy: 0.8417474031448364\n",
      "Step: 1400  \tValid loss: 0.40216001868247986\n",
      "Step: 1500  \tTraining loss: 0.3268718123435974\n",
      "Step: 1500  \tTraining accuracy: 0.8419249057769775\n",
      "Step: 1500  \tValid loss: 0.4007643759250641\n",
      "Step: 1600  \tTraining loss: 0.3256923258304596\n",
      "Step: 1600  \tTraining accuracy: 0.8420140147209167\n",
      "Step: 1600  \tValid loss: 0.3998259902000427\n",
      "Step: 1700  \tTraining loss: 0.3245140016078949\n",
      "Step: 1700  \tTraining accuracy: 0.8421230316162109\n",
      "Step: 1700  \tValid loss: 0.3988851010799408\n",
      "Step: 1800  \tTraining loss: 0.3234421908855438\n",
      "Step: 1800  \tTraining accuracy: 0.8422486186027527\n",
      "Step: 1800  \tValid loss: 0.3981650173664093\n",
      "Step: 1900  \tTraining loss: 0.3222830593585968\n",
      "Step: 1900  \tTraining accuracy: 0.8424428701400757\n",
      "Step: 1900  \tValid loss: 0.39722442626953125\n",
      "Step: 2000  \tTraining loss: 0.3212417960166931\n",
      "Step: 2000  \tTraining accuracy: 0.8426951766014099\n",
      "Step: 2000  \tValid loss: 0.3968939483165741\n",
      "Step: 2100  \tTraining loss: 0.32024917006492615\n",
      "Step: 2100  \tTraining accuracy: 0.8429228663444519\n",
      "Step: 2100  \tValid loss: 0.3966639041900635\n",
      "Step: 2200  \tTraining loss: 0.3193252384662628\n",
      "Step: 2200  \tTraining accuracy: 0.8431529998779297\n",
      "Step: 2200  \tValid loss: 0.3964674472808838\n",
      "Step: 2300  \tTraining loss: 0.3184206783771515\n",
      "Step: 2300  \tTraining accuracy: 0.8434076905250549\n",
      "Step: 2300  \tValid loss: 0.39610862731933594\n",
      "Step: 2400  \tTraining loss: 0.3174625337123871\n",
      "Step: 2400  \tTraining accuracy: 0.8436623215675354\n",
      "Step: 2400  \tValid loss: 0.39565417170524597\n",
      "Step: 2500  \tTraining loss: 0.31645411252975464\n",
      "Step: 2500  \tTraining accuracy: 0.8438547849655151\n",
      "Step: 2500  \tValid loss: 0.395510196685791\n",
      "Step: 2600  \tTraining loss: 0.3155761659145355\n",
      "Step: 2600  \tTraining accuracy: 0.8440520167350769\n",
      "Step: 2600  \tValid loss: 0.39539214968681335\n",
      "Step: 2700  \tTraining loss: 0.3147426247596741\n",
      "Step: 2700  \tTraining accuracy: 0.8442726731300354\n",
      "Step: 2700  \tValid loss: 0.3953263461589813\n",
      "Step: 2800  \tTraining loss: 0.3139548897743225\n",
      "Step: 2800  \tTraining accuracy: 0.8444956541061401\n",
      "Step: 2800  \tValid loss: 0.39550623297691345\n",
      "Step: 2900  \tTraining loss: 0.3132299780845642\n",
      "Step: 2900  \tTraining accuracy: 0.8446674346923828\n",
      "Step: 2900  \tValid loss: 0.39574310183525085\n",
      "Step: 3000  \tTraining loss: 0.3125414550304413\n",
      "Step: 3000  \tTraining accuracy: 0.8448447585105896\n",
      "Step: 3000  \tValid loss: 0.3960496485233307\n",
      "Step: 3100  \tTraining loss: 0.3118838965892792\n",
      "Step: 3100  \tTraining accuracy: 0.8450270891189575\n",
      "Step: 3100  \tValid loss: 0.396308571100235\n",
      "Step: 3200  \tTraining loss: 0.3112523555755615\n",
      "Step: 3200  \tTraining accuracy: 0.8452139496803284\n",
      "Step: 3200  \tValid loss: 0.3966089189052582\n",
      "Step: 3300  \tTraining loss: 0.31064578890800476\n",
      "Step: 3300  \tTraining accuracy: 0.8454360961914062\n",
      "Step: 3300  \tValid loss: 0.39696717262268066\n",
      "Step: 3400  \tTraining loss: 0.31006404757499695\n",
      "Step: 3400  \tTraining accuracy: 0.845629870891571\n",
      "Step: 3400  \tValid loss: 0.3973563611507416\n",
      "Step: 3500  \tTraining loss: 0.30950790643692017\n",
      "Step: 3500  \tTraining accuracy: 0.845782995223999\n",
      "Step: 3500  \tValid loss: 0.39771825075149536\n",
      "Step: 3600  \tTraining loss: 0.3089720606803894\n",
      "Step: 3600  \tTraining accuracy: 0.8459274768829346\n",
      "Step: 3600  \tValid loss: 0.3980104327201843\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8460641\n",
      "Precision: 0.88372093\n",
      "Recall: 0.97317076\n",
      "F1 score: 0.88682055\n",
      "AUC: 0.67032033\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.846064   0.883721  0.973171  0.886821  0.67032  0.308521      0.845715   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.395277        0.84573   0.478171      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3686.0  \n",
      "35\n",
      "(4031, 5)\n",
      "(4031, 1)\n",
      "(2224, 5)\n",
      "(2224, 1)\n",
      "(1807, 5)\n",
      "(1807, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.598982572555542\n",
      "Step: 100  \tTraining accuracy: 0.6077896356582642\n",
      "Step: 100  \tValid loss: 0.6053254008293152\n",
      "Step: 200  \tTraining loss: 0.4371595084667206\n",
      "Step: 200  \tTraining accuracy: 0.6903167366981506\n",
      "Step: 200  \tValid loss: 0.4548654854297638\n",
      "Step: 300  \tTraining loss: 0.3552290201187134\n",
      "Step: 300  \tTraining accuracy: 0.7602083683013916\n",
      "Step: 300  \tValid loss: 0.37606143951416016\n",
      "Step: 400  \tTraining loss: 0.31724148988723755\n",
      "Step: 400  \tTraining accuracy: 0.7932451963424683\n",
      "Step: 400  \tValid loss: 0.3377515375614166\n",
      "Step: 500  \tTraining loss: 0.29383304715156555\n",
      "Step: 500  \tTraining accuracy: 0.8127291202545166\n",
      "Step: 500  \tValid loss: 0.3127574622631073\n",
      "Step: 600  \tTraining loss: 0.27753663063049316\n",
      "Step: 600  \tTraining accuracy: 0.8258722424507141\n",
      "Step: 600  \tValid loss: 0.2940753400325775\n",
      "Step: 700  \tTraining loss: 0.26576802134513855\n",
      "Step: 700  \tTraining accuracy: 0.836059033870697\n",
      "Step: 700  \tValid loss: 0.2805619239807129\n",
      "Step: 800  \tTraining loss: 0.2561524510383606\n",
      "Step: 800  \tTraining accuracy: 0.844075083732605\n",
      "Step: 800  \tValid loss: 0.26997601985931396\n",
      "Step: 900  \tTraining loss: 0.24887874722480774\n",
      "Step: 900  \tTraining accuracy: 0.8506866097450256\n",
      "Step: 900  \tValid loss: 0.2617189288139343\n",
      "Step: 1000  \tTraining loss: 0.24330510199069977\n",
      "Step: 1000  \tTraining accuracy: 0.856206476688385\n",
      "Step: 1000  \tValid loss: 0.25525611639022827\n",
      "Step: 1100  \tTraining loss: 0.2389499843120575\n",
      "Step: 1100  \tTraining accuracy: 0.8608167767524719\n",
      "Step: 1100  \tValid loss: 0.2501891553401947\n",
      "Step: 1200  \tTraining loss: 0.2358333021402359\n",
      "Step: 1200  \tTraining accuracy: 0.8646683692932129\n",
      "Step: 1200  \tValid loss: 0.24672555923461914\n",
      "Step: 1300  \tTraining loss: 0.233772873878479\n",
      "Step: 1300  \tTraining accuracy: 0.8678839206695557\n",
      "Step: 1300  \tValid loss: 0.24430325627326965\n",
      "Step: 1400  \tTraining loss: 0.23211510479450226\n",
      "Step: 1400  \tTraining accuracy: 0.8707424998283386\n",
      "Step: 1400  \tValid loss: 0.2420646846294403\n",
      "Step: 1500  \tTraining loss: 0.23087318241596222\n",
      "Step: 1500  \tTraining accuracy: 0.873258113861084\n",
      "Step: 1500  \tValid loss: 0.2402135729789734\n",
      "Step: 1600  \tTraining loss: 0.2299465537071228\n",
      "Step: 1600  \tTraining accuracy: 0.8754331469535828\n",
      "Step: 1600  \tValid loss: 0.23895005881786346\n",
      "Step: 1700  \tTraining loss: 0.22915470600128174\n",
      "Step: 1700  \tTraining accuracy: 0.8773219585418701\n",
      "Step: 1700  \tValid loss: 0.2376791387796402\n",
      "Step: 1800  \tTraining loss: 0.2284337282180786\n",
      "Step: 1800  \tTraining accuracy: 0.8789807558059692\n",
      "Step: 1800  \tValid loss: 0.23632483184337616\n",
      "Step: 1900  \tTraining loss: 0.22777388989925385\n",
      "Step: 1900  \tTraining accuracy: 0.8804669380187988\n",
      "Step: 1900  \tValid loss: 0.23486076295375824\n",
      "Step: 2000  \tTraining loss: 0.22718477249145508\n",
      "Step: 2000  \tTraining accuracy: 0.881794273853302\n",
      "Step: 2000  \tValid loss: 0.2336159646511078\n",
      "Step: 2100  \tTraining loss: 0.22670263051986694\n",
      "Step: 2100  \tTraining accuracy: 0.882992148399353\n",
      "Step: 2100  \tValid loss: 0.2326371967792511\n",
      "Step: 2200  \tTraining loss: 0.22629712522029877\n",
      "Step: 2200  \tTraining accuracy: 0.8841190338134766\n",
      "Step: 2200  \tValid loss: 0.2319718301296234\n",
      "Step: 2300  \tTraining loss: 0.22593480348587036\n",
      "Step: 2300  \tTraining accuracy: 0.885151207447052\n",
      "Step: 2300  \tValid loss: 0.23161958158016205\n",
      "Step: 2400  \tTraining loss: 0.22561660408973694\n",
      "Step: 2400  \tTraining accuracy: 0.886074423789978\n",
      "Step: 2400  \tValid loss: 0.2313801646232605\n",
      "Step: 2500  \tTraining loss: 0.2253161072731018\n",
      "Step: 2500  \tTraining accuracy: 0.886922299861908\n",
      "Step: 2500  \tValid loss: 0.23115555942058563\n",
      "Step: 2600  \tTraining loss: 0.22501157224178314\n",
      "Step: 2600  \tTraining accuracy: 0.8877328038215637\n",
      "Step: 2600  \tValid loss: 0.2309674322605133\n",
      "Step: 2700  \tTraining loss: 0.2246754914522171\n",
      "Step: 2700  \tTraining accuracy: 0.888444721698761\n",
      "Step: 2700  \tValid loss: 0.23078078031539917\n",
      "Step: 2800  \tTraining loss: 0.22426870465278625\n",
      "Step: 2800  \tTraining accuracy: 0.8891184329986572\n",
      "Step: 2800  \tValid loss: 0.23051156103610992\n",
      "Step: 2900  \tTraining loss: 0.2237786501646042\n",
      "Step: 2900  \tTraining accuracy: 0.8897665739059448\n",
      "Step: 2900  \tValid loss: 0.23022779822349548\n",
      "Step: 3000  \tTraining loss: 0.22318720817565918\n",
      "Step: 3000  \tTraining accuracy: 0.8903792500495911\n",
      "Step: 3000  \tValid loss: 0.22992298007011414\n",
      "Step: 3100  \tTraining loss: 0.22266420722007751\n",
      "Step: 3100  \tTraining accuracy: 0.8909313678741455\n",
      "Step: 3100  \tValid loss: 0.22972387075424194\n",
      "Step: 3200  \tTraining loss: 0.2221887856721878\n",
      "Step: 3200  \tTraining accuracy: 0.8914287090301514\n",
      "Step: 3200  \tValid loss: 0.2296074777841568\n",
      "Step: 3300  \tTraining loss: 0.22175195813179016\n",
      "Step: 3300  \tTraining accuracy: 0.8918993473052979\n",
      "Step: 3300  \tValid loss: 0.229513481259346\n",
      "Step: 3400  \tTraining loss: 0.22133633494377136\n",
      "Step: 3400  \tTraining accuracy: 0.8923344016075134\n",
      "Step: 3400  \tValid loss: 0.22941502928733826\n",
      "Step: 3500  \tTraining loss: 0.22093236446380615\n",
      "Step: 3500  \tTraining accuracy: 0.8927478790283203\n",
      "Step: 3500  \tValid loss: 0.2292754054069519\n",
      "Step: 3600  \tTraining loss: 0.2205394059419632\n",
      "Step: 3600  \tTraining accuracy: 0.8931100964546204\n",
      "Step: 3600  \tValid loss: 0.22911645472049713\n",
      "Step: 3700  \tTraining loss: 0.22015713155269623\n",
      "Step: 3700  \tTraining accuracy: 0.8934456706047058\n",
      "Step: 3700  \tValid loss: 0.22896865010261536\n",
      "Step: 3800  \tTraining loss: 0.21979613602161407\n",
      "Step: 3800  \tTraining accuracy: 0.8937666416168213\n",
      "Step: 3800  \tValid loss: 0.22885675728321075\n",
      "Step: 3900  \tTraining loss: 0.21946309506893158\n",
      "Step: 3900  \tTraining accuracy: 0.894080638885498\n",
      "Step: 3900  \tValid loss: 0.22890393435955048\n",
      "Step: 4000  \tTraining loss: 0.21915662288665771\n",
      "Step: 4000  \tTraining accuracy: 0.8943724036216736\n",
      "Step: 4000  \tValid loss: 0.22899699211120605\n",
      "Step: 4100  \tTraining loss: 0.21887558698654175\n",
      "Step: 4100  \tTraining accuracy: 0.8946498036384583\n",
      "Step: 4100  \tValid loss: 0.22912676632404327\n",
      "Step: 4200  \tTraining loss: 0.2186148315668106\n",
      "Step: 4200  \tTraining accuracy: 0.8949137926101685\n",
      "Step: 4200  \tValid loss: 0.2292560338973999\n",
      "Step: 4300  \tTraining loss: 0.21837319433689117\n",
      "Step: 4300  \tTraining accuracy: 0.8951770663261414\n",
      "Step: 4300  \tValid loss: 0.229420006275177\n",
      "Step: 4400  \tTraining loss: 0.21814870834350586\n",
      "Step: 4400  \tTraining accuracy: 0.8954168558120728\n",
      "Step: 4400  \tValid loss: 0.2295977622270584\n",
      "Step: 4500  \tTraining loss: 0.21793735027313232\n",
      "Step: 4500  \tTraining accuracy: 0.8956597447395325\n",
      "Step: 4500  \tValid loss: 0.22971633076667786\n",
      "Step: 4600  \tTraining loss: 0.21771347522735596\n",
      "Step: 4600  \tTraining accuracy: 0.8958865404129028\n",
      "Step: 4600  \tValid loss: 0.22953596711158752\n",
      "Step: 4700  \tTraining loss: 0.21749268472194672\n",
      "Step: 4700  \tTraining accuracy: 0.8961062431335449\n",
      "Step: 4700  \tValid loss: 0.22962993383407593\n",
      "Step: 4800  \tTraining loss: 0.21730948984622955\n",
      "Step: 4800  \tTraining accuracy: 0.8963245153427124\n",
      "Step: 4800  \tValid loss: 0.22977641224861145\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.89653385\n",
      "Precision: 0.867902\n",
      "Recall: 0.91840607\n",
      "F1 score: 0.92188144\n",
      "AUC: 0.914101\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.896534   0.867902  0.918406  0.921881  0.914101  0.217279      0.896361   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.228853       0.896284   0.260525      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4817.0  \n",
      "36\n",
      "(1421, 5)\n",
      "(1421, 1)\n",
      "(784, 5)\n",
      "(784, 1)\n",
      "(637, 5)\n",
      "(637, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4573133885860443\n",
      "Step: 100  \tTraining accuracy: 0.8332160711288452\n",
      "Step: 100  \tValid loss: 0.4707096517086029\n",
      "Step: 200  \tTraining loss: 0.43507376313209534\n",
      "Step: 200  \tTraining accuracy: 0.8411916494369507\n",
      "Step: 200  \tValid loss: 0.4511728584766388\n",
      "Step: 300  \tTraining loss: 0.4155980050563812\n",
      "Step: 300  \tTraining accuracy: 0.8426460027694702\n",
      "Step: 300  \tValid loss: 0.43217819929122925\n"
     ]
    }
   ],
   "source": [
    "neurons = 8\n",
    "hist_flag=2\n",
    "\n",
    "\n",
    "\n",
    "for num, subj_file_path in enumerate(subj_files_list):\n",
    "    print(num)\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "    \n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "                \n",
    "#     file_path = file_path + \"/OddEvenPlays\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "    train_data_df= pd.read_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df = pd.read_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df = pd.read_csv(file_path+\"/val_data.csv\")\n",
    "\n",
    "    train_X, train_y, test_X, test_y,val_X,val_y = data_split_odd_even(train_data_df,test_data_df,val_data_df)\n",
    "\n",
    "    pretraining = False; \n",
    "    metric_out_df, prob_train, prob_test, prob_val = train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y)\n",
    "    \n",
    "    print(metric_out_df)\n",
    "    \n",
    "   \n",
    " \n",
    "    prob_train_df = pd.DataFrame(prob_train.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "    prob_test_df = pd.DataFrame(prob_test.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "    prob_val_df = pd.DataFrame(prob_val.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "\n",
    "    if hist_flag==0:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currO_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "    \n",
    "    \n",
    "    elif hist_flag==1:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevC_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "\n",
    "    elif hist_flag==2:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevRC_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "# ################################\n",
    "    elif hist_flag==3:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currprev_opts_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "# #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
