{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "onehot_encoder=OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "time_steps = 1\n",
    "inputs = 8\n",
    "outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "    task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "    task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "    task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "    task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "    task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "    task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "    task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "    task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "#     task_df['PrevRT']=task_df['RT'].shift(1)\n",
    "#     task_df.loc[1,'PrevRT']= 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    return task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_split_data(data,start_chunk,end_chunk):\n",
    "    \n",
    "    a=[k for k in range(start_chunk,end_chunk)]\n",
    "    out=[]\n",
    "\n",
    "    for d in range(0,data.shape[0],20):\n",
    "\n",
    "        c= [c+d for c in a]\n",
    "        out = out+c\n",
    "\n",
    "    while out[-1]>=data.shape[0]-1:\n",
    "        out.pop()\n",
    "#     return out\n",
    "    return data[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y): \n",
    "    reset_graph()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 50000\n",
    "    batch_size = int(train_X.shape[0]/2)\n",
    "    # batch_size = 100\n",
    "    length = train_X.shape[0]\n",
    "    display = 100\n",
    "    neurons = neurons\n",
    "\n",
    "    num_batches = 100\n",
    "    seq_len = 10\n",
    "\n",
    "    percent_above_PT = 1\n",
    "\n",
    "    train_threshold = 1.5#PT_R2 + percent_above_PT\n",
    "\n",
    "\n",
    "    save_step = 100\n",
    "\n",
    "\n",
    "    best_loss_val = np.infty\n",
    "    checks_since_last_progress = 0\n",
    "    max_checks_without_progress = 1000\n",
    "\n",
    "\n",
    "    # clear graph (if any) before running\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, time_steps, inputs])\n",
    "\n",
    "    y = tf.placeholder(tf.float32, [None, outputs])\n",
    "\n",
    "    # LSTM Cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=neurons, activation=tf.nn.relu)\n",
    "    cell_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "    # pass into Dense layer\n",
    "    stacked_outputs = tf.reshape(cell_outputs, [-1, neurons])\n",
    "    out = tf.layers.dense(inputs=stacked_outputs, units=outputs)\n",
    "\n",
    "    probability = tf.nn.softmax(out)\n",
    "\n",
    "    # squared error loss or cost function for linear regression\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=y, logits=out))\n",
    "\n",
    "    # optimizer to minimize cost\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels =  tf.argmax(y, 1),\n",
    "                          predictions = tf.argmax(out, 1),\n",
    "                          name = \"accuracy\")\n",
    "    precision = tf.metrics.precision(labels=tf.argmax(y, 1),\n",
    "                                 predictions=tf.argmax(out, 1),\n",
    "                                 name=\"precision\")\n",
    "    recall = tf.metrics.recall(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"recall\")\n",
    "    f1 = 2 * accuracy[1] * recall[1] / ( precision[1] + recall[1] )\n",
    "\n",
    "    acc_up,acc_val = accuracy\n",
    "    auc = tf.metrics.auc(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"auc\")\n",
    "    \n",
    "    valid_store = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #######################\n",
    "#         saver.restore(sess, \"./checkpts/Original_RNN_LSTM_8features_v2.ckpt\")\n",
    "#         saver.restore(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "        \n",
    "        if pretraining == True:\n",
    "\n",
    "            saver.restore(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        #######################\n",
    "        \n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "\n",
    "        # Train the model\n",
    "        for steps in range(epochs):\n",
    "            mini_batch = zip(range(0, length, batch_size),\n",
    "                       range(batch_size, length+1, batch_size))\n",
    "\n",
    "            # train data in mini-batches\n",
    "            for (start, end) in mini_batch:\n",
    "    #             print(start,end)\n",
    "                sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "                                                   y: train_y[start:end,:]}) \n",
    "\n",
    "            ## train data in batches of length subsequence\n",
    "\n",
    "    #         for k in range(num_batches):\n",
    "    #             X_seq, y_seq = random_subsequence(train_X,train_y,seq_len)\n",
    "\n",
    "    #             sess.run(training_op, feed_dict = {X:X_seq,y:y_seq}) \n",
    "            loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "            loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "            # print training performance \n",
    "            if (steps+1) % display == 0:\n",
    "                # evaluate loss function on training set\n",
    "\n",
    "\n",
    "                loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining loss: {}'.format((steps+1), loss_fn))\n",
    "\n",
    "                acc_train = acc_val.eval(feed_dict={X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining accuracy: {}'.format((steps+1), acc_train))\n",
    "\n",
    "\n",
    "                acc_test = acc_val.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest accuracy: {}'.format((steps+1), acc_test))\n",
    "\n",
    "                loss_test = loss.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest loss: {}'.format((steps+1), loss_test))\n",
    "\n",
    "                accu_val = acc_val.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "                loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "                print('Step: {}  \\tValid loss: {}'.format((steps+1), loss_val))\n",
    "\n",
    "                valid_store.append(loss_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (1 + loss_fn/np.log(0.5)) > train_threshold:\n",
    "                    print(\"Threshold achieved, quit training\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            if loss_val < best_loss_val:\n",
    "\n",
    "                        best_loss_val = loss_val\n",
    "                        checks_since_last_progress = 0\n",
    "            else:\n",
    "                            checks_since_last_progress += 1\n",
    "\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if checks_since_last_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "\n",
    "            if (steps+1) % save_step ==0:\n",
    "                                save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#                 save_path = saver.save(sess, \"./checkpts/RNN_Internet_LSTM_model_5features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     evaluate model accuracy\n",
    "        acc, prec, recall, f1, AUC = sess.run([accuracy, precision, recall, f1,auc],\n",
    "                                         feed_dict = {X: train_X, y: train_y})\n",
    "        prob_train = probability.eval(feed_dict = {X: train_X, y: train_y})\n",
    "        prob_test = probability.eval(feed_dict = {X: test_X, y: test_y})\n",
    "        prob_valid = probability.eval(feed_dict = {X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nEvaluation  on training set')\n",
    "        print('Accuracy:', acc[1])\n",
    "        print('Precision:', prec[1])\n",
    "        print('Recall:', recall[1])\n",
    "        print('F1 score:', f1)\n",
    "        print('AUC:', AUC[1])\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        \n",
    "#         save_path = saver.save(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/LaterDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## APP DATA\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "        save_path = saver.save(sess, \"./checkpts/Later_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "    metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,AUC[1],loss_fn,accu_val,best_loss_val,acc_test,loss_test,neurons,learning_rate,epochs,steps]).reshape(-1,14),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\",\"loss\",\"accuracy_val\",\"loss_val\",\"accuracy_test\",\"loss_test\",\"neurons\",\"learning_rate\",\"n_epochs\",\"steps\"])\n",
    "    return metric_out_df, prob_train, prob_test, prob_valid\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def random_subsequence(X,y,seq_len):\n",
    "    rnd  = random.randint(0,len(X)-seq_len)\n",
    "    X_seq, y_seq = X[rnd:rnd+seq_len,:], y[rnd:rnd+seq_len,:]\n",
    "    return X_seq, y_seq\n",
    "\n",
    "    print(y_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odd plays train, even plays test and valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\")\n",
    "dir_path =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"\n",
    "\n",
    "subj_files_list =[]; ## list of subject_files fullfilling a criteria\n",
    "\n",
    "dir_files = [i for i in os.listdir(dir_path) if i.startswith('sub')]\n",
    "\n",
    "for subj_file_path in dir_files:\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "    \n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]   \n",
    "    \n",
    "    if len(play_names) >= 50: ## criteria\n",
    "        subj_files_list.append(subj_file_path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subj_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "num_shuffles=1\n",
    "for num, subj_file_path in enumerate(subj_files_list):\n",
    "    print(num)\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "    \n",
    "#     train_data,test_data, val_data = np.empty((0,task_df.columns.shape[0])),  np.empty((0,task_df.columns.shape[0])), np.empty((0,task_df.columns.shape[0]))\n",
    "    train_data,test_data, val_data = np.empty((0,15)),  np.empty((0,15)), np.empty((0,15))\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "        \n",
    "    comp_task_train_df = pd.DataFrame()\n",
    "\n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]    \n",
    "\n",
    "    for randomization_counter in range(0,num_shuffles):\n",
    "            randomized_play_names= random.sample(play_names,len(play_names))\n",
    "            \n",
    "            for play_num, play_name in enumerate(randomized_play_names):\n",
    "#         for play_num,play_name in enumerate(play_names):\n",
    "\n",
    "                file_name = file_path + \"/\" + play_name\n",
    "                task_df = pd.read_csv(file_name)\n",
    "                task_df = add_releveant_features(task_df)\n",
    "\n",
    "                if np.mod(play_num,2)==0: ## odd trials\n",
    "                    train_data = np.append(train_data,task_df[task_df.TrialNum>1].values, axis=0)\n",
    "\n",
    "                else:\n",
    "                    test_data =  np.append(test_data, task_df[task_df.TrialNum>1].values[0:16], axis=0)\n",
    "                    val_data =  np.append(val_data, task_df[task_df.TrialNum>1].values[16:], axis=0)\n",
    "\n",
    "\n",
    "    train_data_df= pd.DataFrame(train_data,columns=task_df.columns)\n",
    "    val_data_df = pd.DataFrame(test_data,columns=task_df.columns)\n",
    "    test_data_df= pd.DataFrame(val_data,columns=task_df.columns)\n",
    "\n",
    "#     file_path = file_path + \"/OddEvenPlays/\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "#     os.mkdir(file_path)\n",
    "    train_data_df.to_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df.to_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df.to_csv(file_path+\"/val_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_odd_even(train_data_df,test_data_df,val_data_df):\n",
    "\n",
    "#     train_len = 29\n",
    "#     test_len = 14\n",
    "#     val_len = 15\n",
    "\n",
    "    ##----------------- UNCOMMENT BELOW\n",
    "    \n",
    "    \n",
    "#     train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "#     train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "    \n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "    \n",
    "    \n",
    "#     train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice']].values\n",
    "\n",
    "#     train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice']].values\n",
    "\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "#     train_X = task_df.loc[task_df.TrialNum>1, ['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice']].values\n",
    "#     train_y = task_df.loc[task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice']].values\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "####### Prev O + C+ R + CurrO--------------------\n",
    " \n",
    "    train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "    train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "    \n",
    "    test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "    test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "    \n",
    "    val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "    val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "    \n",
    "    \n",
    "    ######## sampling \n",
    "    \n",
    "    \n",
    "#### - Prev RT+C+R+O + Curr O----------------------\n",
    "\n",
    "#     train_X = task_df.loc[task_df.TrialNum>1, ['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     train_y = task_df.loc[task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### PRE TRAINING\n",
    "#     stop = int(0.7*len(train_X))\n",
    "#     print(stop)\n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y= train_X[:stop], train_X[stop:stop+int((len(train_X)-stop)/2)], train_X[stop+int((len(train_X)-stop)/2):],train_y[:stop], train_y[stop:stop+int((len(train_X)-stop)/2)], train_y[stop+int((len(train_X)-stop)/2):]\n",
    "    \n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y = train_X, test_X, test_X, train_y, test_y, test_y\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "    print(val_X.shape)\n",
    "    print(val_y.shape)\n",
    "    print(test_X.shape)\n",
    "    print(test_y.shape)\n",
    "\n",
    "    # # center and scale\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.fit_transform(test_X)\n",
    "    val_X = scaler.fit_transform(val_X)\n",
    "\n",
    "\n",
    "    train_X = train_X[:,None,:]\n",
    "    val_X = val_X[:,None,:]\n",
    "    test_X = test_X[:,None,:]\n",
    "\n",
    "\n",
    "    # # one-hot encode the outputs\n",
    "\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "    encode_categorical_test = test_y.reshape(len(test_y), 1)\n",
    "    encode_categorical_val = val_y.reshape(len(val_y),1)\n",
    "\n",
    "\n",
    "    train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "    test_y = onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "    val_y = onehot_encoder.fit_transform(encode_categorical_val).toarray()\n",
    "\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y, val_X,val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1189, 8)\n",
      "(1189, 1)\n",
      "(640, 8)\n",
      "(640, 1)\n",
      "(520, 8)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-43-45e26c98b632>:36: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-43-45e26c98b632>:37: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-43-45e26c98b632>:41: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Step: 100  \tTraining loss: 0.3112853765487671\n",
      "Step: 100  \tTraining accuracy: 0.8696383237838745\n",
      "Step: 100  \tValid loss: 0.350909560918808\n",
      "Step: 200  \tTraining loss: 0.2606988251209259\n",
      "Step: 200  \tTraining accuracy: 0.8764839172363281\n",
      "Step: 200  \tValid loss: 0.34524044394493103\n",
      "Step: 300  \tTraining loss: 0.2561582028865814\n",
      "Step: 300  \tTraining accuracy: 0.878206193447113\n",
      "Step: 300  \tValid loss: 0.3517181873321533\n",
      "Step: 400  \tTraining loss: 0.25397032499313354\n",
      "Step: 400  \tTraining accuracy: 0.8790674805641174\n",
      "Step: 400  \tValid loss: 0.3514196276664734\n",
      "Step: 500  \tTraining loss: 0.252391517162323\n",
      "Step: 500  \tTraining accuracy: 0.8794520497322083\n",
      "Step: 500  \tValid loss: 0.35040634870529175\n",
      "Step: 600  \tTraining loss: 0.2511492669582367\n",
      "Step: 600  \tTraining accuracy: 0.8795422911643982\n",
      "Step: 600  \tValid loss: 0.34955519437789917\n",
      "Step: 700  \tTraining loss: 0.25008758902549744\n",
      "Step: 700  \tTraining accuracy: 0.8798665404319763\n",
      "Step: 700  \tValid loss: 0.3487115502357483\n",
      "Step: 800  \tTraining loss: 0.24916326999664307\n",
      "Step: 800  \tTraining accuracy: 0.8803879022598267\n",
      "Step: 800  \tValid loss: 0.3479944169521332\n",
      "Step: 900  \tTraining loss: 0.24840782582759857\n",
      "Step: 900  \tTraining accuracy: 0.8809869289398193\n",
      "Step: 900  \tValid loss: 0.34759408235549927\n",
      "Step: 1000  \tTraining loss: 0.24773430824279785\n",
      "Step: 1000  \tTraining accuracy: 0.8814151287078857\n",
      "Step: 1000  \tValid loss: 0.3472960591316223\n",
      "Step: 1100  \tTraining loss: 0.24714107811450958\n",
      "Step: 1100  \tTraining accuracy: 0.8818023204803467\n",
      "Step: 1100  \tValid loss: 0.3471936583518982\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.88215923\n",
      "Precision: 0.9328358\n",
      "Recall: 0.96711797\n",
      "F1 score: 0.8980766\n",
      "AUC: 0.7513009\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.882159   0.932836  0.967118  0.898077  0.751301  0.24693      0.880839   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.339066       0.881543    0.31267      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1144.0  \n",
      "1\n",
      "(4263, 8)\n",
      "(4263, 1)\n",
      "(2352, 8)\n",
      "(2352, 1)\n",
      "(1911, 8)\n",
      "(1911, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4985516369342804\n",
      "Step: 100  \tTraining accuracy: 0.761904776096344\n",
      "Step: 100  \tValid loss: 0.5204095244407654\n",
      "Step: 200  \tTraining loss: 0.4555061161518097\n",
      "Step: 200  \tTraining accuracy: 0.7637031674385071\n",
      "Step: 200  \tValid loss: 0.47607892751693726\n",
      "Step: 300  \tTraining loss: 0.42071959376335144\n",
      "Step: 300  \tTraining accuracy: 0.7729767560958862\n",
      "Step: 300  \tValid loss: 0.4379679262638092\n",
      "Step: 400  \tTraining loss: 0.4008471667766571\n",
      "Step: 400  \tTraining accuracy: 0.7805703282356262\n",
      "Step: 400  \tValid loss: 0.41551026701927185\n",
      "Step: 500  \tTraining loss: 0.3918387293815613\n",
      "Step: 500  \tTraining accuracy: 0.7861443161964417\n",
      "Step: 500  \tValid loss: 0.4057188928127289\n",
      "Step: 600  \tTraining loss: 0.3868788182735443\n",
      "Step: 600  \tTraining accuracy: 0.7908430099487305\n",
      "Step: 600  \tValid loss: 0.40147411823272705\n",
      "Step: 700  \tTraining loss: 0.382510244846344\n",
      "Step: 700  \tTraining accuracy: 0.7946913242340088\n",
      "Step: 700  \tValid loss: 0.3992125689983368\n",
      "Step: 800  \tTraining loss: 0.37832462787628174\n",
      "Step: 800  \tTraining accuracy: 0.7977637052536011\n",
      "Step: 800  \tValid loss: 0.3985165059566498\n",
      "Step: 900  \tTraining loss: 0.375905305147171\n",
      "Step: 900  \tTraining accuracy: 0.8004305362701416\n",
      "Step: 900  \tValid loss: 0.3984866738319397\n",
      "Step: 1000  \tTraining loss: 0.37442827224731445\n",
      "Step: 1000  \tTraining accuracy: 0.8025112152099609\n",
      "Step: 1000  \tValid loss: 0.39824178814888\n",
      "Step: 1100  \tTraining loss: 0.3732892870903015\n",
      "Step: 1100  \tTraining accuracy: 0.8041397333145142\n",
      "Step: 1100  \tValid loss: 0.3978480100631714\n",
      "Step: 1200  \tTraining loss: 0.37207087874412537\n",
      "Step: 1200  \tTraining accuracy: 0.8053932189941406\n",
      "Step: 1200  \tValid loss: 0.3967280089855194\n",
      "Step: 1300  \tTraining loss: 0.37076300382614136\n",
      "Step: 1300  \tTraining accuracy: 0.8064836859703064\n",
      "Step: 1300  \tValid loss: 0.3957793712615967\n",
      "Step: 1400  \tTraining loss: 0.3695078492164612\n",
      "Step: 1400  \tTraining accuracy: 0.8074386715888977\n",
      "Step: 1400  \tValid loss: 0.3950406014919281\n",
      "Step: 1500  \tTraining loss: 0.36821359395980835\n",
      "Step: 1500  \tTraining accuracy: 0.808286190032959\n",
      "Step: 1500  \tValid loss: 0.3940292298793793\n",
      "Step: 1600  \tTraining loss: 0.36694714426994324\n",
      "Step: 1600  \tTraining accuracy: 0.8090319633483887\n",
      "Step: 1600  \tValid loss: 0.39318278431892395\n",
      "Step: 1700  \tTraining loss: 0.3655908703804016\n",
      "Step: 1700  \tTraining accuracy: 0.8097512722015381\n",
      "Step: 1700  \tValid loss: 0.3923790454864502\n",
      "Step: 1800  \tTraining loss: 0.36431440711021423\n",
      "Step: 1800  \tTraining accuracy: 0.8104554414749146\n",
      "Step: 1800  \tValid loss: 0.39176610112190247\n",
      "Step: 1900  \tTraining loss: 0.36314842104911804\n",
      "Step: 1900  \tTraining accuracy: 0.8110897541046143\n",
      "Step: 1900  \tValid loss: 0.3911649286746979\n",
      "Step: 2000  \tTraining loss: 0.36208558082580566\n",
      "Step: 2000  \tTraining accuracy: 0.8116109371185303\n",
      "Step: 2000  \tValid loss: 0.39063510298728943\n",
      "Step: 2100  \tTraining loss: 0.36114370822906494\n",
      "Step: 2100  \tTraining accuracy: 0.8121899962425232\n",
      "Step: 2100  \tValid loss: 0.3902258276939392\n",
      "Step: 2200  \tTraining loss: 0.36033204197883606\n",
      "Step: 2200  \tTraining accuracy: 0.8127315044403076\n",
      "Step: 2200  \tValid loss: 0.3898855447769165\n",
      "Step: 2300  \tTraining loss: 0.3596423864364624\n",
      "Step: 2300  \tTraining accuracy: 0.8132613897323608\n",
      "Step: 2300  \tValid loss: 0.38968750834465027\n",
      "Step: 2400  \tTraining loss: 0.35903486609458923\n",
      "Step: 2400  \tTraining accuracy: 0.8137611746788025\n",
      "Step: 2400  \tValid loss: 0.3896414339542389\n",
      "Step: 2500  \tTraining loss: 0.3584385812282562\n",
      "Step: 2500  \tTraining accuracy: 0.8142488598823547\n",
      "Step: 2500  \tValid loss: 0.38955923914909363\n",
      "Step: 2600  \tTraining loss: 0.35788753628730774\n",
      "Step: 2600  \tTraining accuracy: 0.8147028684616089\n",
      "Step: 2600  \tValid loss: 0.3896048367023468\n",
      "Step: 2700  \tTraining loss: 0.3573717176914215\n",
      "Step: 2700  \tTraining accuracy: 0.8151403665542603\n",
      "Step: 2700  \tValid loss: 0.3895969092845917\n",
      "Step: 2800  \tTraining loss: 0.3569211959838867\n",
      "Step: 2800  \tTraining accuracy: 0.8155417442321777\n",
      "Step: 2800  \tValid loss: 0.3895885646343231\n",
      "Step: 2900  \tTraining loss: 0.3565188944339752\n",
      "Step: 2900  \tTraining accuracy: 0.8159273266792297\n",
      "Step: 2900  \tValid loss: 0.3897567689418793\n",
      "Step: 3000  \tTraining loss: 0.35614657402038574\n",
      "Step: 3000  \tTraining accuracy: 0.8162907361984253\n",
      "Step: 3000  \tValid loss: 0.3899593651294708\n",
      "Step: 3100  \tTraining loss: 0.3557142913341522\n",
      "Step: 3100  \tTraining accuracy: 0.8166341781616211\n",
      "Step: 3100  \tValid loss: 0.38980233669281006\n",
      "Step: 3200  \tTraining loss: 0.355343222618103\n",
      "Step: 3200  \tTraining accuracy: 0.816992998123169\n",
      "Step: 3200  \tValid loss: 0.3900403380393982\n",
      "Step: 3300  \tTraining loss: 0.3549908995628357\n",
      "Step: 3300  \tTraining accuracy: 0.8173334002494812\n",
      "Step: 3300  \tValid loss: 0.39024829864501953\n",
      "Step: 3400  \tTraining loss: 0.354642391204834\n",
      "Step: 3400  \tTraining accuracy: 0.817653477191925\n",
      "Step: 3400  \tValid loss: 0.3905395269393921\n",
      "Step: 3500  \tTraining loss: 0.3543040156364441\n",
      "Step: 3500  \tTraining accuracy: 0.81797194480896\n",
      "Step: 3500  \tValid loss: 0.39083072543144226\n",
      "Step: 3600  \tTraining loss: 0.3539055287837982\n",
      "Step: 3600  \tTraining accuracy: 0.8182592988014221\n",
      "Step: 3600  \tValid loss: 0.3912716209888458\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8185245\n",
      "Precision: 0.86849797\n",
      "Recall: 0.9181341\n",
      "F1 score: 0.84126467\n",
      "AUC: 0.7397688\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.818524   0.868498  0.918134  0.841265  0.739769  0.353659      0.818333   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.389501       0.818303   0.366784      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3656.0  \n",
      "2\n",
      "(754, 8)\n",
      "(754, 1)\n",
      "(416, 8)\n",
      "(416, 1)\n",
      "(338, 8)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6157017946243286\n",
      "Step: 100  \tTraining accuracy: 0.6379310488700867\n",
      "Step: 100  \tValid loss: 0.5818777084350586\n",
      "Step: 200  \tTraining loss: 0.5890673995018005\n",
      "Step: 200  \tTraining accuracy: 0.6582670211791992\n",
      "Step: 200  \tValid loss: 0.576763391494751\n",
      "Step: 300  \tTraining loss: 0.5783849358558655\n",
      "Step: 300  \tTraining accuracy: 0.663129985332489\n",
      "Step: 300  \tValid loss: 0.5704333186149597\n",
      "Step: 400  \tTraining loss: 0.5702078938484192\n",
      "Step: 400  \tTraining accuracy: 0.6657825112342834\n",
      "Step: 400  \tValid loss: 0.5636656284332275\n",
      "Step: 500  \tTraining loss: 0.5633863210678101\n",
      "Step: 500  \tTraining accuracy: 0.6682876348495483\n",
      "Step: 500  \tValid loss: 0.5575618147850037\n",
      "Step: 600  \tTraining loss: 0.557611346244812\n",
      "Step: 600  \tTraining accuracy: 0.6712080836296082\n",
      "Step: 600  \tValid loss: 0.5539315938949585\n",
      "Step: 700  \tTraining loss: 0.5527585744857788\n",
      "Step: 700  \tTraining accuracy: 0.6739441156387329\n",
      "Step: 700  \tValid loss: 0.5528020262718201\n",
      "Step: 800  \tTraining loss: 0.549262285232544\n",
      "Step: 800  \tTraining accuracy: 0.6773651838302612\n",
      "Step: 800  \tValid loss: 0.5533620119094849\n",
      "Step: 900  \tTraining loss: 0.5468268990516663\n",
      "Step: 900  \tTraining accuracy: 0.680449366569519\n",
      "Step: 900  \tValid loss: 0.5522897243499756\n",
      "Step: 1000  \tTraining loss: 0.5449767708778381\n",
      "Step: 1000  \tTraining accuracy: 0.6830238699913025\n",
      "Step: 1000  \tValid loss: 0.5523629784584045\n",
      "Step: 1100  \tTraining loss: 0.5438492298126221\n",
      "Step: 1100  \tTraining accuracy: 0.6853606104850769\n",
      "Step: 1100  \tValid loss: 0.5531545281410217\n",
      "Step: 1200  \tTraining loss: 0.5430447459220886\n",
      "Step: 1200  \tTraining accuracy: 0.6873486042022705\n",
      "Step: 1200  \tValid loss: 0.5536553859710693\n",
      "Step: 1300  \tTraining loss: 0.5423888564109802\n",
      "Step: 1300  \tTraining accuracy: 0.6892838478088379\n",
      "Step: 1300  \tValid loss: 0.5538985133171082\n",
      "Step: 1400  \tTraining loss: 0.5417903065681458\n",
      "Step: 1400  \tTraining accuracy: 0.690883219242096\n",
      "Step: 1400  \tValid loss: 0.554047703742981\n",
      "Step: 1500  \tTraining loss: 0.5412238836288452\n",
      "Step: 1500  \tTraining accuracy: 0.6923991441726685\n",
      "Step: 1500  \tValid loss: 0.5542328357696533\n",
      "Step: 1600  \tTraining loss: 0.5406319499015808\n",
      "Step: 1600  \tTraining accuracy: 0.6936767101287842\n",
      "Step: 1600  \tValid loss: 0.5542957782745361\n",
      "Step: 1700  \tTraining loss: 0.5399719476699829\n",
      "Step: 1700  \tTraining accuracy: 0.6947994828224182\n",
      "Step: 1700  \tValid loss: 0.5542046427726746\n",
      "Step: 1800  \tTraining loss: 0.5392215251922607\n",
      "Step: 1800  \tTraining accuracy: 0.6957559585571289\n",
      "Step: 1800  \tValid loss: 0.5539982318878174\n",
      "Step: 1900  \tTraining loss: 0.5384606122970581\n",
      "Step: 1900  \tTraining accuracy: 0.6966449022293091\n",
      "Step: 1900  \tValid loss: 0.5536482334136963\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.6974767\n",
      "Precision: 0.73848987\n",
      "Recall: 0.8477801\n",
      "F1 score: 0.7455312\n",
      "AUC: 0.671221\n",
      "   accuracy  precision   recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.697477    0.73849  0.84778  0.745531  0.671221  0.537922      0.696985   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.552013       0.696416   0.603512      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1976.0  \n",
      "3\n",
      "(783, 8)\n",
      "(783, 1)\n",
      "(416, 8)\n",
      "(416, 1)\n",
      "(338, 8)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5353713035583496\n",
      "Step: 100  \tTraining accuracy: 0.7522349953651428\n",
      "Step: 100  \tValid loss: 0.5857193470001221\n",
      "Step: 200  \tTraining loss: 0.5070822834968567\n",
      "Step: 200  \tTraining accuracy: 0.743534505367279\n",
      "Step: 200  \tValid loss: 0.5741756558418274\n",
      "Step: 300  \tTraining loss: 0.492725670337677\n",
      "Step: 300  \tTraining accuracy: 0.743842363357544\n",
      "Step: 300  \tValid loss: 0.5630937218666077\n",
      "Step: 400  \tTraining loss: 0.47970694303512573\n",
      "Step: 400  \tTraining accuracy: 0.7458286881446838\n",
      "Step: 400  \tValid loss: 0.5512406229972839\n",
      "Step: 500  \tTraining loss: 0.46674686670303345\n",
      "Step: 500  \tTraining accuracy: 0.7480883002281189\n",
      "Step: 500  \tValid loss: 0.5387905836105347\n",
      "Step: 600  \tTraining loss: 0.4510177969932556\n",
      "Step: 600  \tTraining accuracy: 0.75\n",
      "Step: 600  \tValid loss: 0.5231887102127075\n",
      "Step: 700  \tTraining loss: 0.433005690574646\n",
      "Step: 700  \tTraining accuracy: 0.7525237202644348\n",
      "Step: 700  \tValid loss: 0.5072370767593384\n",
      "Step: 800  \tTraining loss: 0.4175400733947754\n",
      "Step: 800  \tTraining accuracy: 0.7557615637779236\n",
      "Step: 800  \tValid loss: 0.4944334030151367\n",
      "Step: 900  \tTraining loss: 0.4048592150211334\n",
      "Step: 900  \tTraining accuracy: 0.7588500380516052\n",
      "Step: 900  \tValid loss: 0.48368680477142334\n",
      "Step: 1000  \tTraining loss: 0.3944808840751648\n",
      "Step: 1000  \tTraining accuracy: 0.7618363499641418\n",
      "Step: 1000  \tValid loss: 0.4747603237628937\n",
      "Step: 1100  \tTraining loss: 0.38605621457099915\n",
      "Step: 1100  \tTraining accuracy: 0.7646257877349854\n",
      "Step: 1100  \tValid loss: 0.4675474166870117\n",
      "Step: 1200  \tTraining loss: 0.37926191091537476\n",
      "Step: 1200  \tTraining accuracy: 0.7675523161888123\n",
      "Step: 1200  \tValid loss: 0.4618762731552124\n",
      "Step: 1300  \tTraining loss: 0.37380433082580566\n",
      "Step: 1300  \tTraining accuracy: 0.7705309987068176\n",
      "Step: 1300  \tValid loss: 0.45755311846733093\n",
      "Step: 1400  \tTraining loss: 0.3694186806678772\n",
      "Step: 1400  \tTraining accuracy: 0.7732614278793335\n",
      "Step: 1400  \tValid loss: 0.45434755086898804\n",
      "Step: 1500  \tTraining loss: 0.36581745743751526\n",
      "Step: 1500  \tTraining accuracy: 0.77592933177948\n",
      "Step: 1500  \tValid loss: 0.45186248421669006\n",
      "Step: 1600  \tTraining loss: 0.3626860976219177\n",
      "Step: 1600  \tTraining accuracy: 0.7782531976699829\n",
      "Step: 1600  \tValid loss: 0.44985252618789673\n",
      "Step: 1700  \tTraining loss: 0.3598940670490265\n",
      "Step: 1700  \tTraining accuracy: 0.780413806438446\n",
      "Step: 1700  \tValid loss: 0.44846153259277344\n",
      "Step: 1800  \tTraining loss: 0.35754749178886414\n",
      "Step: 1800  \tTraining accuracy: 0.7823647260665894\n",
      "Step: 1800  \tValid loss: 0.44758832454681396\n",
      "Step: 1900  \tTraining loss: 0.3556494116783142\n",
      "Step: 1900  \tTraining accuracy: 0.7842103242874146\n",
      "Step: 1900  \tValid loss: 0.44732266664505005\n",
      "Step: 2000  \tTraining loss: 0.3535897433757782\n",
      "Step: 2000  \tTraining accuracy: 0.7859001159667969\n",
      "Step: 2000  \tValid loss: 0.4479023814201355\n",
      "Step: 2100  \tTraining loss: 0.35174646973609924\n",
      "Step: 2100  \tTraining accuracy: 0.7875202298164368\n",
      "Step: 2100  \tValid loss: 0.4481342136859894\n",
      "Step: 2200  \tTraining loss: 0.3501178026199341\n",
      "Step: 2200  \tTraining accuracy: 0.7890804409980774\n",
      "Step: 2200  \tValid loss: 0.4482154846191406\n",
      "Step: 2300  \tTraining loss: 0.3486884832382202\n",
      "Step: 2300  \tTraining accuracy: 0.7905309796333313\n",
      "Step: 2300  \tValid loss: 0.4483519196510315\n",
      "Step: 2400  \tTraining loss: 0.34747350215911865\n",
      "Step: 2400  \tTraining accuracy: 0.7918304204940796\n",
      "Step: 2400  \tValid loss: 0.4484533667564392\n",
      "Step: 2500  \tTraining loss: 0.3464120328426361\n",
      "Step: 2500  \tTraining accuracy: 0.7930238246917725\n",
      "Step: 2500  \tValid loss: 0.4486338198184967\n",
      "Step: 2600  \tTraining loss: 0.34537652134895325\n",
      "Step: 2600  \tTraining accuracy: 0.794123649597168\n",
      "Step: 2600  \tValid loss: 0.448834091424942\n",
      "Step: 2700  \tTraining loss: 0.3444688320159912\n",
      "Step: 2700  \tTraining accuracy: 0.795091450214386\n",
      "Step: 2700  \tValid loss: 0.4490366578102112\n",
      "Step: 2800  \tTraining loss: 0.3436293601989746\n",
      "Step: 2800  \tTraining accuracy: 0.7960124611854553\n",
      "Step: 2800  \tValid loss: 0.4492029547691345\n",
      "Step: 2900  \tTraining loss: 0.34284788370132446\n",
      "Step: 2900  \tTraining accuracy: 0.7968917489051819\n",
      "Step: 2900  \tValid loss: 0.4493597149848938\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.79771143\n",
      "Precision: 0.8704\n",
      "Recall: 0.9235993\n",
      "F1 score: 0.8213668\n",
      "AUC: 0.75303674\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.797711     0.8704  0.923599  0.821367  0.753037  0.34278      0.796985   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.447294        0.79702   0.382161      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2908.0  \n",
      "4\n",
      "(725, 8)\n",
      "(725, 1)\n",
      "(400, 8)\n",
      "(400, 1)\n",
      "(325, 8)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5138642191886902\n",
      "Step: 100  \tTraining accuracy: 0.8137931227684021\n",
      "Step: 100  \tValid loss: 0.5365526676177979\n",
      "Step: 200  \tTraining loss: 0.42823275923728943\n",
      "Step: 200  \tTraining accuracy: 0.8009195327758789\n",
      "Step: 200  \tValid loss: 0.4730827808380127\n",
      "Step: 300  \tTraining loss: 0.4080355167388916\n",
      "Step: 300  \tTraining accuracy: 0.7953103184700012\n",
      "Step: 300  \tValid loss: 0.46275168657302856\n",
      "Step: 400  \tTraining loss: 0.3936055898666382\n",
      "Step: 400  \tTraining accuracy: 0.7940886616706848\n",
      "Step: 400  \tValid loss: 0.4553406834602356\n",
      "Step: 500  \tTraining loss: 0.3807213604450226\n",
      "Step: 500  \tTraining accuracy: 0.7917241454124451\n",
      "Step: 500  \tValid loss: 0.4486793577671051\n",
      "Step: 600  \tTraining loss: 0.3691349923610687\n",
      "Step: 600  \tTraining accuracy: 0.7909718155860901\n",
      "Step: 600  \tValid loss: 0.4427732825279236\n",
      "Step: 700  \tTraining loss: 0.3588208854198456\n",
      "Step: 700  \tTraining accuracy: 0.7905570268630981\n",
      "Step: 700  \tValid loss: 0.4374978244304657\n",
      "Step: 800  \tTraining loss: 0.34966063499450684\n",
      "Step: 800  \tTraining accuracy: 0.7910804748535156\n",
      "Step: 800  \tValid loss: 0.4326290190219879\n",
      "Step: 900  \tTraining loss: 0.3414720594882965\n",
      "Step: 900  \tTraining accuracy: 0.7917241454124451\n",
      "Step: 900  \tValid loss: 0.4279864430427551\n",
      "Step: 1000  \tTraining loss: 0.3340601921081543\n",
      "Step: 1000  \tTraining accuracy: 0.792522668838501\n",
      "Step: 1000  \tValid loss: 0.4234722852706909\n",
      "Step: 1100  \tTraining loss: 0.32725653052330017\n",
      "Step: 1100  \tTraining accuracy: 0.7934318780899048\n",
      "Step: 1100  \tValid loss: 0.419055700302124\n",
      "Step: 1200  \tTraining loss: 0.3208940029144287\n",
      "Step: 1200  \tTraining accuracy: 0.7945427298545837\n",
      "Step: 1200  \tValid loss: 0.4146849811077118\n",
      "Step: 1300  \tTraining loss: 0.31480762362480164\n",
      "Step: 1300  \tTraining accuracy: 0.7959724068641663\n",
      "Step: 1300  \tValid loss: 0.4102693796157837\n",
      "Step: 1400  \tTraining loss: 0.3088591396808624\n",
      "Step: 1400  \tTraining accuracy: 0.7976500391960144\n",
      "Step: 1400  \tValid loss: 0.40571489930152893\n",
      "Step: 1500  \tTraining loss: 0.3029460310935974\n",
      "Step: 1500  \tTraining accuracy: 0.7992865443229675\n",
      "Step: 1500  \tValid loss: 0.40093886852264404\n",
      "Step: 1600  \tTraining loss: 0.2969974875450134\n",
      "Step: 1600  \tTraining accuracy: 0.801201343536377\n",
      "Step: 1600  \tValid loss: 0.39587295055389404\n",
      "Step: 1700  \tTraining loss: 0.29097044467926025\n",
      "Step: 1700  \tTraining accuracy: 0.8034273982048035\n",
      "Step: 1700  \tValid loss: 0.3904605209827423\n",
      "Step: 1800  \tTraining loss: 0.2848116159439087\n",
      "Step: 1800  \tTraining accuracy: 0.8055960536003113\n",
      "Step: 1800  \tValid loss: 0.38465067744255066\n",
      "Step: 1900  \tTraining loss: 0.2784651517868042\n",
      "Step: 1900  \tTraining accuracy: 0.8076048493385315\n",
      "Step: 1900  \tValid loss: 0.37837183475494385\n",
      "Step: 2000  \tTraining loss: 0.2717958986759186\n",
      "Step: 2000  \tTraining accuracy: 0.809690535068512\n",
      "Step: 2000  \tValid loss: 0.37151962518692017\n",
      "Step: 2100  \tTraining loss: 0.2645205855369568\n",
      "Step: 2100  \tTraining accuracy: 0.8117746114730835\n",
      "Step: 2100  \tValid loss: 0.3638220727443695\n",
      "Step: 2200  \tTraining loss: 0.257034033536911\n",
      "Step: 2200  \tTraining accuracy: 0.8138572573661804\n",
      "Step: 2200  \tValid loss: 0.35554391145706177\n",
      "Step: 2300  \tTraining loss: 0.25056639313697815\n",
      "Step: 2300  \tTraining accuracy: 0.8160306811332703\n",
      "Step: 2300  \tValid loss: 0.34843909740448\n",
      "Step: 2400  \tTraining loss: 0.24538667500019073\n",
      "Step: 2400  \tTraining accuracy: 0.8184005618095398\n",
      "Step: 2400  \tValid loss: 0.34312012791633606\n",
      "Step: 2500  \tTraining loss: 0.24131973087787628\n",
      "Step: 2500  \tTraining accuracy: 0.8206052184104919\n",
      "Step: 2500  \tValid loss: 0.33923691511154175\n",
      "Step: 2600  \tTraining loss: 0.23813194036483765\n",
      "Step: 2600  \tTraining accuracy: 0.8228532671928406\n",
      "Step: 2600  \tValid loss: 0.3364873230457306\n",
      "Step: 2700  \tTraining loss: 0.2356100082397461\n",
      "Step: 2700  \tTraining accuracy: 0.8248535990715027\n",
      "Step: 2700  \tValid loss: 0.33453959226608276\n",
      "Step: 2800  \tTraining loss: 0.23358170688152313\n",
      "Step: 2800  \tTraining accuracy: 0.8267837166786194\n",
      "Step: 2800  \tValid loss: 0.3331591486930847\n",
      "Step: 2900  \tTraining loss: 0.23190510272979736\n",
      "Step: 2900  \tTraining accuracy: 0.8285783529281616\n",
      "Step: 2900  \tValid loss: 0.33215227723121643\n",
      "Step: 3000  \tTraining loss: 0.23044751584529877\n",
      "Step: 3000  \tTraining accuracy: 0.8302980661392212\n",
      "Step: 3000  \tValid loss: 0.3312418460845947\n",
      "Step: 3100  \tTraining loss: 0.2287624329328537\n",
      "Step: 3100  \tTraining accuracy: 0.831859827041626\n",
      "Step: 3100  \tValid loss: 0.32924914360046387\n",
      "Step: 3200  \tTraining loss: 0.22736483812332153\n",
      "Step: 3200  \tTraining accuracy: 0.8333442807197571\n",
      "Step: 3200  \tValid loss: 0.3283887505531311\n",
      "Step: 3300  \tTraining loss: 0.2261764407157898\n",
      "Step: 3300  \tTraining accuracy: 0.8348010778427124\n",
      "Step: 3300  \tValid loss: 0.328176349401474\n",
      "Step: 3400  \tTraining loss: 0.22502906620502472\n",
      "Step: 3400  \tTraining accuracy: 0.8361708521842957\n",
      "Step: 3400  \tValid loss: 0.32818371057510376\n",
      "Step: 3500  \tTraining loss: 0.2238880842924118\n",
      "Step: 3500  \tTraining accuracy: 0.8374412655830383\n",
      "Step: 3500  \tValid loss: 0.3281751573085785\n",
      "Step: 3600  \tTraining loss: 0.2227708250284195\n",
      "Step: 3600  \tTraining accuracy: 0.838620662689209\n",
      "Step: 3600  \tValid loss: 0.32821327447891235\n",
      "Step: 3700  \tTraining loss: 0.22168508172035217\n",
      "Step: 3700  \tTraining accuracy: 0.8397354483604431\n",
      "Step: 3700  \tValid loss: 0.32829979062080383\n",
      "Step: 3800  \tTraining loss: 0.22062477469444275\n",
      "Step: 3800  \tTraining accuracy: 0.8407356142997742\n",
      "Step: 3800  \tValid loss: 0.3284028172492981\n",
      "Step: 3900  \tTraining loss: 0.21959473192691803\n",
      "Step: 3900  \tTraining accuracy: 0.8417196869850159\n",
      "Step: 3900  \tValid loss: 0.3285601735115051\n",
      "Step: 4000  \tTraining loss: 0.21859538555145264\n",
      "Step: 4000  \tTraining accuracy: 0.842688798904419\n",
      "Step: 4000  \tValid loss: 0.3287871181964874\n",
      "Step: 4100  \tTraining loss: 0.21751180291175842\n",
      "Step: 4100  \tTraining accuracy: 0.8435589671134949\n",
      "Step: 4100  \tValid loss: 0.3290461599826813\n",
      "Step: 4200  \tTraining loss: 0.21634690463542938\n",
      "Step: 4200  \tTraining accuracy: 0.8443872332572937\n",
      "Step: 4200  \tValid loss: 0.32937976717948914\n",
      "Step: 4300  \tTraining loss: 0.21513019502162933\n",
      "Step: 4300  \tTraining accuracy: 0.8451764583587646\n",
      "Step: 4300  \tValid loss: 0.32976043224334717\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.84596115\n",
      "Precision: 0.88684213\n",
      "Recall: 0.9361111\n",
      "F1 score: 0.86882496\n",
      "AUC: 0.90915143\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.845961   0.886842  0.936111  0.868825  0.909151  0.214401      0.845229   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.328152       0.845133   0.312474      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4361.0  \n",
      "5\n",
      "(841, 8)\n",
      "(841, 1)\n",
      "(464, 8)\n",
      "(464, 1)\n",
      "(377, 8)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6612610220909119\n",
      "Step: 100  \tTraining accuracy: 0.6147443652153015\n",
      "Step: 100  \tValid loss: 0.641713559627533\n",
      "Step: 200  \tTraining loss: 0.6520605087280273\n",
      "Step: 200  \tTraining accuracy: 0.6246532201766968\n",
      "Step: 200  \tValid loss: 0.6404756903648376\n",
      "Step: 300  \tTraining loss: 0.6427159905433655\n",
      "Step: 300  \tTraining accuracy: 0.6313912272453308\n",
      "Step: 300  \tValid loss: 0.6392353773117065\n",
      "Step: 400  \tTraining loss: 0.63421630859375\n",
      "Step: 400  \tTraining accuracy: 0.6361474394798279\n",
      "Step: 400  \tValid loss: 0.6379150748252869\n",
      "Step: 500  \tTraining loss: 0.6265611052513123\n",
      "Step: 500  \tTraining accuracy: 0.6397145986557007\n",
      "Step: 500  \tValid loss: 0.6356105208396912\n",
      "Step: 600  \tTraining loss: 0.6179360151290894\n",
      "Step: 600  \tTraining accuracy: 0.6430656313896179\n",
      "Step: 600  \tValid loss: 0.6310330033302307\n",
      "Step: 700  \tTraining loss: 0.6090697646141052\n",
      "Step: 700  \tTraining accuracy: 0.6468489766120911\n",
      "Step: 700  \tValid loss: 0.6259828209877014\n",
      "Step: 800  \tTraining loss: 0.6011121273040771\n",
      "Step: 800  \tTraining accuracy: 0.649940550327301\n",
      "Step: 800  \tValid loss: 0.6228083968162537\n",
      "Step: 900  \tTraining loss: 0.5942181348800659\n",
      "Step: 900  \tTraining accuracy: 0.6528642177581787\n",
      "Step: 900  \tValid loss: 0.6213283538818359\n",
      "Step: 1000  \tTraining loss: 0.5882837176322937\n",
      "Step: 1000  \tTraining accuracy: 0.6555479168891907\n",
      "Step: 1000  \tValid loss: 0.62046879529953\n",
      "Step: 1100  \tTraining loss: 0.5836399793624878\n",
      "Step: 1100  \tTraining accuracy: 0.657890260219574\n",
      "Step: 1100  \tValid loss: 0.6205302476882935\n",
      "Step: 1200  \tTraining loss: 0.5796120166778564\n",
      "Step: 1200  \tTraining accuracy: 0.6600837707519531\n",
      "Step: 1200  \tValid loss: 0.6206203103065491\n",
      "Step: 1300  \tTraining loss: 0.5762942433357239\n",
      "Step: 1300  \tTraining accuracy: 0.6620689630508423\n",
      "Step: 1300  \tValid loss: 0.6206337213516235\n",
      "Step: 1400  \tTraining loss: 0.573409914970398\n",
      "Step: 1400  \tTraining accuracy: 0.6637600660324097\n",
      "Step: 1400  \tValid loss: 0.6209736466407776\n",
      "Step: 1500  \tTraining loss: 0.5708914399147034\n",
      "Step: 1500  \tTraining accuracy: 0.6652999520301819\n",
      "Step: 1500  \tValid loss: 0.6213392615318298\n",
      "Step: 1600  \tTraining loss: 0.5683444142341614\n",
      "Step: 1600  \tTraining accuracy: 0.6665260195732117\n",
      "Step: 1600  \tValid loss: 0.6211615204811096\n",
      "Step: 1700  \tTraining loss: 0.5661240816116333\n",
      "Step: 1700  \tTraining accuracy: 0.6674593687057495\n",
      "Step: 1700  \tValid loss: 0.6204164028167725\n",
      "Step: 1800  \tTraining loss: 0.5642561316490173\n",
      "Step: 1800  \tTraining accuracy: 0.6682181358337402\n",
      "Step: 1800  \tValid loss: 0.6198956966400146\n",
      "Step: 1900  \tTraining loss: 0.5625249743461609\n",
      "Step: 1900  \tTraining accuracy: 0.6690555214881897\n",
      "Step: 1900  \tValid loss: 0.6193473935127258\n",
      "Step: 2000  \tTraining loss: 0.5607967972755432\n",
      "Step: 2000  \tTraining accuracy: 0.6698070168495178\n",
      "Step: 2000  \tValid loss: 0.6186013221740723\n",
      "Step: 2100  \tTraining loss: 0.5591523051261902\n",
      "Step: 2100  \tTraining accuracy: 0.6703692078590393\n",
      "Step: 2100  \tValid loss: 0.6181760430335999\n",
      "Step: 2200  \tTraining loss: 0.5576105713844299\n",
      "Step: 2200  \tTraining accuracy: 0.6708514094352722\n",
      "Step: 2200  \tValid loss: 0.6179797649383545\n",
      "Step: 2300  \tTraining loss: 0.55607008934021\n",
      "Step: 2300  \tTraining accuracy: 0.6714757680892944\n",
      "Step: 2300  \tValid loss: 0.617371141910553\n",
      "Step: 2400  \tTraining loss: 0.5544639825820923\n",
      "Step: 2400  \tTraining accuracy: 0.6720975637435913\n",
      "Step: 2400  \tValid loss: 0.6166765689849854\n",
      "Step: 2500  \tTraining loss: 0.552815854549408\n",
      "Step: 2500  \tTraining accuracy: 0.6727171540260315\n",
      "Step: 2500  \tValid loss: 0.6157293915748596\n",
      "Step: 2600  \tTraining loss: 0.5510656237602234\n",
      "Step: 2600  \tTraining accuracy: 0.6733347177505493\n",
      "Step: 2600  \tValid loss: 0.6158885955810547\n",
      "Step: 2700  \tTraining loss: 0.5493478178977966\n",
      "Step: 2700  \tTraining accuracy: 0.6739506125450134\n",
      "Step: 2700  \tValid loss: 0.6166341304779053\n",
      "Step: 2800  \tTraining loss: 0.5479276180267334\n",
      "Step: 2800  \tTraining accuracy: 0.6746081709861755\n",
      "Step: 2800  \tValid loss: 0.6169711947441101\n",
      "Step: 2900  \tTraining loss: 0.5468120574951172\n",
      "Step: 2900  \tTraining accuracy: 0.6752612590789795\n",
      "Step: 2900  \tValid loss: 0.6172347068786621\n",
      "Step: 3000  \tTraining loss: 0.5458003282546997\n",
      "Step: 3000  \tTraining accuracy: 0.6759104132652283\n",
      "Step: 3000  \tValid loss: 0.6173800826072693\n",
      "Step: 3100  \tTraining loss: 0.5448718070983887\n",
      "Step: 3100  \tTraining accuracy: 0.6766339540481567\n",
      "Step: 3100  \tValid loss: 0.61774080991745\n",
      "Step: 3200  \tTraining loss: 0.5440131425857544\n",
      "Step: 3200  \tTraining accuracy: 0.6772738695144653\n",
      "Step: 3200  \tValid loss: 0.6180764436721802\n",
      "Step: 3300  \tTraining loss: 0.5431669354438782\n",
      "Step: 3300  \tTraining accuracy: 0.6778743267059326\n",
      "Step: 3300  \tValid loss: 0.6183613538742065\n",
      "Step: 3400  \tTraining loss: 0.5421974062919617\n",
      "Step: 3400  \tTraining accuracy: 0.6783502101898193\n",
      "Step: 3400  \tValid loss: 0.6185518503189087\n",
      "Step: 3500  \tTraining loss: 0.5407789349555969\n",
      "Step: 3500  \tTraining accuracy: 0.6787468194961548\n",
      "Step: 3500  \tValid loss: 0.6182714700698853\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.6791378\n",
      "Precision: 0.72988504\n",
      "Recall: 0.8037975\n",
      "F1 score: 0.71186733\n",
      "AUC: 0.70980066\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.679138   0.729885  0.803797  0.711867  0.709801  0.54043      0.678529   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.615615       0.678612    0.64849      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3521.0  \n",
      "6\n",
      "(1131, 8)\n",
      "(1131, 1)\n",
      "(624, 8)\n",
      "(624, 1)\n",
      "(507, 8)\n",
      "(507, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5824602842330933\n",
      "Step: 100  \tTraining accuracy: 0.7418214082717896\n",
      "Step: 100  \tValid loss: 0.60923832654953\n",
      "Step: 200  \tTraining loss: 0.439910888671875\n",
      "Step: 200  \tTraining accuracy: 0.7630415558815002\n",
      "Step: 200  \tValid loss: 0.46141961216926575\n",
      "Step: 300  \tTraining loss: 0.4120047092437744\n",
      "Step: 300  \tTraining accuracy: 0.7939876317977905\n",
      "Step: 300  \tValid loss: 0.4355948865413666\n",
      "Step: 400  \tTraining loss: 0.4049672782421112\n",
      "Step: 400  \tTraining accuracy: 0.8082606792449951\n",
      "Step: 400  \tValid loss: 0.4300859868526459\n",
      "Step: 500  \tTraining loss: 0.4003077745437622\n",
      "Step: 500  \tTraining accuracy: 0.8167796730995178\n",
      "Step: 500  \tValid loss: 0.42656806111335754\n",
      "Step: 600  \tTraining loss: 0.3963228762149811\n",
      "Step: 600  \tTraining accuracy: 0.8215577602386475\n",
      "Step: 600  \tValid loss: 0.42363229393959045\n",
      "Step: 700  \tTraining loss: 0.39261317253112793\n",
      "Step: 700  \tTraining accuracy: 0.8252057433128357\n",
      "Step: 700  \tValid loss: 0.42154189944267273\n",
      "Step: 800  \tTraining loss: 0.38906607031822205\n",
      "Step: 800  \tTraining accuracy: 0.8278219699859619\n",
      "Step: 800  \tValid loss: 0.41954657435417175\n",
      "Step: 900  \tTraining loss: 0.3852592408657074\n",
      "Step: 900  \tTraining accuracy: 0.8299266695976257\n",
      "Step: 900  \tValid loss: 0.417509526014328\n",
      "Step: 1000  \tTraining loss: 0.3810834288597107\n",
      "Step: 1000  \tTraining accuracy: 0.8316813111305237\n",
      "Step: 1000  \tValid loss: 0.41549956798553467\n",
      "Step: 1100  \tTraining loss: 0.3765791058540344\n",
      "Step: 1100  \tTraining accuracy: 0.8331438899040222\n",
      "Step: 1100  \tValid loss: 0.4136882722377777\n",
      "Step: 1200  \tTraining loss: 0.3721614181995392\n",
      "Step: 1200  \tTraining accuracy: 0.8345057964324951\n",
      "Step: 1200  \tValid loss: 0.41224679350852966\n",
      "Step: 1300  \tTraining loss: 0.36801382899284363\n",
      "Step: 1300  \tTraining accuracy: 0.8355791568756104\n",
      "Step: 1300  \tValid loss: 0.41137197613716125\n",
      "Step: 1400  \tTraining loss: 0.36415377259254456\n",
      "Step: 1400  \tTraining accuracy: 0.8366898894309998\n",
      "Step: 1400  \tValid loss: 0.4107014238834381\n",
      "Step: 1500  \tTraining loss: 0.36070704460144043\n",
      "Step: 1500  \tTraining accuracy: 0.837556004524231\n",
      "Step: 1500  \tValid loss: 0.4111262559890747\n",
      "Step: 1600  \tTraining loss: 0.3577966094017029\n",
      "Step: 1600  \tTraining accuracy: 0.8383674025535583\n",
      "Step: 1600  \tValid loss: 0.4114220440387726\n",
      "Step: 1700  \tTraining loss: 0.3552926480770111\n",
      "Step: 1700  \tTraining accuracy: 0.8391608595848083\n",
      "Step: 1700  \tValid loss: 0.41206640005111694\n",
      "Step: 1800  \tTraining loss: 0.35310879349708557\n",
      "Step: 1800  \tTraining accuracy: 0.8398130536079407\n",
      "Step: 1800  \tValid loss: 0.4125720262527466\n",
      "Step: 1900  \tTraining loss: 0.35119786858558655\n",
      "Step: 1900  \tTraining accuracy: 0.8403947949409485\n",
      "Step: 1900  \tValid loss: 0.41300836205482483\n",
      "Step: 2000  \tTraining loss: 0.34945937991142273\n",
      "Step: 2000  \tTraining accuracy: 0.8408714532852173\n",
      "Step: 2000  \tValid loss: 0.4133968949317932\n",
      "Step: 2100  \tTraining loss: 0.3478677272796631\n",
      "Step: 2100  \tTraining accuracy: 0.8413232564926147\n",
      "Step: 2100  \tValid loss: 0.41353628039360046\n",
      "Step: 2200  \tTraining loss: 0.3464050889015198\n",
      "Step: 2200  \tTraining accuracy: 0.8417946696281433\n",
      "Step: 2200  \tValid loss: 0.41359826922416687\n",
      "Step: 2300  \tTraining loss: 0.345045268535614\n",
      "Step: 2300  \tTraining accuracy: 0.8422831296920776\n",
      "Step: 2300  \tValid loss: 0.4135443866252899\n",
      "Step: 2400  \tTraining loss: 0.34364408254623413\n",
      "Step: 2400  \tTraining accuracy: 0.8427488207817078\n",
      "Step: 2400  \tValid loss: 0.41308289766311646\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.84319454\n",
      "Precision: 0.82391304\n",
      "Recall: 0.82570803\n",
      "F1 score: 0.84411204\n",
      "AUC: 0.85258615\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.843195   0.823913  0.825708  0.844112  0.852586  0.343524      0.842893   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.410667       0.843023   0.338058      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2408.0  \n",
      "7\n",
      "(986, 8)\n",
      "(986, 1)\n",
      "(544, 8)\n",
      "(544, 1)\n",
      "(442, 8)\n",
      "(442, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6463804841041565\n",
      "Step: 100  \tTraining accuracy: 0.6227180361747742\n",
      "Step: 100  \tValid loss: 0.6394057273864746\n",
      "Step: 200  \tTraining loss: 0.6054188013076782\n",
      "Step: 200  \tTraining accuracy: 0.6352264881134033\n",
      "Step: 200  \tValid loss: 0.5878565311431885\n",
      "Step: 300  \tTraining loss: 0.5725908279418945\n",
      "Step: 300  \tTraining accuracy: 0.6545639038085938\n",
      "Step: 300  \tValid loss: 0.5453904271125793\n",
      "Step: 400  \tTraining loss: 0.5562548637390137\n",
      "Step: 400  \tTraining accuracy: 0.6756013035774231\n",
      "Step: 400  \tValid loss: 0.5221610069274902\n",
      "Step: 500  \tTraining loss: 0.5496531128883362\n",
      "Step: 500  \tTraining accuracy: 0.6905567049980164\n",
      "Step: 500  \tValid loss: 0.511379599571228\n",
      "Step: 600  \tTraining loss: 0.5464754700660706\n",
      "Step: 600  \tTraining accuracy: 0.7004425525665283\n",
      "Step: 600  \tValid loss: 0.5058892369270325\n",
      "Step: 700  \tTraining loss: 0.5443347692489624\n",
      "Step: 700  \tTraining accuracy: 0.7070525884628296\n",
      "Step: 700  \tValid loss: 0.5027215480804443\n",
      "Step: 800  \tTraining loss: 0.5425006151199341\n",
      "Step: 800  \tTraining accuracy: 0.7118999361991882\n",
      "Step: 800  \tValid loss: 0.5006906390190125\n",
      "Step: 900  \tTraining loss: 0.5409224033355713\n",
      "Step: 900  \tTraining accuracy: 0.7156067490577698\n",
      "Step: 900  \tValid loss: 0.49917861819267273\n",
      "Step: 1000  \tTraining loss: 0.5395264625549316\n",
      "Step: 1000  \tTraining accuracy: 0.7185331583023071\n",
      "Step: 1000  \tValid loss: 0.4979235827922821\n",
      "Step: 1100  \tTraining loss: 0.5381929278373718\n",
      "Step: 1100  \tTraining accuracy: 0.7208055853843689\n",
      "Step: 1100  \tValid loss: 0.4967863857746124\n",
      "Step: 1200  \tTraining loss: 0.5371055006980896\n",
      "Step: 1200  \tTraining accuracy: 0.7225945591926575\n",
      "Step: 1200  \tValid loss: 0.496005117893219\n",
      "Step: 1300  \tTraining loss: 0.5361574292182922\n",
      "Step: 1300  \tTraining accuracy: 0.7241379022598267\n",
      "Step: 1300  \tValid loss: 0.49538248777389526\n",
      "Step: 1400  \tTraining loss: 0.5353198647499084\n",
      "Step: 1400  \tTraining accuracy: 0.7254526615142822\n",
      "Step: 1400  \tValid loss: 0.49487438797950745\n",
      "Step: 1500  \tTraining loss: 0.5346080660820007\n",
      "Step: 1500  \tTraining accuracy: 0.7265509963035583\n",
      "Step: 1500  \tValid loss: 0.49452921748161316\n",
      "Step: 1600  \tTraining loss: 0.5340021252632141\n",
      "Step: 1600  \tTraining accuracy: 0.7274749875068665\n",
      "Step: 1600  \tValid loss: 0.4941902160644531\n",
      "Step: 1700  \tTraining loss: 0.533469021320343\n",
      "Step: 1700  \tTraining accuracy: 0.7283483743667603\n",
      "Step: 1700  \tValid loss: 0.49386709928512573\n",
      "Step: 1800  \tTraining loss: 0.5329864621162415\n",
      "Step: 1800  \tTraining accuracy: 0.7291509509086609\n",
      "Step: 1800  \tValid loss: 0.4935818910598755\n",
      "Step: 1900  \tTraining loss: 0.5325407385826111\n",
      "Step: 1900  \tTraining accuracy: 0.72989422082901\n",
      "Step: 1900  \tValid loss: 0.493356317281723\n",
      "Step: 2000  \tTraining loss: 0.5321186184883118\n",
      "Step: 2000  \tTraining accuracy: 0.7306131720542908\n",
      "Step: 2000  \tValid loss: 0.4931669235229492\n",
      "Step: 2100  \tTraining loss: 0.5317104458808899\n",
      "Step: 2100  \tTraining accuracy: 0.731311559677124\n",
      "Step: 2100  \tValid loss: 0.49301406741142273\n",
      "Step: 2200  \tTraining loss: 0.5313066840171814\n",
      "Step: 2200  \tTraining accuracy: 0.7319684624671936\n",
      "Step: 2200  \tValid loss: 0.4928782880306244\n",
      "Step: 2300  \tTraining loss: 0.5309011340141296\n",
      "Step: 2300  \tTraining accuracy: 0.7326346635818481\n",
      "Step: 2300  \tValid loss: 0.49274227023124695\n",
      "Step: 2400  \tTraining loss: 0.5304670929908752\n",
      "Step: 2400  \tTraining accuracy: 0.7332656979560852\n",
      "Step: 2400  \tValid loss: 0.4925743639469147\n",
      "Step: 2500  \tTraining loss: 0.5300276875495911\n",
      "Step: 2500  \tTraining accuracy: 0.7338659763336182\n",
      "Step: 2500  \tValid loss: 0.492587149143219\n",
      "Step: 2600  \tTraining loss: 0.5295695066452026\n",
      "Step: 2600  \tTraining accuracy: 0.7343992590904236\n",
      "Step: 2600  \tValid loss: 0.49257907271385193\n",
      "Step: 2700  \tTraining loss: 0.5290983319282532\n",
      "Step: 2700  \tTraining accuracy: 0.7349496483802795\n",
      "Step: 2700  \tValid loss: 0.4925633668899536\n",
      "Step: 2800  \tTraining loss: 0.528611421585083\n",
      "Step: 2800  \tTraining accuracy: 0.7354416251182556\n",
      "Step: 2800  \tValid loss: 0.4925520420074463\n",
      "Step: 2900  \tTraining loss: 0.5281230807304382\n",
      "Step: 2900  \tTraining accuracy: 0.7359168529510498\n",
      "Step: 2900  \tValid loss: 0.4925677478313446\n",
      "Step: 3000  \tTraining loss: 0.5276319980621338\n",
      "Step: 3000  \tTraining accuracy: 0.7363426685333252\n",
      "Step: 3000  \tValid loss: 0.4925706088542938\n",
      "Step: 3100  \tTraining loss: 0.5271528959274292\n",
      "Step: 3100  \tTraining accuracy: 0.7367904782295227\n",
      "Step: 3100  \tValid loss: 0.4925537109375\n",
      "Step: 3200  \tTraining loss: 0.526697039604187\n",
      "Step: 3200  \tTraining accuracy: 0.7372420430183411\n",
      "Step: 3200  \tValid loss: 0.49248671531677246\n",
      "Step: 3300  \tTraining loss: 0.5262450575828552\n",
      "Step: 3300  \tTraining accuracy: 0.7376813888549805\n",
      "Step: 3300  \tValid loss: 0.49241745471954346\n",
      "Step: 3400  \tTraining loss: 0.5257988572120667\n",
      "Step: 3400  \tTraining accuracy: 0.7381096482276917\n",
      "Step: 3400  \tValid loss: 0.49233660101890564\n",
      "Step: 3500  \tTraining loss: 0.5253587365150452\n",
      "Step: 3500  \tTraining accuracy: 0.7384983897209167\n",
      "Step: 3500  \tValid loss: 0.4922372102737427\n",
      "Step: 3600  \tTraining loss: 0.5249209403991699\n",
      "Step: 3600  \tTraining accuracy: 0.7388938069343567\n",
      "Step: 3600  \tValid loss: 0.4921860992908478\n",
      "Step: 3700  \tTraining loss: 0.5244907736778259\n",
      "Step: 3700  \tTraining accuracy: 0.7392258644104004\n",
      "Step: 3700  \tValid loss: 0.49214425683021545\n",
      "Step: 3800  \tTraining loss: 0.5240674018859863\n",
      "Step: 3800  \tTraining accuracy: 0.7395266890525818\n",
      "Step: 3800  \tValid loss: 0.49208176136016846\n",
      "Step: 3900  \tTraining loss: 0.5236474275588989\n",
      "Step: 3900  \tTraining accuracy: 0.7398250699043274\n",
      "Step: 3900  \tValid loss: 0.49201011657714844\n",
      "Step: 4000  \tTraining loss: 0.5232289433479309\n",
      "Step: 4000  \tTraining accuracy: 0.7401083707809448\n",
      "Step: 4000  \tValid loss: 0.491955429315567\n",
      "Step: 4100  \tTraining loss: 0.5228093266487122\n",
      "Step: 4100  \tTraining accuracy: 0.7403650879859924\n",
      "Step: 4100  \tValid loss: 0.491923063993454\n",
      "Step: 4200  \tTraining loss: 0.5223888754844666\n",
      "Step: 4200  \tTraining accuracy: 0.7406217455863953\n",
      "Step: 4200  \tValid loss: 0.4919087886810303\n",
      "Step: 4300  \tTraining loss: 0.5219672918319702\n",
      "Step: 4300  \tTraining accuracy: 0.7408662438392639\n",
      "Step: 4300  \tValid loss: 0.4919239580631256\n",
      "Step: 4400  \tTraining loss: 0.5215453505516052\n",
      "Step: 4400  \tTraining accuracy: 0.7410995364189148\n",
      "Step: 4400  \tValid loss: 0.4919489622116089\n",
      "Step: 4500  \tTraining loss: 0.5211247801780701\n",
      "Step: 4500  \tTraining accuracy: 0.7412539720535278\n",
      "Step: 4500  \tValid loss: 0.4919772446155548\n",
      "Step: 4600  \tTraining loss: 0.5207086801528931\n",
      "Step: 4600  \tTraining accuracy: 0.7413904666900635\n",
      "Step: 4600  \tValid loss: 0.4920298755168915\n",
      "Step: 4700  \tTraining loss: 0.5202945470809937\n",
      "Step: 4700  \tTraining accuracy: 0.7415210604667664\n",
      "Step: 4700  \tValid loss: 0.49210548400878906\n",
      "Step: 4800  \tTraining loss: 0.5198836922645569\n",
      "Step: 4800  \tTraining accuracy: 0.7416675686836243\n",
      "Step: 4800  \tValid loss: 0.4922119677066803\n",
      "Step: 4900  \tTraining loss: 0.5194761753082275\n",
      "Step: 4900  \tTraining accuracy: 0.7418184280395508\n",
      "Step: 4900  \tValid loss: 0.4923399090766907\n",
      "Step: 5000  \tTraining loss: 0.5190737843513489\n",
      "Step: 5000  \tTraining accuracy: 0.741963267326355\n",
      "Step: 5000  \tValid loss: 0.4924909472465515\n",
      "Step: 5100  \tTraining loss: 0.5186764001846313\n",
      "Step: 5100  \tTraining accuracy: 0.742102324962616\n",
      "Step: 5100  \tValid loss: 0.49267399311065674\n",
      "Step: 5200  \tTraining loss: 0.5182806849479675\n",
      "Step: 5200  \tTraining accuracy: 0.7422556281089783\n",
      "Step: 5200  \tValid loss: 0.4928934574127197\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7423742\n",
      "Precision: 0.7009646\n",
      "Recall: 0.5860215\n",
      "F1 score: 0.67607135\n",
      "AUC: 0.7172778\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.742374   0.700965  0.586021  0.676071  0.717278  0.518222      0.742306   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.491907       0.742147   0.533837      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5214.0  \n",
      "8\n",
      "(2668, 8)\n",
      "(2668, 1)\n",
      "(1472, 8)\n",
      "(1472, 1)\n",
      "(1196, 8)\n",
      "(1196, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6276217699050903\n",
      "Step: 100  \tTraining accuracy: 0.6499250531196594\n",
      "Step: 100  \tValid loss: 0.6426294445991516\n",
      "Step: 200  \tTraining loss: 0.4962146282196045\n",
      "Step: 200  \tTraining accuracy: 0.6967766284942627\n",
      "Step: 200  \tValid loss: 0.5022104382514954\n",
      "Step: 300  \tTraining loss: 0.3965408205986023\n",
      "Step: 300  \tTraining accuracy: 0.7474512457847595\n",
      "Step: 300  \tValid loss: 0.3906807601451874\n",
      "Step: 400  \tTraining loss: 0.3520052433013916\n",
      "Step: 400  \tTraining accuracy: 0.7788070440292358\n",
      "Step: 400  \tValid loss: 0.33914679288864136\n",
      "Step: 500  \tTraining loss: 0.3330548405647278\n",
      "Step: 500  \tTraining accuracy: 0.7968099117279053\n",
      "Step: 500  \tValid loss: 0.3165304362773895\n",
      "Step: 600  \tTraining loss: 0.3246222138404846\n",
      "Step: 600  \tTraining accuracy: 0.8084366917610168\n",
      "Step: 600  \tValid loss: 0.30704987049102783\n",
      "Step: 700  \tTraining loss: 0.31943920254707336\n",
      "Step: 700  \tTraining accuracy: 0.8166589736938477\n",
      "Step: 700  \tValid loss: 0.30171480774879456\n",
      "Step: 800  \tTraining loss: 0.3162083327770233\n",
      "Step: 800  \tTraining accuracy: 0.8229885101318359\n",
      "Step: 800  \tValid loss: 0.29947543144226074\n",
      "Step: 900  \tTraining loss: 0.3139163553714752\n",
      "Step: 900  \tTraining accuracy: 0.827938973903656\n",
      "Step: 900  \tValid loss: 0.2968043088912964\n",
      "Step: 1000  \tTraining loss: 0.3119947910308838\n",
      "Step: 1000  \tTraining accuracy: 0.8318077921867371\n",
      "Step: 1000  \tValid loss: 0.2954740822315216\n",
      "Step: 1100  \tTraining loss: 0.31048741936683655\n",
      "Step: 1100  \tTraining accuracy: 0.8349753618240356\n",
      "Step: 1100  \tValid loss: 0.29421332478523254\n",
      "Step: 1200  \tTraining loss: 0.3093249797821045\n",
      "Step: 1200  \tTraining accuracy: 0.8377713561058044\n",
      "Step: 1200  \tValid loss: 0.29295510053634644\n",
      "Step: 1300  \tTraining loss: 0.3081062436103821\n",
      "Step: 1300  \tTraining accuracy: 0.8401199579238892\n",
      "Step: 1300  \tValid loss: 0.2915072739124298\n",
      "Step: 1400  \tTraining loss: 0.3070448637008667\n",
      "Step: 1400  \tTraining accuracy: 0.8422732949256897\n",
      "Step: 1400  \tValid loss: 0.2901870310306549\n",
      "Step: 1500  \tTraining loss: 0.3061133027076721\n",
      "Step: 1500  \tTraining accuracy: 0.8441942930221558\n",
      "Step: 1500  \tValid loss: 0.28922900557518005\n",
      "Step: 1600  \tTraining loss: 0.3052475154399872\n",
      "Step: 1600  \tTraining accuracy: 0.8458310961723328\n",
      "Step: 1600  \tValid loss: 0.288619726896286\n",
      "Step: 1700  \tTraining loss: 0.3044895827770233\n",
      "Step: 1700  \tTraining accuracy: 0.8472922444343567\n",
      "Step: 1700  \tValid loss: 0.28816112875938416\n",
      "Step: 1800  \tTraining loss: 0.30376046895980835\n",
      "Step: 1800  \tTraining accuracy: 0.8485864400863647\n",
      "Step: 1800  \tValid loss: 0.2878170609474182\n",
      "Step: 1900  \tTraining loss: 0.3030376434326172\n",
      "Step: 1900  \tTraining accuracy: 0.849750816822052\n",
      "Step: 1900  \tValid loss: 0.287538081407547\n",
      "Step: 2000  \tTraining loss: 0.3023391366004944\n",
      "Step: 2000  \tTraining accuracy: 0.8507668972015381\n",
      "Step: 2000  \tValid loss: 0.2872160077095032\n",
      "Step: 2100  \tTraining loss: 0.3016851544380188\n",
      "Step: 2100  \tTraining accuracy: 0.8517022132873535\n",
      "Step: 2100  \tValid loss: 0.28685441613197327\n",
      "Step: 2200  \tTraining loss: 0.30012235045433044\n",
      "Step: 2200  \tTraining accuracy: 0.8525417447090149\n",
      "Step: 2200  \tValid loss: 0.28638243675231934\n",
      "Step: 2300  \tTraining loss: 0.298757404088974\n",
      "Step: 2300  \tTraining accuracy: 0.8533899784088135\n",
      "Step: 2300  \tValid loss: 0.28775349259376526\n",
      "Step: 2400  \tTraining loss: 0.2978947162628174\n",
      "Step: 2400  \tTraining accuracy: 0.8541819453239441\n",
      "Step: 2400  \tValid loss: 0.28768864274024963\n",
      "Step: 2500  \tTraining loss: 0.29714861512184143\n",
      "Step: 2500  \tTraining accuracy: 0.8548939824104309\n",
      "Step: 2500  \tValid loss: 0.2875426411628723\n",
      "Step: 2600  \tTraining loss: 0.2964899241924286\n",
      "Step: 2600  \tTraining accuracy: 0.8555207848548889\n",
      "Step: 2600  \tValid loss: 0.2875816226005554\n",
      "Step: 2700  \tTraining loss: 0.29587802290916443\n",
      "Step: 2700  \tTraining accuracy: 0.8561072945594788\n",
      "Step: 2700  \tValid loss: 0.28765639662742615\n",
      "Step: 2800  \tTraining loss: 0.29534944891929626\n",
      "Step: 2800  \tTraining accuracy: 0.856651246547699\n",
      "Step: 2800  \tValid loss: 0.287621408700943\n",
      "Step: 2900  \tTraining loss: 0.294879287481308\n",
      "Step: 2900  \tTraining accuracy: 0.8571569323539734\n",
      "Step: 2900  \tValid loss: 0.28771084547042847\n",
      "Step: 3000  \tTraining loss: 0.2944587171077728\n",
      "Step: 3000  \tTraining accuracy: 0.8576347231864929\n",
      "Step: 3000  \tValid loss: 0.28788354992866516\n",
      "Step: 3100  \tTraining loss: 0.2940794825553894\n",
      "Step: 3100  \tTraining accuracy: 0.8580812215805054\n",
      "Step: 3100  \tValid loss: 0.2880093455314636\n",
      "Step: 3200  \tTraining loss: 0.29372134804725647\n",
      "Step: 3200  \tTraining accuracy: 0.858511209487915\n",
      "Step: 3200  \tValid loss: 0.2880915701389313\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8589032\n",
      "Precision: 0.8986486\n",
      "Recall: 0.8773087\n",
      "F1 score: 0.8485826\n",
      "AUC: 0.87355024\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.858903   0.898649  0.877309  0.848583  0.87355  0.293721      0.858666   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.286349       0.858483   0.327595      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3199.0  \n",
      "9\n",
      "(754, 8)\n",
      "(754, 1)\n",
      "(400, 8)\n",
      "(400, 1)\n",
      "(325, 8)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5576675534248352\n",
      "Step: 100  \tTraining accuracy: 0.7877984046936035\n",
      "Step: 100  \tValid loss: 0.6762186288833618\n",
      "Step: 200  \tTraining loss: 0.5139923691749573\n",
      "Step: 200  \tTraining accuracy: 0.7689207196235657\n",
      "Step: 200  \tValid loss: 0.6960067749023438\n",
      "Step: 300  \tTraining loss: 0.5002346038818359\n",
      "Step: 300  \tTraining accuracy: 0.7726293206214905\n",
      "Step: 300  \tValid loss: 0.6846977472305298\n",
      "Step: 400  \tTraining loss: 0.4858623445034027\n",
      "Step: 400  \tTraining accuracy: 0.7746099233627319\n",
      "Step: 400  \tValid loss: 0.6661573052406311\n",
      "Step: 500  \tTraining loss: 0.47255927324295044\n",
      "Step: 500  \tTraining accuracy: 0.7757121324539185\n",
      "Step: 500  \tValid loss: 0.6477420330047607\n",
      "Step: 600  \tTraining loss: 0.4628891348838806\n",
      "Step: 600  \tTraining accuracy: 0.7764142751693726\n",
      "Step: 600  \tValid loss: 0.6370201110839844\n",
      "Step: 700  \tTraining loss: 0.4551613926887512\n",
      "Step: 700  \tTraining accuracy: 0.7769007086753845\n",
      "Step: 700  \tValid loss: 0.6269569993019104\n",
      "Step: 800  \tTraining loss: 0.4486580491065979\n",
      "Step: 800  \tTraining accuracy: 0.7772575616836548\n",
      "Step: 800  \tValid loss: 0.6174004077911377\n",
      "Step: 900  \tTraining loss: 0.443376362323761\n",
      "Step: 900  \tTraining accuracy: 0.7776100635528564\n",
      "Step: 900  \tValid loss: 0.609880805015564\n",
      "Step: 1000  \tTraining loss: 0.4392322897911072\n",
      "Step: 1000  \tTraining accuracy: 0.7779594659805298\n",
      "Step: 1000  \tValid loss: 0.6027587056159973\n",
      "Step: 1100  \tTraining loss: 0.43602901697158813\n",
      "Step: 1100  \tTraining accuracy: 0.7783710956573486\n",
      "Step: 1100  \tValid loss: 0.5972789525985718\n",
      "Step: 1200  \tTraining loss: 0.43355971574783325\n",
      "Step: 1200  \tTraining accuracy: 0.7786524295806885\n",
      "Step: 1200  \tValid loss: 0.5928754210472107\n",
      "Step: 1300  \tTraining loss: 0.4316787123680115\n",
      "Step: 1300  \tTraining accuracy: 0.7789968848228455\n",
      "Step: 1300  \tValid loss: 0.589255154132843\n",
      "Step: 1400  \tTraining loss: 0.43023526668548584\n",
      "Step: 1400  \tTraining accuracy: 0.7793903946876526\n",
      "Step: 1400  \tValid loss: 0.586270809173584\n",
      "Step: 1500  \tTraining loss: 0.42910632491111755\n",
      "Step: 1500  \tTraining accuracy: 0.7798694968223572\n",
      "Step: 1500  \tValid loss: 0.5837094783782959\n",
      "Step: 1600  \tTraining loss: 0.42817947268486023\n",
      "Step: 1600  \tTraining accuracy: 0.7802432775497437\n",
      "Step: 1600  \tValid loss: 0.5817524194717407\n",
      "Step: 1700  \tTraining loss: 0.42734262347221375\n",
      "Step: 1700  \tTraining accuracy: 0.780571699142456\n",
      "Step: 1700  \tValid loss: 0.5799874067306519\n",
      "Step: 1800  \tTraining loss: 0.4265340268611908\n",
      "Step: 1800  \tTraining accuracy: 0.7808240056037903\n",
      "Step: 1800  \tValid loss: 0.5783525109291077\n",
      "Step: 1900  \tTraining loss: 0.4256838262081146\n",
      "Step: 1900  \tTraining accuracy: 0.7810856103897095\n",
      "Step: 1900  \tValid loss: 0.5767810344696045\n",
      "Step: 2000  \tTraining loss: 0.4247366189956665\n",
      "Step: 2000  \tTraining accuracy: 0.7813203930854797\n",
      "Step: 2000  \tValid loss: 0.5750097632408142\n",
      "Step: 2100  \tTraining loss: 0.4236689805984497\n",
      "Step: 2100  \tTraining accuracy: 0.7815982103347778\n",
      "Step: 2100  \tValid loss: 0.5730829834938049\n",
      "Step: 2200  \tTraining loss: 0.42251911759376526\n",
      "Step: 2200  \tTraining accuracy: 0.7818501591682434\n",
      "Step: 2200  \tValid loss: 0.5711113810539246\n",
      "Step: 2300  \tTraining loss: 0.4213804304599762\n",
      "Step: 2300  \tTraining accuracy: 0.7820497155189514\n",
      "Step: 2300  \tValid loss: 0.5692497491836548\n",
      "Step: 2400  \tTraining loss: 0.42035365104675293\n",
      "Step: 2400  \tTraining accuracy: 0.7822898626327515\n",
      "Step: 2400  \tValid loss: 0.5674561858177185\n",
      "Step: 2500  \tTraining loss: 0.4194716811180115\n",
      "Step: 2500  \tTraining accuracy: 0.7825103402137756\n",
      "Step: 2500  \tValid loss: 0.5660855770111084\n",
      "Step: 2600  \tTraining loss: 0.41873258352279663\n",
      "Step: 2600  \tTraining accuracy: 0.78274005651474\n",
      "Step: 2600  \tValid loss: 0.5649784207344055\n",
      "Step: 2700  \tTraining loss: 0.41811028122901917\n",
      "Step: 2700  \tTraining accuracy: 0.7829269766807556\n",
      "Step: 2700  \tValid loss: 0.5641903877258301\n",
      "Step: 2800  \tTraining loss: 0.4175834059715271\n",
      "Step: 2800  \tTraining accuracy: 0.7831248044967651\n",
      "Step: 2800  \tValid loss: 0.5635491013526917\n",
      "Step: 2900  \tTraining loss: 0.41689544916152954\n",
      "Step: 2900  \tTraining accuracy: 0.783356249332428\n",
      "Step: 2900  \tValid loss: 0.5635578632354736\n",
      "Step: 3000  \tTraining loss: 0.4163309335708618\n",
      "Step: 3000  \tTraining accuracy: 0.7836178541183472\n",
      "Step: 3000  \tValid loss: 0.562681257724762\n",
      "Step: 3100  \tTraining loss: 0.41585084795951843\n",
      "Step: 3100  \tTraining accuracy: 0.7838844060897827\n",
      "Step: 3100  \tValid loss: 0.5621705651283264\n",
      "Step: 3200  \tTraining loss: 0.41535449028015137\n",
      "Step: 3200  \tTraining accuracy: 0.7841340899467468\n",
      "Step: 3200  \tValid loss: 0.5617728233337402\n",
      "Step: 3300  \tTraining loss: 0.41486498713493347\n",
      "Step: 3300  \tTraining accuracy: 0.784430742263794\n",
      "Step: 3300  \tValid loss: 0.5610508918762207\n",
      "Step: 3400  \tTraining loss: 0.41447582840919495\n",
      "Step: 3400  \tTraining accuracy: 0.7847299575805664\n",
      "Step: 3400  \tValid loss: 0.5609161853790283\n",
      "Step: 3500  \tTraining loss: 0.41411247849464417\n",
      "Step: 3500  \tTraining accuracy: 0.7850117683410645\n",
      "Step: 3500  \tValid loss: 0.5606310963630676\n",
      "Step: 3600  \tTraining loss: 0.4137735962867737\n",
      "Step: 3600  \tTraining accuracy: 0.7852967381477356\n",
      "Step: 3600  \tValid loss: 0.560451865196228\n",
      "Step: 3700  \tTraining loss: 0.41344958543777466\n",
      "Step: 3700  \tTraining accuracy: 0.7855846285820007\n",
      "Step: 3700  \tValid loss: 0.5602489709854126\n",
      "Step: 3800  \tTraining loss: 0.41313567757606506\n",
      "Step: 3800  \tTraining accuracy: 0.7858752012252808\n",
      "Step: 3800  \tValid loss: 0.5600900053977966\n",
      "Step: 3900  \tTraining loss: 0.4128311574459076\n",
      "Step: 3900  \tTraining accuracy: 0.7861506938934326\n",
      "Step: 3900  \tValid loss: 0.5599421858787537\n",
      "Step: 4000  \tTraining loss: 0.4125421643257141\n",
      "Step: 4000  \tTraining accuracy: 0.7864293456077576\n",
      "Step: 4000  \tValid loss: 0.5599468946456909\n",
      "Step: 4100  \tTraining loss: 0.41226139664649963\n",
      "Step: 4100  \tTraining accuracy: 0.7866942882537842\n",
      "Step: 4100  \tValid loss: 0.5597846508026123\n",
      "Step: 4200  \tTraining loss: 0.4119853079319\n",
      "Step: 4200  \tTraining accuracy: 0.7869464159011841\n",
      "Step: 4200  \tValid loss: 0.559553861618042\n",
      "Step: 4300  \tTraining loss: 0.411710649728775\n",
      "Step: 4300  \tTraining accuracy: 0.7871866822242737\n",
      "Step: 4300  \tValid loss: 0.5593165755271912\n",
      "Step: 4400  \tTraining loss: 0.41143515706062317\n",
      "Step: 4400  \tTraining accuracy: 0.7874158620834351\n",
      "Step: 4400  \tValid loss: 0.5590469837188721\n",
      "Step: 4500  \tTraining loss: 0.41115903854370117\n",
      "Step: 4500  \tTraining accuracy: 0.7876347899436951\n",
      "Step: 4500  \tValid loss: 0.5588465332984924\n",
      "Step: 4600  \tTraining loss: 0.41088178753852844\n",
      "Step: 4600  \tTraining accuracy: 0.7878441214561462\n",
      "Step: 4600  \tValid loss: 0.5585635304450989\n",
      "Step: 4700  \tTraining loss: 0.410603404045105\n",
      "Step: 4700  \tTraining accuracy: 0.7880589365959167\n",
      "Step: 4700  \tValid loss: 0.5583028197288513\n",
      "Step: 4800  \tTraining loss: 0.41032254695892334\n",
      "Step: 4800  \tTraining accuracy: 0.7882363200187683\n",
      "Step: 4800  \tValid loss: 0.5580043196678162\n",
      "Step: 4900  \tTraining loss: 0.4100396931171417\n",
      "Step: 4900  \tTraining accuracy: 0.7884063124656677\n",
      "Step: 4900  \tValid loss: 0.5577201247215271\n",
      "Step: 5000  \tTraining loss: 0.40975433588027954\n",
      "Step: 5000  \tTraining accuracy: 0.7885831594467163\n",
      "Step: 5000  \tValid loss: 0.557466983795166\n",
      "Step: 5100  \tTraining loss: 0.40946710109710693\n",
      "Step: 5100  \tTraining accuracy: 0.7887529730796814\n",
      "Step: 5100  \tValid loss: 0.557182788848877\n",
      "Step: 5200  \tTraining loss: 0.409180611371994\n",
      "Step: 5200  \tTraining accuracy: 0.7889161705970764\n",
      "Step: 5200  \tValid loss: 0.5569174885749817\n",
      "Step: 5300  \tTraining loss: 0.40889450907707214\n",
      "Step: 5300  \tTraining accuracy: 0.7890860438346863\n",
      "Step: 5300  \tValid loss: 0.5565968751907349\n",
      "Step: 5400  \tTraining loss: 0.40861040353775024\n",
      "Step: 5400  \tTraining accuracy: 0.7892748117446899\n",
      "Step: 5400  \tValid loss: 0.5562908053398132\n",
      "Step: 5500  \tTraining loss: 0.40832754969596863\n",
      "Step: 5500  \tTraining accuracy: 0.7894443273544312\n",
      "Step: 5500  \tValid loss: 0.5559480786323547\n",
      "Step: 5600  \tTraining loss: 0.4080452024936676\n",
      "Step: 5600  \tTraining accuracy: 0.7896320223808289\n",
      "Step: 5600  \tValid loss: 0.5556817054748535\n",
      "Step: 5700  \tTraining loss: 0.4077635705471039\n",
      "Step: 5700  \tTraining accuracy: 0.7898131012916565\n",
      "Step: 5700  \tValid loss: 0.5553765892982483\n",
      "Step: 5800  \tTraining loss: 0.40748435258865356\n",
      "Step: 5800  \tTraining accuracy: 0.7899878621101379\n",
      "Step: 5800  \tValid loss: 0.5551289916038513\n",
      "Step: 5900  \tTraining loss: 0.40720629692077637\n",
      "Step: 5900  \tTraining accuracy: 0.7901451587677002\n",
      "Step: 5900  \tValid loss: 0.5548168420791626\n",
      "Step: 6000  \tTraining loss: 0.40693074464797974\n",
      "Step: 6000  \tTraining accuracy: 0.7902970910072327\n",
      "Step: 6000  \tValid loss: 0.5545300841331482\n",
      "Step: 6100  \tTraining loss: 0.40665778517723083\n",
      "Step: 6100  \tTraining accuracy: 0.7904440760612488\n",
      "Step: 6100  \tValid loss: 0.5542209148406982\n",
      "Step: 6200  \tTraining loss: 0.40638551115989685\n",
      "Step: 6200  \tTraining accuracy: 0.7905972003936768\n",
      "Step: 6200  \tValid loss: 0.5538987517356873\n",
      "Step: 6300  \tTraining loss: 0.4061155319213867\n",
      "Step: 6300  \tTraining accuracy: 0.7907454967498779\n",
      "Step: 6300  \tValid loss: 0.553590714931488\n",
      "Step: 6400  \tTraining loss: 0.4058469831943512\n",
      "Step: 6400  \tTraining accuracy: 0.7908890843391418\n",
      "Step: 6400  \tValid loss: 0.553312361240387\n",
      "Step: 6500  \tTraining loss: 0.4055822491645813\n",
      "Step: 6500  \tTraining accuracy: 0.7910282015800476\n",
      "Step: 6500  \tValid loss: 0.5530434250831604\n",
      "Step: 6600  \tTraining loss: 0.4053196609020233\n",
      "Step: 6600  \tTraining accuracy: 0.791142463684082\n",
      "Step: 6600  \tValid loss: 0.5527517795562744\n",
      "Step: 6700  \tTraining loss: 0.405058890581131\n",
      "Step: 6700  \tTraining accuracy: 0.7912532687187195\n",
      "Step: 6700  \tValid loss: 0.552466630935669\n",
      "Step: 6800  \tTraining loss: 0.40479975938796997\n",
      "Step: 6800  \tTraining accuracy: 0.7913607954978943\n",
      "Step: 6800  \tValid loss: 0.5521954894065857\n",
      "Step: 6900  \tTraining loss: 0.4045403301715851\n",
      "Step: 6900  \tTraining accuracy: 0.791465163230896\n",
      "Step: 6900  \tValid loss: 0.5519099235534668\n",
      "Step: 7000  \tTraining loss: 0.40424683690071106\n",
      "Step: 7000  \tTraining accuracy: 0.7915665507316589\n",
      "Step: 7000  \tValid loss: 0.5516357421875\n",
      "Step: 7100  \tTraining loss: 0.40397632122039795\n",
      "Step: 7100  \tTraining accuracy: 0.7916650772094727\n",
      "Step: 7100  \tValid loss: 0.5513964295387268\n",
      "Step: 7200  \tTraining loss: 0.4037100374698639\n",
      "Step: 7200  \tTraining accuracy: 0.7917608022689819\n",
      "Step: 7200  \tValid loss: 0.5512199401855469\n",
      "Step: 7300  \tTraining loss: 0.4034428298473358\n",
      "Step: 7300  \tTraining accuracy: 0.7918539643287659\n",
      "Step: 7300  \tValid loss: 0.5509742498397827\n",
      "Step: 7400  \tTraining loss: 0.40317776799201965\n",
      "Step: 7400  \tTraining accuracy: 0.7919445037841797\n",
      "Step: 7400  \tValid loss: 0.5507236123085022\n",
      "Step: 7500  \tTraining loss: 0.4029155373573303\n",
      "Step: 7500  \tTraining accuracy: 0.7920326590538025\n",
      "Step: 7500  \tValid loss: 0.5504962801933289\n",
      "Step: 7600  \tTraining loss: 0.40265390276908875\n",
      "Step: 7600  \tTraining accuracy: 0.7921095490455627\n",
      "Step: 7600  \tValid loss: 0.5501949191093445\n",
      "Step: 7700  \tTraining loss: 0.4023941457271576\n",
      "Step: 7700  \tTraining accuracy: 0.7921843528747559\n",
      "Step: 7700  \tValid loss: 0.5499392151832581\n",
      "Step: 7800  \tTraining loss: 0.4021349847316742\n",
      "Step: 7800  \tTraining accuracy: 0.7922660112380981\n",
      "Step: 7800  \tValid loss: 0.5497105717658997\n",
      "Step: 7900  \tTraining loss: 0.40187907218933105\n",
      "Step: 7900  \tTraining accuracy: 0.7923455834388733\n",
      "Step: 7900  \tValid loss: 0.5494605898857117\n",
      "Step: 8000  \tTraining loss: 0.4016231596469879\n",
      "Step: 8000  \tTraining accuracy: 0.7924231290817261\n",
      "Step: 8000  \tValid loss: 0.549246072769165\n",
      "Step: 8100  \tTraining loss: 0.401370108127594\n",
      "Step: 8100  \tTraining accuracy: 0.792498767375946\n",
      "Step: 8100  \tValid loss: 0.5490610599517822\n",
      "Step: 8200  \tTraining loss: 0.4011176526546478\n",
      "Step: 8200  \tTraining accuracy: 0.792572557926178\n",
      "Step: 8200  \tValid loss: 0.5488998889923096\n",
      "Step: 8300  \tTraining loss: 0.40077975392341614\n",
      "Step: 8300  \tTraining accuracy: 0.7926445603370667\n",
      "Step: 8300  \tValid loss: 0.5494234561920166\n",
      "Step: 8400  \tTraining loss: 0.4004400074481964\n",
      "Step: 8400  \tTraining accuracy: 0.7927229404449463\n",
      "Step: 8400  \tValid loss: 0.5491727590560913\n",
      "Step: 8500  \tTraining loss: 0.40007615089416504\n",
      "Step: 8500  \tTraining accuracy: 0.792807400226593\n",
      "Step: 8500  \tValid loss: 0.549523115158081\n",
      "Step: 8600  \tTraining loss: 0.39970871806144714\n",
      "Step: 8600  \tTraining accuracy: 0.7928899526596069\n",
      "Step: 8600  \tValid loss: 0.5493919253349304\n",
      "Step: 8700  \tTraining loss: 0.3992893695831299\n",
      "Step: 8700  \tTraining accuracy: 0.792970597743988\n",
      "Step: 8700  \tValid loss: 0.5501464605331421\n",
      "Step: 8800  \tTraining loss: 0.39891767501831055\n",
      "Step: 8800  \tTraining accuracy: 0.7930493354797363\n",
      "Step: 8800  \tValid loss: 0.549921452999115\n",
      "Step: 8900  \tTraining loss: 0.3985676169395447\n",
      "Step: 8900  \tTraining accuracy: 0.7931340336799622\n",
      "Step: 8900  \tValid loss: 0.5498227477073669\n",
      "Step: 9000  \tTraining loss: 0.39823099970817566\n",
      "Step: 9000  \tTraining accuracy: 0.7932016253471375\n",
      "Step: 9000  \tValid loss: 0.5496268272399902\n",
      "Step: 9100  \tTraining loss: 0.3979108929634094\n",
      "Step: 9100  \tTraining accuracy: 0.7932677865028381\n",
      "Step: 9100  \tValid loss: 0.549331545829773\n",
      "Step: 9200  \tTraining loss: 0.39760199189186096\n",
      "Step: 9200  \tTraining accuracy: 0.7933251261711121\n",
      "Step: 9200  \tValid loss: 0.5494297742843628\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.79338115\n",
      "Precision: 0.8543897\n",
      "Recall: 0.88470066\n",
      "F1 score: 0.80720913\n",
      "AUC: 0.8301391\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.793381    0.85439  0.884701  0.807209  0.830139  0.397442      0.793118   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.548756       0.793282   0.522278      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  9253.0  \n",
      "10\n",
      "(957, 8)\n",
      "(957, 1)\n",
      "(528, 8)\n",
      "(528, 1)\n",
      "(429, 8)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6161689162254333\n",
      "Step: 100  \tTraining accuracy: 0.6624869108200073\n",
      "Step: 100  \tValid loss: 0.6400042772293091\n",
      "Step: 200  \tTraining loss: 0.5310275554656982\n",
      "Step: 200  \tTraining accuracy: 0.6938349008560181\n",
      "Step: 200  \tValid loss: 0.5527031421661377\n",
      "Step: 300  \tTraining loss: 0.4444792568683624\n",
      "Step: 300  \tTraining accuracy: 0.73542320728302\n",
      "Step: 300  \tValid loss: 0.44993865489959717\n",
      "Step: 400  \tTraining loss: 0.4000283181667328\n",
      "Step: 400  \tTraining accuracy: 0.7625018954277039\n",
      "Step: 400  \tValid loss: 0.39023357629776\n",
      "Step: 500  \tTraining loss: 0.38278502225875854\n",
      "Step: 500  \tTraining accuracy: 0.7798676490783691\n",
      "Step: 500  \tValid loss: 0.3643950819969177\n",
      "Step: 600  \tTraining loss: 0.37573930621147156\n",
      "Step: 600  \tTraining accuracy: 0.7913935780525208\n",
      "Step: 600  \tValid loss: 0.35309839248657227\n",
      "Step: 700  \tTraining loss: 0.37188372015953064\n",
      "Step: 700  \tTraining accuracy: 0.7999356985092163\n",
      "Step: 700  \tValid loss: 0.3475973606109619\n",
      "Step: 800  \tTraining loss: 0.36934202909469604\n",
      "Step: 800  \tTraining accuracy: 0.8066179156303406\n",
      "Step: 800  \tValid loss: 0.34441328048706055\n",
      "Step: 900  \tTraining loss: 0.36731669306755066\n",
      "Step: 900  \tTraining accuracy: 0.8116663694381714\n",
      "Step: 900  \tValid loss: 0.3425239026546478\n",
      "Step: 1000  \tTraining loss: 0.3656196892261505\n",
      "Step: 1000  \tTraining accuracy: 0.8154869675636292\n",
      "Step: 1000  \tValid loss: 0.34124213457107544\n",
      "Step: 1100  \tTraining loss: 0.3641468286514282\n",
      "Step: 1100  \tTraining accuracy: 0.818579912185669\n",
      "Step: 1100  \tValid loss: 0.3402085304260254\n",
      "Step: 1200  \tTraining loss: 0.3628280758857727\n",
      "Step: 1200  \tTraining accuracy: 0.8210440278053284\n",
      "Step: 1200  \tValid loss: 0.3393838405609131\n",
      "Step: 1300  \tTraining loss: 0.36160385608673096\n",
      "Step: 1300  \tTraining accuracy: 0.8229467272758484\n",
      "Step: 1300  \tValid loss: 0.338746041059494\n",
      "Step: 1400  \tTraining loss: 0.360355019569397\n",
      "Step: 1400  \tTraining accuracy: 0.8246062397956848\n",
      "Step: 1400  \tValid loss: 0.3382861614227295\n",
      "Step: 1500  \tTraining loss: 0.3590688407421112\n",
      "Step: 1500  \tTraining accuracy: 0.8260728716850281\n",
      "Step: 1500  \tValid loss: 0.33780160546302795\n",
      "Step: 1600  \tTraining loss: 0.35779106616973877\n",
      "Step: 1600  \tTraining accuracy: 0.8273502588272095\n",
      "Step: 1600  \tValid loss: 0.3372751772403717\n",
      "Step: 1700  \tTraining loss: 0.3565341830253601\n",
      "Step: 1700  \tTraining accuracy: 0.828314483165741\n",
      "Step: 1700  \tValid loss: 0.3366045653820038\n",
      "Step: 1800  \tTraining loss: 0.3552992641925812\n",
      "Step: 1800  \tTraining accuracy: 0.8291685581207275\n",
      "Step: 1800  \tValid loss: 0.3359609544277191\n",
      "Step: 1900  \tTraining loss: 0.35408279299736023\n",
      "Step: 1900  \tTraining accuracy: 0.8299584984779358\n",
      "Step: 1900  \tValid loss: 0.33547285199165344\n",
      "Step: 2000  \tTraining loss: 0.3528841733932495\n",
      "Step: 2000  \tTraining accuracy: 0.8305870294570923\n",
      "Step: 2000  \tValid loss: 0.3350082337856293\n",
      "Step: 2100  \tTraining loss: 0.3516983687877655\n",
      "Step: 2100  \tTraining accuracy: 0.8312307000160217\n",
      "Step: 2100  \tValid loss: 0.3345945477485657\n",
      "Step: 2200  \tTraining loss: 0.35051989555358887\n",
      "Step: 2200  \tTraining accuracy: 0.8317416310310364\n",
      "Step: 2200  \tValid loss: 0.33425217866897583\n",
      "Step: 2300  \tTraining loss: 0.34931138157844543\n",
      "Step: 2300  \tTraining accuracy: 0.8323000073432922\n",
      "Step: 2300  \tValid loss: 0.33404120802879333\n",
      "Step: 2400  \tTraining loss: 0.34809914231300354\n",
      "Step: 2400  \tTraining accuracy: 0.8327886462211609\n",
      "Step: 2400  \tValid loss: 0.3339917063713074\n",
      "Step: 2500  \tTraining loss: 0.3469516336917877\n",
      "Step: 2500  \tTraining accuracy: 0.8332160711288452\n",
      "Step: 2500  \tValid loss: 0.3340194523334503\n",
      "Step: 2600  \tTraining loss: 0.34585899114608765\n",
      "Step: 2600  \tTraining accuracy: 0.8335894346237183\n",
      "Step: 2600  \tValid loss: 0.3340817093849182\n",
      "Step: 2700  \tTraining loss: 0.3448152244091034\n",
      "Step: 2700  \tTraining accuracy: 0.833895206451416\n",
      "Step: 2700  \tValid loss: 0.33423149585723877\n",
      "Step: 2800  \tTraining loss: 0.34382206201553345\n",
      "Step: 2800  \tTraining accuracy: 0.8341407775878906\n",
      "Step: 2800  \tValid loss: 0.33442220091819763\n",
      "Step: 2900  \tTraining loss: 0.34276139736175537\n",
      "Step: 2900  \tTraining accuracy: 0.8343507647514343\n",
      "Step: 2900  \tValid loss: 0.33449241518974304\n",
      "Step: 3000  \tTraining loss: 0.3415762782096863\n",
      "Step: 3000  \tTraining accuracy: 0.8345465064048767\n",
      "Step: 3000  \tValid loss: 0.33428335189819336\n",
      "Step: 3100  \tTraining loss: 0.34064042568206787\n",
      "Step: 3100  \tTraining accuracy: 0.8347637057304382\n",
      "Step: 3100  \tValid loss: 0.33449745178222656\n",
      "Step: 3200  \tTraining loss: 0.33969467878341675\n",
      "Step: 3200  \tTraining accuracy: 0.8349670767784119\n",
      "Step: 3200  \tValid loss: 0.33484143018722534\n",
      "Step: 3300  \tTraining loss: 0.3387165367603302\n",
      "Step: 3300  \tTraining accuracy: 0.8351258039474487\n",
      "Step: 3300  \tValid loss: 0.33516162633895874\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8352906\n",
      "Precision: 0.86287624\n",
      "Recall: 0.8835617\n",
      "F1 score: 0.84518415\n",
      "AUC: 0.8318612\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.835291   0.862876  0.883562  0.845184  0.831861  0.337944       0.83517   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.333852       0.834978   0.384069      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3374.0  \n",
      "11\n",
      "(754, 8)\n",
      "(754, 1)\n",
      "(416, 8)\n",
      "(416, 1)\n",
      "(338, 8)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4972146451473236\n",
      "Step: 100  \tTraining accuracy: 0.7692307829856873\n",
      "Step: 100  \tValid loss: 0.4789261519908905\n",
      "Step: 200  \tTraining loss: 0.38601720333099365\n",
      "Step: 200  \tTraining accuracy: 0.7953138947486877\n",
      "Step: 200  \tValid loss: 0.38702642917633057\n",
      "Step: 300  \tTraining loss: 0.3549964129924774\n",
      "Step: 300  \tTraining accuracy: 0.8114058375358582\n",
      "Step: 300  \tValid loss: 0.36385247111320496\n",
      "Step: 400  \tTraining loss: 0.34752941131591797\n",
      "Step: 400  \tTraining accuracy: 0.8184918761253357\n",
      "Step: 400  \tValid loss: 0.35874155163764954\n",
      "Step: 500  \tTraining loss: 0.3442137539386749\n",
      "Step: 500  \tTraining accuracy: 0.8224285244941711\n",
      "Step: 500  \tValid loss: 0.3554912805557251\n",
      "Step: 600  \tTraining loss: 0.3418178856372833\n",
      "Step: 600  \tTraining accuracy: 0.8252953886985779\n",
      "Step: 600  \tValid loss: 0.35255807638168335\n",
      "Step: 700  \tTraining loss: 0.3397752642631531\n",
      "Step: 700  \tTraining accuracy: 0.8273821473121643\n",
      "Step: 700  \tValid loss: 0.34981292486190796\n",
      "Step: 800  \tTraining loss: 0.3379451632499695\n",
      "Step: 800  \tTraining accuracy: 0.8289124965667725\n",
      "Step: 800  \tValid loss: 0.3472621738910675\n",
      "Step: 900  \tTraining loss: 0.33626288175582886\n",
      "Step: 900  \tTraining accuracy: 0.8299266695976257\n",
      "Step: 900  \tValid loss: 0.34490716457366943\n",
      "Step: 1000  \tTraining loss: 0.33468562364578247\n",
      "Step: 1000  \tTraining accuracy: 0.8306575417518616\n",
      "Step: 1000  \tValid loss: 0.34272173047065735\n",
      "Step: 1100  \tTraining loss: 0.3331895172595978\n",
      "Step: 1100  \tTraining accuracy: 0.8312492370605469\n",
      "Step: 1100  \tValid loss: 0.3406834006309509\n",
      "Step: 1200  \tTraining loss: 0.3317573666572571\n",
      "Step: 1200  \tTraining accuracy: 0.8320839405059814\n",
      "Step: 1200  \tValid loss: 0.33870500326156616\n",
      "Step: 1300  \tTraining loss: 0.33033204078674316\n",
      "Step: 1300  \tTraining accuracy: 0.8328381776809692\n",
      "Step: 1300  \tValid loss: 0.33673617243766785\n",
      "Step: 1400  \tTraining loss: 0.3289196491241455\n",
      "Step: 1400  \tTraining accuracy: 0.833480715751648\n",
      "Step: 1400  \tValid loss: 0.3348641097545624\n",
      "Step: 1500  \tTraining loss: 0.3275364637374878\n",
      "Step: 1500  \tTraining accuracy: 0.8340345621109009\n",
      "Step: 1500  \tValid loss: 0.3330274820327759\n",
      "Step: 1600  \tTraining loss: 0.3261513411998749\n",
      "Step: 1600  \tTraining accuracy: 0.8346025347709656\n",
      "Step: 1600  \tValid loss: 0.3312494456768036\n",
      "Step: 1700  \tTraining loss: 0.3247532844543457\n",
      "Step: 1700  \tTraining accuracy: 0.8351418972015381\n",
      "Step: 1700  \tValid loss: 0.3294575810432434\n",
      "Step: 1800  \tTraining loss: 0.3233374357223511\n",
      "Step: 1800  \tTraining accuracy: 0.8356574177742004\n",
      "Step: 1800  \tValid loss: 0.3276435136795044\n",
      "Step: 1900  \tTraining loss: 0.32193851470947266\n",
      "Step: 1900  \tTraining accuracy: 0.8361172676086426\n",
      "Step: 1900  \tValid loss: 0.3258565664291382\n",
      "Step: 2000  \tTraining loss: 0.3205426037311554\n",
      "Step: 2000  \tTraining accuracy: 0.8364619612693787\n",
      "Step: 2000  \tValid loss: 0.3241192698478699\n",
      "Step: 2100  \tTraining loss: 0.319145530462265\n",
      "Step: 2100  \tTraining accuracy: 0.836870014667511\n",
      "Step: 2100  \tValid loss: 0.3224370777606964\n",
      "Step: 2200  \tTraining loss: 0.31778767704963684\n",
      "Step: 2200  \tTraining accuracy: 0.837270975112915\n",
      "Step: 2200  \tValid loss: 0.32082563638687134\n",
      "Step: 2300  \tTraining loss: 0.3164430558681488\n",
      "Step: 2300  \tTraining accuracy: 0.8377247452735901\n",
      "Step: 2300  \tValid loss: 0.3192409873008728\n",
      "Step: 2400  \tTraining loss: 0.3151232898235321\n",
      "Step: 2400  \tTraining accuracy: 0.8380833864212036\n",
      "Step: 2400  \tValid loss: 0.3176935911178589\n",
      "Step: 2500  \tTraining loss: 0.3138420879840851\n",
      "Step: 2500  \tTraining accuracy: 0.8384669423103333\n",
      "Step: 2500  \tValid loss: 0.31618615984916687\n",
      "Step: 2600  \tTraining loss: 0.31260135769844055\n",
      "Step: 2600  \tTraining accuracy: 0.8388463854789734\n",
      "Step: 2600  \tValid loss: 0.3147415816783905\n",
      "Step: 2700  \tTraining loss: 0.31138038635253906\n",
      "Step: 2700  \tTraining accuracy: 0.8391472101211548\n",
      "Step: 2700  \tValid loss: 0.31337496638298035\n",
      "Step: 2800  \tTraining loss: 0.3101634383201599\n",
      "Step: 2800  \tTraining accuracy: 0.8394261002540588\n",
      "Step: 2800  \tValid loss: 0.3121495246887207\n",
      "Step: 2900  \tTraining loss: 0.30895349383354187\n",
      "Step: 2900  \tTraining accuracy: 0.8396621346473694\n",
      "Step: 2900  \tValid loss: 0.3110843300819397\n",
      "Step: 3000  \tTraining loss: 0.3077712655067444\n",
      "Step: 3000  \tTraining accuracy: 0.8398597240447998\n",
      "Step: 3000  \tValid loss: 0.31017494201660156\n",
      "Step: 3100  \tTraining loss: 0.30665260553359985\n",
      "Step: 3100  \tTraining accuracy: 0.8400878310203552\n",
      "Step: 3100  \tValid loss: 0.30938059091567993\n",
      "Step: 3200  \tTraining loss: 0.3056109845638275\n",
      "Step: 3200  \tTraining accuracy: 0.8402593731880188\n",
      "Step: 3200  \tValid loss: 0.30852049589157104\n",
      "Step: 3300  \tTraining loss: 0.3046052157878876\n",
      "Step: 3300  \tTraining accuracy: 0.8404407501220703\n",
      "Step: 3300  \tValid loss: 0.3076281249523163\n",
      "Step: 3400  \tTraining loss: 0.303617388010025\n",
      "Step: 3400  \tTraining accuracy: 0.8406310677528381\n",
      "Step: 3400  \tValid loss: 0.30670973658561707\n",
      "Step: 3500  \tTraining loss: 0.30268335342407227\n",
      "Step: 3500  \tTraining accuracy: 0.8407911658287048\n",
      "Step: 3500  \tValid loss: 0.3060213625431061\n",
      "Step: 3600  \tTraining loss: 0.30191466212272644\n",
      "Step: 3600  \tTraining accuracy: 0.8409608602523804\n",
      "Step: 3600  \tValid loss: 0.3052904009819031\n",
      "Step: 3700  \tTraining loss: 0.3012065589427948\n",
      "Step: 3700  \tTraining accuracy: 0.8411213159561157\n",
      "Step: 3700  \tValid loss: 0.30462324619293213\n",
      "Step: 3800  \tTraining loss: 0.3005533516407013\n",
      "Step: 3800  \tTraining accuracy: 0.8412555456161499\n",
      "Step: 3800  \tValid loss: 0.3040178120136261\n",
      "Step: 3900  \tTraining loss: 0.2999468147754669\n",
      "Step: 3900  \tTraining accuracy: 0.8413999676704407\n",
      "Step: 3900  \tValid loss: 0.30348676443099976\n",
      "Step: 4000  \tTraining loss: 0.29940131306648254\n",
      "Step: 4000  \tTraining accuracy: 0.8415539264678955\n",
      "Step: 4000  \tValid loss: 0.30294352769851685\n",
      "Step: 4100  \tTraining loss: 0.2988959848880768\n",
      "Step: 4100  \tTraining accuracy: 0.8417165875434875\n",
      "Step: 4100  \tValid loss: 0.3024260103702545\n",
      "Step: 4200  \tTraining loss: 0.2984226644039154\n",
      "Step: 4200  \tTraining accuracy: 0.8418874144554138\n",
      "Step: 4200  \tValid loss: 0.30196473002433777\n",
      "Step: 4300  \tTraining loss: 0.29798057675361633\n",
      "Step: 4300  \tTraining accuracy: 0.842034637928009\n",
      "Step: 4300  \tValid loss: 0.3015235662460327\n",
      "Step: 4400  \tTraining loss: 0.2975713908672333\n",
      "Step: 4400  \tTraining accuracy: 0.8421903252601624\n",
      "Step: 4400  \tValid loss: 0.3010600805282593\n",
      "Step: 4500  \tTraining loss: 0.29718777537345886\n",
      "Step: 4500  \tTraining accuracy: 0.8423389792442322\n",
      "Step: 4500  \tValid loss: 0.3006120026111603\n",
      "Step: 4600  \tTraining loss: 0.2968258857727051\n",
      "Step: 4600  \tTraining accuracy: 0.8424665331840515\n",
      "Step: 4600  \tValid loss: 0.3002198040485382\n",
      "Step: 4700  \tTraining loss: 0.29645976424217224\n",
      "Step: 4700  \tTraining accuracy: 0.8426171541213989\n",
      "Step: 4700  \tValid loss: 0.2998567521572113\n",
      "Step: 4800  \tTraining loss: 0.2961154282093048\n",
      "Step: 4800  \tTraining accuracy: 0.8427474498748779\n",
      "Step: 4800  \tValid loss: 0.2995714843273163\n",
      "Step: 4900  \tTraining loss: 0.29578298330307007\n",
      "Step: 4900  \tTraining accuracy: 0.8428723812103271\n",
      "Step: 4900  \tValid loss: 0.2992597818374634\n",
      "Step: 5000  \tTraining loss: 0.2954539358615875\n",
      "Step: 5000  \tTraining accuracy: 0.8430056571960449\n",
      "Step: 5000  \tValid loss: 0.29898330569267273\n",
      "Step: 5100  \tTraining loss: 0.2951168715953827\n",
      "Step: 5100  \tTraining accuracy: 0.8431205153465271\n",
      "Step: 5100  \tValid loss: 0.29871490597724915\n",
      "Step: 5200  \tTraining loss: 0.29473552107810974\n",
      "Step: 5200  \tTraining accuracy: 0.8432437777519226\n",
      "Step: 5200  \tValid loss: 0.29839450120925903\n",
      "Step: 5300  \tTraining loss: 0.29425859451293945\n",
      "Step: 5300  \tTraining accuracy: 0.843375027179718\n",
      "Step: 5300  \tValid loss: 0.29792097210884094\n",
      "Step: 5400  \tTraining loss: 0.2938336133956909\n",
      "Step: 5400  \tTraining accuracy: 0.8434765338897705\n",
      "Step: 5400  \tValid loss: 0.29754838347435\n",
      "Step: 5500  \tTraining loss: 0.29339340329170227\n",
      "Step: 5500  \tTraining accuracy: 0.8436351418495178\n",
      "Step: 5500  \tValid loss: 0.2972359359264374\n",
      "Step: 5600  \tTraining loss: 0.292948842048645\n",
      "Step: 5600  \tTraining accuracy: 0.8437880873680115\n",
      "Step: 5600  \tValid loss: 0.29687997698783875\n",
      "Step: 5700  \tTraining loss: 0.29256319999694824\n",
      "Step: 5700  \tTraining accuracy: 0.8439356088638306\n",
      "Step: 5700  \tValid loss: 0.2966547906398773\n",
      "Step: 5800  \tTraining loss: 0.2922060191631317\n",
      "Step: 5800  \tTraining accuracy: 0.8440664410591125\n",
      "Step: 5800  \tValid loss: 0.2964324653148651\n",
      "Step: 5900  \tTraining loss: 0.29187530279159546\n",
      "Step: 5900  \tTraining accuracy: 0.844181478023529\n",
      "Step: 5900  \tValid loss: 0.29622310400009155\n",
      "Step: 6000  \tTraining loss: 0.29156583547592163\n",
      "Step: 6000  \tTraining accuracy: 0.8442703485488892\n",
      "Step: 6000  \tValid loss: 0.29608410596847534\n",
      "Step: 6100  \tTraining loss: 0.2912667989730835\n",
      "Step: 6100  \tTraining accuracy: 0.8443672060966492\n",
      "Step: 6100  \tValid loss: 0.29594606161117554\n",
      "Step: 6200  \tTraining loss: 0.2909785807132721\n",
      "Step: 6200  \tTraining accuracy: 0.8444609642028809\n",
      "Step: 6200  \tValid loss: 0.29579633474349976\n",
      "Step: 6300  \tTraining loss: 0.29069578647613525\n",
      "Step: 6300  \tTraining accuracy: 0.8445411324501038\n",
      "Step: 6300  \tValid loss: 0.2956547439098358\n",
      "Step: 6400  \tTraining loss: 0.29041731357574463\n",
      "Step: 6400  \tTraining accuracy: 0.8446395993232727\n",
      "Step: 6400  \tValid loss: 0.295530766248703\n",
      "Step: 6500  \tTraining loss: 0.29013699293136597\n",
      "Step: 6500  \tTraining accuracy: 0.8447350859642029\n",
      "Step: 6500  \tValid loss: 0.2954546809196472\n",
      "Step: 6600  \tTraining loss: 0.2898641526699066\n",
      "Step: 6600  \tTraining accuracy: 0.8448377251625061\n",
      "Step: 6600  \tValid loss: 0.2954167127609253\n",
      "Step: 6700  \tTraining loss: 0.2896025478839874\n",
      "Step: 6700  \tTraining accuracy: 0.844937264919281\n",
      "Step: 6700  \tValid loss: 0.2953689992427826\n",
      "Step: 6800  \tTraining loss: 0.28935113549232483\n",
      "Step: 6800  \tTraining accuracy: 0.8450535535812378\n",
      "Step: 6800  \tValid loss: 0.29533621668815613\n",
      "Step: 6900  \tTraining loss: 0.2891119122505188\n",
      "Step: 6900  \tTraining accuracy: 0.845137357711792\n",
      "Step: 6900  \tValid loss: 0.2953091561794281\n",
      "Step: 7000  \tTraining loss: 0.28888288140296936\n",
      "Step: 7000  \tTraining accuracy: 0.8452092409133911\n",
      "Step: 7000  \tValid loss: 0.2952820956707001\n",
      "Step: 7100  \tTraining loss: 0.2886640429496765\n",
      "Step: 7100  \tTraining accuracy: 0.8452790975570679\n",
      "Step: 7100  \tValid loss: 0.29526713490486145\n",
      "Step: 7200  \tTraining loss: 0.28845271468162537\n",
      "Step: 7200  \tTraining accuracy: 0.845346987247467\n",
      "Step: 7200  \tValid loss: 0.2952667474746704\n",
      "Step: 7300  \tTraining loss: 0.2882491946220398\n",
      "Step: 7300  \tTraining accuracy: 0.8454312682151794\n",
      "Step: 7300  \tValid loss: 0.29526421427726746\n",
      "Step: 7400  \tTraining loss: 0.2880515158176422\n",
      "Step: 7400  \tTraining accuracy: 0.8455132842063904\n",
      "Step: 7400  \tValid loss: 0.29526570439338684\n",
      "Step: 7500  \tTraining loss: 0.28786012530326843\n",
      "Step: 7500  \tTraining accuracy: 0.8455841541290283\n",
      "Step: 7500  \tValid loss: 0.2953014075756073\n",
      "Step: 7600  \tTraining loss: 0.2876758277416229\n",
      "Step: 7600  \tTraining accuracy: 0.845661997795105\n",
      "Step: 7600  \tValid loss: 0.2953348457813263\n",
      "Step: 7700  \tTraining loss: 0.287494033575058\n",
      "Step: 7700  \tTraining accuracy: 0.8457204103469849\n",
      "Step: 7700  \tValid loss: 0.29539063572883606\n",
      "Step: 7800  \tTraining loss: 0.2873210608959198\n",
      "Step: 7800  \tTraining accuracy: 0.8457773327827454\n",
      "Step: 7800  \tValid loss: 0.2954346835613251\n",
      "Step: 7900  \tTraining loss: 0.2871546745300293\n",
      "Step: 7900  \tTraining accuracy: 0.8458412885665894\n",
      "Step: 7900  \tValid loss: 0.2954903244972229\n",
      "Step: 8000  \tTraining loss: 0.2869884669780731\n",
      "Step: 8000  \tTraining accuracy: 0.8459036350250244\n",
      "Step: 8000  \tValid loss: 0.29555821418762207\n",
      "Step: 8100  \tTraining loss: 0.28682780265808105\n",
      "Step: 8100  \tTraining accuracy: 0.8459561467170715\n",
      "Step: 8100  \tValid loss: 0.2956322431564331\n",
      "Step: 8200  \tTraining loss: 0.2866727113723755\n",
      "Step: 8200  \tTraining accuracy: 0.8459911346435547\n",
      "Step: 8200  \tValid loss: 0.2957281768321991\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8460333\n",
      "Precision: 0.6721311\n",
      "Recall: 0.70689654\n",
      "F1 score: 0.8673619\n",
      "AUC: 0.80172414\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.846033   0.672131  0.706897  0.867362  0.801724  0.286584      0.845992   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.295245       0.846008   0.272243      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  8258.0  \n",
      "12\n",
      "(754, 8)\n",
      "(754, 1)\n",
      "(400, 8)\n",
      "(400, 1)\n",
      "(325, 8)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5236255526542664\n",
      "Step: 100  \tTraining accuracy: 0.7334217429161072\n",
      "Step: 100  \tValid loss: 0.5518247485160828\n",
      "Step: 200  \tTraining loss: 0.46252959966659546\n",
      "Step: 200  \tTraining accuracy: 0.7335423231124878\n",
      "Step: 200  \tValid loss: 0.5018756985664368\n",
      "Step: 300  \tTraining loss: 0.4386754035949707\n",
      "Step: 300  \tTraining accuracy: 0.7440732717514038\n",
      "Step: 300  \tValid loss: 0.4847293794155121\n",
      "Step: 400  \tTraining loss: 0.42257076501846313\n",
      "Step: 400  \tTraining accuracy: 0.7541899681091309\n",
      "Step: 400  \tValid loss: 0.46944335103034973\n",
      "Step: 500  \tTraining loss: 0.4094085693359375\n",
      "Step: 500  \tTraining accuracy: 0.7614692449569702\n",
      "Step: 500  \tValid loss: 0.45599788427352905\n",
      "Step: 600  \tTraining loss: 0.3992080092430115\n",
      "Step: 600  \tTraining accuracy: 0.7664744257926941\n",
      "Step: 600  \tValid loss: 0.4458959102630615\n",
      "Step: 700  \tTraining loss: 0.39129161834716797\n",
      "Step: 700  \tTraining accuracy: 0.7710843086242676\n",
      "Step: 700  \tValid loss: 0.4378982186317444\n",
      "Step: 800  \tTraining loss: 0.3848413825035095\n",
      "Step: 800  \tTraining accuracy: 0.7755469679832458\n",
      "Step: 800  \tValid loss: 0.431192547082901\n",
      "Step: 900  \tTraining loss: 0.37960633635520935\n",
      "Step: 900  \tTraining accuracy: 0.7801525592803955\n",
      "Step: 900  \tValid loss: 0.4258381128311157\n",
      "Step: 1000  \tTraining loss: 0.37532809376716614\n",
      "Step: 1000  \tTraining accuracy: 0.7842161655426025\n",
      "Step: 1000  \tValid loss: 0.42151597142219543\n",
      "Step: 1100  \tTraining loss: 0.3717840909957886\n",
      "Step: 1100  \tTraining accuracy: 0.7879567742347717\n",
      "Step: 1100  \tValid loss: 0.4180103540420532\n",
      "Step: 1200  \tTraining loss: 0.3687794804573059\n",
      "Step: 1200  \tTraining accuracy: 0.7912236452102661\n",
      "Step: 1200  \tValid loss: 0.41504815220832825\n",
      "Step: 1300  \tTraining loss: 0.3662053942680359\n",
      "Step: 1300  \tTraining accuracy: 0.794022262096405\n",
      "Step: 1300  \tValid loss: 0.4128085672855377\n",
      "Step: 1400  \tTraining loss: 0.36401262879371643\n",
      "Step: 1400  \tTraining accuracy: 0.7964566349983215\n",
      "Step: 1400  \tValid loss: 0.4105582535266876\n",
      "Step: 1500  \tTraining loss: 0.36209702491760254\n",
      "Step: 1500  \tTraining accuracy: 0.7986486554145813\n",
      "Step: 1500  \tValid loss: 0.40844622254371643\n",
      "Step: 1600  \tTraining loss: 0.3604218661785126\n",
      "Step: 1600  \tTraining accuracy: 0.800601601600647\n",
      "Step: 1600  \tValid loss: 0.40667060017585754\n",
      "Step: 1700  \tTraining loss: 0.35895511507987976\n",
      "Step: 1700  \tTraining accuracy: 0.8022770285606384\n",
      "Step: 1700  \tValid loss: 0.4052000045776367\n",
      "Step: 1800  \tTraining loss: 0.3576692044734955\n",
      "Step: 1800  \tTraining accuracy: 0.8037996888160706\n",
      "Step: 1800  \tValid loss: 0.40397003293037415\n",
      "Step: 1900  \tTraining loss: 0.35653191804885864\n",
      "Step: 1900  \tTraining accuracy: 0.8051943182945251\n",
      "Step: 1900  \tValid loss: 0.4029407501220703\n",
      "Step: 2000  \tTraining loss: 0.3555121421813965\n",
      "Step: 2000  \tTraining accuracy: 0.8063766956329346\n",
      "Step: 2000  \tValid loss: 0.40203750133514404\n",
      "Step: 2100  \tTraining loss: 0.3545790910720825\n",
      "Step: 2100  \tTraining accuracy: 0.8074437975883484\n",
      "Step: 2100  \tValid loss: 0.4012969732284546\n",
      "Step: 2200  \tTraining loss: 0.35370585322380066\n",
      "Step: 2200  \tTraining accuracy: 0.8084430694580078\n",
      "Step: 2200  \tValid loss: 0.4006582498550415\n",
      "Step: 2300  \tTraining loss: 0.3528749942779541\n",
      "Step: 2300  \tTraining accuracy: 0.8093836307525635\n",
      "Step: 2300  \tValid loss: 0.4001011252403259\n",
      "Step: 2400  \tTraining loss: 0.3520771265029907\n",
      "Step: 2400  \tTraining accuracy: 0.8102441430091858\n",
      "Step: 2400  \tValid loss: 0.3996357321739197\n",
      "Step: 2500  \tTraining loss: 0.3513053357601166\n",
      "Step: 2500  \tTraining accuracy: 0.8110896348953247\n",
      "Step: 2500  \tValid loss: 0.39921700954437256\n",
      "Step: 2600  \tTraining loss: 0.35056063532829285\n",
      "Step: 2600  \tTraining accuracy: 0.8118953704833984\n",
      "Step: 2600  \tValid loss: 0.39891234040260315\n",
      "Step: 2700  \tTraining loss: 0.34984290599823\n",
      "Step: 2700  \tTraining accuracy: 0.8126147985458374\n",
      "Step: 2700  \tValid loss: 0.39865121245384216\n",
      "Step: 2800  \tTraining loss: 0.3491372764110565\n",
      "Step: 2800  \tTraining accuracy: 0.8132572770118713\n",
      "Step: 2800  \tValid loss: 0.39844024181365967\n",
      "Step: 2900  \tTraining loss: 0.348452627658844\n",
      "Step: 2900  \tTraining accuracy: 0.8138547539710999\n",
      "Step: 2900  \tValid loss: 0.3983200192451477\n",
      "Step: 3000  \tTraining loss: 0.34780406951904297\n",
      "Step: 3000  \tTraining accuracy: 0.8145033717155457\n",
      "Step: 3000  \tValid loss: 0.39815157651901245\n",
      "Step: 3100  \tTraining loss: 0.34719422459602356\n",
      "Step: 3100  \tTraining accuracy: 0.815131664276123\n",
      "Step: 3100  \tValid loss: 0.3979773223400116\n",
      "Step: 3200  \tTraining loss: 0.3466224670410156\n",
      "Step: 3200  \tTraining accuracy: 0.8157200217247009\n",
      "Step: 3200  \tValid loss: 0.39782196283340454\n",
      "Step: 3300  \tTraining loss: 0.3461017608642578\n",
      "Step: 3300  \tTraining accuracy: 0.81633460521698\n",
      "Step: 3300  \tValid loss: 0.39766377210617065\n",
      "Step: 3400  \tTraining loss: 0.34558072686195374\n",
      "Step: 3400  \tTraining accuracy: 0.8169528245925903\n",
      "Step: 3400  \tValid loss: 0.39753487706184387\n",
      "Step: 3500  \tTraining loss: 0.34501320123672485\n",
      "Step: 3500  \tTraining accuracy: 0.8175352811813354\n",
      "Step: 3500  \tValid loss: 0.39715123176574707\n",
      "Step: 3600  \tTraining loss: 0.34452003240585327\n",
      "Step: 3600  \tTraining accuracy: 0.8180658221244812\n",
      "Step: 3600  \tValid loss: 0.39689692854881287\n",
      "Step: 3700  \tTraining loss: 0.34408941864967346\n",
      "Step: 3700  \tTraining accuracy: 0.8185673356056213\n",
      "Step: 3700  \tValid loss: 0.3967817723751068\n",
      "Step: 3800  \tTraining loss: 0.34368330240249634\n",
      "Step: 3800  \tTraining accuracy: 0.8190601468086243\n",
      "Step: 3800  \tValid loss: 0.3966945707798004\n",
      "Step: 3900  \tTraining loss: 0.3433004915714264\n",
      "Step: 3900  \tTraining accuracy: 0.8195098042488098\n",
      "Step: 3900  \tValid loss: 0.3966291844844818\n",
      "Step: 4000  \tTraining loss: 0.3429364264011383\n",
      "Step: 4000  \tTraining accuracy: 0.8199366927146912\n",
      "Step: 4000  \tValid loss: 0.3965766131877899\n",
      "Step: 4100  \tTraining loss: 0.342603474855423\n",
      "Step: 4100  \tTraining accuracy: 0.8203591704368591\n",
      "Step: 4100  \tValid loss: 0.3966018259525299\n",
      "Step: 4200  \tTraining loss: 0.3422847092151642\n",
      "Step: 4200  \tTraining accuracy: 0.8207775950431824\n",
      "Step: 4200  \tValid loss: 0.39665931463241577\n",
      "Step: 4300  \tTraining loss: 0.3419654071331024\n",
      "Step: 4300  \tTraining accuracy: 0.8211922645568848\n",
      "Step: 4300  \tValid loss: 0.3967018127441406\n",
      "Step: 4400  \tTraining loss: 0.3416701555252075\n",
      "Step: 4400  \tTraining accuracy: 0.821587860584259\n",
      "Step: 4400  \tValid loss: 0.3967271149158478\n",
      "Step: 4500  \tTraining loss: 0.34139302372932434\n",
      "Step: 4500  \tTraining accuracy: 0.8219656944274902\n",
      "Step: 4500  \tValid loss: 0.3967585265636444\n",
      "Step: 4600  \tTraining loss: 0.3411334156990051\n",
      "Step: 4600  \tTraining accuracy: 0.8222971558570862\n",
      "Step: 4600  \tValid loss: 0.3968062698841095\n",
      "Step: 4700  \tTraining loss: 0.34088701009750366\n",
      "Step: 4700  \tTraining accuracy: 0.82257080078125\n",
      "Step: 4700  \tValid loss: 0.396859347820282\n",
      "Step: 4800  \tTraining loss: 0.340614378452301\n",
      "Step: 4800  \tTraining accuracy: 0.8228328824043274\n",
      "Step: 4800  \tValid loss: 0.3968726694583893\n",
      "Step: 4900  \tTraining loss: 0.34036052227020264\n",
      "Step: 4900  \tTraining accuracy: 0.8230842351913452\n",
      "Step: 4900  \tValid loss: 0.3969396948814392\n",
      "Step: 5000  \tTraining loss: 0.3401122987270355\n",
      "Step: 5000  \tTraining accuracy: 0.82333904504776\n",
      "Step: 5000  \tValid loss: 0.39707323908805847\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8235837\n",
      "Precision: 0.8717504\n",
      "Recall: 0.9095841\n",
      "F1 score: 0.84107584\n",
      "AUC: 0.77071244\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.823584    0.87175  0.909584  0.841076  0.770712  0.340076      0.823462   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.396567       0.823426   0.404958      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5014.0  \n",
      "13\n",
      "(957, 8)\n",
      "(957, 1)\n",
      "(528, 8)\n",
      "(528, 1)\n",
      "(429, 8)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5958056449890137\n",
      "Step: 100  \tTraining accuracy: 0.6823406219482422\n",
      "Step: 100  \tValid loss: 0.6352578401565552\n",
      "Step: 200  \tTraining loss: 0.4808974862098694\n",
      "Step: 200  \tTraining accuracy: 0.7056774497032166\n",
      "Step: 200  \tValid loss: 0.5300644636154175\n",
      "Step: 300  \tTraining loss: 0.38829514384269714\n",
      "Step: 300  \tTraining accuracy: 0.7431557178497314\n",
      "Step: 300  \tValid loss: 0.4227105975151062\n",
      "Step: 400  \tTraining loss: 0.34916985034942627\n",
      "Step: 400  \tTraining accuracy: 0.7716076970100403\n",
      "Step: 400  \tValid loss: 0.3760139048099518\n",
      "Step: 500  \tTraining loss: 0.3323134779930115\n",
      "Step: 500  \tTraining accuracy: 0.7902008295059204\n",
      "Step: 500  \tValid loss: 0.35505184531211853\n",
      "Step: 600  \tTraining loss: 0.3242848813533783\n",
      "Step: 600  \tTraining accuracy: 0.8035527467727661\n",
      "Step: 600  \tValid loss: 0.3448895812034607\n",
      "Step: 700  \tTraining loss: 0.3201356828212738\n",
      "Step: 700  \tTraining accuracy: 0.8128767609596252\n",
      "Step: 700  \tValid loss: 0.3394368588924408\n",
      "Step: 800  \tTraining loss: 0.31760865449905396\n",
      "Step: 800  \tTraining accuracy: 0.819714367389679\n",
      "Step: 800  \tValid loss: 0.3359786570072174\n",
      "Step: 900  \tTraining loss: 0.3158688545227051\n",
      "Step: 900  \tTraining accuracy: 0.8249431252479553\n",
      "Step: 900  \tValid loss: 0.33427155017852783\n",
      "Step: 1000  \tTraining loss: 0.31465578079223633\n",
      "Step: 1000  \tTraining accuracy: 0.8291810750961304\n",
      "Step: 1000  \tValid loss: 0.3331770598888397\n",
      "Step: 1100  \tTraining loss: 0.31375837326049805\n",
      "Step: 1100  \tTraining accuracy: 0.8327611088752747\n",
      "Step: 1100  \tValid loss: 0.3320399820804596\n",
      "Step: 1200  \tTraining loss: 0.3130344748497009\n",
      "Step: 1200  \tTraining accuracy: 0.8358093500137329\n",
      "Step: 1200  \tValid loss: 0.3310815691947937\n",
      "Step: 1300  \tTraining loss: 0.3124333918094635\n",
      "Step: 1300  \tTraining accuracy: 0.8383281230926514\n",
      "Step: 1300  \tValid loss: 0.3303142786026001\n",
      "Step: 1400  \tTraining loss: 0.3118983209133148\n",
      "Step: 1400  \tTraining accuracy: 0.8405510783195496\n",
      "Step: 1400  \tValid loss: 0.3296367824077606\n",
      "Step: 1500  \tTraining loss: 0.3114069104194641\n",
      "Step: 1500  \tTraining accuracy: 0.8425395488739014\n",
      "Step: 1500  \tValid loss: 0.3290494680404663\n",
      "Step: 1600  \tTraining loss: 0.3109482228755951\n",
      "Step: 1600  \tTraining accuracy: 0.8442714214324951\n",
      "Step: 1600  \tValid loss: 0.328511506319046\n",
      "Step: 1700  \tTraining loss: 0.31052151322364807\n",
      "Step: 1700  \tTraining accuracy: 0.8458250164985657\n",
      "Step: 1700  \tValid loss: 0.32809653878211975\n",
      "Step: 1800  \tTraining loss: 0.3101106286048889\n",
      "Step: 1800  \tTraining accuracy: 0.8472309112548828\n",
      "Step: 1800  \tValid loss: 0.32780247926712036\n",
      "Step: 1900  \tTraining loss: 0.30969691276550293\n",
      "Step: 1900  \tTraining accuracy: 0.8485695719718933\n",
      "Step: 1900  \tValid loss: 0.32755938172340393\n",
      "Step: 2000  \tTraining loss: 0.30926448106765747\n",
      "Step: 2000  \tTraining accuracy: 0.8497441411018372\n",
      "Step: 2000  \tValid loss: 0.3275575041770935\n",
      "Step: 2100  \tTraining loss: 0.3087928593158722\n",
      "Step: 2100  \tTraining accuracy: 0.8508040904998779\n",
      "Step: 2100  \tValid loss: 0.3276408314704895\n",
      "Step: 2200  \tTraining loss: 0.30829331278800964\n",
      "Step: 2200  \tTraining accuracy: 0.8517654538154602\n",
      "Step: 2200  \tValid loss: 0.32776758074760437\n",
      "Step: 2300  \tTraining loss: 0.3078014850616455\n",
      "Step: 2300  \tTraining accuracy: 0.8526413440704346\n",
      "Step: 2300  \tValid loss: 0.32781243324279785\n",
      "Step: 2400  \tTraining loss: 0.30732378363609314\n",
      "Step: 2400  \tTraining accuracy: 0.8534204959869385\n",
      "Step: 2400  \tValid loss: 0.3278998136520386\n",
      "Step: 2500  \tTraining loss: 0.3068722188472748\n",
      "Step: 2500  \tTraining accuracy: 0.8541573286056519\n",
      "Step: 2500  \tValid loss: 0.32799431681632996\n",
      "Step: 2600  \tTraining loss: 0.3064076602458954\n",
      "Step: 2600  \tTraining accuracy: 0.8548773527145386\n",
      "Step: 2600  \tValid loss: 0.3284277617931366\n",
      "Step: 2700  \tTraining loss: 0.3060063421726227\n",
      "Step: 2700  \tTraining accuracy: 0.8555628061294556\n",
      "Step: 2700  \tValid loss: 0.3286578953266144\n",
      "Step: 2800  \tTraining loss: 0.30557286739349365\n",
      "Step: 2800  \tTraining accuracy: 0.8562173247337341\n",
      "Step: 2800  \tValid loss: 0.3288056552410126\n",
      "Step: 2900  \tTraining loss: 0.3051365911960602\n",
      "Step: 2900  \tTraining accuracy: 0.8568259477615356\n",
      "Step: 2900  \tValid loss: 0.3292025327682495\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.857411\n",
      "Precision: 0.89248896\n",
      "Recall: 0.92802453\n",
      "F1 score: 0.8741473\n",
      "AUC: 0.84394646\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.857411   0.892489  0.928025  0.874147  0.843946  0.305014      0.857115   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.327516        0.85707   0.287738      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2931.0  \n",
      "14\n",
      "(1798, 8)\n",
      "(1798, 1)\n",
      "(992, 8)\n",
      "(992, 1)\n",
      "(806, 8)\n",
      "(806, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5971552133560181\n",
      "Step: 100  \tTraining accuracy: 0.7091212272644043\n",
      "Step: 100  \tValid loss: 0.6128835082054138\n",
      "Step: 200  \tTraining loss: 0.5391019582748413\n",
      "Step: 200  \tTraining accuracy: 0.7078235149383545\n",
      "Step: 200  \tValid loss: 0.5800381898880005\n",
      "Step: 300  \tTraining loss: 0.5055748224258423\n",
      "Step: 300  \tTraining accuracy: 0.7157953381538391\n",
      "Step: 300  \tValid loss: 0.5480892062187195\n",
      "Step: 400  \tTraining loss: 0.47190412878990173\n",
      "Step: 400  \tTraining accuracy: 0.7251708507537842\n",
      "Step: 400  \tValid loss: 0.5169981718063354\n",
      "Step: 500  \tTraining loss: 0.4448571503162384\n",
      "Step: 500  \tTraining accuracy: 0.733963668346405\n",
      "Step: 500  \tValid loss: 0.4915849566459656\n",
      "Step: 600  \tTraining loss: 0.425889790058136\n",
      "Step: 600  \tTraining accuracy: 0.7421377301216125\n",
      "Step: 600  \tValid loss: 0.4748235046863556\n",
      "Step: 700  \tTraining loss: 0.413621187210083\n",
      "Step: 700  \tTraining accuracy: 0.7497646808624268\n",
      "Step: 700  \tValid loss: 0.46421703696250916\n",
      "Step: 800  \tTraining loss: 0.40574976801872253\n",
      "Step: 800  \tTraining accuracy: 0.7564330697059631\n",
      "Step: 800  \tValid loss: 0.45734983682632446\n",
      "Step: 900  \tTraining loss: 0.40071171522140503\n",
      "Step: 900  \tTraining accuracy: 0.7621540427207947\n",
      "Step: 900  \tValid loss: 0.45280370116233826\n",
      "Step: 1000  \tTraining loss: 0.3973791003227234\n",
      "Step: 1000  \tTraining accuracy: 0.7667291164398193\n",
      "Step: 1000  \tValid loss: 0.44976678490638733\n",
      "Step: 1100  \tTraining loss: 0.39512431621551514\n",
      "Step: 1100  \tTraining accuracy: 0.7706181406974792\n",
      "Step: 1100  \tValid loss: 0.44756531715393066\n",
      "Step: 1200  \tTraining loss: 0.3935275077819824\n",
      "Step: 1200  \tTraining accuracy: 0.7739033699035645\n",
      "Step: 1200  \tValid loss: 0.44589176774024963\n",
      "Step: 1300  \tTraining loss: 0.39234498143196106\n",
      "Step: 1300  \tTraining accuracy: 0.776618480682373\n",
      "Step: 1300  \tValid loss: 0.4445214867591858\n",
      "Step: 1400  \tTraining loss: 0.3914121091365814\n",
      "Step: 1400  \tTraining accuracy: 0.7790755033493042\n",
      "Step: 1400  \tValid loss: 0.4434523284435272\n",
      "Step: 1500  \tTraining loss: 0.390621542930603\n",
      "Step: 1500  \tTraining accuracy: 0.7812703847885132\n",
      "Step: 1500  \tValid loss: 0.4425552189350128\n",
      "Step: 1600  \tTraining loss: 0.38992607593536377\n",
      "Step: 1600  \tTraining accuracy: 0.7831282019615173\n",
      "Step: 1600  \tValid loss: 0.4416563808917999\n",
      "Step: 1700  \tTraining loss: 0.3892924189567566\n",
      "Step: 1700  \tTraining accuracy: 0.784727156162262\n",
      "Step: 1700  \tValid loss: 0.44086387753486633\n",
      "Step: 1800  \tTraining loss: 0.38871145248413086\n",
      "Step: 1800  \tTraining accuracy: 0.7862545847892761\n",
      "Step: 1800  \tValid loss: 0.439920574426651\n",
      "Step: 1900  \tTraining loss: 0.3881569504737854\n",
      "Step: 1900  \tTraining accuracy: 0.7876920104026794\n",
      "Step: 1900  \tValid loss: 0.4390679597854614\n",
      "Step: 2000  \tTraining loss: 0.3876117169857025\n",
      "Step: 2000  \tTraining accuracy: 0.7890105843544006\n",
      "Step: 2000  \tValid loss: 0.43816524744033813\n",
      "Step: 2100  \tTraining loss: 0.38705307245254517\n",
      "Step: 2100  \tTraining accuracy: 0.7902140617370605\n",
      "Step: 2100  \tValid loss: 0.43723195791244507\n",
      "Step: 2200  \tTraining loss: 0.3864147365093231\n",
      "Step: 2200  \tTraining accuracy: 0.791292667388916\n",
      "Step: 2200  \tValid loss: 0.4361545443534851\n",
      "Step: 2300  \tTraining loss: 0.3855125308036804\n",
      "Step: 2300  \tTraining accuracy: 0.7922877073287964\n",
      "Step: 2300  \tValid loss: 0.43480029702186584\n",
      "Step: 2400  \tTraining loss: 0.38438570499420166\n",
      "Step: 2400  \tTraining accuracy: 0.793150782585144\n",
      "Step: 2400  \tValid loss: 0.4333548843860626\n",
      "Step: 2500  \tTraining loss: 0.38342782855033875\n",
      "Step: 2500  \tTraining accuracy: 0.7939547300338745\n",
      "Step: 2500  \tValid loss: 0.4322086572647095\n",
      "Step: 2600  \tTraining loss: 0.3826257288455963\n",
      "Step: 2600  \tTraining accuracy: 0.7947283387184143\n",
      "Step: 2600  \tValid loss: 0.4315738081932068\n",
      "Step: 2700  \tTraining loss: 0.3818836212158203\n",
      "Step: 2700  \tTraining accuracy: 0.7954645752906799\n",
      "Step: 2700  \tValid loss: 0.43115514516830444\n",
      "Step: 2800  \tTraining loss: 0.3812263607978821\n",
      "Step: 2800  \tTraining accuracy: 0.7961674332618713\n",
      "Step: 2800  \tValid loss: 0.43072187900543213\n",
      "Step: 2900  \tTraining loss: 0.38062727451324463\n",
      "Step: 2900  \tTraining accuracy: 0.7968210577964783\n",
      "Step: 2900  \tValid loss: 0.4302927553653717\n",
      "Step: 3000  \tTraining loss: 0.38006407022476196\n",
      "Step: 3000  \tTraining accuracy: 0.7974491715431213\n",
      "Step: 3000  \tValid loss: 0.4298518896102905\n",
      "Step: 3100  \tTraining loss: 0.3795364797115326\n",
      "Step: 3100  \tTraining accuracy: 0.7980542778968811\n",
      "Step: 3100  \tValid loss: 0.4295352101325989\n",
      "Step: 3200  \tTraining loss: 0.3790360689163208\n",
      "Step: 3200  \tTraining accuracy: 0.7986210584640503\n",
      "Step: 3200  \tValid loss: 0.4292198419570923\n",
      "Step: 3300  \tTraining loss: 0.378561794757843\n",
      "Step: 3300  \tTraining accuracy: 0.799161434173584\n",
      "Step: 3300  \tValid loss: 0.4289472699165344\n",
      "Step: 3400  \tTraining loss: 0.378068745136261\n",
      "Step: 3400  \tTraining accuracy: 0.7996529936790466\n",
      "Step: 3400  \tValid loss: 0.42854562401771545\n",
      "Step: 3500  \tTraining loss: 0.37755149602890015\n",
      "Step: 3500  \tTraining accuracy: 0.8001483082771301\n",
      "Step: 3500  \tValid loss: 0.42808797955513\n",
      "Step: 3600  \tTraining loss: 0.3770315945148468\n",
      "Step: 3600  \tTraining accuracy: 0.8006157279014587\n",
      "Step: 3600  \tValid loss: 0.4276668131351471\n",
      "Step: 3700  \tTraining loss: 0.37653788924217224\n",
      "Step: 3700  \tTraining accuracy: 0.8010803461074829\n",
      "Step: 3700  \tValid loss: 0.42734405398368835\n",
      "Step: 3800  \tTraining loss: 0.3760644197463989\n",
      "Step: 3800  \tTraining accuracy: 0.8015276193618774\n",
      "Step: 3800  \tValid loss: 0.4270840287208557\n",
      "Step: 3900  \tTraining loss: 0.37560272216796875\n",
      "Step: 3900  \tTraining accuracy: 0.8019516468048096\n",
      "Step: 3900  \tValid loss: 0.42685213685035706\n",
      "Step: 4000  \tTraining loss: 0.3751506209373474\n",
      "Step: 4000  \tTraining accuracy: 0.802361249923706\n",
      "Step: 4000  \tValid loss: 0.426612913608551\n",
      "Step: 4100  \tTraining loss: 0.3747119903564453\n",
      "Step: 4100  \tTraining accuracy: 0.8027575016021729\n",
      "Step: 4100  \tValid loss: 0.42640307545661926\n",
      "Step: 4200  \tTraining loss: 0.3741781413555145\n",
      "Step: 4200  \tTraining accuracy: 0.8031547665596008\n",
      "Step: 4200  \tValid loss: 0.426217257976532\n",
      "Step: 4300  \tTraining loss: 0.373704731464386\n",
      "Step: 4300  \tTraining accuracy: 0.8035268187522888\n",
      "Step: 4300  \tValid loss: 0.4259711802005768\n",
      "Step: 4400  \tTraining loss: 0.37326285243034363\n",
      "Step: 4400  \tTraining accuracy: 0.8038817048072815\n",
      "Step: 4400  \tValid loss: 0.42584505677223206\n",
      "Step: 4500  \tTraining loss: 0.3728446960449219\n",
      "Step: 4500  \tTraining accuracy: 0.8042206764221191\n",
      "Step: 4500  \tValid loss: 0.42573314905166626\n",
      "Step: 4600  \tTraining loss: 0.3724568486213684\n",
      "Step: 4600  \tTraining accuracy: 0.8045569658279419\n",
      "Step: 4600  \tValid loss: 0.42565926909446716\n",
      "Step: 4700  \tTraining loss: 0.3720908761024475\n",
      "Step: 4700  \tTraining accuracy: 0.8048967123031616\n",
      "Step: 4700  \tValid loss: 0.42568403482437134\n",
      "Step: 4800  \tTraining loss: 0.37174633145332336\n",
      "Step: 4800  \tTraining accuracy: 0.8052163124084473\n",
      "Step: 4800  \tValid loss: 0.42577651143074036\n",
      "Step: 4900  \tTraining loss: 0.37141913175582886\n",
      "Step: 4900  \tTraining accuracy: 0.8055227398872375\n",
      "Step: 4900  \tValid loss: 0.42588183283805847\n",
      "Step: 5000  \tTraining loss: 0.3711118996143341\n",
      "Step: 5000  \tTraining accuracy: 0.8058224320411682\n",
      "Step: 5000  \tValid loss: 0.4259914755821228\n",
      "Step: 5100  \tTraining loss: 0.370819091796875\n",
      "Step: 5100  \tTraining accuracy: 0.8061102032661438\n",
      "Step: 5100  \tValid loss: 0.4261007606983185\n",
      "Step: 5200  \tTraining loss: 0.3705393373966217\n",
      "Step: 5200  \tTraining accuracy: 0.8063814043998718\n",
      "Step: 5200  \tValid loss: 0.4261913299560547\n",
      "Step: 5300  \tTraining loss: 0.3702707290649414\n",
      "Step: 5300  \tTraining accuracy: 0.8066475987434387\n",
      "Step: 5300  \tValid loss: 0.4262980818748474\n",
      "Step: 5400  \tTraining loss: 0.3700113296508789\n",
      "Step: 5400  \tTraining accuracy: 0.8069038391113281\n",
      "Step: 5400  \tValid loss: 0.4264053404331207\n",
      "Step: 5500  \tTraining loss: 0.3697633743286133\n",
      "Step: 5500  \tTraining accuracy: 0.8071557879447937\n",
      "Step: 5500  \tValid loss: 0.4264928102493286\n",
      "Step: 5600  \tTraining loss: 0.3695257008075714\n",
      "Step: 5600  \tTraining accuracy: 0.807413637638092\n",
      "Step: 5600  \tValid loss: 0.42656025290489197\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8076624\n",
      "Precision: 0.8545455\n",
      "Recall: 0.85181236\n",
      "F1 score: 0.80636877\n",
      "AUC: 0.8468364\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.807662   0.854545  0.851812  0.806369  0.846836  0.369411      0.807311   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.425632       0.807325   0.543669      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5648.0  \n",
      "15\n",
      "(870, 8)\n",
      "(870, 1)\n",
      "(480, 8)\n",
      "(480, 1)\n",
      "(390, 8)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5513265132904053\n",
      "Step: 100  \tTraining accuracy: 0.7160919308662415\n",
      "Step: 100  \tValid loss: 0.5546064972877502\n",
      "Step: 200  \tTraining loss: 0.5227932929992676\n",
      "Step: 200  \tTraining accuracy: 0.7214559316635132\n",
      "Step: 200  \tValid loss: 0.5340032577514648\n",
      "Step: 300  \tTraining loss: 0.5007139444351196\n",
      "Step: 300  \tTraining accuracy: 0.7305747270584106\n",
      "Step: 300  \tValid loss: 0.5138959288597107\n",
      "Step: 400  \tTraining loss: 0.4801771938800812\n",
      "Step: 400  \tTraining accuracy: 0.7412151098251343\n",
      "Step: 400  \tValid loss: 0.49442681670188904\n",
      "Step: 500  \tTraining loss: 0.46489250659942627\n",
      "Step: 500  \tTraining accuracy: 0.7471264600753784\n",
      "Step: 500  \tValid loss: 0.478845477104187\n",
      "Step: 600  \tTraining loss: 0.45292603969573975\n",
      "Step: 600  \tTraining accuracy: 0.752246618270874\n",
      "Step: 600  \tValid loss: 0.4662042558193207\n",
      "Step: 700  \tTraining loss: 0.43960121273994446\n",
      "Step: 700  \tTraining accuracy: 0.7575596570968628\n",
      "Step: 700  \tValid loss: 0.45436158776283264\n",
      "Step: 800  \tTraining loss: 0.42783668637275696\n",
      "Step: 800  \tTraining accuracy: 0.7614559531211853\n",
      "Step: 800  \tValid loss: 0.449165016412735\n",
      "Step: 900  \tTraining loss: 0.41849491000175476\n",
      "Step: 900  \tTraining accuracy: 0.7641649842262268\n",
      "Step: 900  \tValid loss: 0.4446641206741333\n",
      "Step: 1000  \tTraining loss: 0.41060763597488403\n",
      "Step: 1000  \tTraining accuracy: 0.7664851546287537\n",
      "Step: 1000  \tValid loss: 0.4419413208961487\n",
      "Step: 1100  \tTraining loss: 0.40417203307151794\n",
      "Step: 1100  \tTraining accuracy: 0.7684181928634644\n",
      "Step: 1100  \tValid loss: 0.4397905766963959\n",
      "Step: 1200  \tTraining loss: 0.3985115885734558\n",
      "Step: 1200  \tTraining accuracy: 0.7704647779464722\n",
      "Step: 1200  \tValid loss: 0.43954190611839294\n",
      "Step: 1300  \tTraining loss: 0.39490756392478943\n",
      "Step: 1300  \tTraining accuracy: 0.7722299098968506\n",
      "Step: 1300  \tValid loss: 0.43975740671157837\n",
      "Step: 1400  \tTraining loss: 0.3920905590057373\n",
      "Step: 1400  \tTraining accuracy: 0.7740740776062012\n",
      "Step: 1400  \tValid loss: 0.43897324800491333\n",
      "Step: 1500  \tTraining loss: 0.3896886706352234\n",
      "Step: 1500  \tTraining accuracy: 0.7753864526748657\n",
      "Step: 1500  \tValid loss: 0.4380466043949127\n",
      "Step: 1600  \tTraining loss: 0.38740241527557373\n",
      "Step: 1600  \tTraining accuracy: 0.7766777873039246\n",
      "Step: 1600  \tValid loss: 0.4376717209815979\n",
      "Step: 1700  \tTraining loss: 0.38535046577453613\n",
      "Step: 1700  \tTraining accuracy: 0.7778822779655457\n",
      "Step: 1700  \tValid loss: 0.43673768639564514\n",
      "Step: 1800  \tTraining loss: 0.3833136260509491\n",
      "Step: 1800  \tTraining accuracy: 0.7789819240570068\n",
      "Step: 1800  \tValid loss: 0.43589073419570923\n",
      "Step: 1900  \tTraining loss: 0.3810805380344391\n",
      "Step: 1900  \tTraining accuracy: 0.7800248265266418\n",
      "Step: 1900  \tValid loss: 0.4347781538963318\n",
      "Step: 2000  \tTraining loss: 0.3784053325653076\n",
      "Step: 2000  \tTraining accuracy: 0.7807839512825012\n",
      "Step: 2000  \tValid loss: 0.43334200978279114\n",
      "Step: 2100  \tTraining loss: 0.3758564591407776\n",
      "Step: 2100  \tTraining accuracy: 0.7815811634063721\n",
      "Step: 2100  \tValid loss: 0.4321472942829132\n",
      "Step: 2200  \tTraining loss: 0.3736906945705414\n",
      "Step: 2200  \tTraining accuracy: 0.7823576331138611\n",
      "Step: 2200  \tValid loss: 0.4312388002872467\n",
      "Step: 2300  \tTraining loss: 0.3718557059764862\n",
      "Step: 2300  \tTraining accuracy: 0.7830140590667725\n",
      "Step: 2300  \tValid loss: 0.43101969361305237\n",
      "Step: 2400  \tTraining loss: 0.37022048234939575\n",
      "Step: 2400  \tTraining accuracy: 0.7836390137672424\n",
      "Step: 2400  \tValid loss: 0.4309960603713989\n",
      "Step: 2500  \tTraining loss: 0.3687185049057007\n",
      "Step: 2500  \tTraining accuracy: 0.7842599153518677\n",
      "Step: 2500  \tValid loss: 0.43106067180633545\n",
      "Step: 2600  \tTraining loss: 0.36732518672943115\n",
      "Step: 2600  \tTraining accuracy: 0.7849447727203369\n",
      "Step: 2600  \tValid loss: 0.43130651116371155\n",
      "Step: 2700  \tTraining loss: 0.36602267622947693\n",
      "Step: 2700  \tTraining accuracy: 0.7855996489524841\n",
      "Step: 2700  \tValid loss: 0.4316175878047943\n",
      "Step: 2800  \tTraining loss: 0.36480116844177246\n",
      "Step: 2800  \tTraining accuracy: 0.786227822303772\n",
      "Step: 2800  \tValid loss: 0.4320206344127655\n",
      "Step: 2900  \tTraining loss: 0.3636511564254761\n",
      "Step: 2900  \tTraining accuracy: 0.7868118286132812\n",
      "Step: 2900  \tValid loss: 0.4324485659599304\n",
      "Step: 3000  \tTraining loss: 0.3625599145889282\n",
      "Step: 3000  \tTraining accuracy: 0.7873173356056213\n",
      "Step: 3000  \tValid loss: 0.43292149901390076\n",
      "Step: 3100  \tTraining loss: 0.36151576042175293\n",
      "Step: 3100  \tTraining accuracy: 0.7878085374832153\n",
      "Step: 3100  \tValid loss: 0.43343955278396606\n",
      "Step: 3200  \tTraining loss: 0.3605029881000519\n",
      "Step: 3200  \tTraining accuracy: 0.7882685661315918\n",
      "Step: 3200  \tValid loss: 0.43395110964775085\n",
      "Step: 3300  \tTraining loss: 0.3595044016838074\n",
      "Step: 3300  \tTraining accuracy: 0.7887002825737\n",
      "Step: 3300  \tValid loss: 0.4344748258590698\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7891062\n",
      "Precision: 0.86042947\n",
      "Recall: 0.907767\n",
      "F1 score: 0.81023186\n",
      "AUC: 0.77332795\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.789106   0.860429  0.907767  0.810232  0.773328  0.35873      0.788488   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.430977       0.788567   0.549221      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3377.0  \n",
      "16\n",
      "(1624, 8)\n",
      "(1624, 1)\n",
      "(880, 8)\n",
      "(880, 1)\n",
      "(715, 8)\n",
      "(715, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6377191543579102\n",
      "Step: 100  \tTraining accuracy: 0.6410098671913147\n",
      "Step: 100  \tValid loss: 0.6354718804359436\n",
      "Step: 200  \tTraining loss: 0.5310728549957275\n",
      "Step: 200  \tTraining accuracy: 0.688829243183136\n",
      "Step: 200  \tValid loss: 0.5244062542915344\n",
      "Step: 300  \tTraining loss: 0.44123852252960205\n",
      "Step: 300  \tTraining accuracy: 0.7379062175750732\n",
      "Step: 300  \tValid loss: 0.4293242394924164\n",
      "Step: 400  \tTraining loss: 0.39879992604255676\n",
      "Step: 400  \tTraining accuracy: 0.7668646574020386\n",
      "Step: 400  \tValid loss: 0.38180992007255554\n",
      "Step: 500  \tTraining loss: 0.3805856704711914\n",
      "Step: 500  \tTraining accuracy: 0.7842758893966675\n",
      "Step: 500  \tValid loss: 0.3602908253669739\n",
      "Step: 600  \tTraining loss: 0.3721306324005127\n",
      "Step: 600  \tTraining accuracy: 0.7954738140106201\n",
      "Step: 600  \tValid loss: 0.3499213755130768\n",
      "Step: 700  \tTraining loss: 0.36767876148223877\n",
      "Step: 700  \tTraining accuracy: 0.8031808137893677\n",
      "Step: 700  \tValid loss: 0.3444441854953766\n",
      "Step: 800  \tTraining loss: 0.36495310068130493\n",
      "Step: 800  \tTraining accuracy: 0.8087924718856812\n",
      "Step: 800  \tValid loss: 0.3412443995475769\n",
      "Step: 900  \tTraining loss: 0.36299222707748413\n",
      "Step: 900  \tTraining accuracy: 0.8133036494255066\n",
      "Step: 900  \tValid loss: 0.3391500413417816\n",
      "Step: 1000  \tTraining loss: 0.36135992407798767\n",
      "Step: 1000  \tTraining accuracy: 0.8170616030693054\n",
      "Step: 1000  \tValid loss: 0.3375949263572693\n",
      "Step: 1100  \tTraining loss: 0.35984906554222107\n",
      "Step: 1100  \tTraining accuracy: 0.8200449347496033\n",
      "Step: 1100  \tValid loss: 0.33628222346305847\n",
      "Step: 1200  \tTraining loss: 0.3583589792251587\n",
      "Step: 1200  \tTraining accuracy: 0.8225366473197937\n",
      "Step: 1200  \tValid loss: 0.3350549042224884\n",
      "Step: 1300  \tTraining loss: 0.35685038566589355\n",
      "Step: 1300  \tTraining accuracy: 0.8248534202575684\n",
      "Step: 1300  \tValid loss: 0.3338565230369568\n",
      "Step: 1400  \tTraining loss: 0.3553149104118347\n",
      "Step: 1400  \tTraining accuracy: 0.8268500566482544\n",
      "Step: 1400  \tValid loss: 0.3326399028301239\n",
      "Step: 1500  \tTraining loss: 0.35376638174057007\n",
      "Step: 1500  \tTraining accuracy: 0.828592836856842\n",
      "Step: 1500  \tValid loss: 0.3314131200313568\n",
      "Step: 1600  \tTraining loss: 0.3522360920906067\n",
      "Step: 1600  \tTraining accuracy: 0.8301509022712708\n",
      "Step: 1600  \tValid loss: 0.3302049934864044\n",
      "Step: 1700  \tTraining loss: 0.3507572412490845\n",
      "Step: 1700  \tTraining accuracy: 0.8315954208374023\n",
      "Step: 1700  \tValid loss: 0.32905855774879456\n",
      "Step: 1800  \tTraining loss: 0.34934914112091064\n",
      "Step: 1800  \tTraining accuracy: 0.8328925967216492\n",
      "Step: 1800  \tValid loss: 0.3280535042285919\n",
      "Step: 1900  \tTraining loss: 0.3480260372161865\n",
      "Step: 1900  \tTraining accuracy: 0.8341671228408813\n",
      "Step: 1900  \tValid loss: 0.32715919613838196\n",
      "Step: 2000  \tTraining loss: 0.3467855155467987\n",
      "Step: 2000  \tTraining accuracy: 0.8353906273841858\n",
      "Step: 2000  \tValid loss: 0.32637593150138855\n",
      "Step: 2100  \tTraining loss: 0.3456019461154938\n",
      "Step: 2100  \tTraining accuracy: 0.8366159796714783\n",
      "Step: 2100  \tValid loss: 0.3256482779979706\n",
      "Step: 2200  \tTraining loss: 0.3444645404815674\n",
      "Step: 2200  \tTraining accuracy: 0.8376695513725281\n",
      "Step: 2200  \tValid loss: 0.32496941089630127\n",
      "Step: 2300  \tTraining loss: 0.34332409501075745\n",
      "Step: 2300  \tTraining accuracy: 0.8386157155036926\n",
      "Step: 2300  \tValid loss: 0.3244008719921112\n",
      "Step: 2400  \tTraining loss: 0.3419313430786133\n",
      "Step: 2400  \tTraining accuracy: 0.8394813537597656\n",
      "Step: 2400  \tValid loss: 0.3238476514816284\n",
      "Step: 2500  \tTraining loss: 0.34068748354911804\n",
      "Step: 2500  \tTraining accuracy: 0.8403017520904541\n",
      "Step: 2500  \tValid loss: 0.3233683407306671\n",
      "Step: 2600  \tTraining loss: 0.33969762921333313\n",
      "Step: 2600  \tTraining accuracy: 0.8410090208053589\n",
      "Step: 2600  \tValid loss: 0.3227979838848114\n",
      "Step: 2700  \tTraining loss: 0.3388037085533142\n",
      "Step: 2700  \tTraining accuracy: 0.8416512608528137\n",
      "Step: 2700  \tValid loss: 0.32228732109069824\n",
      "Step: 2800  \tTraining loss: 0.3379702866077423\n",
      "Step: 2800  \tTraining accuracy: 0.8422467708587646\n",
      "Step: 2800  \tValid loss: 0.3218088746070862\n",
      "Step: 2900  \tTraining loss: 0.3371889591217041\n",
      "Step: 2900  \tTraining accuracy: 0.842800498008728\n",
      "Step: 2900  \tValid loss: 0.32141077518463135\n",
      "Step: 3000  \tTraining loss: 0.33644381165504456\n",
      "Step: 3000  \tTraining accuracy: 0.8433061242103577\n",
      "Step: 3000  \tValid loss: 0.32103827595710754\n",
      "Step: 3100  \tTraining loss: 0.3357294499874115\n",
      "Step: 3100  \tTraining accuracy: 0.8437582850456238\n",
      "Step: 3100  \tValid loss: 0.32069286704063416\n",
      "Step: 3200  \tTraining loss: 0.3350442349910736\n",
      "Step: 3200  \tTraining accuracy: 0.8441915512084961\n",
      "Step: 3200  \tValid loss: 0.32048138976097107\n",
      "Step: 3300  \tTraining loss: 0.33433908224105835\n",
      "Step: 3300  \tTraining accuracy: 0.8446077704429626\n",
      "Step: 3300  \tValid loss: 0.32032546401023865\n",
      "Step: 3400  \tTraining loss: 0.33368605375289917\n",
      "Step: 3400  \tTraining accuracy: 0.8449898362159729\n",
      "Step: 3400  \tValid loss: 0.3200741708278656\n",
      "Step: 3500  \tTraining loss: 0.33305585384368896\n",
      "Step: 3500  \tTraining accuracy: 0.8453137874603271\n",
      "Step: 3500  \tValid loss: 0.3199887275695801\n",
      "Step: 3600  \tTraining loss: 0.33241987228393555\n",
      "Step: 3600  \tTraining accuracy: 0.8455844521522522\n",
      "Step: 3600  \tValid loss: 0.3200835585594177\n",
      "Step: 3700  \tTraining loss: 0.33132094144821167\n",
      "Step: 3700  \tTraining accuracy: 0.8458402752876282\n",
      "Step: 3700  \tValid loss: 0.32010942697525024\n",
      "Step: 3800  \tTraining loss: 0.3306998014450073\n",
      "Step: 3800  \tTraining accuracy: 0.8460659384727478\n",
      "Step: 3800  \tValid loss: 0.3198886811733246\n",
      "Step: 3900  \tTraining loss: 0.33010557293891907\n",
      "Step: 3900  \tTraining accuracy: 0.846295952796936\n",
      "Step: 3900  \tValid loss: 0.3198661804199219\n",
      "Step: 4000  \tTraining loss: 0.32954680919647217\n",
      "Step: 4000  \tTraining accuracy: 0.8465222120285034\n",
      "Step: 4000  \tValid loss: 0.3198659121990204\n",
      "Step: 4100  \tTraining loss: 0.32902106642723083\n",
      "Step: 4100  \tTraining accuracy: 0.8467450141906738\n",
      "Step: 4100  \tValid loss: 0.3198583126068115\n",
      "Step: 4200  \tTraining loss: 0.32853612303733826\n",
      "Step: 4200  \tTraining accuracy: 0.8469495177268982\n",
      "Step: 4200  \tValid loss: 0.3199194073677063\n",
      "Step: 4300  \tTraining loss: 0.328029602766037\n",
      "Step: 4300  \tTraining accuracy: 0.8471444845199585\n",
      "Step: 4300  \tValid loss: 0.32012295722961426\n",
      "Step: 4400  \tTraining loss: 0.327523410320282\n",
      "Step: 4400  \tTraining accuracy: 0.8473304510116577\n",
      "Step: 4400  \tValid loss: 0.3203331232070923\n",
      "Step: 4500  \tTraining loss: 0.32708269357681274\n",
      "Step: 4500  \tTraining accuracy: 0.8475080132484436\n",
      "Step: 4500  \tValid loss: 0.3205028772354126\n",
      "Step: 4600  \tTraining loss: 0.32669124007225037\n",
      "Step: 4600  \tTraining accuracy: 0.8476641774177551\n",
      "Step: 4600  \tValid loss: 0.32065728306770325\n",
      "Step: 4700  \tTraining loss: 0.3263362646102905\n",
      "Step: 4700  \tTraining accuracy: 0.8478202819824219\n",
      "Step: 4700  \tValid loss: 0.32086536288261414\n",
      "Step: 4800  \tTraining loss: 0.32599538564682007\n",
      "Step: 4800  \tTraining accuracy: 0.8479959964752197\n",
      "Step: 4800  \tValid loss: 0.32110780477523804\n",
      "Step: 4900  \tTraining loss: 0.325669527053833\n",
      "Step: 4900  \tTraining accuracy: 0.8481580018997192\n",
      "Step: 4900  \tValid loss: 0.32134905457496643\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.84830725\n",
      "Precision: 0.84836066\n",
      "Recall: 0.8391892\n",
      "F1 score: 0.8436969\n",
      "AUC: 0.8568117\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.848307   0.848361  0.839189  0.843697  0.856812  0.325642      0.848204   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.319796       0.848155   0.345374      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4907.0  \n",
      "17\n",
      "(783, 8)\n",
      "(783, 1)\n",
      "(432, 8)\n",
      "(432, 1)\n",
      "(351, 8)\n",
      "(351, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4171246886253357\n",
      "Step: 100  \tTraining accuracy: 0.8339719176292419\n",
      "Step: 100  \tValid loss: 0.5496806502342224\n",
      "Step: 200  \tTraining loss: 0.3853601813316345\n",
      "Step: 200  \tTraining accuracy: 0.8148148059844971\n",
      "Step: 200  \tValid loss: 0.51531982421875\n",
      "Step: 300  \tTraining loss: 0.37869563698768616\n",
      "Step: 300  \tTraining accuracy: 0.8107279539108276\n",
      "Step: 300  \tValid loss: 0.5099464058876038\n",
      "Step: 400  \tTraining loss: 0.37582969665527344\n",
      "Step: 400  \tTraining accuracy: 0.8100711703300476\n",
      "Step: 400  \tValid loss: 0.5076184868812561\n",
      "Step: 500  \tTraining loss: 0.37360551953315735\n",
      "Step: 500  \tTraining accuracy: 0.8095643520355225\n",
      "Step: 500  \tValid loss: 0.5060337781906128\n",
      "Step: 600  \tTraining loss: 0.3716178834438324\n",
      "Step: 600  \tTraining accuracy: 0.8088935613632202\n",
      "Step: 600  \tValid loss: 0.5046677589416504\n",
      "Step: 700  \tTraining loss: 0.3697265386581421\n",
      "Step: 700  \tTraining accuracy: 0.8087238669395447\n",
      "Step: 700  \tValid loss: 0.5033072829246521\n",
      "Step: 800  \tTraining loss: 0.36789196729660034\n",
      "Step: 800  \tTraining accuracy: 0.8090251088142395\n",
      "Step: 800  \tValid loss: 0.502041220664978\n",
      "Step: 900  \tTraining loss: 0.3661639988422394\n",
      "Step: 900  \tTraining accuracy: 0.8092554807662964\n",
      "Step: 900  \tValid loss: 0.5007688999176025\n",
      "Step: 1000  \tTraining loss: 0.36450883746147156\n",
      "Step: 1000  \tTraining accuracy: 0.8095718026161194\n",
      "Step: 1000  \tValid loss: 0.49945303797721863\n",
      "Step: 1100  \tTraining loss: 0.3627191483974457\n",
      "Step: 1100  \tTraining accuracy: 0.809949517250061\n",
      "Step: 1100  \tValid loss: 0.4976276755332947\n",
      "Step: 1200  \tTraining loss: 0.3609503507614136\n",
      "Step: 1200  \tTraining accuracy: 0.8102615475654602\n",
      "Step: 1200  \tValid loss: 0.49612176418304443\n",
      "Step: 1300  \tTraining loss: 0.3592624068260193\n",
      "Step: 1300  \tTraining accuracy: 0.8105236291885376\n",
      "Step: 1300  \tValid loss: 0.4944562315940857\n",
      "Step: 1400  \tTraining loss: 0.3575783967971802\n",
      "Step: 1400  \tTraining accuracy: 0.8106995820999146\n",
      "Step: 1400  \tValid loss: 0.49265056848526\n",
      "Step: 1500  \tTraining loss: 0.3558869957923889\n",
      "Step: 1500  \tTraining accuracy: 0.8108953237533569\n",
      "Step: 1500  \tValid loss: 0.49075475335121155\n",
      "Step: 1600  \tTraining loss: 0.35416311025619507\n",
      "Step: 1600  \tTraining accuracy: 0.8110657930374146\n",
      "Step: 1600  \tValid loss: 0.4887343943119049\n",
      "Step: 1700  \tTraining loss: 0.35236191749572754\n",
      "Step: 1700  \tTraining accuracy: 0.8111382126808167\n",
      "Step: 1700  \tValid loss: 0.4865788221359253\n",
      "Step: 1800  \tTraining loss: 0.35052549839019775\n",
      "Step: 1800  \tTraining accuracy: 0.811202347278595\n",
      "Step: 1800  \tValid loss: 0.48439809679985046\n",
      "Step: 1900  \tTraining loss: 0.3488326668739319\n",
      "Step: 1900  \tTraining accuracy: 0.8112595081329346\n",
      "Step: 1900  \tValid loss: 0.48243337869644165\n",
      "Step: 2000  \tTraining loss: 0.3473532199859619\n",
      "Step: 2000  \tTraining accuracy: 0.8114418387413025\n",
      "Step: 2000  \tValid loss: 0.4807582497596741\n",
      "Step: 2100  \tTraining loss: 0.34605297446250916\n",
      "Step: 2100  \tTraining accuracy: 0.8115129470825195\n",
      "Step: 2100  \tValid loss: 0.4793248772621155\n",
      "Step: 2200  \tTraining loss: 0.344699501991272\n",
      "Step: 2200  \tTraining accuracy: 0.8116962313652039\n",
      "Step: 2200  \tValid loss: 0.4778933823108673\n",
      "Step: 2300  \tTraining loss: 0.34300488233566284\n",
      "Step: 2300  \tTraining accuracy: 0.8119483590126038\n",
      "Step: 2300  \tValid loss: 0.47624537348747253\n",
      "Step: 2400  \tTraining loss: 0.341711163520813\n",
      "Step: 2400  \tTraining accuracy: 0.8121790289878845\n",
      "Step: 2400  \tValid loss: 0.47528529167175293\n",
      "Step: 2500  \tTraining loss: 0.340594619512558\n",
      "Step: 2500  \tTraining accuracy: 0.81244295835495\n",
      "Step: 2500  \tValid loss: 0.4744473695755005\n",
      "Step: 2600  \tTraining loss: 0.33964139223098755\n",
      "Step: 2600  \tTraining accuracy: 0.8127864003181458\n",
      "Step: 2600  \tValid loss: 0.47370636463165283\n",
      "Step: 2700  \tTraining loss: 0.3387674391269684\n",
      "Step: 2700  \tTraining accuracy: 0.8131762146949768\n",
      "Step: 2700  \tValid loss: 0.47306421399116516\n",
      "Step: 2800  \tTraining loss: 0.3378559648990631\n",
      "Step: 2800  \tTraining accuracy: 0.8135840892791748\n",
      "Step: 2800  \tValid loss: 0.47256797552108765\n",
      "Step: 2900  \tTraining loss: 0.33669373393058777\n",
      "Step: 2900  \tTraining accuracy: 0.8138961791992188\n",
      "Step: 2900  \tValid loss: 0.4723384976387024\n",
      "Step: 3000  \tTraining loss: 0.33530929684638977\n",
      "Step: 3000  \tTraining accuracy: 0.8142520189285278\n",
      "Step: 3000  \tValid loss: 0.47213760018348694\n",
      "Step: 3100  \tTraining loss: 0.33394545316696167\n",
      "Step: 3100  \tTraining accuracy: 0.814584493637085\n",
      "Step: 3100  \tValid loss: 0.47199538350105286\n",
      "Step: 3200  \tTraining loss: 0.33267050981521606\n",
      "Step: 3200  \tTraining accuracy: 0.8149364590644836\n",
      "Step: 3200  \tValid loss: 0.4719895124435425\n",
      "Step: 3300  \tTraining loss: 0.33149880170822144\n",
      "Step: 3300  \tTraining accuracy: 0.8153453469276428\n",
      "Step: 3300  \tValid loss: 0.4720529019832611\n",
      "Step: 3400  \tTraining loss: 0.3304597735404968\n",
      "Step: 3400  \tTraining accuracy: 0.815710723400116\n",
      "Step: 3400  \tValid loss: 0.47215956449508667\n",
      "Step: 3500  \tTraining loss: 0.3295189440250397\n",
      "Step: 3500  \tTraining accuracy: 0.8160179257392883\n",
      "Step: 3500  \tValid loss: 0.472279816865921\n",
      "Step: 3600  \tTraining loss: 0.3286658227443695\n",
      "Step: 3600  \tTraining accuracy: 0.8163257837295532\n",
      "Step: 3600  \tValid loss: 0.4724295437335968\n",
      "Step: 3700  \tTraining loss: 0.327930212020874\n",
      "Step: 3700  \tTraining accuracy: 0.8165993094444275\n",
      "Step: 3700  \tValid loss: 0.4725770950317383\n",
      "Step: 3800  \tTraining loss: 0.32727769017219543\n",
      "Step: 3800  \tTraining accuracy: 0.8168582320213318\n",
      "Step: 3800  \tValid loss: 0.47276997566223145\n",
      "Step: 3900  \tTraining loss: 0.32667866349220276\n",
      "Step: 3900  \tTraining accuracy: 0.8170705437660217\n",
      "Step: 3900  \tValid loss: 0.4728446304798126\n",
      "Step: 4000  \tTraining loss: 0.3261485695838928\n",
      "Step: 4000  \tTraining accuracy: 0.8172882795333862\n",
      "Step: 4000  \tValid loss: 0.4727129638195038\n",
      "Step: 4100  \tTraining loss: 0.32562652230262756\n",
      "Step: 4100  \tTraining accuracy: 0.8174952268600464\n",
      "Step: 4100  \tValid loss: 0.4728414714336395\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8176922\n",
      "Precision: 0.87482613\n",
      "Recall: 0.9632466\n",
      "F1 score: 0.8570273\n",
      "AUC: 0.63546944\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.817692   0.874826  0.963247  0.857027  0.635469  0.325516      0.817244   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.471911       0.817465   0.423312      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4121.0  \n",
      "18\n",
      "(1189, 8)\n",
      "(1189, 1)\n",
      "(640, 8)\n",
      "(640, 1)\n",
      "(520, 8)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.505548894405365\n",
      "Step: 100  \tTraining accuracy: 0.7846930027008057\n",
      "Step: 100  \tValid loss: 0.5619622468948364\n",
      "Step: 200  \tTraining loss: 0.4409090280532837\n",
      "Step: 200  \tTraining accuracy: 0.7795364856719971\n",
      "Step: 200  \tValid loss: 0.48706015944480896\n",
      "Step: 300  \tTraining loss: 0.43675243854522705\n",
      "Step: 300  \tTraining accuracy: 0.7876677513122559\n",
      "Step: 300  \tValid loss: 0.4830043911933899\n",
      "Step: 400  \tTraining loss: 0.4333999752998352\n",
      "Step: 400  \tTraining accuracy: 0.7909179329872131\n",
      "Step: 400  \tValid loss: 0.4789246916770935\n",
      "Step: 500  \tTraining loss: 0.43066513538360596\n",
      "Step: 500  \tTraining accuracy: 0.7929145097732544\n",
      "Step: 500  \tValid loss: 0.47499150037765503\n",
      "Step: 600  \tTraining loss: 0.42841291427612305\n",
      "Step: 600  \tTraining accuracy: 0.7941085696220398\n",
      "Step: 600  \tValid loss: 0.47146135568618774\n",
      "Step: 700  \tTraining loss: 0.42645546793937683\n",
      "Step: 700  \tTraining accuracy: 0.7956553101539612\n",
      "Step: 700  \tValid loss: 0.4682900905609131\n",
      "Step: 800  \tTraining loss: 0.4247606694698334\n",
      "Step: 800  \tTraining accuracy: 0.7973003387451172\n",
      "Step: 800  \tValid loss: 0.46565675735473633\n",
      "Step: 900  \tTraining loss: 0.42333924770355225\n",
      "Step: 900  \tTraining accuracy: 0.7988088726997375\n",
      "Step: 900  \tValid loss: 0.4635709226131439\n",
      "Step: 1000  \tTraining loss: 0.42211782932281494\n",
      "Step: 1000  \tTraining accuracy: 0.800000011920929\n",
      "Step: 1000  \tValid loss: 0.4618150591850281\n",
      "Step: 1100  \tTraining loss: 0.42108190059661865\n",
      "Step: 1100  \tTraining accuracy: 0.80096435546875\n",
      "Step: 1100  \tValid loss: 0.46036356687545776\n",
      "Step: 1200  \tTraining loss: 0.41940054297447205\n",
      "Step: 1200  \tTraining accuracy: 0.8018721342086792\n",
      "Step: 1200  \tValid loss: 0.459693968296051\n",
      "Step: 1300  \tTraining loss: 0.4184662699699402\n",
      "Step: 1300  \tTraining accuracy: 0.802566647529602\n",
      "Step: 1300  \tValid loss: 0.45941147208213806\n",
      "Step: 1400  \tTraining loss: 0.41770607233047485\n",
      "Step: 1400  \tTraining accuracy: 0.8031582832336426\n",
      "Step: 1400  \tValid loss: 0.45906195044517517\n",
      "Step: 1500  \tTraining loss: 0.41704005002975464\n",
      "Step: 1500  \tTraining accuracy: 0.8036683797836304\n",
      "Step: 1500  \tValid loss: 0.45879992842674255\n",
      "Step: 1600  \tTraining loss: 0.41642776131629944\n",
      "Step: 1600  \tTraining accuracy: 0.8041126728057861\n",
      "Step: 1600  \tValid loss: 0.4585897922515869\n",
      "Step: 1700  \tTraining loss: 0.4158288240432739\n",
      "Step: 1700  \tTraining accuracy: 0.8045289516448975\n",
      "Step: 1700  \tValid loss: 0.45840340852737427\n",
      "Step: 1800  \tTraining loss: 0.4152289927005768\n",
      "Step: 1800  \tTraining accuracy: 0.8048732876777649\n",
      "Step: 1800  \tValid loss: 0.4583978056907654\n",
      "Step: 1900  \tTraining loss: 0.41464123129844666\n",
      "Step: 1900  \tTraining accuracy: 0.8052494525909424\n",
      "Step: 1900  \tValid loss: 0.4583331048488617\n",
      "Step: 2000  \tTraining loss: 0.4139961898326874\n",
      "Step: 2000  \tTraining accuracy: 0.8055652379989624\n",
      "Step: 2000  \tValid loss: 0.45839768648147583\n",
      "Step: 2100  \tTraining loss: 0.41327711939811707\n",
      "Step: 2100  \tTraining accuracy: 0.8058502078056335\n",
      "Step: 2100  \tValid loss: 0.45828670263290405\n",
      "Step: 2200  \tTraining loss: 0.4124795198440552\n",
      "Step: 2200  \tTraining accuracy: 0.8061087131500244\n",
      "Step: 2200  \tValid loss: 0.45818647742271423\n",
      "Step: 2300  \tTraining loss: 0.41164523363113403\n",
      "Step: 2300  \tTraining accuracy: 0.8063631653785706\n",
      "Step: 2300  \tValid loss: 0.458123117685318\n",
      "Step: 2400  \tTraining loss: 0.4108043909072876\n",
      "Step: 2400  \tTraining accuracy: 0.8066140413284302\n",
      "Step: 2400  \tValid loss: 0.45795851945877075\n",
      "Step: 2500  \tTraining loss: 0.4099791646003723\n",
      "Step: 2500  \tTraining accuracy: 0.8068791627883911\n",
      "Step: 2500  \tValid loss: 0.45783957839012146\n",
      "Step: 2600  \tTraining loss: 0.4091584384441376\n",
      "Step: 2600  \tTraining accuracy: 0.8071402311325073\n",
      "Step: 2600  \tValid loss: 0.45771312713623047\n",
      "Step: 2700  \tTraining loss: 0.4083263874053955\n",
      "Step: 2700  \tTraining accuracy: 0.8074136972427368\n",
      "Step: 2700  \tValid loss: 0.4575894773006439\n",
      "Step: 2800  \tTraining loss: 0.40748485922813416\n",
      "Step: 2800  \tTraining accuracy: 0.8076982498168945\n",
      "Step: 2800  \tValid loss: 0.45745816826820374\n",
      "Step: 2900  \tTraining loss: 0.4066144824028015\n",
      "Step: 2900  \tTraining accuracy: 0.80793297290802\n",
      "Step: 2900  \tValid loss: 0.45722073316574097\n",
      "Step: 3000  \tTraining loss: 0.40487974882125854\n",
      "Step: 3000  \tTraining accuracy: 0.8081517815589905\n",
      "Step: 3000  \tValid loss: 0.4561610221862793\n",
      "Step: 3100  \tTraining loss: 0.40340542793273926\n",
      "Step: 3100  \tTraining accuracy: 0.8084539175033569\n",
      "Step: 3100  \tValid loss: 0.4579274654388428\n",
      "Step: 3200  \tTraining loss: 0.40227240324020386\n",
      "Step: 3200  \tTraining accuracy: 0.8087369203567505\n",
      "Step: 3200  \tValid loss: 0.4584124684333801\n",
      "Step: 3300  \tTraining loss: 0.40130218863487244\n",
      "Step: 3300  \tTraining accuracy: 0.8090155720710754\n",
      "Step: 3300  \tValid loss: 0.4587307870388031\n",
      "Step: 3400  \tTraining loss: 0.40043842792510986\n",
      "Step: 3400  \tTraining accuracy: 0.8092648386955261\n",
      "Step: 3400  \tValid loss: 0.4592355787754059\n",
      "Step: 3500  \tTraining loss: 0.3996177315711975\n",
      "Step: 3500  \tTraining accuracy: 0.8094874024391174\n",
      "Step: 3500  \tValid loss: 0.4598638415336609\n",
      "Step: 3600  \tTraining loss: 0.39845114946365356\n",
      "Step: 3600  \tTraining accuracy: 0.8096613883972168\n",
      "Step: 3600  \tValid loss: 0.46001338958740234\n",
      "Step: 3700  \tTraining loss: 0.39763304591178894\n",
      "Step: 3700  \tTraining accuracy: 0.8099074959754944\n",
      "Step: 3700  \tValid loss: 0.4606701731681824\n",
      "Step: 3800  \tTraining loss: 0.3969360589981079\n",
      "Step: 3800  \tTraining accuracy: 0.8101404905319214\n",
      "Step: 3800  \tValid loss: 0.46120890974998474\n",
      "Step: 3900  \tTraining loss: 0.39627906680107117\n",
      "Step: 3900  \tTraining accuracy: 0.8103503584861755\n",
      "Step: 3900  \tValid loss: 0.4619729518890381\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.81057113\n",
      "Precision: 0.8468809\n",
      "Recall: 0.960343\n",
      "F1 score: 0.8614608\n",
      "AUC: 0.66376525\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.810571   0.846881  0.960343  0.861461  0.663765  0.395697      0.810285   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.456159       0.810313   0.425891      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3995.0  \n",
      "19\n",
      "(899, 8)\n",
      "(899, 1)\n",
      "(480, 8)\n",
      "(480, 1)\n",
      "(390, 8)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.44386738538742065\n",
      "Step: 100  \tTraining accuracy: 0.8264738321304321\n",
      "Step: 100  \tValid loss: 0.45720672607421875\n",
      "Step: 200  \tTraining loss: 0.43959715962409973\n",
      "Step: 200  \tTraining accuracy: 0.8294602632522583\n",
      "Step: 200  \tValid loss: 0.45276740193367004\n",
      "Step: 300  \tTraining loss: 0.4369431436061859\n",
      "Step: 300  \tTraining accuracy: 0.8300653696060181\n",
      "Step: 300  \tValid loss: 0.4501880705356598\n",
      "Step: 400  \tTraining loss: 0.4352147579193115\n",
      "Step: 400  \tTraining accuracy: 0.8303254842758179\n",
      "Step: 400  \tValid loss: 0.44855430722236633\n",
      "Step: 500  \tTraining loss: 0.43321171402931213\n",
      "Step: 500  \tTraining accuracy: 0.83084636926651\n",
      "Step: 500  \tValid loss: 0.4458307921886444\n",
      "Step: 600  \tTraining loss: 0.4320071041584015\n",
      "Step: 600  \tTraining accuracy: 0.831691324710846\n",
      "Step: 600  \tValid loss: 0.4447050988674164\n",
      "Step: 700  \tTraining loss: 0.43100661039352417\n",
      "Step: 700  \tTraining accuracy: 0.8323634266853333\n",
      "Step: 700  \tValid loss: 0.44403722882270813\n",
      "Step: 800  \tTraining loss: 0.43005508184432983\n",
      "Step: 800  \tTraining accuracy: 0.8328564763069153\n",
      "Step: 800  \tValid loss: 0.4434691071510315\n",
      "Step: 900  \tTraining loss: 0.4290893077850342\n",
      "Step: 900  \tTraining accuracy: 0.833233654499054\n",
      "Step: 900  \tValid loss: 0.4429610073566437\n",
      "Step: 1000  \tTraining loss: 0.4280485212802887\n",
      "Step: 1000  \tTraining accuracy: 0.8335909843444824\n",
      "Step: 1000  \tValid loss: 0.4425535202026367\n",
      "Step: 1100  \tTraining loss: 0.42682957649230957\n",
      "Step: 1100  \tTraining accuracy: 0.8338802456855774\n",
      "Step: 1100  \tValid loss: 0.4421972334384918\n",
      "Step: 1200  \tTraining loss: 0.42544087767601013\n",
      "Step: 1200  \tTraining accuracy: 0.8340210318565369\n",
      "Step: 1200  \tValid loss: 0.44195693731307983\n",
      "Step: 1300  \tTraining loss: 0.42424774169921875\n",
      "Step: 1300  \tTraining accuracy: 0.8340941071510315\n",
      "Step: 1300  \tValid loss: 0.44209110736846924\n",
      "Step: 1400  \tTraining loss: 0.4231618046760559\n",
      "Step: 1400  \tTraining accuracy: 0.8341981768608093\n",
      "Step: 1400  \tValid loss: 0.44237497448921204\n",
      "Step: 1500  \tTraining loss: 0.421871542930603\n",
      "Step: 1500  \tTraining accuracy: 0.8343658447265625\n",
      "Step: 1500  \tValid loss: 0.44317224621772766\n",
      "Step: 1600  \tTraining loss: 0.42051243782043457\n",
      "Step: 1600  \tTraining accuracy: 0.834511935710907\n",
      "Step: 1600  \tValid loss: 0.44408708810806274\n",
      "Step: 1700  \tTraining loss: 0.4193272292613983\n",
      "Step: 1700  \tTraining accuracy: 0.8346402645111084\n",
      "Step: 1700  \tValid loss: 0.44467657804489136\n",
      "Step: 1800  \tTraining loss: 0.4181675612926483\n",
      "Step: 1800  \tTraining accuracy: 0.8347539901733398\n",
      "Step: 1800  \tValid loss: 0.4455428421497345\n",
      "Step: 1900  \tTraining loss: 0.41717061400413513\n",
      "Step: 1900  \tTraining accuracy: 0.8348858952522278\n",
      "Step: 1900  \tValid loss: 0.44659024477005005\n",
      "Step: 2000  \tTraining loss: 0.41635650396347046\n",
      "Step: 2000  \tTraining accuracy: 0.8349463939666748\n",
      "Step: 2000  \tValid loss: 0.44729551672935486\n",
      "Step: 2100  \tTraining loss: 0.4155462384223938\n",
      "Step: 2100  \tTraining accuracy: 0.8350009918212891\n",
      "Step: 2100  \tValid loss: 0.447970449924469\n",
      "Step: 2200  \tTraining loss: 0.41336381435394287\n",
      "Step: 2200  \tTraining accuracy: 0.8350504636764526\n",
      "Step: 2200  \tValid loss: 0.4484015107154846\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.83507043\n",
      "Precision: 0.8312711\n",
      "Recall: 0.99461645\n",
      "F1 score: 0.9097765\n",
      "AUC: 0.51653904\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0   0.83507   0.831271  0.994616  0.909777  0.516539  0.413079      0.835218   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.441922       0.835345    0.40301      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2208.0  \n",
      "20\n",
      "(899, 8)\n",
      "(899, 1)\n",
      "(496, 8)\n",
      "(496, 1)\n",
      "(403, 8)\n",
      "(403, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6458690762519836\n",
      "Step: 100  \tTraining accuracy: 0.621802031993866\n",
      "Step: 100  \tValid loss: 0.637352705001831\n",
      "Step: 200  \tTraining loss: 0.5913063287734985\n",
      "Step: 200  \tTraining accuracy: 0.6518353819847107\n",
      "Step: 200  \tValid loss: 0.581987202167511\n",
      "Step: 300  \tTraining loss: 0.5316751003265381\n",
      "Step: 300  \tTraining accuracy: 0.6765294671058655\n",
      "Step: 300  \tValid loss: 0.5293680429458618\n",
      "Step: 400  \tTraining loss: 0.4782775640487671\n",
      "Step: 400  \tTraining accuracy: 0.6987128257751465\n",
      "Step: 400  \tValid loss: 0.4797804057598114\n",
      "Step: 500  \tTraining loss: 0.4485490620136261\n",
      "Step: 500  \tTraining accuracy: 0.7172166705131531\n",
      "Step: 500  \tValid loss: 0.45473939180374146\n",
      "Step: 600  \tTraining loss: 0.4335583746433258\n",
      "Step: 600  \tTraining accuracy: 0.7306097745895386\n",
      "Step: 600  \tValid loss: 0.44440391659736633\n",
      "Step: 700  \tTraining loss: 0.4234545826911926\n",
      "Step: 700  \tTraining accuracy: 0.7398819327354431\n",
      "Step: 700  \tValid loss: 0.43714454770088196\n",
      "Step: 800  \tTraining loss: 0.41831696033477783\n",
      "Step: 800  \tTraining accuracy: 0.7466073632240295\n",
      "Step: 800  \tValid loss: 0.4357932209968567\n",
      "Step: 900  \tTraining loss: 0.4145526587963104\n",
      "Step: 900  \tTraining accuracy: 0.7518811821937561\n",
      "Step: 900  \tValid loss: 0.4339929223060608\n",
      "Step: 1000  \tTraining loss: 0.4119209051132202\n",
      "Step: 1000  \tTraining accuracy: 0.7560447454452515\n",
      "Step: 1000  \tValid loss: 0.43346360325813293\n",
      "Step: 1100  \tTraining loss: 0.4095104932785034\n",
      "Step: 1100  \tTraining accuracy: 0.7594681978225708\n",
      "Step: 1100  \tValid loss: 0.4327184557914734\n",
      "Step: 1200  \tTraining loss: 0.4073449373245239\n",
      "Step: 1200  \tTraining accuracy: 0.7623446583747864\n",
      "Step: 1200  \tValid loss: 0.4315466582775116\n",
      "Step: 1300  \tTraining loss: 0.40580448508262634\n",
      "Step: 1300  \tTraining accuracy: 0.7647163271903992\n",
      "Step: 1300  \tValid loss: 0.43159258365631104\n",
      "Step: 1400  \tTraining loss: 0.4044266641139984\n",
      "Step: 1400  \tTraining accuracy: 0.766695499420166\n",
      "Step: 1400  \tValid loss: 0.4320274591445923\n",
      "Step: 1500  \tTraining loss: 0.4031195640563965\n",
      "Step: 1500  \tTraining accuracy: 0.7683249711990356\n",
      "Step: 1500  \tValid loss: 0.4327760636806488\n",
      "Step: 1600  \tTraining loss: 0.40186384320259094\n",
      "Step: 1600  \tTraining accuracy: 0.769851803779602\n",
      "Step: 1600  \tValid loss: 0.4336588978767395\n",
      "Step: 1700  \tTraining loss: 0.4005998373031616\n",
      "Step: 1700  \tTraining accuracy: 0.7711935639381409\n",
      "Step: 1700  \tValid loss: 0.4344331920146942\n",
      "Step: 1800  \tTraining loss: 0.3993549942970276\n",
      "Step: 1800  \tTraining accuracy: 0.772318422794342\n",
      "Step: 1800  \tValid loss: 0.43491244316101074\n",
      "Step: 1900  \tTraining loss: 0.39814451336860657\n",
      "Step: 1900  \tTraining accuracy: 0.7732916474342346\n",
      "Step: 1900  \tValid loss: 0.43563592433929443\n",
      "Step: 2000  \tTraining loss: 0.3969312012195587\n",
      "Step: 2000  \tTraining accuracy: 0.7742220759391785\n",
      "Step: 2000  \tValid loss: 0.4363131821155548\n",
      "Step: 2100  \tTraining loss: 0.39580681920051575\n",
      "Step: 2100  \tTraining accuracy: 0.7750888466835022\n",
      "Step: 2100  \tValid loss: 0.4369999170303345\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7759009\n",
      "Precision: 0.8472803\n",
      "Recall: 0.8083832\n",
      "F1 score: 0.7576724\n",
      "AUC: 0.8124831\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.775901    0.84728  0.808383  0.757672  0.812483  0.395454      0.775041   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.431263       0.775079   0.490864      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2132.0  \n",
      "21\n",
      "(957, 8)\n",
      "(957, 1)\n",
      "(528, 8)\n",
      "(528, 1)\n",
      "(429, 8)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6310562491416931\n",
      "Step: 100  \tTraining accuracy: 0.6593521237373352\n",
      "Step: 100  \tValid loss: 0.6368608474731445\n",
      "Step: 200  \tTraining loss: 0.5301710963249207\n",
      "Step: 200  \tTraining accuracy: 0.6924416422843933\n",
      "Step: 200  \tValid loss: 0.5613366365432739\n",
      "Step: 300  \tTraining loss: 0.4419108033180237\n",
      "Step: 300  \tTraining accuracy: 0.7295715808868408\n",
      "Step: 300  \tValid loss: 0.4739246368408203\n",
      "Step: 400  \tTraining loss: 0.3723287582397461\n",
      "Step: 400  \tTraining accuracy: 0.7645917534828186\n",
      "Step: 400  \tValid loss: 0.40093502402305603\n",
      "Step: 500  \tTraining loss: 0.32635271549224854\n",
      "Step: 500  \tTraining accuracy: 0.7885754108428955\n",
      "Step: 500  \tValid loss: 0.3523496687412262\n",
      "Step: 600  \tTraining loss: 0.2975996732711792\n",
      "Step: 600  \tTraining accuracy: 0.8054526448249817\n",
      "Step: 600  \tValid loss: 0.3220358192920685\n",
      "Step: 700  \tTraining loss: 0.2792523205280304\n",
      "Step: 700  \tTraining accuracy: 0.8182622194290161\n",
      "Step: 700  \tValid loss: 0.3027927577495575\n",
      "Step: 800  \tTraining loss: 0.2670806348323822\n",
      "Step: 800  \tTraining accuracy: 0.8277255296707153\n",
      "Step: 800  \tValid loss: 0.2901860475540161\n",
      "Step: 900  \tTraining loss: 0.2586749494075775\n",
      "Step: 900  \tTraining accuracy: 0.8349007368087769\n",
      "Step: 900  \tValid loss: 0.2816472053527832\n",
      "Step: 1000  \tTraining loss: 0.25265318155288696\n",
      "Step: 1000  \tTraining accuracy: 0.8406753540039062\n",
      "Step: 1000  \tValid loss: 0.2757030725479126\n",
      "Step: 1100  \tTraining loss: 0.24819107353687286\n",
      "Step: 1100  \tTraining accuracy: 0.8453003168106079\n",
      "Step: 1100  \tValid loss: 0.2714623510837555\n",
      "Step: 1200  \tTraining loss: 0.24478058516979218\n",
      "Step: 1200  \tTraining accuracy: 0.8492117524147034\n",
      "Step: 1200  \tValid loss: 0.26837971806526184\n",
      "Step: 1300  \tTraining loss: 0.24209170043468475\n",
      "Step: 1300  \tTraining accuracy: 0.8526228070259094\n",
      "Step: 1300  \tValid loss: 0.266101598739624\n",
      "Step: 1400  \tTraining loss: 0.23990888893604279\n",
      "Step: 1400  \tTraining accuracy: 0.8555284738540649\n",
      "Step: 1400  \tValid loss: 0.2644042372703552\n",
      "Step: 1500  \tTraining loss: 0.2380867600440979\n",
      "Step: 1500  \tTraining accuracy: 0.8581054210662842\n",
      "Step: 1500  \tValid loss: 0.26312747597694397\n",
      "Step: 1600  \tTraining loss: 0.23652788996696472\n",
      "Step: 1600  \tTraining accuracy: 0.8604509830474854\n",
      "Step: 1600  \tValid loss: 0.2621593475341797\n",
      "Step: 1700  \tTraining loss: 0.23516802489757538\n",
      "Step: 1700  \tTraining accuracy: 0.8626072406768799\n",
      "Step: 1700  \tValid loss: 0.26141148805618286\n",
      "Step: 1800  \tTraining loss: 0.23396825790405273\n",
      "Step: 1800  \tTraining accuracy: 0.8645768165588379\n",
      "Step: 1800  \tValid loss: 0.2608058750629425\n",
      "Step: 1900  \tTraining loss: 0.23290055990219116\n",
      "Step: 1900  \tTraining accuracy: 0.866361677646637\n",
      "Step: 1900  \tValid loss: 0.260297954082489\n",
      "Step: 2000  \tTraining loss: 0.23194724321365356\n",
      "Step: 2000  \tTraining accuracy: 0.867990255355835\n",
      "Step: 2000  \tValid loss: 0.25984030961990356\n",
      "Step: 2100  \tTraining loss: 0.23109422624111176\n",
      "Step: 2100  \tTraining accuracy: 0.8695109486579895\n",
      "Step: 2100  \tValid loss: 0.25941380858421326\n",
      "Step: 2200  \tTraining loss: 0.23033055663108826\n",
      "Step: 2200  \tTraining accuracy: 0.8708901405334473\n",
      "Step: 2200  \tValid loss: 0.2590175271034241\n",
      "Step: 2300  \tTraining loss: 0.22964714467525482\n",
      "Step: 2300  \tTraining accuracy: 0.8721699714660645\n",
      "Step: 2300  \tValid loss: 0.2586615979671478\n",
      "Step: 2400  \tTraining loss: 0.22903621196746826\n",
      "Step: 2400  \tTraining accuracy: 0.873340904712677\n",
      "Step: 2400  \tValid loss: 0.258357435464859\n",
      "Step: 2500  \tTraining loss: 0.22849027812480927\n",
      "Step: 2500  \tTraining accuracy: 0.8744375705718994\n",
      "Step: 2500  \tValid loss: 0.25809958577156067\n",
      "Step: 2600  \tTraining loss: 0.2280006855726242\n",
      "Step: 2600  \tTraining accuracy: 0.8754481673240662\n",
      "Step: 2600  \tValid loss: 0.2579064965248108\n",
      "Step: 2700  \tTraining loss: 0.22755920886993408\n",
      "Step: 2700  \tTraining accuracy: 0.8763628602027893\n",
      "Step: 2700  \tValid loss: 0.2577725648880005\n",
      "Step: 2800  \tTraining loss: 0.2271578311920166\n",
      "Step: 2800  \tTraining accuracy: 0.8772299885749817\n",
      "Step: 2800  \tValid loss: 0.25768205523490906\n",
      "Step: 2900  \tTraining loss: 0.22678984701633453\n",
      "Step: 2900  \tTraining accuracy: 0.8780729174613953\n",
      "Step: 2900  \tValid loss: 0.2576294243335724\n",
      "Step: 3000  \tTraining loss: 0.22644944489002228\n",
      "Step: 3000  \tTraining accuracy: 0.878858745098114\n",
      "Step: 3000  \tValid loss: 0.25761088728904724\n",
      "Step: 3100  \tTraining loss: 0.22613176703453064\n",
      "Step: 3100  \tTraining accuracy: 0.8795758485794067\n",
      "Step: 3100  \tValid loss: 0.2576199769973755\n",
      "Step: 3200  \tTraining loss: 0.22583304345607758\n",
      "Step: 3200  \tTraining accuracy: 0.8802474737167358\n",
      "Step: 3200  \tValid loss: 0.25765252113342285\n",
      "Step: 3300  \tTraining loss: 0.2255498766899109\n",
      "Step: 3300  \tTraining accuracy: 0.8808777332305908\n",
      "Step: 3300  \tValid loss: 0.2577054500579834\n",
      "Step: 3400  \tTraining loss: 0.2252798080444336\n",
      "Step: 3400  \tTraining accuracy: 0.881439208984375\n",
      "Step: 3400  \tValid loss: 0.25777557492256165\n",
      "Step: 3500  \tTraining loss: 0.2250206172466278\n",
      "Step: 3500  \tTraining accuracy: 0.881968080997467\n",
      "Step: 3500  \tValid loss: 0.25785964727401733\n",
      "Step: 3600  \tTraining loss: 0.22477106750011444\n",
      "Step: 3600  \tTraining accuracy: 0.8824524879455566\n",
      "Step: 3600  \tValid loss: 0.2579607665538788\n",
      "Step: 3700  \tTraining loss: 0.22449184954166412\n",
      "Step: 3700  \tTraining accuracy: 0.8829246759414673\n",
      "Step: 3700  \tValid loss: 0.258107990026474\n",
      "Step: 3800  \tTraining loss: 0.22423098981380463\n",
      "Step: 3800  \tTraining accuracy: 0.8833716511726379\n",
      "Step: 3800  \tValid loss: 0.2582447826862335\n",
      "Step: 3900  \tTraining loss: 0.223984494805336\n",
      "Step: 3900  \tTraining accuracy: 0.883795440196991\n",
      "Step: 3900  \tValid loss: 0.25836440920829773\n",
      "Step: 4000  \tTraining loss: 0.22369521856307983\n",
      "Step: 4000  \tTraining accuracy: 0.8841844797134399\n",
      "Step: 4000  \tValid loss: 0.25847136974334717\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8845543\n",
      "Precision: 0.9057471\n",
      "Recall: 0.90160185\n",
      "F1 score: 0.88252556\n",
      "AUC: 0.91137785\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.884554   0.905747  0.901602  0.882526  0.911378  0.223659      0.884208   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0   0.25761       0.884233   0.301453      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4010.0  \n",
      "22\n",
      "(1015, 8)\n",
      "(1015, 1)\n",
      "(560, 8)\n",
      "(560, 1)\n",
      "(455, 8)\n",
      "(455, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5917650461196899\n",
      "Step: 100  \tTraining accuracy: 0.7270935773849487\n",
      "Step: 100  \tValid loss: 0.6240785121917725\n",
      "Step: 200  \tTraining loss: 0.5566706657409668\n",
      "Step: 200  \tTraining accuracy: 0.7310344576835632\n",
      "Step: 200  \tValid loss: 0.6113591194152832\n",
      "Step: 300  \tTraining loss: 0.5253132581710815\n",
      "Step: 300  \tTraining accuracy: 0.7357635498046875\n",
      "Step: 300  \tValid loss: 0.585555911064148\n",
      "Step: 400  \tTraining loss: 0.49675872921943665\n",
      "Step: 400  \tTraining accuracy: 0.7400422096252441\n",
      "Step: 400  \tValid loss: 0.5607536435127258\n",
      "Step: 500  \tTraining loss: 0.4767868220806122\n",
      "Step: 500  \tTraining accuracy: 0.7431855797767639\n",
      "Step: 500  \tValid loss: 0.5420186519622803\n",
      "Step: 600  \tTraining loss: 0.4625069200992584\n",
      "Step: 600  \tTraining accuracy: 0.7461710572242737\n",
      "Step: 600  \tValid loss: 0.5271372199058533\n",
      "Step: 700  \tTraining loss: 0.4535355269908905\n",
      "Step: 700  \tTraining accuracy: 0.7483895421028137\n",
      "Step: 700  \tValid loss: 0.5183698534965515\n",
      "Step: 800  \tTraining loss: 0.4481329619884491\n",
      "Step: 800  \tTraining accuracy: 0.7501477599143982\n",
      "Step: 800  \tValid loss: 0.5143711566925049\n",
      "Step: 900  \tTraining loss: 0.4448806345462799\n",
      "Step: 900  \tTraining accuracy: 0.7512025237083435\n",
      "Step: 900  \tValid loss: 0.513224720954895\n",
      "Step: 1000  \tTraining loss: 0.442775160074234\n",
      "Step: 1000  \tTraining accuracy: 0.7521389722824097\n",
      "Step: 1000  \tValid loss: 0.513123095035553\n",
      "Step: 1100  \tTraining loss: 0.4412609338760376\n",
      "Step: 1100  \tTraining accuracy: 0.7530377507209778\n",
      "Step: 1100  \tValid loss: 0.5135920643806458\n",
      "Step: 1200  \tTraining loss: 0.44013917446136475\n",
      "Step: 1200  \tTraining accuracy: 0.7538231015205383\n",
      "Step: 1200  \tValid loss: 0.5141931772232056\n",
      "Step: 1300  \tTraining loss: 0.43922799825668335\n",
      "Step: 1300  \tTraining accuracy: 0.7545221447944641\n",
      "Step: 1300  \tValid loss: 0.5148321390151978\n",
      "Step: 1400  \tTraining loss: 0.438451886177063\n",
      "Step: 1400  \tTraining accuracy: 0.75526362657547\n",
      "Step: 1400  \tValid loss: 0.5154768824577332\n",
      "Step: 1500  \tTraining loss: 0.43777135014533997\n",
      "Step: 1500  \tTraining accuracy: 0.7558348774909973\n",
      "Step: 1500  \tValid loss: 0.5160821676254272\n",
      "Step: 1600  \tTraining loss: 0.43714576959609985\n",
      "Step: 1600  \tTraining accuracy: 0.7563324570655823\n",
      "Step: 1600  \tValid loss: 0.5165554881095886\n",
      "Step: 1700  \tTraining loss: 0.43657639622688293\n",
      "Step: 1700  \tTraining accuracy: 0.7567397952079773\n",
      "Step: 1700  \tValid loss: 0.5170058608055115\n",
      "Step: 1800  \tTraining loss: 0.43603968620300293\n",
      "Step: 1800  \tTraining accuracy: 0.7570161819458008\n",
      "Step: 1800  \tValid loss: 0.5173321962356567\n",
      "Step: 1900  \tTraining loss: 0.43552038073539734\n",
      "Step: 1900  \tTraining accuracy: 0.7571295499801636\n",
      "Step: 1900  \tValid loss: 0.5176181197166443\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7572313\n",
      "Precision: 0.74172187\n",
      "Recall: 0.74832964\n",
      "F1 score: 0.7605893\n",
      "AUC: 0.7708079\n",
      "   accuracy  precision   recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.757231   0.741722  0.74833  0.760589  0.770808  0.435224      0.756806   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.513066       0.757248   0.461486      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1959.0  \n",
      "23\n",
      "(841, 8)\n",
      "(841, 1)\n",
      "(464, 8)\n",
      "(464, 1)\n",
      "(377, 8)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5704256296157837\n",
      "Step: 100  \tTraining accuracy: 0.7241379022598267\n",
      "Step: 100  \tValid loss: 0.5979592800140381\n",
      "Step: 200  \tTraining loss: 0.555094838142395\n",
      "Step: 200  \tTraining accuracy: 0.7213634848594666\n",
      "Step: 200  \tValid loss: 0.5860949754714966\n",
      "Step: 300  \tTraining loss: 0.5442591905593872\n",
      "Step: 300  \tTraining accuracy: 0.7229488492012024\n",
      "Step: 300  \tValid loss: 0.5724111199378967\n",
      "Step: 400  \tTraining loss: 0.5336460471153259\n",
      "Step: 400  \tTraining accuracy: 0.7254968285560608\n",
      "Step: 400  \tValid loss: 0.5579864382743835\n",
      "Step: 500  \tTraining loss: 0.5246392488479614\n",
      "Step: 500  \tTraining accuracy: 0.7290263175964355\n",
      "Step: 500  \tValid loss: 0.5456075072288513\n",
      "Step: 600  \tTraining loss: 0.5172933340072632\n",
      "Step: 600  \tTraining accuracy: 0.7333261370658875\n",
      "Step: 600  \tValid loss: 0.5356977581977844\n",
      "Step: 700  \tTraining loss: 0.5111818909645081\n",
      "Step: 700  \tTraining accuracy: 0.7367602586746216\n",
      "Step: 700  \tValid loss: 0.5279504060745239\n",
      "Step: 800  \tTraining loss: 0.505813717842102\n",
      "Step: 800  \tTraining accuracy: 0.7398335337638855\n",
      "Step: 800  \tValid loss: 0.5218439698219299\n",
      "Step: 900  \tTraining loss: 0.5005426406860352\n",
      "Step: 900  \tTraining accuracy: 0.7426033616065979\n",
      "Step: 900  \tValid loss: 0.5166299343109131\n",
      "Step: 1000  \tTraining loss: 0.49416735768318176\n",
      "Step: 1000  \tTraining accuracy: 0.745228111743927\n",
      "Step: 1000  \tValid loss: 0.5107688307762146\n",
      "Step: 1100  \tTraining loss: 0.4853239953517914\n",
      "Step: 1100  \tTraining accuracy: 0.7476926445960999\n",
      "Step: 1100  \tValid loss: 0.5021532773971558\n",
      "Step: 1200  \tTraining loss: 0.4754250645637512\n",
      "Step: 1200  \tTraining accuracy: 0.7499870657920837\n",
      "Step: 1200  \tValid loss: 0.4923918545246124\n",
      "Step: 1300  \tTraining loss: 0.4669407904148102\n",
      "Step: 1300  \tTraining accuracy: 0.7526278495788574\n",
      "Step: 1300  \tValid loss: 0.48410168290138245\n",
      "Step: 1400  \tTraining loss: 0.4605502188205719\n",
      "Step: 1400  \tTraining accuracy: 0.755185604095459\n",
      "Step: 1400  \tValid loss: 0.47797688841819763\n",
      "Step: 1500  \tTraining loss: 0.45598793029785156\n",
      "Step: 1500  \tTraining accuracy: 0.7575956583023071\n",
      "Step: 1500  \tValid loss: 0.4737495481967926\n",
      "Step: 1600  \tTraining loss: 0.4528117775917053\n",
      "Step: 1600  \tTraining accuracy: 0.7597330212593079\n",
      "Step: 1600  \tValid loss: 0.47094884514808655\n",
      "Step: 1700  \tTraining loss: 0.4506184458732605\n",
      "Step: 1700  \tTraining accuracy: 0.7618635892868042\n",
      "Step: 1700  \tValid loss: 0.4691353738307953\n",
      "Step: 1800  \tTraining loss: 0.44909030199050903\n",
      "Step: 1800  \tTraining accuracy: 0.7638865113258362\n",
      "Step: 1800  \tValid loss: 0.4679695963859558\n",
      "Step: 1900  \tTraining loss: 0.447998583316803\n",
      "Step: 1900  \tTraining accuracy: 0.7657871842384338\n",
      "Step: 1900  \tValid loss: 0.46721670031547546\n",
      "Step: 2000  \tTraining loss: 0.44718918204307556\n",
      "Step: 2000  \tTraining accuracy: 0.7675538659095764\n",
      "Step: 2000  \tValid loss: 0.46672528982162476\n",
      "Step: 2100  \tTraining loss: 0.44656136631965637\n",
      "Step: 2100  \tTraining accuracy: 0.7691192030906677\n",
      "Step: 2100  \tValid loss: 0.46640142798423767\n",
      "Step: 2200  \tTraining loss: 0.4460507929325104\n",
      "Step: 2200  \tTraining accuracy: 0.7706772089004517\n",
      "Step: 2200  \tValid loss: 0.4661884307861328\n",
      "Step: 2300  \tTraining loss: 0.4456169605255127\n",
      "Step: 2300  \tTraining accuracy: 0.7720174193382263\n",
      "Step: 2300  \tValid loss: 0.4660522937774658\n",
      "Step: 2400  \tTraining loss: 0.44523367285728455\n",
      "Step: 2400  \tTraining accuracy: 0.7732436060905457\n",
      "Step: 2400  \tValid loss: 0.46597224473953247\n",
      "Step: 2500  \tTraining loss: 0.4448847770690918\n",
      "Step: 2500  \tTraining accuracy: 0.7744182348251343\n",
      "Step: 2500  \tValid loss: 0.4659351408481598\n",
      "Step: 2600  \tTraining loss: 0.4445596933364868\n",
      "Step: 2600  \tTraining accuracy: 0.7755240201950073\n",
      "Step: 2600  \tValid loss: 0.46593207120895386\n",
      "Step: 2700  \tTraining loss: 0.44425150752067566\n",
      "Step: 2700  \tTraining accuracy: 0.7765238881111145\n",
      "Step: 2700  \tValid loss: 0.465956449508667\n",
      "Step: 2800  \tTraining loss: 0.4439551532268524\n",
      "Step: 2800  \tTraining accuracy: 0.7774510979652405\n",
      "Step: 2800  \tValid loss: 0.466002881526947\n",
      "Step: 2900  \tTraining loss: 0.4436677396297455\n",
      "Step: 2900  \tTraining accuracy: 0.7782923579216003\n",
      "Step: 2900  \tValid loss: 0.46606701612472534\n",
      "Step: 3000  \tTraining loss: 0.44338661432266235\n",
      "Step: 3000  \tTraining accuracy: 0.7790765762329102\n",
      "Step: 3000  \tValid loss: 0.46614527702331543\n",
      "Step: 3100  \tTraining loss: 0.4431098997592926\n",
      "Step: 3100  \tTraining accuracy: 0.7798288464546204\n",
      "Step: 3100  \tValid loss: 0.46623411774635315\n",
      "Step: 3200  \tTraining loss: 0.44283634424209595\n",
      "Step: 3200  \tTraining accuracy: 0.7805333733558655\n",
      "Step: 3200  \tValid loss: 0.4663310647010803\n",
      "Step: 3300  \tTraining loss: 0.44256436824798584\n",
      "Step: 3300  \tTraining accuracy: 0.7811945676803589\n",
      "Step: 3300  \tValid loss: 0.4664340615272522\n",
      "Step: 3400  \tTraining loss: 0.4422929883003235\n",
      "Step: 3400  \tTraining accuracy: 0.7818340063095093\n",
      "Step: 3400  \tValid loss: 0.466540664434433\n",
      "Step: 3500  \tTraining loss: 0.4420209527015686\n",
      "Step: 3500  \tTraining accuracy: 0.7824363708496094\n",
      "Step: 3500  \tValid loss: 0.4666498303413391\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7829881\n",
      "Precision: 0.81869686\n",
      "Recall: 0.94909686\n",
      "F1 score: 0.8407446\n",
      "AUC: 0.69868636\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.782988   0.818697  0.949097  0.840745  0.698686  0.441865      0.782589   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0   0.46593       0.782437    0.47086      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3556.0  \n",
      "24\n",
      "(1189, 8)\n",
      "(1189, 1)\n",
      "(640, 8)\n",
      "(640, 1)\n",
      "(520, 8)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6340808868408203\n",
      "Step: 100  \tTraining accuracy: 0.6089150309562683\n",
      "Step: 100  \tValid loss: 0.6384063363075256\n",
      "Step: 200  \tTraining loss: 0.6049380302429199\n",
      "Step: 200  \tTraining accuracy: 0.6588467955589294\n",
      "Step: 200  \tValid loss: 0.6184295415878296\n",
      "Step: 300  \tTraining loss: 0.5986809134483337\n",
      "Step: 300  \tTraining accuracy: 0.6767453551292419\n",
      "Step: 300  \tValid loss: 0.6159783601760864\n",
      "Step: 400  \tTraining loss: 0.5927111506462097\n",
      "Step: 400  \tTraining accuracy: 0.6847984194755554\n",
      "Step: 400  \tValid loss: 0.6104446053504944\n",
      "Step: 500  \tTraining loss: 0.5872690081596375\n",
      "Step: 500  \tTraining accuracy: 0.6889938712120056\n",
      "Step: 500  \tValid loss: 0.6043100357055664\n",
      "Step: 600  \tTraining loss: 0.5821250081062317\n",
      "Step: 600  \tTraining accuracy: 0.6920519471168518\n",
      "Step: 600  \tValid loss: 0.5981086492538452\n",
      "Step: 700  \tTraining loss: 0.5771238207817078\n",
      "Step: 700  \tTraining accuracy: 0.6937773823738098\n",
      "Step: 700  \tValid loss: 0.5917481184005737\n",
      "Step: 800  \tTraining loss: 0.5724164247512817\n",
      "Step: 800  \tTraining accuracy: 0.6953833699226379\n",
      "Step: 800  \tValid loss: 0.5855902433395386\n",
      "Step: 900  \tTraining loss: 0.5681018233299255\n",
      "Step: 900  \tTraining accuracy: 0.6972123384475708\n",
      "Step: 900  \tValid loss: 0.5799301266670227\n",
      "Step: 1000  \tTraining loss: 0.5643929839134216\n",
      "Step: 1000  \tTraining accuracy: 0.6989700198173523\n",
      "Step: 1000  \tValid loss: 0.5752913355827332\n",
      "Step: 1100  \tTraining loss: 0.5613122582435608\n",
      "Step: 1100  \tTraining accuracy: 0.7004740834236145\n",
      "Step: 1100  \tValid loss: 0.5716328620910645\n",
      "Step: 1200  \tTraining loss: 0.5587748289108276\n",
      "Step: 1200  \tTraining accuracy: 0.7022347450256348\n",
      "Step: 1200  \tValid loss: 0.5687350630760193\n",
      "Step: 1300  \tTraining loss: 0.5566360354423523\n",
      "Step: 1300  \tTraining accuracy: 0.7039520740509033\n",
      "Step: 1300  \tValid loss: 0.5665027499198914\n",
      "Step: 1400  \tTraining loss: 0.5547585487365723\n",
      "Step: 1400  \tTraining accuracy: 0.7055727243423462\n",
      "Step: 1400  \tValid loss: 0.564599335193634\n",
      "Step: 1500  \tTraining loss: 0.5530691742897034\n",
      "Step: 1500  \tTraining accuracy: 0.7070286273956299\n",
      "Step: 1500  \tValid loss: 0.5629607439041138\n",
      "Step: 1600  \tTraining loss: 0.5515353083610535\n",
      "Step: 1600  \tTraining accuracy: 0.7084614634513855\n",
      "Step: 1600  \tValid loss: 0.56155925989151\n",
      "Step: 1700  \tTraining loss: 0.550142228603363\n",
      "Step: 1700  \tTraining accuracy: 0.7095659375190735\n",
      "Step: 1700  \tValid loss: 0.5603736639022827\n",
      "Step: 1800  \tTraining loss: 0.5488317608833313\n",
      "Step: 1800  \tTraining accuracy: 0.7106658220291138\n",
      "Step: 1800  \tValid loss: 0.5594539642333984\n",
      "Step: 1900  \tTraining loss: 0.5475425124168396\n",
      "Step: 1900  \tTraining accuracy: 0.7117388844490051\n",
      "Step: 1900  \tValid loss: 0.5589339733123779\n",
      "Step: 2000  \tTraining loss: 0.5462949872016907\n",
      "Step: 2000  \tTraining accuracy: 0.7125927805900574\n",
      "Step: 2000  \tValid loss: 0.5587781667709351\n",
      "Step: 2100  \tTraining loss: 0.5451322197914124\n",
      "Step: 2100  \tTraining accuracy: 0.7134671807289124\n",
      "Step: 2100  \tValid loss: 0.558445930480957\n",
      "Step: 2200  \tTraining loss: 0.5441054701805115\n",
      "Step: 2200  \tTraining accuracy: 0.7144780158996582\n",
      "Step: 2200  \tValid loss: 0.5582165718078613\n",
      "Step: 2300  \tTraining loss: 0.5432257652282715\n",
      "Step: 2300  \tTraining accuracy: 0.7154746651649475\n",
      "Step: 2300  \tValid loss: 0.558078944683075\n",
      "Step: 2400  \tTraining loss: 0.5424480438232422\n",
      "Step: 2400  \tTraining accuracy: 0.7164589762687683\n",
      "Step: 2400  \tValid loss: 0.5579786896705627\n",
      "Step: 2500  \tTraining loss: 0.5417437553405762\n",
      "Step: 2500  \tTraining accuracy: 0.7173803448677063\n",
      "Step: 2500  \tValid loss: 0.5579208135604858\n",
      "Step: 2600  \tTraining loss: 0.5411227941513062\n",
      "Step: 2600  \tTraining accuracy: 0.718146026134491\n",
      "Step: 2600  \tValid loss: 0.5578861236572266\n",
      "Step: 2700  \tTraining loss: 0.5405486226081848\n",
      "Step: 2700  \tTraining accuracy: 0.7189181447029114\n",
      "Step: 2700  \tValid loss: 0.5578508973121643\n",
      "Step: 2800  \tTraining loss: 0.5399715304374695\n",
      "Step: 2800  \tTraining accuracy: 0.719649612903595\n",
      "Step: 2800  \tValid loss: 0.5579419732093811\n",
      "Step: 2900  \tTraining loss: 0.5393186807632446\n",
      "Step: 2900  \tTraining accuracy: 0.7203596234321594\n",
      "Step: 2900  \tValid loss: 0.558074951171875\n",
      "Step: 3000  \tTraining loss: 0.5387163758277893\n",
      "Step: 3000  \tTraining accuracy: 0.7210214734077454\n",
      "Step: 3000  \tValid loss: 0.5582465529441833\n",
      "Step: 3100  \tTraining loss: 0.5381627082824707\n",
      "Step: 3100  \tTraining accuracy: 0.721653938293457\n",
      "Step: 3100  \tValid loss: 0.5583004951477051\n",
      "Step: 3200  \tTraining loss: 0.5376379489898682\n",
      "Step: 3200  \tTraining accuracy: 0.7221921682357788\n",
      "Step: 3200  \tValid loss: 0.558268129825592\n",
      "Step: 3300  \tTraining loss: 0.5371343493461609\n",
      "Step: 3300  \tTraining accuracy: 0.7227104306221008\n",
      "Step: 3300  \tValid loss: 0.5582770109176636\n",
      "Step: 3400  \tTraining loss: 0.5366498827934265\n",
      "Step: 3400  \tTraining accuracy: 0.7231976985931396\n",
      "Step: 3400  \tValid loss: 0.5581988096237183\n",
      "Step: 3500  \tTraining loss: 0.536185085773468\n",
      "Step: 3500  \tTraining accuracy: 0.7236691117286682\n",
      "Step: 3500  \tValid loss: 0.5580576658248901\n",
      "Step: 3600  \tTraining loss: 0.5357372164726257\n",
      "Step: 3600  \tTraining accuracy: 0.7241499423980713\n",
      "Step: 3600  \tValid loss: 0.5578900575637817\n",
      "Step: 3700  \tTraining loss: 0.5352997779846191\n",
      "Step: 3700  \tTraining accuracy: 0.7245693802833557\n",
      "Step: 3700  \tValid loss: 0.5577346682548523\n",
      "Step: 3800  \tTraining loss: 0.5348701477050781\n",
      "Step: 3800  \tTraining accuracy: 0.7249665260314941\n",
      "Step: 3800  \tValid loss: 0.557558000087738\n",
      "Step: 3900  \tTraining loss: 0.5344475507736206\n",
      "Step: 3900  \tTraining accuracy: 0.7253429889678955\n",
      "Step: 3900  \tValid loss: 0.5573760867118835\n",
      "Step: 4000  \tTraining loss: 0.5340069532394409\n",
      "Step: 4000  \tTraining accuracy: 0.7257543206214905\n",
      "Step: 4000  \tValid loss: 0.5571651458740234\n",
      "Step: 4100  \tTraining loss: 0.5335826277732849\n",
      "Step: 4100  \tTraining accuracy: 0.7261032462120056\n",
      "Step: 4100  \tValid loss: 0.5568960905075073\n",
      "Step: 4200  \tTraining loss: 0.5331631302833557\n",
      "Step: 4200  \tTraining accuracy: 0.7264354228973389\n",
      "Step: 4200  \tValid loss: 0.5567119121551514\n",
      "Step: 4300  \tTraining loss: 0.532754123210907\n",
      "Step: 4300  \tTraining accuracy: 0.7267318964004517\n",
      "Step: 4300  \tValid loss: 0.5565335750579834\n",
      "Step: 4400  \tTraining loss: 0.5323534607887268\n",
      "Step: 4400  \tTraining accuracy: 0.727034330368042\n",
      "Step: 4400  \tValid loss: 0.5563419461250305\n",
      "Step: 4500  \tTraining loss: 0.5319713354110718\n",
      "Step: 4500  \tTraining accuracy: 0.7273327112197876\n",
      "Step: 4500  \tValid loss: 0.5561124086380005\n",
      "Step: 4600  \tTraining loss: 0.5316044092178345\n",
      "Step: 4600  \tTraining accuracy: 0.7276366949081421\n",
      "Step: 4600  \tValid loss: 0.555861234664917\n",
      "Step: 4700  \tTraining loss: 0.5312490463256836\n",
      "Step: 4700  \tTraining accuracy: 0.7279368042945862\n",
      "Step: 4700  \tValid loss: 0.5557056665420532\n",
      "Step: 4800  \tTraining loss: 0.5308961272239685\n",
      "Step: 4800  \tTraining accuracy: 0.7282242178916931\n",
      "Step: 4800  \tValid loss: 0.5555598139762878\n",
      "Step: 4900  \tTraining loss: 0.5305561423301697\n",
      "Step: 4900  \tTraining accuracy: 0.7285085916519165\n",
      "Step: 4900  \tValid loss: 0.5553452372550964\n",
      "Step: 5000  \tTraining loss: 0.5301641225814819\n",
      "Step: 5000  \tTraining accuracy: 0.7287901043891907\n",
      "Step: 5000  \tValid loss: 0.5557038187980652\n",
      "Step: 5100  \tTraining loss: 0.5297781825065613\n",
      "Step: 5100  \tTraining accuracy: 0.7290688753128052\n",
      "Step: 5100  \tValid loss: 0.5557354688644409\n",
      "Step: 5200  \tTraining loss: 0.5294355750083923\n",
      "Step: 5200  \tTraining accuracy: 0.7293450832366943\n",
      "Step: 5200  \tValid loss: 0.5556563138961792\n",
      "Step: 5300  \tTraining loss: 0.5291038155555725\n",
      "Step: 5300  \tTraining accuracy: 0.7296107411384583\n",
      "Step: 5300  \tValid loss: 0.5556327700614929\n",
      "Step: 5400  \tTraining loss: 0.5287788510322571\n",
      "Step: 5400  \tTraining accuracy: 0.7298585176467896\n",
      "Step: 5400  \tValid loss: 0.5555974245071411\n",
      "Step: 5500  \tTraining loss: 0.5284720063209534\n",
      "Step: 5500  \tTraining accuracy: 0.7301206588745117\n",
      "Step: 5500  \tValid loss: 0.5555577278137207\n",
      "Step: 5600  \tTraining loss: 0.5281765460968018\n",
      "Step: 5600  \tTraining accuracy: 0.7303733825683594\n",
      "Step: 5600  \tValid loss: 0.5555784106254578\n",
      "Step: 5700  \tTraining loss: 0.5278889536857605\n",
      "Step: 5700  \tTraining accuracy: 0.7306246161460876\n",
      "Step: 5700  \tValid loss: 0.5555370450019836\n",
      "Step: 5800  \tTraining loss: 0.5276122093200684\n",
      "Step: 5800  \tTraining accuracy: 0.7308597564697266\n",
      "Step: 5800  \tValid loss: 0.5555459260940552\n",
      "Step: 5900  \tTraining loss: 0.5273435115814209\n",
      "Step: 5900  \tTraining accuracy: 0.7311087250709534\n",
      "Step: 5900  \tValid loss: 0.5555970668792725\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7313493\n",
      "Precision: 0.7720207\n",
      "Recall: 0.8232044\n",
      "F1 score: 0.75481504\n",
      "AUC: 0.7223549\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.731349   0.772021  0.823204  0.754815  0.722355  0.527338      0.731238   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.555342        0.73131   0.497342      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5901.0  \n",
      "25\n",
      "(1421, 8)\n",
      "(1421, 1)\n",
      "(768, 8)\n",
      "(768, 1)\n",
      "(624, 8)\n",
      "(624, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6605614423751831\n",
      "Step: 100  \tTraining accuracy: 0.6228008270263672\n",
      "Step: 100  \tValid loss: 0.6481947898864746\n",
      "Step: 200  \tTraining loss: 0.5880527496337891\n",
      "Step: 200  \tTraining accuracy: 0.6525744199752808\n",
      "Step: 200  \tValid loss: 0.566733181476593\n",
      "Step: 300  \tTraining loss: 0.5613692998886108\n",
      "Step: 300  \tTraining accuracy: 0.6758904457092285\n",
      "Step: 300  \tValid loss: 0.5402548909187317\n",
      "Step: 400  \tTraining loss: 0.5561906695365906\n",
      "Step: 400  \tTraining accuracy: 0.6870182752609253\n",
      "Step: 400  \tValid loss: 0.5382737517356873\n",
      "Step: 500  \tTraining loss: 0.5540857911109924\n",
      "Step: 500  \tTraining accuracy: 0.6926536560058594\n",
      "Step: 500  \tValid loss: 0.5380675196647644\n",
      "Step: 600  \tTraining loss: 0.5529136657714844\n",
      "Step: 600  \tTraining accuracy: 0.6959834694862366\n",
      "Step: 600  \tValid loss: 0.5381010174751282\n",
      "Step: 700  \tTraining loss: 0.5520051121711731\n",
      "Step: 700  \tTraining accuracy: 0.6985081434249878\n",
      "Step: 700  \tValid loss: 0.5379483103752136\n",
      "Step: 800  \tTraining loss: 0.5512173771858215\n",
      "Step: 800  \tTraining accuracy: 0.7004073262214661\n",
      "Step: 800  \tValid loss: 0.5379045605659485\n",
      "Step: 900  \tTraining loss: 0.550499677658081\n",
      "Step: 900  \tTraining accuracy: 0.702110767364502\n",
      "Step: 900  \tValid loss: 0.5379908680915833\n",
      "Step: 1000  \tTraining loss: 0.5498377084732056\n",
      "Step: 1000  \tTraining accuracy: 0.7034557461738586\n",
      "Step: 1000  \tValid loss: 0.5381659269332886\n",
      "Step: 1100  \tTraining loss: 0.5491766333580017\n",
      "Step: 1100  \tTraining accuracy: 0.7045108675956726\n",
      "Step: 1100  \tValid loss: 0.5383341312408447\n",
      "Step: 1200  \tTraining loss: 0.5485007166862488\n",
      "Step: 1200  \tTraining accuracy: 0.7056915163993835\n",
      "Step: 1200  \tValid loss: 0.538605272769928\n",
      "Step: 1300  \tTraining loss: 0.5478372573852539\n",
      "Step: 1300  \tTraining accuracy: 0.7068539261817932\n",
      "Step: 1300  \tValid loss: 0.5387219786643982\n",
      "Step: 1400  \tTraining loss: 0.5471773147583008\n",
      "Step: 1400  \tTraining accuracy: 0.7077652215957642\n",
      "Step: 1400  \tValid loss: 0.5388947129249573\n",
      "Step: 1500  \tTraining loss: 0.5464827418327332\n",
      "Step: 1500  \tTraining accuracy: 0.7086243629455566\n",
      "Step: 1500  \tValid loss: 0.5391106009483337\n",
      "Step: 1600  \tTraining loss: 0.5457559823989868\n",
      "Step: 1600  \tTraining accuracy: 0.7093497514724731\n",
      "Step: 1600  \tValid loss: 0.5393134951591492\n",
      "Step: 1700  \tTraining loss: 0.5449767112731934\n",
      "Step: 1700  \tTraining accuracy: 0.7100088596343994\n",
      "Step: 1700  \tValid loss: 0.5396785736083984\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7106738\n",
      "Precision: 0.70319635\n",
      "Recall: 0.69265366\n",
      "F1 score: 0.7053062\n",
      "AUC: 0.7170165\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.710674   0.703196  0.692654  0.705306  0.717017  0.544299      0.710441   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.537889        0.70988   0.563155      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1784.0  \n",
      "26\n",
      "(870, 8)\n",
      "(870, 1)\n",
      "(464, 8)\n",
      "(464, 1)\n",
      "(377, 8)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6510089635848999\n",
      "Step: 100  \tTraining accuracy: 0.6218391060829163\n",
      "Step: 100  \tValid loss: 0.6542765498161316\n",
      "Step: 200  \tTraining loss: 0.6104699969291687\n",
      "Step: 200  \tTraining accuracy: 0.6257264614105225\n",
      "Step: 200  \tValid loss: 0.6179112195968628\n",
      "Step: 300  \tTraining loss: 0.5742940902709961\n",
      "Step: 300  \tTraining accuracy: 0.6356011033058167\n",
      "Step: 300  \tValid loss: 0.5883181095123291\n",
      "Step: 400  \tTraining loss: 0.5503395795822144\n",
      "Step: 400  \tTraining accuracy: 0.6495085954666138\n",
      "Step: 400  \tValid loss: 0.5700410604476929\n",
      "Step: 500  \tTraining loss: 0.5182479619979858\n",
      "Step: 500  \tTraining accuracy: 0.6663209795951843\n",
      "Step: 500  \tValid loss: 0.5525067448616028\n",
      "Step: 600  \tTraining loss: 0.4946128726005554\n",
      "Step: 600  \tTraining accuracy: 0.6796817183494568\n",
      "Step: 600  \tValid loss: 0.5406585931777954\n",
      "Step: 700  \tTraining loss: 0.48338767886161804\n",
      "Step: 700  \tTraining accuracy: 0.6892959475517273\n",
      "Step: 700  \tValid loss: 0.5352160334587097\n"
     ]
    }
   ],
   "source": [
    "neurons = 8\n",
    "\n",
    "\n",
    "for num, subj_file_path in enumerate(subj_files_list):\n",
    "    print(num)\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "    \n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "                \n",
    "#     file_path = file_path + \"/OddEvenPlays\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "    train_data_df= pd.read_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df = pd.read_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df = pd.read_csv(file_path+\"/val_data.csv\")\n",
    "\n",
    " \n",
    "    train_X, train_y, test_X, test_y,val_X,val_y = data_split_odd_even(train_data_df,test_data_df,val_data_df)\n",
    "\n",
    "    pretraining = False;\n",
    "    metric_out_df, prob_train, prob_test, prob_val = train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y)\n",
    "    \n",
    "    print(metric_out_df)\n",
    "    \n",
    "    metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currprev_opts_metricsneurons=\"+str(neurons)+\".csv\")\n",
    " \n",
    "    prob_train_df = pd.DataFrame(prob_train.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "    prob_test_df = pd.DataFrame(prob_test.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "    prob_val_df = pd.DataFrame(prob_val.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "\n",
    "\n",
    "# ################################\n",
    "    prob_train_df.to_csv(file_path + \"/prob_train_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "    prob_test_df.to_csv(file_path + \"/prob_test_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "    prob_val_df.to_csv(file_path + \"/prob_val_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "# #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
