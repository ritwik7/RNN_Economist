{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "onehot_encoder=OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "time_steps = 1\n",
    "inputs = 4\n",
    "outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "    task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "    task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "    task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "    task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "    task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "    task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "    task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "    task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "#     task_df['PrevRT']=task_df['RT'].shift(1)\n",
    "#     task_df.loc[1,'PrevRT']= 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    return task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_split_data(data,start_chunk,end_chunk):\n",
    "    \n",
    "    a=[k for k in range(start_chunk,end_chunk)]\n",
    "    out=[]\n",
    "\n",
    "    for d in range(0,data.shape[0],20):\n",
    "\n",
    "        c= [c+d for c in a]\n",
    "        out = out+c\n",
    "\n",
    "    while out[-1]>=data.shape[0]-1:\n",
    "        out.pop()\n",
    "#     return out\n",
    "    return data[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y): \n",
    "    reset_graph()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 50000\n",
    "    batch_size = int(train_X.shape[0]/2)\n",
    "    # batch_size = 100\n",
    "    length = train_X.shape[0]\n",
    "    display = 100\n",
    "    neurons = neurons\n",
    "\n",
    "    num_batches = 100\n",
    "    seq_len = 10\n",
    "\n",
    "    percent_above_PT = 1\n",
    "\n",
    "    train_threshold = 1.5#PT_R2 + percent_above_PT\n",
    "\n",
    "\n",
    "    save_step = 100\n",
    "\n",
    "\n",
    "    best_loss_val = np.infty\n",
    "    checks_since_last_progress = 0\n",
    "    max_checks_without_progress = 1000\n",
    "\n",
    "\n",
    "    # clear graph (if any) before running\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, time_steps, inputs])\n",
    "\n",
    "    y = tf.placeholder(tf.float32, [None, outputs])\n",
    "\n",
    "    # LSTM Cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=neurons, activation=tf.nn.relu)\n",
    "    cell_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "    # pass into Dense layer\n",
    "    stacked_outputs = tf.reshape(cell_outputs, [-1, neurons])\n",
    "    out = tf.layers.dense(inputs=stacked_outputs, units=outputs)\n",
    "\n",
    "    probability = tf.nn.softmax(out)\n",
    "\n",
    "    # squared error loss or cost function for linear regression\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=y, logits=out))\n",
    "\n",
    "    # optimizer to minimize cost\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels =  tf.argmax(y, 1),\n",
    "                          predictions = tf.argmax(out, 1),\n",
    "                          name = \"accuracy\")\n",
    "    precision = tf.metrics.precision(labels=tf.argmax(y, 1),\n",
    "                                 predictions=tf.argmax(out, 1),\n",
    "                                 name=\"precision\")\n",
    "    recall = tf.metrics.recall(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"recall\")\n",
    "    f1 = 2 * accuracy[1] * recall[1] / ( precision[1] + recall[1] )\n",
    "\n",
    "    acc_up,acc_val = accuracy\n",
    "    auc = tf.metrics.auc(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"auc\")\n",
    "    \n",
    "    valid_store = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #######################\n",
    "#         saver.restore(sess, \"./checkpts/Original_RNN_LSTM_8features_v2.ckpt\")\n",
    "#         saver.restore(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "        \n",
    "        if pretraining == True:\n",
    "\n",
    "            saver.restore(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        #######################\n",
    "        \n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "\n",
    "        # Train the model\n",
    "        for steps in range(epochs):\n",
    "            mini_batch = zip(range(0, length, batch_size),\n",
    "                       range(batch_size, length+1, batch_size))\n",
    "\n",
    "            # train data in mini-batches\n",
    "            for (start, end) in mini_batch:\n",
    "    #             print(start,end)\n",
    "                sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "                                                   y: train_y[start:end,:]}) \n",
    "\n",
    "            ## train data in batches of length subsequence\n",
    "\n",
    "    #         for k in range(num_batches):\n",
    "    #             X_seq, y_seq = random_subsequence(train_X,train_y,seq_len)\n",
    "\n",
    "    #             sess.run(training_op, feed_dict = {X:X_seq,y:y_seq}) \n",
    "            loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "            loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "            # print training performance \n",
    "            if (steps+1) % display == 0:\n",
    "                # evaluate loss function on training set\n",
    "\n",
    "\n",
    "                loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining loss: {}'.format((steps+1), loss_fn))\n",
    "\n",
    "                acc_train = acc_val.eval(feed_dict={X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining accuracy: {}'.format((steps+1), acc_train))\n",
    "\n",
    "\n",
    "                acc_test = acc_val.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest accuracy: {}'.format((steps+1), acc_test))\n",
    "\n",
    "                loss_test = loss.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest loss: {}'.format((steps+1), loss_test))\n",
    "\n",
    "                accu_val = acc_val.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "                loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "                print('Step: {}  \\tValid loss: {}'.format((steps+1), loss_val))\n",
    "\n",
    "                valid_store.append(loss_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (1 + loss_fn/np.log(0.5)) > train_threshold:\n",
    "                    print(\"Threshold achieved, quit training\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            if loss_val < best_loss_val:\n",
    "\n",
    "                        best_loss_val = loss_val\n",
    "                        checks_since_last_progress = 0\n",
    "            else:\n",
    "                            checks_since_last_progress += 1\n",
    "\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if checks_since_last_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "\n",
    "            if (steps+1) % save_step ==0:\n",
    "                                save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#                 save_path = saver.save(sess, \"./checkpts/RNN_Internet_LSTM_model_5features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     evaluate model accuracy\n",
    "        acc, prec, recall, f1, AUC = sess.run([accuracy, precision, recall, f1,auc],\n",
    "                                         feed_dict = {X: train_X, y: train_y})\n",
    "        prob_train = probability.eval(feed_dict = {X: train_X, y: train_y})\n",
    "        prob_test = probability.eval(feed_dict = {X: test_X, y: test_y})\n",
    "        prob_valid = probability.eval(feed_dict = {X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nEvaluation  on training set')\n",
    "        print('Accuracy:', acc[1])\n",
    "        print('Precision:', prec[1])\n",
    "        print('Recall:', recall[1])\n",
    "        print('F1 score:', f1)\n",
    "        print('AUC:', AUC[1])\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        \n",
    "#         save_path = saver.save(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/LaterDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## APP DATA\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "        save_path = saver.save(sess, \"./checkpts/Later_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "    metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,AUC[1],loss_fn,accu_val,best_loss_val,acc_test,loss_test,neurons,learning_rate,epochs,steps]).reshape(-1,14),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\",\"loss\",\"accuracy_val\",\"loss_val\",\"accuracy_test\",\"loss_test\",\"neurons\",\"learning_rate\",\"n_epochs\",\"steps\"])\n",
    "    return metric_out_df, prob_train, prob_test, prob_valid\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def random_subsequence(X,y,seq_len):\n",
    "    rnd  = random.randint(0,len(X)-seq_len)\n",
    "    X_seq, y_seq = X[rnd:rnd+seq_len,:], y[rnd:rnd+seq_len,:]\n",
    "    return X_seq, y_seq\n",
    "\n",
    "    print(y_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odd plays train, even plays test and valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\")\n",
    "dir_path =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"\n",
    "\n",
    "subj_files_list =[]; ## list of subject_files fullfilling a criteria\n",
    "\n",
    "dir_files = [i for i in os.listdir(dir_path) if i.startswith('sub')]\n",
    "\n",
    "for subj_file_path in dir_files:\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "    \n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]   \n",
    "    \n",
    "    if len(play_names) >= 50: ## criteria\n",
    "        subj_files_list.append(subj_file_path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subj_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "num_shuffles=1\n",
    "for num, subj_file_path in enumerate(subj_files_list):\n",
    "    print(num)\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "    \n",
    "#     train_data,test_data, val_data = np.empty((0,task_df.columns.shape[0])),  np.empty((0,task_df.columns.shape[0])), np.empty((0,task_df.columns.shape[0]))\n",
    "    train_data,test_data, val_data = np.empty((0,15)),  np.empty((0,15)), np.empty((0,15))\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "        \n",
    "    comp_task_train_df = pd.DataFrame()\n",
    "\n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]    \n",
    "\n",
    "    for randomization_counter in range(0,num_shuffles):\n",
    "            randomized_play_names= random.sample(play_names,len(play_names))\n",
    "            \n",
    "            for play_num, play_name in enumerate(randomized_play_names):\n",
    "#         for play_num,play_name in enumerate(play_names):\n",
    "\n",
    "                file_name = file_path + \"/\" + play_name\n",
    "                task_df = pd.read_csv(file_name)\n",
    "                task_df = add_releveant_features(task_df)\n",
    "\n",
    "                if np.mod(play_num,2)==0: ## odd trials\n",
    "                    train_data = np.append(train_data,task_df[task_df.TrialNum>1].values, axis=0)\n",
    "\n",
    "                else:\n",
    "                    test_data =  np.append(test_data, task_df[task_df.TrialNum>1].values[0:16], axis=0)\n",
    "                    val_data =  np.append(val_data, task_df[task_df.TrialNum>1].values[16:], axis=0)\n",
    "\n",
    "\n",
    "    train_data_df= pd.DataFrame(train_data,columns=task_df.columns)\n",
    "    val_data_df = pd.DataFrame(test_data,columns=task_df.columns)\n",
    "    test_data_df= pd.DataFrame(val_data,columns=task_df.columns)\n",
    "\n",
    "#     file_path = file_path + \"/OddEvenPlays/\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "#     os.mkdir(file_path)\n",
    "    train_data_df.to_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df.to_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df.to_csv(file_path+\"/val_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_odd_even(train_data_df,test_data_df,val_data_df):\n",
    "\n",
    "#     train_len = 29\n",
    "#     test_len = 14\n",
    "#     val_len = 15\n",
    "\n",
    "    ##----------------- UNCOMMENT BELOW\n",
    "    \n",
    "    if hist_flag==0: ## CURR OPTIONS ONLY\n",
    "        \n",
    "    \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "    elif hist_flag==1: ## CURR OPTIONS, PREV ACTIONS:\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "        \n",
    "        \n",
    "      \n",
    "    elif hist_flag==2: # CURR OPTIONS, PREV OUTCOME        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif hist_flag==3: ## CURR OPTIONS, PREV ACTIONS, PREV OUTCOME\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "             \n",
    "        \n",
    "\n",
    "####### Prev O + C+ R + CurrO--------------------\n",
    "    elif hist_flag==4: # CURR OPTIONS, PREV ACTIONS, PREV OUTCOME, PREV OPTIONS\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ######## sampling \n",
    "    \n",
    "    \n",
    "#### - Prev RT+C+R+O + Curr O----------------------\n",
    "\n",
    "#     train_X = task_df.loc[task_df.TrialNum>1, ['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     train_y = task_df.loc[task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### PRE TRAINING\n",
    "#     stop = int(0.7*len(train_X))\n",
    "#     print(stop)\n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y= train_X[:stop], train_X[stop:stop+int((len(train_X)-stop)/2)], train_X[stop+int((len(train_X)-stop)/2):],train_y[:stop], train_y[stop:stop+int((len(train_X)-stop)/2)], train_y[stop+int((len(train_X)-stop)/2):]\n",
    "    \n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y = train_X, test_X, test_X, train_y, test_y, test_y\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "    print(val_X.shape)\n",
    "    print(val_y.shape)\n",
    "    print(test_X.shape)\n",
    "    print(test_y.shape)\n",
    "\n",
    "    # # center and scale\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.fit_transform(test_X)\n",
    "    val_X = scaler.fit_transform(val_X)\n",
    "\n",
    "\n",
    "    train_X = train_X[:,None,:]\n",
    "    val_X = val_X[:,None,:]\n",
    "    test_X = test_X[:,None,:]\n",
    "\n",
    "\n",
    "    # # one-hot encode the outputs\n",
    "\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "    encode_categorical_test = test_y.reshape(len(test_y), 1)\n",
    "    encode_categorical_val = val_y.reshape(len(val_y),1)\n",
    "\n",
    "\n",
    "    train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "    test_y = onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "    val_y = onehot_encoder.fit_transform(encode_categorical_val).toarray()\n",
    "\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y, val_X,val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1189, 4)\n",
      "(1189, 1)\n",
      "(640, 4)\n",
      "(640, 1)\n",
      "(520, 4)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4122586250305176\n",
      "Step: 100  \tTraining accuracy: 0.8696383237838745\n",
      "Step: 100  \tValid loss: 0.4179782271385193\n",
      "Step: 200  \tTraining loss: 0.3965326249599457\n",
      "Step: 200  \tTraining accuracy: 0.8651780486106873\n",
      "Step: 200  \tValid loss: 0.4017415940761566\n",
      "Step: 300  \tTraining loss: 0.3911227881908417\n",
      "Step: 300  \tTraining accuracy: 0.8642772436141968\n",
      "Step: 300  \tValid loss: 0.39914512634277344\n",
      "Step: 400  \tTraining loss: 0.3882175087928772\n",
      "Step: 400  \tTraining accuracy: 0.8638902306556702\n",
      "Step: 400  \tValid loss: 0.39857369661331177\n",
      "Step: 500  \tTraining loss: 0.3867374360561371\n",
      "Step: 500  \tTraining accuracy: 0.8636749982833862\n",
      "Step: 500  \tValid loss: 0.39885038137435913\n",
      "Step: 600  \tTraining loss: 0.3859616816043854\n",
      "Step: 600  \tTraining accuracy: 0.8635379672050476\n",
      "Step: 600  \tValid loss: 0.3993118703365326\n",
      "Step: 700  \tTraining loss: 0.3855016529560089\n",
      "Step: 700  \tTraining accuracy: 0.8634430170059204\n",
      "Step: 700  \tValid loss: 0.3996945023536682\n",
      "Step: 800  \tTraining loss: 0.385179340839386\n",
      "Step: 800  \tTraining accuracy: 0.8633733987808228\n",
      "Step: 800  \tValid loss: 0.3999437689781189\n",
      "Step: 900  \tTraining loss: 0.38491958379745483\n",
      "Step: 900  \tTraining accuracy: 0.8633201718330383\n",
      "Step: 900  \tValid loss: 0.40008267760276794\n",
      "Step: 1000  \tTraining loss: 0.3846918046474457\n",
      "Step: 1000  \tTraining accuracy: 0.8632780909538269\n",
      "Step: 1000  \tValid loss: 0.4001482129096985\n",
      "Step: 1100  \tTraining loss: 0.3844810724258423\n",
      "Step: 1100  \tTraining accuracy: 0.8632440567016602\n",
      "Step: 1100  \tValid loss: 0.40017175674438477\n",
      "Step: 1200  \tTraining loss: 0.38427790999412537\n",
      "Step: 1200  \tTraining accuracy: 0.8632159233093262\n",
      "Step: 1200  \tValid loss: 0.40017637610435486\n",
      "Step: 1300  \tTraining loss: 0.3840741813182831\n",
      "Step: 1300  \tTraining accuracy: 0.8631923198699951\n",
      "Step: 1300  \tValid loss: 0.40017786622047424\n",
      "Step: 1400  \tTraining loss: 0.38386568427085876\n",
      "Step: 1400  \tTraining accuracy: 0.863172173500061\n",
      "Step: 1400  \tValid loss: 0.4001871943473816\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8631548\n",
      "Precision: 0.8696383\n",
      "Recall: 1.0\n",
      "F1 score: 0.92333883\n",
      "AUC: 0.5\n",
      "   accuracy  precision  recall  f1_score  auc      loss  accuracy_val  \\\n",
      "0  0.863155   0.869638     1.0  0.923339  0.5  0.383866       0.86292   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.398574       0.862898   0.427909      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1399.0  \n",
      "1\n",
      "(4263, 4)\n",
      "(4263, 1)\n",
      "(2352, 4)\n",
      "(2352, 1)\n",
      "(1911, 4)\n",
      "(1911, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5436684489250183\n",
      "Step: 100  \tTraining accuracy: 0.7593244314193726\n",
      "Step: 100  \tValid loss: 0.5600231289863586\n",
      "Step: 200  \tTraining loss: 0.5274693965911865\n",
      "Step: 200  \tTraining accuracy: 0.7523652911186218\n",
      "Step: 200  \tValid loss: 0.5514146685600281\n",
      "Step: 300  \tTraining loss: 0.5236079096794128\n",
      "Step: 300  \tTraining accuracy: 0.7509734630584717\n",
      "Step: 300  \tValid loss: 0.5470257997512817\n",
      "Step: 400  \tTraining loss: 0.5190865397453308\n",
      "Step: 400  \tTraining accuracy: 0.7503769993782043\n",
      "Step: 400  \tValid loss: 0.54180508852005\n",
      "Step: 500  \tTraining loss: 0.5136435627937317\n",
      "Step: 500  \tTraining accuracy: 0.7500455975532532\n",
      "Step: 500  \tValid loss: 0.5356355905532837\n",
      "Step: 600  \tTraining loss: 0.5068587064743042\n",
      "Step: 600  \tTraining accuracy: 0.7498347163200378\n",
      "Step: 600  \tValid loss: 0.5280548930168152\n",
      "Step: 700  \tTraining loss: 0.4980684220790863\n",
      "Step: 700  \tTraining accuracy: 0.7496887445449829\n",
      "Step: 700  \tValid loss: 0.5182709097862244\n",
      "Step: 800  \tTraining loss: 0.486027330160141\n",
      "Step: 800  \tTraining accuracy: 0.7495816946029663\n",
      "Step: 800  \tValid loss: 0.5047454833984375\n",
      "Step: 900  \tTraining loss: 0.4691801965236664\n",
      "Step: 900  \tTraining accuracy: 0.7494997978210449\n",
      "Step: 900  \tValid loss: 0.4856184422969818\n",
      "Step: 1000  \tTraining loss: 0.4508223533630371\n",
      "Step: 1000  \tTraining accuracy: 0.7501018643379211\n",
      "Step: 1000  \tValid loss: 0.46529585123062134\n",
      "Step: 1100  \tTraining loss: 0.43621572852134705\n",
      "Step: 1100  \tTraining accuracy: 0.7516950964927673\n",
      "Step: 1100  \tValid loss: 0.44848087430000305\n",
      "Step: 1200  \tTraining loss: 0.4263128340244293\n",
      "Step: 1200  \tTraining accuracy: 0.7537761926651001\n",
      "Step: 1200  \tValid loss: 0.4367067515850067\n",
      "Step: 1300  \tTraining loss: 0.4204699397087097\n",
      "Step: 1300  \tTraining accuracy: 0.756331205368042\n",
      "Step: 1300  \tValid loss: 0.4295795261859894\n",
      "Step: 1400  \tTraining loss: 0.41719284653663635\n",
      "Step: 1400  \tTraining accuracy: 0.758803129196167\n",
      "Step: 1400  \tValid loss: 0.4251801371574402\n",
      "Step: 1500  \tTraining loss: 0.41539618372917175\n",
      "Step: 1500  \tTraining accuracy: 0.7611443996429443\n",
      "Step: 1500  \tValid loss: 0.4224779009819031\n",
      "Step: 1600  \tTraining loss: 0.4144308567047119\n",
      "Step: 1600  \tTraining accuracy: 0.7632516622543335\n",
      "Step: 1600  \tValid loss: 0.42082908749580383\n",
      "Step: 1700  \tTraining loss: 0.41387391090393066\n",
      "Step: 1700  \tTraining accuracy: 0.7651746273040771\n",
      "Step: 1700  \tValid loss: 0.4197823405265808\n",
      "Step: 1800  \tTraining loss: 0.41347789764404297\n",
      "Step: 1800  \tTraining accuracy: 0.7669180035591125\n",
      "Step: 1800  \tValid loss: 0.4191402494907379\n",
      "Step: 1900  \tTraining loss: 0.4132920503616333\n",
      "Step: 1900  \tTraining accuracy: 0.768523633480072\n",
      "Step: 1900  \tValid loss: 0.41880205273628235\n",
      "Step: 2000  \tTraining loss: 0.41315361857414246\n",
      "Step: 2000  \tTraining accuracy: 0.7700367569923401\n",
      "Step: 2000  \tValid loss: 0.41846999526023865\n",
      "Step: 2100  \tTraining loss: 0.412943035364151\n",
      "Step: 2100  \tTraining accuracy: 0.7714422941207886\n",
      "Step: 2100  \tValid loss: 0.41819655895233154\n",
      "Step: 2200  \tTraining loss: 0.4128550589084625\n",
      "Step: 2200  \tTraining accuracy: 0.7727498412132263\n",
      "Step: 2200  \tValid loss: 0.4180606007575989\n",
      "Step: 2300  \tTraining loss: 0.412749707698822\n",
      "Step: 2300  \tTraining accuracy: 0.7739202976226807\n",
      "Step: 2300  \tValid loss: 0.41780707240104675\n",
      "Step: 2400  \tTraining loss: 0.412712424993515\n",
      "Step: 2400  \tTraining accuracy: 0.7749961614608765\n",
      "Step: 2400  \tValid loss: 0.4177669882774353\n",
      "Step: 2500  \tTraining loss: 0.41268086433410645\n",
      "Step: 2500  \tTraining accuracy: 0.7759745717048645\n",
      "Step: 2500  \tValid loss: 0.4177221655845642\n",
      "Step: 2600  \tTraining loss: 0.4126487970352173\n",
      "Step: 2600  \tTraining accuracy: 0.7768808603286743\n",
      "Step: 2600  \tValid loss: 0.4176882803440094\n",
      "Step: 2700  \tTraining loss: 0.41261518001556396\n",
      "Step: 2700  \tTraining accuracy: 0.7777143120765686\n",
      "Step: 2700  \tValid loss: 0.41766050457954407\n",
      "Step: 2800  \tTraining loss: 0.4125729501247406\n",
      "Step: 2800  \tTraining accuracy: 0.7785042524337769\n",
      "Step: 2800  \tValid loss: 0.41761893033981323\n",
      "Step: 2900  \tTraining loss: 0.41252589225769043\n",
      "Step: 2900  \tTraining accuracy: 0.7792428731918335\n",
      "Step: 2900  \tValid loss: 0.4176180958747864\n",
      "Step: 3000  \tTraining loss: 0.4124768078327179\n",
      "Step: 3000  \tTraining accuracy: 0.7799273729324341\n",
      "Step: 3000  \tValid loss: 0.4176075756549835\n",
      "Step: 3100  \tTraining loss: 0.4124205410480499\n",
      "Step: 3100  \tTraining accuracy: 0.780570924282074\n",
      "Step: 3100  \tValid loss: 0.41755908727645874\n",
      "Step: 3200  \tTraining loss: 0.4123561382293701\n",
      "Step: 3200  \tTraining accuracy: 0.781177282333374\n",
      "Step: 3200  \tValid loss: 0.4174995720386505\n",
      "Step: 3300  \tTraining loss: 0.41227877140045166\n",
      "Step: 3300  \tTraining accuracy: 0.7817463278770447\n",
      "Step: 3300  \tValid loss: 0.41744160652160645\n",
      "Step: 3400  \tTraining loss: 0.4121898412704468\n",
      "Step: 3400  \tTraining accuracy: 0.7822779417037964\n",
      "Step: 3400  \tValid loss: 0.41736865043640137\n",
      "Step: 3500  \tTraining loss: 0.4120807349681854\n",
      "Step: 3500  \tTraining accuracy: 0.7827786803245544\n",
      "Step: 3500  \tValid loss: 0.4172843396663666\n",
      "Step: 3600  \tTraining loss: 0.4119545817375183\n",
      "Step: 3600  \tTraining accuracy: 0.7832512259483337\n",
      "Step: 3600  \tValid loss: 0.4171769320964813\n",
      "Step: 3700  \tTraining loss: 0.4118102788925171\n",
      "Step: 3700  \tTraining accuracy: 0.7837011218070984\n",
      "Step: 3700  \tValid loss: 0.4170680642127991\n",
      "Step: 3800  \tTraining loss: 0.41164565086364746\n",
      "Step: 3800  \tTraining accuracy: 0.7841082215309143\n",
      "Step: 3800  \tValid loss: 0.41692912578582764\n",
      "Step: 3900  \tTraining loss: 0.4114494025707245\n",
      "Step: 3900  \tTraining accuracy: 0.7844880819320679\n",
      "Step: 3900  \tValid loss: 0.416827917098999\n",
      "Step: 4000  \tTraining loss: 0.41121870279312134\n",
      "Step: 4000  \tTraining accuracy: 0.784845769405365\n",
      "Step: 4000  \tValid loss: 0.4167312681674957\n",
      "Step: 4100  \tTraining loss: 0.410953551530838\n",
      "Step: 4100  \tTraining accuracy: 0.785191535949707\n",
      "Step: 4100  \tValid loss: 0.41647717356681824\n",
      "Step: 4200  \tTraining loss: 0.4106708765029907\n",
      "Step: 4200  \tTraining accuracy: 0.7855150103569031\n",
      "Step: 4200  \tValid loss: 0.41624540090560913\n",
      "Step: 4300  \tTraining loss: 0.4104110300540924\n",
      "Step: 4300  \tTraining accuracy: 0.7858205437660217\n",
      "Step: 4300  \tValid loss: 0.41595959663391113\n",
      "Step: 4400  \tTraining loss: 0.41015946865081787\n",
      "Step: 4400  \tTraining accuracy: 0.7861092686653137\n",
      "Step: 4400  \tValid loss: 0.4157141149044037\n",
      "Step: 4500  \tTraining loss: 0.4099210202693939\n",
      "Step: 4500  \tTraining accuracy: 0.7864008545875549\n",
      "Step: 4500  \tValid loss: 0.41548028588294983\n",
      "Step: 4600  \tTraining loss: 0.4096902012825012\n",
      "Step: 4600  \tTraining accuracy: 0.786695122718811\n",
      "Step: 4600  \tValid loss: 0.4152665138244629\n",
      "Step: 4700  \tTraining loss: 0.40946346521377563\n",
      "Step: 4700  \tTraining accuracy: 0.78697669506073\n",
      "Step: 4700  \tValid loss: 0.41505348682403564\n",
      "Step: 4800  \tTraining loss: 0.40914782881736755\n",
      "Step: 4800  \tTraining accuracy: 0.7872340679168701\n",
      "Step: 4800  \tValid loss: 0.41493475437164307\n",
      "Step: 4900  \tTraining loss: 0.40878692269325256\n",
      "Step: 4900  \tTraining accuracy: 0.7874953746795654\n",
      "Step: 4900  \tValid loss: 0.4146742522716522\n",
      "Step: 5000  \tTraining loss: 0.40844812989234924\n",
      "Step: 5000  \tTraining accuracy: 0.787757933139801\n",
      "Step: 5000  \tValid loss: 0.4144274592399597\n",
      "Step: 5100  \tTraining loss: 0.4080800414085388\n",
      "Step: 5100  \tTraining accuracy: 0.7880101203918457\n",
      "Step: 5100  \tValid loss: 0.41410398483276367\n",
      "Step: 5200  \tTraining loss: 0.40776824951171875\n",
      "Step: 5200  \tTraining accuracy: 0.7882570624351501\n",
      "Step: 5200  \tValid loss: 0.41369175910949707\n",
      "Step: 5300  \tTraining loss: 0.40749815106391907\n",
      "Step: 5300  \tTraining accuracy: 0.7884990572929382\n",
      "Step: 5300  \tValid loss: 0.41346779465675354\n",
      "Step: 5400  \tTraining loss: 0.407244473695755\n",
      "Step: 5400  \tTraining accuracy: 0.7887188196182251\n",
      "Step: 5400  \tValid loss: 0.4132320284843445\n",
      "Step: 5500  \tTraining loss: 0.4070051908493042\n",
      "Step: 5500  \tTraining accuracy: 0.7889262437820435\n",
      "Step: 5500  \tValid loss: 0.4129668176174164\n",
      "Step: 5600  \tTraining loss: 0.4068051278591156\n",
      "Step: 5600  \tTraining accuracy: 0.7891431450843811\n",
      "Step: 5600  \tValid loss: 0.41274333000183105\n",
      "Step: 5700  \tTraining loss: 0.40662726759910583\n",
      "Step: 5700  \tTraining accuracy: 0.7893626689910889\n",
      "Step: 5700  \tValid loss: 0.41257163882255554\n",
      "Step: 5800  \tTraining loss: 0.40647220611572266\n",
      "Step: 5800  \tTraining accuracy: 0.7895705103874207\n",
      "Step: 5800  \tValid loss: 0.41240525245666504\n",
      "Step: 5900  \tTraining loss: 0.40632519125938416\n",
      "Step: 5900  \tTraining accuracy: 0.7897592186927795\n",
      "Step: 5900  \tValid loss: 0.41229724884033203\n",
      "Step: 6000  \tTraining loss: 0.40618395805358887\n",
      "Step: 6000  \tTraining accuracy: 0.7899396419525146\n",
      "Step: 6000  \tValid loss: 0.4121522903442383\n",
      "Step: 6100  \tTraining loss: 0.4060564339160919\n",
      "Step: 6100  \tTraining accuracy: 0.7901121377944946\n",
      "Step: 6100  \tValid loss: 0.41203197836875916\n",
      "Step: 6200  \tTraining loss: 0.40593910217285156\n",
      "Step: 6200  \tTraining accuracy: 0.7902751564979553\n",
      "Step: 6200  \tValid loss: 0.4118715226650238\n",
      "Step: 6300  \tTraining loss: 0.40584349632263184\n",
      "Step: 6300  \tTraining accuracy: 0.7904386520385742\n",
      "Step: 6300  \tValid loss: 0.41178789734840393\n",
      "Step: 6400  \tTraining loss: 0.40575844049453735\n",
      "Step: 6400  \tTraining accuracy: 0.7906006574630737\n",
      "Step: 6400  \tValid loss: 0.4117024838924408\n",
      "Step: 6500  \tTraining loss: 0.40567746758461\n",
      "Step: 6500  \tTraining accuracy: 0.7907503843307495\n",
      "Step: 6500  \tValid loss: 0.41160234808921814\n",
      "Step: 6600  \tTraining loss: 0.4056129455566406\n",
      "Step: 6600  \tTraining accuracy: 0.7908973693847656\n",
      "Step: 6600  \tValid loss: 0.4115350842475891\n",
      "Step: 6700  \tTraining loss: 0.4055544137954712\n",
      "Step: 6700  \tTraining accuracy: 0.7910363674163818\n",
      "Step: 6700  \tValid loss: 0.41148611903190613\n",
      "Step: 6800  \tTraining loss: 0.40550267696380615\n",
      "Step: 6800  \tTraining accuracy: 0.791172981262207\n",
      "Step: 6800  \tValid loss: 0.41141706705093384\n",
      "Step: 6900  \tTraining loss: 0.4054548740386963\n",
      "Step: 6900  \tTraining accuracy: 0.7913038730621338\n",
      "Step: 6900  \tValid loss: 0.4113732874393463\n",
      "Step: 7000  \tTraining loss: 0.40541309118270874\n",
      "Step: 7000  \tTraining accuracy: 0.7914327383041382\n",
      "Step: 7000  \tValid loss: 0.4113292098045349\n",
      "Step: 7100  \tTraining loss: 0.4053766429424286\n",
      "Step: 7100  \tTraining accuracy: 0.7915579080581665\n",
      "Step: 7100  \tValid loss: 0.4112790822982788\n",
      "Step: 7200  \tTraining loss: 0.4053455591201782\n",
      "Step: 7200  \tTraining accuracy: 0.7916812300682068\n",
      "Step: 7200  \tValid loss: 0.4112609028816223\n",
      "Step: 7300  \tTraining loss: 0.4053167402744293\n",
      "Step: 7300  \tTraining accuracy: 0.7918011546134949\n",
      "Step: 7300  \tValid loss: 0.4112382233142853\n",
      "Step: 7400  \tTraining loss: 0.40529194474220276\n",
      "Step: 7400  \tTraining accuracy: 0.7919178009033203\n",
      "Step: 7400  \tValid loss: 0.4112159013748169\n",
      "Step: 7500  \tTraining loss: 0.40526968240737915\n",
      "Step: 7500  \tTraining accuracy: 0.7920313477516174\n",
      "Step: 7500  \tValid loss: 0.41121652722358704\n",
      "Step: 7600  \tTraining loss: 0.40525001287460327\n",
      "Step: 7600  \tTraining accuracy: 0.7921403050422668\n",
      "Step: 7600  \tValid loss: 0.41120609641075134\n",
      "Step: 7700  \tTraining loss: 0.40523192286491394\n",
      "Step: 7700  \tTraining accuracy: 0.792246401309967\n",
      "Step: 7700  \tValid loss: 0.4112105071544647\n",
      "Step: 7800  \tTraining loss: 0.4052145779132843\n",
      "Step: 7800  \tTraining accuracy: 0.7923497557640076\n",
      "Step: 7800  \tValid loss: 0.4111919403076172\n",
      "Step: 7900  \tTraining loss: 0.4051991105079651\n",
      "Step: 7900  \tTraining accuracy: 0.7924520373344421\n",
      "Step: 7900  \tValid loss: 0.4111729860305786\n",
      "Step: 8000  \tTraining loss: 0.4051840603351593\n",
      "Step: 8000  \tTraining accuracy: 0.7925531268119812\n",
      "Step: 8000  \tValid loss: 0.4111911356449127\n",
      "Step: 8100  \tTraining loss: 0.4051700830459595\n",
      "Step: 8100  \tTraining accuracy: 0.7926459312438965\n",
      "Step: 8100  \tValid loss: 0.4112212061882019\n",
      "Step: 8200  \tTraining loss: 0.40515536069869995\n",
      "Step: 8200  \tTraining accuracy: 0.7927336096763611\n",
      "Step: 8200  \tValid loss: 0.4112035036087036\n",
      "Step: 8300  \tTraining loss: 0.4051421880722046\n",
      "Step: 8300  \tTraining accuracy: 0.7928248047828674\n",
      "Step: 8300  \tValid loss: 0.4112013876438141\n",
      "Step: 8400  \tTraining loss: 0.40512901544570923\n",
      "Step: 8400  \tTraining accuracy: 0.7929180264472961\n",
      "Step: 8400  \tValid loss: 0.4112003743648529\n",
      "Step: 8500  \tTraining loss: 0.4051165282726288\n",
      "Step: 8500  \tTraining accuracy: 0.7930076718330383\n",
      "Step: 8500  \tValid loss: 0.41119861602783203\n",
      "Step: 8600  \tTraining loss: 0.4051046371459961\n",
      "Step: 8600  \tTraining accuracy: 0.793097972869873\n",
      "Step: 8600  \tValid loss: 0.4112095236778259\n",
      "Step: 8700  \tTraining loss: 0.4050925374031067\n",
      "Step: 8700  \tTraining accuracy: 0.793183445930481\n",
      "Step: 8700  \tValid loss: 0.4111953675746918\n",
      "Step: 8800  \tTraining loss: 0.4050804376602173\n",
      "Step: 8800  \tTraining accuracy: 0.7932683229446411\n",
      "Step: 8800  \tValid loss: 0.41119635105133057\n",
      "Step: 8900  \tTraining loss: 0.40504464507102966\n",
      "Step: 8900  \tTraining accuracy: 0.7933499813079834\n",
      "Step: 8900  \tValid loss: 0.41107892990112305\n",
      "Step: 9000  \tTraining loss: 0.40500563383102417\n",
      "Step: 9000  \tTraining accuracy: 0.7934271097183228\n",
      "Step: 9000  \tValid loss: 0.4111193120479584\n",
      "Step: 9100  \tTraining loss: 0.4049869775772095\n",
      "Step: 9100  \tTraining accuracy: 0.7935039401054382\n",
      "Step: 9100  \tValid loss: 0.41113904118537903\n",
      "Step: 9200  \tTraining loss: 0.4049654006958008\n",
      "Step: 9200  \tTraining accuracy: 0.7935777306556702\n",
      "Step: 9200  \tValid loss: 0.4111582040786743\n",
      "Step: 9300  \tTraining loss: 0.40494632720947266\n",
      "Step: 9300  \tTraining accuracy: 0.7936486601829529\n",
      "Step: 9300  \tValid loss: 0.41119205951690674\n",
      "Step: 9400  \tTraining loss: 0.4049266278743744\n",
      "Step: 9400  \tTraining accuracy: 0.7937168478965759\n",
      "Step: 9400  \tValid loss: 0.4112185835838318\n",
      "Step: 9500  \tTraining loss: 0.40490880608558655\n",
      "Step: 9500  \tTraining accuracy: 0.7937836050987244\n",
      "Step: 9500  \tValid loss: 0.4112430214881897\n",
      "Step: 9600  \tTraining loss: 0.4048916697502136\n",
      "Step: 9600  \tTraining accuracy: 0.7938489317893982\n",
      "Step: 9600  \tValid loss: 0.4112178683280945\n",
      "Step: 9700  \tTraining loss: 0.4048755466938019\n",
      "Step: 9700  \tTraining accuracy: 0.793912947177887\n",
      "Step: 9700  \tValid loss: 0.41125011444091797\n",
      "Step: 9800  \tTraining loss: 0.404860258102417\n",
      "Step: 9800  \tTraining accuracy: 0.7939755916595459\n",
      "Step: 9800  \tValid loss: 0.4112493693828583\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.794037\n",
      "Precision: 0.8439372\n",
      "Recall: 0.91380906\n",
      "F1 score: 0.8256007\n",
      "AUC: 0.69033533\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.794037   0.843937  0.913809  0.825601  0.690335  0.404849      0.793975   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0     0.411       0.793967    0.41355      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  9880.0  \n",
      "2\n",
      "(754, 4)\n",
      "(754, 1)\n",
      "(416, 4)\n",
      "(416, 1)\n",
      "(338, 4)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6244319677352905\n",
      "Step: 100  \tTraining accuracy: 0.6273209452629089\n",
      "Step: 100  \tValid loss: 0.5836849808692932\n",
      "Step: 200  \tTraining loss: 0.5977338552474976\n",
      "Step: 200  \tTraining accuracy: 0.6525198817253113\n",
      "Step: 200  \tValid loss: 0.578913152217865\n",
      "Step: 300  \tTraining loss: 0.5903721451759338\n",
      "Step: 300  \tTraining accuracy: 0.6533156633377075\n",
      "Step: 300  \tValid loss: 0.5800477266311646\n",
      "Step: 400  \tTraining loss: 0.5852451324462891\n",
      "Step: 400  \tTraining accuracy: 0.6542251110076904\n",
      "Step: 400  \tValid loss: 0.5770902633666992\n",
      "Step: 500  \tTraining loss: 0.5805004239082336\n",
      "Step: 500  \tTraining accuracy: 0.6556144952774048\n",
      "Step: 500  \tValid loss: 0.5730692148208618\n",
      "Step: 600  \tTraining loss: 0.5760448575019836\n",
      "Step: 600  \tTraining accuracy: 0.6579455137252808\n",
      "Step: 600  \tValid loss: 0.5688397884368896\n",
      "Step: 700  \tTraining loss: 0.5719798803329468\n",
      "Step: 700  \tTraining accuracy: 0.6611915826797485\n",
      "Step: 700  \tValid loss: 0.564742922782898\n",
      "Step: 800  \tTraining loss: 0.568429708480835\n",
      "Step: 800  \tTraining accuracy: 0.6645446419715881\n",
      "Step: 800  \tValid loss: 0.5610408186912537\n",
      "Step: 900  \tTraining loss: 0.5654861330986023\n",
      "Step: 900  \tTraining accuracy: 0.6682009696960449\n",
      "Step: 900  \tValid loss: 0.5579195022583008\n",
      "Step: 1000  \tTraining loss: 0.5631639957427979\n",
      "Step: 1000  \tTraining accuracy: 0.6712969541549683\n",
      "Step: 1000  \tValid loss: 0.5554381012916565\n",
      "Step: 1100  \tTraining loss: 0.5614013075828552\n",
      "Step: 1100  \tTraining accuracy: 0.674055814743042\n",
      "Step: 1100  \tValid loss: 0.553539514541626\n",
      "Step: 1200  \tTraining loss: 0.5600963830947876\n",
      "Step: 1200  \tTraining accuracy: 0.676680862903595\n",
      "Step: 1200  \tValid loss: 0.5521109104156494\n",
      "Step: 1300  \tTraining loss: 0.5591428875923157\n",
      "Step: 1300  \tTraining accuracy: 0.6790450811386108\n",
      "Step: 1300  \tValid loss: 0.5510365962982178\n",
      "Step: 1400  \tTraining loss: 0.5584496855735779\n",
      "Step: 1400  \tTraining accuracy: 0.6809607744216919\n",
      "Step: 1400  \tValid loss: 0.5502223968505859\n",
      "Step: 1500  \tTraining loss: 0.557945728302002\n",
      "Step: 1500  \tTraining accuracy: 0.6824750900268555\n",
      "Step: 1500  \tValid loss: 0.5495858788490295\n",
      "Step: 1600  \tTraining loss: 0.5575779676437378\n",
      "Step: 1600  \tTraining accuracy: 0.6837939620018005\n",
      "Step: 1600  \tValid loss: 0.549058735370636\n",
      "Step: 1700  \tTraining loss: 0.5573078989982605\n",
      "Step: 1700  \tTraining accuracy: 0.6850735545158386\n",
      "Step: 1700  \tValid loss: 0.5486421585083008\n",
      "Step: 1800  \tTraining loss: 0.5571079254150391\n",
      "Step: 1800  \tTraining accuracy: 0.6862068772315979\n",
      "Step: 1800  \tValid loss: 0.5483112931251526\n",
      "Step: 1900  \tTraining loss: 0.5569584965705872\n",
      "Step: 1900  \tTraining accuracy: 0.6871818900108337\n",
      "Step: 1900  \tValid loss: 0.5480486154556274\n",
      "Step: 2000  \tTraining loss: 0.5568454265594482\n",
      "Step: 2000  \tTraining accuracy: 0.6881248950958252\n",
      "Step: 2000  \tValid loss: 0.5478405356407166\n",
      "Step: 2100  \tTraining loss: 0.5567589998245239\n",
      "Step: 2100  \tTraining accuracy: 0.6889435052871704\n",
      "Step: 2100  \tValid loss: 0.547680139541626\n",
      "Step: 2200  \tTraining loss: 0.5566917657852173\n",
      "Step: 2200  \tTraining accuracy: 0.6896860003471375\n",
      "Step: 2200  \tValid loss: 0.54756098985672\n",
      "Step: 2300  \tTraining loss: 0.5566384196281433\n",
      "Step: 2300  \tTraining accuracy: 0.6903919577598572\n",
      "Step: 2300  \tValid loss: 0.5474715828895569\n",
      "Step: 2400  \tTraining loss: 0.5565955638885498\n",
      "Step: 2400  \tTraining accuracy: 0.6910096406936646\n",
      "Step: 2400  \tValid loss: 0.5474070310592651\n",
      "Step: 2500  \tTraining loss: 0.5565599203109741\n",
      "Step: 2500  \tTraining accuracy: 0.6915768980979919\n",
      "Step: 2500  \tValid loss: 0.5473626255989075\n",
      "Step: 2600  \tTraining loss: 0.5565301179885864\n",
      "Step: 2600  \tTraining accuracy: 0.692047655582428\n",
      "Step: 2600  \tValid loss: 0.5473359227180481\n",
      "Step: 2700  \tTraining loss: 0.556504487991333\n",
      "Step: 2700  \tTraining accuracy: 0.6924828290939331\n",
      "Step: 2700  \tValid loss: 0.5473231673240662\n",
      "Step: 2800  \tTraining loss: 0.5564819574356079\n",
      "Step: 2800  \tTraining accuracy: 0.6928864121437073\n",
      "Step: 2800  \tValid loss: 0.5473216772079468\n",
      "Step: 2900  \tTraining loss: 0.5564621090888977\n",
      "Step: 2900  \tTraining accuracy: 0.6932616829872131\n",
      "Step: 2900  \tValid loss: 0.5473291277885437\n",
      "Step: 3000  \tTraining loss: 0.5564444661140442\n",
      "Step: 3000  \tTraining accuracy: 0.6936564445495605\n",
      "Step: 3000  \tValid loss: 0.5473509430885315\n",
      "Step: 3100  \tTraining loss: 0.5564281344413757\n",
      "Step: 3100  \tTraining accuracy: 0.6940470337867737\n",
      "Step: 3100  \tValid loss: 0.5473787188529968\n",
      "Step: 3200  \tTraining loss: 0.5564131736755371\n",
      "Step: 3200  \tTraining accuracy: 0.694412887096405\n",
      "Step: 3200  \tValid loss: 0.5474110245704651\n",
      "Step: 3300  \tTraining loss: 0.5563991665840149\n",
      "Step: 3300  \tTraining accuracy: 0.6947561502456665\n",
      "Step: 3300  \tValid loss: 0.5474507808685303\n",
      "Step: 3400  \tTraining loss: 0.5563862323760986\n",
      "Step: 3400  \tTraining accuracy: 0.69507896900177\n",
      "Step: 3400  \tValid loss: 0.547493577003479\n",
      "Step: 3500  \tTraining loss: 0.5563738346099854\n",
      "Step: 3500  \tTraining accuracy: 0.6953446269035339\n",
      "Step: 3500  \tValid loss: 0.5475383996963501\n",
      "Step: 3600  \tTraining loss: 0.5563620328903198\n",
      "Step: 3600  \tTraining accuracy: 0.6955953240394592\n",
      "Step: 3600  \tValid loss: 0.5475848913192749\n",
      "Step: 3700  \tTraining loss: 0.5563508868217468\n",
      "Step: 3700  \tTraining accuracy: 0.6958322525024414\n",
      "Step: 3700  \tValid loss: 0.5476323366165161\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.69607425\n",
      "Precision: 0.72401434\n",
      "Recall: 0.85412264\n",
      "F1 score: 0.7534616\n",
      "AUC: 0.65304\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.696074   0.724014  0.854123  0.753462  0.65304  0.556344      0.695964   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.547321       0.695883   0.579863      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3764.0  \n",
      "3\n",
      "(783, 4)\n",
      "(783, 1)\n",
      "(416, 4)\n",
      "(416, 1)\n",
      "(338, 4)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5324986577033997\n",
      "Step: 100  \tTraining accuracy: 0.7522349953651428\n",
      "Step: 100  \tValid loss: 0.5888172388076782\n",
      "Step: 200  \tTraining loss: 0.5199381113052368\n",
      "Step: 200  \tTraining accuracy: 0.7431034445762634\n",
      "Step: 200  \tValid loss: 0.5800305604934692\n",
      "Step: 300  \tTraining loss: 0.5004806518554688\n",
      "Step: 300  \tTraining accuracy: 0.741249680519104\n",
      "Step: 300  \tValid loss: 0.5599446892738342\n",
      "Step: 400  \tTraining loss: 0.47933533787727356\n",
      "Step: 400  \tTraining accuracy: 0.7404523491859436\n",
      "Step: 400  \tValid loss: 0.5401829481124878\n",
      "Step: 500  \tTraining loss: 0.456527978181839\n",
      "Step: 500  \tTraining accuracy: 0.7400086522102356\n",
      "Step: 500  \tValid loss: 0.518927276134491\n",
      "Step: 600  \tTraining loss: 0.43561604619026184\n",
      "Step: 600  \tTraining accuracy: 0.7423240542411804\n",
      "Step: 600  \tValid loss: 0.5010156631469727\n",
      "Step: 700  \tTraining loss: 0.4192562699317932\n",
      "Step: 700  \tTraining accuracy: 0.7456271648406982\n",
      "Step: 700  \tValid loss: 0.4858957529067993\n",
      "Step: 800  \tTraining loss: 0.4063410758972168\n",
      "Step: 800  \tTraining accuracy: 0.7499566674232483\n",
      "Step: 800  \tValid loss: 0.47408586740493774\n",
      "Step: 900  \tTraining loss: 0.3962022066116333\n",
      "Step: 900  \tTraining accuracy: 0.7541096210479736\n",
      "Step: 900  \tValid loss: 0.46535947918891907\n",
      "Step: 1000  \tTraining loss: 0.38871586322784424\n",
      "Step: 1000  \tTraining accuracy: 0.7581417560577393\n",
      "Step: 1000  \tValid loss: 0.4592445194721222\n",
      "Step: 1100  \tTraining loss: 0.38308337330818176\n",
      "Step: 1100  \tTraining accuracy: 0.762149453163147\n",
      "Step: 1100  \tValid loss: 0.4549814462661743\n",
      "Step: 1200  \tTraining loss: 0.3788595497608185\n",
      "Step: 1200  \tTraining accuracy: 0.7658564448356628\n",
      "Step: 1200  \tValid loss: 0.4523513913154602\n",
      "Step: 1300  \tTraining loss: 0.3757359981536865\n",
      "Step: 1300  \tTraining accuracy: 0.7692827582359314\n",
      "Step: 1300  \tValid loss: 0.45018675923347473\n",
      "Step: 1400  \tTraining loss: 0.3733988106250763\n",
      "Step: 1400  \tTraining accuracy: 0.7724426984786987\n",
      "Step: 1400  \tValid loss: 0.4488067626953125\n",
      "Step: 1500  \tTraining loss: 0.3715435564517975\n",
      "Step: 1500  \tTraining accuracy: 0.7753912210464478\n",
      "Step: 1500  \tValid loss: 0.44793254137039185\n",
      "Step: 1600  \tTraining loss: 0.3700028657913208\n",
      "Step: 1600  \tTraining accuracy: 0.7779595851898193\n",
      "Step: 1600  \tValid loss: 0.44730010628700256\n",
      "Step: 1700  \tTraining loss: 0.36876368522644043\n",
      "Step: 1700  \tTraining accuracy: 0.7802561521530151\n",
      "Step: 1700  \tValid loss: 0.44711336493492126\n",
      "Step: 1800  \tTraining loss: 0.36771437525749207\n",
      "Step: 1800  \tTraining accuracy: 0.7822532653808594\n",
      "Step: 1800  \tValid loss: 0.44661733508110046\n",
      "Step: 1900  \tTraining loss: 0.36681774258613586\n",
      "Step: 1900  \tTraining accuracy: 0.7840346097946167\n",
      "Step: 1900  \tValid loss: 0.44646257162094116\n",
      "Step: 2000  \tTraining loss: 0.3660687506198883\n",
      "Step: 2000  \tTraining accuracy: 0.7856666445732117\n",
      "Step: 2000  \tValid loss: 0.44620126485824585\n",
      "Step: 2100  \tTraining loss: 0.3653678894042969\n",
      "Step: 2100  \tTraining accuracy: 0.7872347235679626\n",
      "Step: 2100  \tValid loss: 0.4458509683609009\n",
      "Step: 2200  \tTraining loss: 0.36469757556915283\n",
      "Step: 2200  \tTraining accuracy: 0.7886267304420471\n",
      "Step: 2200  \tValid loss: 0.4457319974899292\n",
      "Step: 2300  \tTraining loss: 0.36405354738235474\n",
      "Step: 2300  \tTraining accuracy: 0.7898950576782227\n",
      "Step: 2300  \tValid loss: 0.4453194737434387\n",
      "Step: 2400  \tTraining loss: 0.36346903443336487\n",
      "Step: 2400  \tTraining accuracy: 0.7911108732223511\n",
      "Step: 2400  \tValid loss: 0.4452594518661499\n",
      "Step: 2500  \tTraining loss: 0.36289361119270325\n",
      "Step: 2500  \tTraining accuracy: 0.7922009229660034\n",
      "Step: 2500  \tValid loss: 0.44451016187667847\n",
      "Step: 2600  \tTraining loss: 0.36229223012924194\n",
      "Step: 2600  \tTraining accuracy: 0.7932054400444031\n",
      "Step: 2600  \tValid loss: 0.44406428933143616\n",
      "Step: 2700  \tTraining loss: 0.36165252327919006\n",
      "Step: 2700  \tTraining accuracy: 0.794134259223938\n",
      "Step: 2700  \tValid loss: 0.4435684382915497\n",
      "Step: 2800  \tTraining loss: 0.3609924614429474\n",
      "Step: 2800  \tTraining accuracy: 0.7949954867362976\n",
      "Step: 2800  \tValid loss: 0.44325196743011475\n",
      "Step: 2900  \tTraining loss: 0.3603173494338989\n",
      "Step: 2900  \tTraining accuracy: 0.7958191633224487\n",
      "Step: 2900  \tValid loss: 0.44282716512680054\n",
      "Step: 3000  \tTraining loss: 0.35961031913757324\n",
      "Step: 3000  \tTraining accuracy: 0.7966310977935791\n",
      "Step: 3000  \tValid loss: 0.4424009621143341\n",
      "Step: 3100  \tTraining loss: 0.35889339447021484\n",
      "Step: 3100  \tTraining accuracy: 0.797389805316925\n",
      "Step: 3100  \tValid loss: 0.4420558512210846\n",
      "Step: 3200  \tTraining loss: 0.35815197229385376\n",
      "Step: 3200  \tTraining accuracy: 0.7981209754943848\n",
      "Step: 3200  \tValid loss: 0.4418835937976837\n",
      "Step: 3300  \tTraining loss: 0.35739201307296753\n",
      "Step: 3300  \tTraining accuracy: 0.7988072037696838\n",
      "Step: 3300  \tValid loss: 0.4417091906070709\n",
      "Step: 3400  \tTraining loss: 0.3566586971282959\n",
      "Step: 3400  \tTraining accuracy: 0.7994524836540222\n",
      "Step: 3400  \tValid loss: 0.4415135085582733\n",
      "Step: 3500  \tTraining loss: 0.3559437394142151\n",
      "Step: 3500  \tTraining accuracy: 0.8000603318214417\n",
      "Step: 3500  \tValid loss: 0.4411230683326721\n",
      "Step: 3600  \tTraining loss: 0.3552370071411133\n",
      "Step: 3600  \tTraining accuracy: 0.80063396692276\n",
      "Step: 3600  \tValid loss: 0.4409177601337433\n",
      "Step: 3700  \tTraining loss: 0.3545377850532532\n",
      "Step: 3700  \tTraining accuracy: 0.801176130771637\n",
      "Step: 3700  \tValid loss: 0.44074615836143494\n",
      "Step: 3800  \tTraining loss: 0.35387319326400757\n",
      "Step: 3800  \tTraining accuracy: 0.8016894459724426\n",
      "Step: 3800  \tValid loss: 0.4406213164329529\n",
      "Step: 3900  \tTraining loss: 0.35323086380958557\n",
      "Step: 3900  \tTraining accuracy: 0.8021760582923889\n",
      "Step: 3900  \tValid loss: 0.44049760699272156\n",
      "Step: 4000  \tTraining loss: 0.3525465428829193\n",
      "Step: 4000  \tTraining accuracy: 0.802638053894043\n",
      "Step: 4000  \tValid loss: 0.4404315948486328\n",
      "Step: 4100  \tTraining loss: 0.3518686890602112\n",
      "Step: 4100  \tTraining accuracy: 0.8030933141708374\n",
      "Step: 4100  \tValid loss: 0.44015735387802124\n",
      "Step: 4200  \tTraining loss: 0.3512125313282013\n",
      "Step: 4200  \tTraining accuracy: 0.8035579919815063\n",
      "Step: 4200  \tValid loss: 0.44011321663856506\n",
      "Step: 4300  \tTraining loss: 0.35061073303222656\n",
      "Step: 4300  \tTraining accuracy: 0.8039854764938354\n",
      "Step: 4300  \tValid loss: 0.43999215960502625\n",
      "Step: 4400  \tTraining loss: 0.3500469923019409\n",
      "Step: 4400  \tTraining accuracy: 0.8043933510780334\n",
      "Step: 4400  \tValid loss: 0.4398782551288605\n",
      "Step: 4500  \tTraining loss: 0.3495260179042816\n",
      "Step: 4500  \tTraining accuracy: 0.8047974705696106\n",
      "Step: 4500  \tValid loss: 0.4397055506706238\n",
      "Step: 4600  \tTraining loss: 0.3490418493747711\n",
      "Step: 4600  \tTraining accuracy: 0.8051838278770447\n",
      "Step: 4600  \tValid loss: 0.43953996896743774\n",
      "Step: 4700  \tTraining loss: 0.3485949635505676\n",
      "Step: 4700  \tTraining accuracy: 0.8055536150932312\n",
      "Step: 4700  \tValid loss: 0.4392516314983368\n",
      "Step: 4800  \tTraining loss: 0.34819117188453674\n",
      "Step: 4800  \tTraining accuracy: 0.8059077858924866\n",
      "Step: 4800  \tValid loss: 0.43922755122184753\n",
      "Step: 4900  \tTraining loss: 0.34781646728515625\n",
      "Step: 4900  \tTraining accuracy: 0.8062474131584167\n",
      "Step: 4900  \tValid loss: 0.43916600942611694\n",
      "Step: 5000  \tTraining loss: 0.34747615456581116\n",
      "Step: 5000  \tTraining accuracy: 0.8065732717514038\n",
      "Step: 5000  \tValid loss: 0.4391651451587677\n",
      "Step: 5100  \tTraining loss: 0.34715500473976135\n",
      "Step: 5100  \tTraining accuracy: 0.8069120049476624\n",
      "Step: 5100  \tValid loss: 0.43921801447868347\n",
      "Step: 5200  \tTraining loss: 0.34683293104171753\n",
      "Step: 5200  \tTraining accuracy: 0.8071870803833008\n",
      "Step: 5200  \tValid loss: 0.4392654597759247\n",
      "Step: 5300  \tTraining loss: 0.3464896082878113\n",
      "Step: 5300  \tTraining accuracy: 0.8073525428771973\n",
      "Step: 5300  \tValid loss: 0.4394315481185913\n",
      "Step: 5400  \tTraining loss: 0.3461480140686035\n",
      "Step: 5400  \tTraining accuracy: 0.8075118064880371\n",
      "Step: 5400  \tValid loss: 0.43967071175575256\n",
      "Step: 5500  \tTraining loss: 0.34574392437934875\n",
      "Step: 5500  \tTraining accuracy: 0.807665228843689\n",
      "Step: 5500  \tValid loss: 0.4400807023048401\n",
      "Step: 5600  \tTraining loss: 0.34545111656188965\n",
      "Step: 5600  \tTraining accuracy: 0.8078248500823975\n",
      "Step: 5600  \tValid loss: 0.43996959924697876\n",
      "Step: 5700  \tTraining loss: 0.34523189067840576\n",
      "Step: 5700  \tTraining accuracy: 0.8079788088798523\n",
      "Step: 5700  \tValid loss: 0.43984001874923706\n",
      "Step: 5800  \tTraining loss: 0.3450263738632202\n",
      "Step: 5800  \tTraining accuracy: 0.8081274032592773\n",
      "Step: 5800  \tValid loss: 0.43983665108680725\n",
      "Step: 5900  \tTraining loss: 0.34481871128082275\n",
      "Step: 5900  \tTraining accuracy: 0.8082820773124695\n",
      "Step: 5900  \tValid loss: 0.4397144317626953\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.80846435\n",
      "Precision: 0.8828383\n",
      "Recall: 0.9083192\n",
      "F1 score: 0.8199655\n",
      "AUC: 0.7711699\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.808464   0.882838  0.908319  0.819965  0.77117  0.344581      0.808189   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.439125        0.80828   0.388131      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5933.0  \n",
      "4\n",
      "(725, 4)\n",
      "(725, 1)\n",
      "(400, 4)\n",
      "(400, 1)\n",
      "(325, 4)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6169520020484924\n",
      "Step: 100  \tTraining accuracy: 0.864827573299408\n",
      "Step: 100  \tValid loss: 0.6260049939155579\n",
      "Step: 200  \tTraining loss: 0.4810192883014679\n",
      "Step: 200  \tTraining accuracy: 0.8427585959434509\n",
      "Step: 200  \tValid loss: 0.5090388059616089\n",
      "Step: 300  \tTraining loss: 0.43173137307167053\n",
      "Step: 300  \tTraining accuracy: 0.8281379342079163\n",
      "Step: 300  \tValid loss: 0.47138381004333496\n",
      "Step: 400  \tTraining loss: 0.41689443588256836\n",
      "Step: 400  \tTraining accuracy: 0.8169457912445068\n",
      "Step: 400  \tValid loss: 0.46231505274772644\n",
      "Step: 500  \tTraining loss: 0.4075721204280853\n",
      "Step: 500  \tTraining accuracy: 0.8104214668273926\n",
      "Step: 500  \tValid loss: 0.45652496814727783\n",
      "Step: 600  \tTraining loss: 0.39937177300453186\n",
      "Step: 600  \tTraining accuracy: 0.8057680130004883\n",
      "Step: 600  \tValid loss: 0.4510141611099243\n",
      "Step: 700  \tTraining loss: 0.3916456699371338\n",
      "Step: 700  \tTraining accuracy: 0.8020159006118774\n",
      "Step: 700  \tValid loss: 0.44562146067619324\n",
      "Step: 800  \tTraining loss: 0.38418760895729065\n",
      "Step: 800  \tTraining accuracy: 0.7994482517242432\n",
      "Step: 800  \tValid loss: 0.44027283787727356\n",
      "Step: 900  \tTraining loss: 0.37687015533447266\n",
      "Step: 900  \tTraining accuracy: 0.7970790863037109\n",
      "Step: 900  \tValid loss: 0.4348677694797516\n",
      "Step: 1000  \tTraining loss: 0.3695618212223053\n",
      "Step: 1000  \tTraining accuracy: 0.7952086925506592\n",
      "Step: 1000  \tValid loss: 0.4292564392089844\n",
      "Step: 1100  \tTraining loss: 0.36211925745010376\n",
      "Step: 1100  \tTraining accuracy: 0.7936945557594299\n",
      "Step: 1100  \tValid loss: 0.42327579855918884\n",
      "Step: 1200  \tTraining loss: 0.35439372062683105\n",
      "Step: 1200  \tTraining accuracy: 0.7927436232566833\n",
      "Step: 1200  \tValid loss: 0.41676095128059387\n",
      "Step: 1300  \tTraining loss: 0.34626537561416626\n",
      "Step: 1300  \tTraining accuracy: 0.7921103239059448\n",
      "Step: 1300  \tValid loss: 0.4096280336380005\n",
      "Step: 1400  \tTraining loss: 0.3376963138580322\n",
      "Step: 1400  \tTraining accuracy: 0.7919795513153076\n",
      "Step: 1400  \tValid loss: 0.4019412696361542\n",
      "Step: 1500  \tTraining loss: 0.3287617564201355\n",
      "Step: 1500  \tTraining accuracy: 0.7924851179122925\n",
      "Step: 1500  \tValid loss: 0.3938775658607483\n",
      "Step: 1600  \tTraining loss: 0.3196364939212799\n",
      "Step: 1600  \tTraining accuracy: 0.7937708497047424\n",
      "Step: 1600  \tValid loss: 0.38568809628486633\n",
      "Step: 1700  \tTraining loss: 0.31054195761680603\n",
      "Step: 1700  \tTraining accuracy: 0.7956112623214722\n",
      "Step: 1700  \tValid loss: 0.3776264488697052\n",
      "Step: 1800  \tTraining loss: 0.3016950190067291\n",
      "Step: 1800  \tTraining accuracy: 0.7978719472885132\n",
      "Step: 1800  \tValid loss: 0.3699050545692444\n",
      "Step: 1900  \tTraining loss: 0.293277770280838\n",
      "Step: 1900  \tTraining accuracy: 0.7998881936073303\n",
      "Step: 1900  \tValid loss: 0.36267712712287903\n",
      "Step: 2000  \tTraining loss: 0.28542253375053406\n",
      "Step: 2000  \tTraining accuracy: 0.8017683625221252\n",
      "Step: 2000  \tValid loss: 0.35604721307754517\n",
      "Step: 2100  \tTraining loss: 0.27834105491638184\n",
      "Step: 2100  \tTraining accuracy: 0.8038687705993652\n",
      "Step: 2100  \tValid loss: 0.3504410684108734\n",
      "Step: 2200  \tTraining loss: 0.2721373736858368\n",
      "Step: 2200  \tTraining accuracy: 0.805966317653656\n",
      "Step: 2200  \tValid loss: 0.34541305899620056\n",
      "Step: 2300  \tTraining loss: 0.26659679412841797\n",
      "Step: 2300  \tTraining accuracy: 0.808091938495636\n",
      "Step: 2300  \tValid loss: 0.3411770761013031\n",
      "Step: 2400  \tTraining loss: 0.26163730025291443\n",
      "Step: 2400  \tTraining accuracy: 0.8101540803909302\n",
      "Step: 2400  \tValid loss: 0.3373527526855469\n",
      "Step: 2500  \tTraining loss: 0.25720661878585815\n",
      "Step: 2500  \tTraining accuracy: 0.8121322989463806\n",
      "Step: 2500  \tValid loss: 0.33403313159942627\n",
      "Step: 2600  \tTraining loss: 0.25327327847480774\n",
      "Step: 2600  \tTraining accuracy: 0.8141717314720154\n",
      "Step: 2600  \tValid loss: 0.3312091529369354\n",
      "Step: 2700  \tTraining loss: 0.24980470538139343\n",
      "Step: 2700  \tTraining accuracy: 0.8161613345146179\n",
      "Step: 2700  \tValid loss: 0.32888153195381165\n",
      "Step: 2800  \tTraining loss: 0.24676014482975006\n",
      "Step: 2800  \tTraining accuracy: 0.8179811835289001\n",
      "Step: 2800  \tValid loss: 0.3270047903060913\n",
      "Step: 2900  \tTraining loss: 0.24409271776676178\n",
      "Step: 2900  \tTraining accuracy: 0.8197942972183228\n",
      "Step: 2900  \tValid loss: 0.325509250164032\n",
      "Step: 3000  \tTraining loss: 0.24175314605236053\n",
      "Step: 3000  \tTraining accuracy: 0.8215312957763672\n",
      "Step: 3000  \tValid loss: 0.3243342638015747\n",
      "Step: 3100  \tTraining loss: 0.23970824480056763\n",
      "Step: 3100  \tTraining accuracy: 0.82326740026474\n",
      "Step: 3100  \tValid loss: 0.32331207394599915\n",
      "Step: 3200  \tTraining loss: 0.23791034519672394\n",
      "Step: 3200  \tTraining accuracy: 0.8248713612556458\n",
      "Step: 3200  \tValid loss: 0.322615385055542\n",
      "Step: 3300  \tTraining loss: 0.23631787300109863\n",
      "Step: 3300  \tTraining accuracy: 0.8264615535736084\n",
      "Step: 3300  \tValid loss: 0.32210400700569153\n",
      "Step: 3400  \tTraining loss: 0.2348962128162384\n",
      "Step: 3400  \tTraining accuracy: 0.8280391097068787\n",
      "Step: 3400  \tValid loss: 0.3217325210571289\n",
      "Step: 3500  \tTraining loss: 0.23361670970916748\n",
      "Step: 3500  \tTraining accuracy: 0.8295252323150635\n",
      "Step: 3500  \tValid loss: 0.32147037982940674\n",
      "Step: 3600  \tTraining loss: 0.2324560284614563\n",
      "Step: 3600  \tTraining accuracy: 0.8309470415115356\n",
      "Step: 3600  \tValid loss: 0.32129189372062683\n",
      "Step: 3700  \tTraining loss: 0.2313951551914215\n",
      "Step: 3700  \tTraining accuracy: 0.8322910070419312\n",
      "Step: 3700  \tValid loss: 0.32117852568626404\n",
      "Step: 3800  \tTraining loss: 0.2304186373949051\n",
      "Step: 3800  \tTraining accuracy: 0.8335448503494263\n",
      "Step: 3800  \tValid loss: 0.32111576199531555\n",
      "Step: 3900  \tTraining loss: 0.2295195460319519\n",
      "Step: 3900  \tTraining accuracy: 0.8347514271736145\n",
      "Step: 3900  \tValid loss: 0.3210276663303375\n",
      "Step: 4000  \tTraining loss: 0.22869029641151428\n",
      "Step: 4000  \tTraining accuracy: 0.8358446359634399\n",
      "Step: 4000  \tValid loss: 0.3210465610027313\n",
      "Step: 4100  \tTraining loss: 0.2279212474822998\n",
      "Step: 4100  \tTraining accuracy: 0.8368837833404541\n",
      "Step: 4100  \tValid loss: 0.3211100697517395\n",
      "Step: 4200  \tTraining loss: 0.22720636427402496\n",
      "Step: 4200  \tTraining accuracy: 0.8378562331199646\n",
      "Step: 4200  \tValid loss: 0.3212137520313263\n",
      "Step: 4300  \tTraining loss: 0.22654342651367188\n",
      "Step: 4300  \tTraining accuracy: 0.8387991786003113\n",
      "Step: 4300  \tValid loss: 0.32137879729270935\n",
      "Step: 4400  \tTraining loss: 0.22592826187610626\n",
      "Step: 4400  \tTraining accuracy: 0.8396987915039062\n",
      "Step: 4400  \tValid loss: 0.32157212495803833\n",
      "Step: 4500  \tTraining loss: 0.22535645961761475\n",
      "Step: 4500  \tTraining accuracy: 0.8405579328536987\n",
      "Step: 4500  \tValid loss: 0.3217441141605377\n",
      "Step: 4600  \tTraining loss: 0.22482463717460632\n",
      "Step: 4600  \tTraining accuracy: 0.8413641452789307\n",
      "Step: 4600  \tValid loss: 0.32195770740509033\n",
      "Step: 4700  \tTraining loss: 0.2243293970823288\n",
      "Step: 4700  \tTraining accuracy: 0.8421357274055481\n",
      "Step: 4700  \tValid loss: 0.32220473885536194\n",
      "Step: 4800  \tTraining loss: 0.2238672524690628\n",
      "Step: 4800  \tTraining accuracy: 0.842918336391449\n",
      "Step: 4800  \tValid loss: 0.3224756717681885\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8436687\n",
      "Precision: 0.87532467\n",
      "Recall: 0.9361111\n",
      "F1 score: 0.8719798\n",
      "AUC: 0.90230215\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.843669   0.875325  0.936111   0.87198  0.902302  0.223592       0.84306   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.321022       0.842977   0.293579      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4862.0  \n",
      "5\n",
      "(841, 4)\n",
      "(841, 1)\n",
      "(464, 4)\n",
      "(464, 1)\n",
      "(377, 4)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6704267263412476\n",
      "Step: 100  \tTraining accuracy: 0.5707491040229797\n",
      "Step: 100  \tValid loss: 0.6507517099380493\n",
      "Step: 200  \tTraining loss: 0.6624817252159119\n",
      "Step: 200  \tTraining accuracy: 0.5897740721702576\n",
      "Step: 200  \tValid loss: 0.6408419609069824\n",
      "Step: 300  \tTraining loss: 0.6545987129211426\n",
      "Step: 300  \tTraining accuracy: 0.6033293604850769\n",
      "Step: 300  \tValid loss: 0.6323215961456299\n",
      "Step: 400  \tTraining loss: 0.644858717918396\n",
      "Step: 400  \tTraining accuracy: 0.6138949990272522\n",
      "Step: 400  \tValid loss: 0.622633159160614\n",
      "Step: 500  \tTraining loss: 0.6328981518745422\n",
      "Step: 500  \tTraining accuracy: 0.6222750544548035\n",
      "Step: 500  \tValid loss: 0.6149106025695801\n",
      "Step: 600  \tTraining loss: 0.6224640011787415\n",
      "Step: 600  \tTraining accuracy: 0.6285806894302368\n",
      "Step: 600  \tValid loss: 0.6073373556137085\n",
      "Step: 700  \tTraining loss: 0.6135156750679016\n",
      "Step: 700  \tTraining accuracy: 0.6337693333625793\n",
      "Step: 700  \tValid loss: 0.6003422141075134\n",
      "Step: 800  \tTraining loss: 0.6064520478248596\n",
      "Step: 800  \tTraining accuracy: 0.638684093952179\n",
      "Step: 800  \tValid loss: 0.5948169231414795\n",
      "Step: 900  \tTraining loss: 0.6013792157173157\n",
      "Step: 900  \tTraining accuracy: 0.6423025727272034\n",
      "Step: 900  \tValid loss: 0.5913412570953369\n",
      "Step: 1000  \tTraining loss: 0.5979431867599487\n",
      "Step: 1000  \tTraining accuracy: 0.6454721689224243\n",
      "Step: 1000  \tValid loss: 0.5893523693084717\n",
      "Step: 1100  \tTraining loss: 0.5957100987434387\n",
      "Step: 1100  \tTraining accuracy: 0.6484910249710083\n",
      "Step: 1100  \tValid loss: 0.5884197354316711\n",
      "Step: 1200  \tTraining loss: 0.5942701697349548\n",
      "Step: 1200  \tTraining accuracy: 0.6515535116195679\n",
      "Step: 1200  \tValid loss: 0.588347315788269\n",
      "Step: 1300  \tTraining loss: 0.5933051705360413\n",
      "Step: 1300  \tTraining accuracy: 0.6541260480880737\n",
      "Step: 1300  \tValid loss: 0.5887036919593811\n",
      "Step: 1400  \tTraining loss: 0.5926197171211243\n",
      "Step: 1400  \tTraining accuracy: 0.6561853289604187\n",
      "Step: 1400  \tValid loss: 0.5892898440361023\n",
      "Step: 1500  \tTraining loss: 0.5920946598052979\n",
      "Step: 1500  \tTraining accuracy: 0.6582475900650024\n",
      "Step: 1500  \tValid loss: 0.5897982120513916\n",
      "Step: 1600  \tTraining loss: 0.5916738510131836\n",
      "Step: 1600  \tTraining accuracy: 0.6599286794662476\n",
      "Step: 1600  \tValid loss: 0.5902682542800903\n",
      "Step: 1700  \tTraining loss: 0.5913212299346924\n",
      "Step: 1700  \tTraining accuracy: 0.6613699197769165\n",
      "Step: 1700  \tValid loss: 0.590812087059021\n",
      "Step: 1800  \tTraining loss: 0.5909208059310913\n",
      "Step: 1800  \tTraining accuracy: 0.6626125574111938\n",
      "Step: 1800  \tValid loss: 0.5914289355278015\n",
      "Step: 1900  \tTraining loss: 0.5905442237854004\n",
      "Step: 1900  \tTraining accuracy: 0.6637207865715027\n",
      "Step: 1900  \tValid loss: 0.5919118523597717\n",
      "Step: 2000  \tTraining loss: 0.5902343392372131\n",
      "Step: 2000  \tTraining accuracy: 0.6646239161491394\n",
      "Step: 2000  \tValid loss: 0.5925471782684326\n",
      "Step: 2100  \tTraining loss: 0.5899602770805359\n",
      "Step: 2100  \tTraining accuracy: 0.6653809547424316\n",
      "Step: 2100  \tValid loss: 0.5930169224739075\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.6660122\n",
      "Precision: 0.693837\n",
      "Recall: 0.73628694\n",
      "F1 score: 0.6857813\n",
      "AUC: 0.6583342\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.666012   0.693837  0.736287  0.685781  0.658334  0.589765      0.665959   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.588285       0.665701   0.645034      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2179.0  \n",
      "6\n",
      "(1131, 4)\n",
      "(1131, 1)\n",
      "(624, 4)\n",
      "(624, 1)\n",
      "(507, 4)\n",
      "(507, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5337023735046387\n",
      "Step: 100  \tTraining accuracy: 0.8328912258148193\n",
      "Step: 100  \tValid loss: 0.5420094132423401\n",
      "Step: 200  \tTraining loss: 0.4341273307800293\n",
      "Step: 200  \tTraining accuracy: 0.8352490663528442\n",
      "Step: 200  \tValid loss: 0.45380011200904846\n",
      "Step: 300  \tTraining loss: 0.42272844910621643\n",
      "Step: 300  \tTraining accuracy: 0.8355437517166138\n",
      "Step: 300  \tValid loss: 0.4457640051841736\n",
      "Step: 400  \tTraining loss: 0.4165278673171997\n",
      "Step: 400  \tTraining accuracy: 0.8355437517166138\n",
      "Step: 400  \tValid loss: 0.4404534697532654\n",
      "Step: 500  \tTraining loss: 0.41212961077690125\n",
      "Step: 500  \tTraining accuracy: 0.8357402682304382\n",
      "Step: 500  \tValid loss: 0.436676949262619\n",
      "Step: 600  \tTraining loss: 0.4084683060646057\n",
      "Step: 600  \tTraining accuracy: 0.835704505443573\n",
      "Step: 600  \tValid loss: 0.4335120618343353\n",
      "Step: 700  \tTraining loss: 0.40532442927360535\n",
      "Step: 700  \tTraining accuracy: 0.8360198736190796\n",
      "Step: 700  \tValid loss: 0.4310116767883301\n",
      "Step: 800  \tTraining loss: 0.40259605646133423\n",
      "Step: 800  \tTraining accuracy: 0.8363100290298462\n",
      "Step: 800  \tValid loss: 0.4290219843387604\n",
      "Step: 900  \tTraining loss: 0.4002462923526764\n",
      "Step: 900  \tTraining accuracy: 0.8366879820823669\n",
      "Step: 900  \tValid loss: 0.42747917771339417\n",
      "Step: 1000  \tTraining loss: 0.39819496870040894\n",
      "Step: 1000  \tTraining accuracy: 0.8371725082397461\n",
      "Step: 1000  \tValid loss: 0.42629510164260864\n",
      "Step: 1100  \tTraining loss: 0.3963979184627533\n",
      "Step: 1100  \tTraining accuracy: 0.8377331495285034\n",
      "Step: 1100  \tValid loss: 0.4254152774810791\n",
      "Step: 1200  \tTraining loss: 0.39480462670326233\n",
      "Step: 1200  \tTraining accuracy: 0.8385807275772095\n",
      "Step: 1200  \tValid loss: 0.42473745346069336\n",
      "Step: 1300  \tTraining loss: 0.3933819830417633\n",
      "Step: 1300  \tTraining accuracy: 0.8392572999000549\n",
      "Step: 1300  \tValid loss: 0.4242241084575653\n",
      "Step: 1400  \tTraining loss: 0.39210402965545654\n",
      "Step: 1400  \tTraining accuracy: 0.8400628566741943\n",
      "Step: 1400  \tValid loss: 0.42381247878074646\n",
      "Step: 1500  \tTraining loss: 0.3909548223018646\n",
      "Step: 1500  \tTraining accuracy: 0.8409097790718079\n",
      "Step: 1500  \tValid loss: 0.4235135018825531\n",
      "Step: 1600  \tTraining loss: 0.3899311423301697\n",
      "Step: 1600  \tTraining accuracy: 0.8417615294456482\n",
      "Step: 1600  \tValid loss: 0.4232688248157501\n",
      "Step: 1700  \tTraining loss: 0.3890250325202942\n",
      "Step: 1700  \tTraining accuracy: 0.8425367474555969\n",
      "Step: 1700  \tValid loss: 0.4231075942516327\n",
      "Step: 1800  \tTraining loss: 0.3882351815700531\n",
      "Step: 1800  \tTraining accuracy: 0.8431729078292847\n",
      "Step: 1800  \tValid loss: 0.42297792434692383\n",
      "Step: 1900  \tTraining loss: 0.38751664757728577\n",
      "Step: 1900  \tTraining accuracy: 0.8437163829803467\n",
      "Step: 1900  \tValid loss: 0.42277124524116516\n",
      "Step: 2000  \tTraining loss: 0.3868832290172577\n",
      "Step: 2000  \tTraining accuracy: 0.844181478023529\n",
      "Step: 2000  \tValid loss: 0.4226892292499542\n",
      "Step: 2100  \tTraining loss: 0.38634154200553894\n",
      "Step: 2100  \tTraining accuracy: 0.8446227312088013\n",
      "Step: 2100  \tValid loss: 0.42270150780677795\n",
      "Step: 2200  \tTraining loss: 0.3858731985092163\n",
      "Step: 2200  \tTraining accuracy: 0.8450846076011658\n",
      "Step: 2200  \tValid loss: 0.42273643612861633\n",
      "Step: 2300  \tTraining loss: 0.38546475768089294\n",
      "Step: 2300  \tTraining accuracy: 0.8455054759979248\n",
      "Step: 2300  \tValid loss: 0.4228581190109253\n",
      "Step: 2400  \tTraining loss: 0.38510680198669434\n",
      "Step: 2400  \tTraining accuracy: 0.8458716869354248\n",
      "Step: 2400  \tValid loss: 0.42297792434692383\n",
      "Step: 2500  \tTraining loss: 0.3847932815551758\n",
      "Step: 2500  \tTraining accuracy: 0.8462260365486145\n",
      "Step: 2500  \tValid loss: 0.4230707585811615\n",
      "Step: 2600  \tTraining loss: 0.38451430201530457\n",
      "Step: 2600  \tTraining accuracy: 0.84650057554245\n",
      "Step: 2600  \tValid loss: 0.4231882393360138\n",
      "Step: 2700  \tTraining loss: 0.3842622637748718\n",
      "Step: 2700  \tTraining accuracy: 0.8467544317245483\n",
      "Step: 2700  \tValid loss: 0.4232967495918274\n",
      "Step: 2800  \tTraining loss: 0.38403183221817017\n",
      "Step: 2800  \tTraining accuracy: 0.8469576239585876\n",
      "Step: 2800  \tValid loss: 0.42336997389793396\n",
      "Step: 2900  \tTraining loss: 0.38381513953208923\n",
      "Step: 2900  \tTraining accuracy: 0.8471000790596008\n",
      "Step: 2900  \tValid loss: 0.42339903116226196\n",
      "Step: 3000  \tTraining loss: 0.38360294699668884\n",
      "Step: 3000  \tTraining accuracy: 0.847247838973999\n",
      "Step: 3000  \tValid loss: 0.42336305975914\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8473859\n",
      "Precision: 0.8012552\n",
      "Recall: 0.83442265\n",
      "F1 score: 0.86456877\n",
      "AUC: 0.8465268\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.847386   0.801255  0.834423  0.864569  0.846527  0.383535      0.847362   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.422677       0.847418    0.37131      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3031.0  \n",
      "7\n",
      "(986, 4)\n",
      "(986, 1)\n",
      "(544, 4)\n",
      "(544, 1)\n",
      "(442, 4)\n",
      "(442, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6611955165863037\n",
      "Step: 100  \tTraining accuracy: 0.6227180361747742\n",
      "Step: 100  \tValid loss: 0.6569463014602661\n",
      "Step: 200  \tTraining loss: 0.6390135288238525\n",
      "Step: 200  \tTraining accuracy: 0.6233941912651062\n",
      "Step: 200  \tValid loss: 0.6268412470817566\n",
      "Step: 300  \tTraining loss: 0.6072442531585693\n",
      "Step: 300  \tTraining accuracy: 0.6318458318710327\n",
      "Step: 300  \tValid loss: 0.5839011073112488\n",
      "Step: 400  \tTraining loss: 0.580057680606842\n",
      "Step: 400  \tTraining accuracy: 0.6476383805274963\n",
      "Step: 400  \tValid loss: 0.5458735227584839\n",
      "Step: 500  \tTraining loss: 0.5649521946907043\n",
      "Step: 500  \tTraining accuracy: 0.6656524538993835\n",
      "Step: 500  \tValid loss: 0.5210623145103455\n",
      "Step: 600  \tTraining loss: 0.5591033697128296\n",
      "Step: 600  \tTraining accuracy: 0.678867757320404\n",
      "Step: 600  \tValid loss: 0.5087389945983887\n",
      "Step: 700  \tTraining loss: 0.5569433569908142\n",
      "Step: 700  \tTraining accuracy: 0.6883289217948914\n",
      "Step: 700  \tValid loss: 0.5029964447021484\n",
      "Step: 800  \tTraining loss: 0.5560344457626343\n",
      "Step: 800  \tTraining accuracy: 0.6955375075340271\n",
      "Step: 800  \tValid loss: 0.5001790523529053\n",
      "Step: 900  \tTraining loss: 0.5555237531661987\n",
      "Step: 900  \tTraining accuracy: 0.7007517218589783\n",
      "Step: 900  \tValid loss: 0.49869504570961\n",
      "Step: 1000  \tTraining loss: 0.5549660921096802\n",
      "Step: 1000  \tTraining accuracy: 0.7051884531974792\n",
      "Step: 1000  \tValid loss: 0.4977974593639374\n",
      "Step: 1100  \tTraining loss: 0.5545414090156555\n",
      "Step: 1100  \tTraining accuracy: 0.7088766694068909\n",
      "Step: 1100  \tValid loss: 0.4972573518753052\n",
      "Step: 1200  \tTraining loss: 0.5541858077049255\n",
      "Step: 1200  \tTraining accuracy: 0.7120116353034973\n",
      "Step: 1200  \tValid loss: 0.4969137907028198\n",
      "Step: 1300  \tTraining loss: 0.5538703799247742\n",
      "Step: 1300  \tTraining accuracy: 0.7145233154296875\n",
      "Step: 1300  \tValid loss: 0.4966922104358673\n",
      "Step: 1400  \tTraining loss: 0.5535758137702942\n",
      "Step: 1400  \tTraining accuracy: 0.7165877819061279\n",
      "Step: 1400  \tValid loss: 0.49650073051452637\n",
      "Step: 1500  \tTraining loss: 0.5533176064491272\n",
      "Step: 1500  \tTraining accuracy: 0.7185423374176025\n",
      "Step: 1500  \tValid loss: 0.4963783323764801\n",
      "Step: 1600  \tTraining loss: 0.5530952215194702\n",
      "Step: 1600  \tTraining accuracy: 0.7202119827270508\n",
      "Step: 1600  \tValid loss: 0.4963076114654541\n",
      "Step: 1700  \tTraining loss: 0.5528757572174072\n",
      "Step: 1700  \tTraining accuracy: 0.7216485142707825\n",
      "Step: 1700  \tValid loss: 0.496243417263031\n",
      "Step: 1800  \tTraining loss: 0.5526660680770874\n",
      "Step: 1800  \tTraining accuracy: 0.7228919267654419\n",
      "Step: 1800  \tValid loss: 0.4961671233177185\n",
      "Step: 1900  \tTraining loss: 0.5524719953536987\n",
      "Step: 1900  \tTraining accuracy: 0.724000871181488\n",
      "Step: 1900  \tValid loss: 0.4961128234863281\n",
      "Step: 2000  \tTraining loss: 0.552282452583313\n",
      "Step: 2000  \tTraining accuracy: 0.7250220775604248\n",
      "Step: 2000  \tValid loss: 0.49606749415397644\n",
      "Step: 2100  \tTraining loss: 0.5520968437194824\n",
      "Step: 2100  \tTraining accuracy: 0.7259684205055237\n",
      "Step: 2100  \tValid loss: 0.4960212707519531\n",
      "Step: 2200  \tTraining loss: 0.5519159436225891\n",
      "Step: 2200  \tTraining accuracy: 0.7268031239509583\n",
      "Step: 2200  \tValid loss: 0.4959767162799835\n",
      "Step: 2300  \tTraining loss: 0.5517429709434509\n",
      "Step: 2300  \tTraining accuracy: 0.7275862097740173\n",
      "Step: 2300  \tValid loss: 0.49593353271484375\n",
      "Step: 2400  \tTraining loss: 0.5515729188919067\n",
      "Step: 2400  \tTraining accuracy: 0.7283025979995728\n",
      "Step: 2400  \tValid loss: 0.4958832263946533\n",
      "Step: 2500  \tTraining loss: 0.5514051914215088\n",
      "Step: 2500  \tTraining accuracy: 0.7289605736732483\n",
      "Step: 2500  \tValid loss: 0.49582067131996155\n",
      "Step: 2600  \tTraining loss: 0.5512330532073975\n",
      "Step: 2600  \tTraining accuracy: 0.7295668721199036\n",
      "Step: 2600  \tValid loss: 0.49572518467903137\n",
      "Step: 2700  \tTraining loss: 0.5510585904121399\n",
      "Step: 2700  \tTraining accuracy: 0.7301274538040161\n",
      "Step: 2700  \tValid loss: 0.495649516582489\n",
      "Step: 2800  \tTraining loss: 0.5508912205696106\n",
      "Step: 2800  \tTraining accuracy: 0.7306472659111023\n",
      "Step: 2800  \tValid loss: 0.4955730438232422\n",
      "Step: 2900  \tTraining loss: 0.5507133603096008\n",
      "Step: 2900  \tTraining accuracy: 0.7311305403709412\n",
      "Step: 2900  \tValid loss: 0.49548810720443726\n",
      "Step: 3000  \tTraining loss: 0.5505404472351074\n",
      "Step: 3000  \tTraining accuracy: 0.731563925743103\n",
      "Step: 3000  \tValid loss: 0.4954248368740082\n",
      "Step: 3100  \tTraining loss: 0.550378143787384\n",
      "Step: 3100  \tTraining accuracy: 0.731968879699707\n",
      "Step: 3100  \tValid loss: 0.4953557252883911\n",
      "Step: 3200  \tTraining loss: 0.5502201318740845\n",
      "Step: 3200  \tTraining accuracy: 0.7323480844497681\n",
      "Step: 3200  \tValid loss: 0.4952732026576996\n",
      "Step: 3300  \tTraining loss: 0.5500636100769043\n",
      "Step: 3300  \tTraining accuracy: 0.7327039837837219\n",
      "Step: 3300  \tValid loss: 0.4951933026313782\n",
      "Step: 3400  \tTraining loss: 0.5499088764190674\n",
      "Step: 3400  \tTraining accuracy: 0.7330083847045898\n",
      "Step: 3400  \tValid loss: 0.49511584639549255\n",
      "Step: 3500  \tTraining loss: 0.5497554540634155\n",
      "Step: 3500  \tTraining accuracy: 0.7332951426506042\n",
      "Step: 3500  \tValid loss: 0.4950404465198517\n",
      "Step: 3600  \tTraining loss: 0.549604058265686\n",
      "Step: 3600  \tTraining accuracy: 0.7335799932479858\n",
      "Step: 3600  \tValid loss: 0.4949665069580078\n",
      "Step: 3700  \tTraining loss: 0.5494537949562073\n",
      "Step: 3700  \tTraining accuracy: 0.7338492274284363\n",
      "Step: 3700  \tValid loss: 0.4948943555355072\n",
      "Step: 3800  \tTraining loss: 0.5493056774139404\n",
      "Step: 3800  \tTraining accuracy: 0.7341040968894958\n",
      "Step: 3800  \tValid loss: 0.4948294162750244\n",
      "Step: 3900  \tTraining loss: 0.5491596460342407\n",
      "Step: 3900  \tTraining accuracy: 0.7343721389770508\n",
      "Step: 3900  \tValid loss: 0.4947628676891327\n",
      "Step: 4000  \tTraining loss: 0.5490149855613708\n",
      "Step: 4000  \tTraining accuracy: 0.7346394062042236\n",
      "Step: 4000  \tValid loss: 0.4946979582309723\n",
      "Step: 4100  \tTraining loss: 0.5488724708557129\n",
      "Step: 4100  \tTraining accuracy: 0.7349059581756592\n",
      "Step: 4100  \tValid loss: 0.49463462829589844\n",
      "Step: 4200  \tTraining loss: 0.5487316250801086\n",
      "Step: 4200  \tTraining accuracy: 0.735171914100647\n",
      "Step: 4200  \tValid loss: 0.49457335472106934\n",
      "Step: 4300  \tTraining loss: 0.5485924482345581\n",
      "Step: 4300  \tTraining accuracy: 0.7354253530502319\n",
      "Step: 4300  \tValid loss: 0.4945142865180969\n",
      "Step: 4400  \tTraining loss: 0.548454999923706\n",
      "Step: 4400  \tTraining accuracy: 0.7356671690940857\n",
      "Step: 4400  \tValid loss: 0.4944566786289215\n",
      "Step: 4500  \tTraining loss: 0.5483195185661316\n",
      "Step: 4500  \tTraining accuracy: 0.7358866930007935\n",
      "Step: 4500  \tValid loss: 0.494401216506958\n",
      "Step: 4600  \tTraining loss: 0.5481852889060974\n",
      "Step: 4600  \tTraining accuracy: 0.7360854148864746\n",
      "Step: 4600  \tValid loss: 0.4943477511405945\n",
      "Step: 4700  \tTraining loss: 0.5480533838272095\n",
      "Step: 4700  \tTraining accuracy: 0.7362865209579468\n",
      "Step: 4700  \tValid loss: 0.4942969083786011\n",
      "Step: 4800  \tTraining loss: 0.5479229092597961\n",
      "Step: 4800  \tTraining accuracy: 0.7364791035652161\n",
      "Step: 4800  \tValid loss: 0.49424833059310913\n",
      "Step: 4900  \tTraining loss: 0.5477942824363708\n",
      "Step: 4900  \tTraining accuracy: 0.7366742491722107\n",
      "Step: 4900  \tValid loss: 0.4941994249820709\n",
      "Step: 5000  \tTraining loss: 0.5476678609848022\n",
      "Step: 5000  \tTraining accuracy: 0.736861526966095\n",
      "Step: 5000  \tValid loss: 0.4941554367542267\n",
      "Step: 5100  \tTraining loss: 0.547543466091156\n",
      "Step: 5100  \tTraining accuracy: 0.7370614409446716\n",
      "Step: 5100  \tValid loss: 0.49411481618881226\n",
      "Step: 5200  \tTraining loss: 0.5474211573600769\n",
      "Step: 5200  \tTraining accuracy: 0.7372536063194275\n",
      "Step: 5200  \tValid loss: 0.4940783679485321\n",
      "Step: 5300  \tTraining loss: 0.5473006963729858\n",
      "Step: 5300  \tTraining accuracy: 0.737438440322876\n",
      "Step: 5300  \tValid loss: 0.49404552578926086\n",
      "Step: 5400  \tTraining loss: 0.5471826791763306\n",
      "Step: 5400  \tTraining accuracy: 0.7376163601875305\n",
      "Step: 5400  \tValid loss: 0.49401602149009705\n",
      "Step: 5500  \tTraining loss: 0.5470667481422424\n",
      "Step: 5500  \tTraining accuracy: 0.7377970218658447\n",
      "Step: 5500  \tValid loss: 0.49398961663246155\n",
      "Step: 5600  \tTraining loss: 0.5469528436660767\n",
      "Step: 5600  \tTraining accuracy: 0.7379621267318726\n",
      "Step: 5600  \tValid loss: 0.49396541714668274\n",
      "Step: 5700  \tTraining loss: 0.5468415021896362\n",
      "Step: 5700  \tTraining accuracy: 0.7381213307380676\n",
      "Step: 5700  \tValid loss: 0.4939432740211487\n",
      "Step: 5800  \tTraining loss: 0.5467323064804077\n",
      "Step: 5800  \tTraining accuracy: 0.7382661700248718\n",
      "Step: 5800  \tValid loss: 0.4939238727092743\n",
      "Step: 5900  \tTraining loss: 0.5466256141662598\n",
      "Step: 5900  \tTraining accuracy: 0.7384060621261597\n",
      "Step: 5900  \tValid loss: 0.493905633687973\n",
      "Step: 6000  \tTraining loss: 0.5465213060379028\n",
      "Step: 6000  \tTraining accuracy: 0.7385412454605103\n",
      "Step: 6000  \tValid loss: 0.49389100074768066\n",
      "Step: 6100  \tTraining loss: 0.5464193224906921\n",
      "Step: 6100  \tTraining accuracy: 0.738680362701416\n",
      "Step: 6100  \tValid loss: 0.49387887120246887\n",
      "Step: 6200  \tTraining loss: 0.5463196635246277\n",
      "Step: 6200  \tTraining accuracy: 0.7388149499893188\n",
      "Step: 6200  \tValid loss: 0.4938686490058899\n",
      "Step: 6300  \tTraining loss: 0.5462223887443542\n",
      "Step: 6300  \tTraining accuracy: 0.7389371395111084\n",
      "Step: 6300  \tValid loss: 0.4938610792160034\n",
      "Step: 6400  \tTraining loss: 0.5461275577545166\n",
      "Step: 6400  \tTraining accuracy: 0.7390714287757874\n",
      "Step: 6400  \tValid loss: 0.4938555359840393\n",
      "Step: 6500  \tTraining loss: 0.5460349321365356\n",
      "Step: 6500  \tTraining accuracy: 0.739201545715332\n",
      "Step: 6500  \tValid loss: 0.49385058879852295\n",
      "Step: 6600  \tTraining loss: 0.5459444522857666\n",
      "Step: 6600  \tTraining accuracy: 0.7393354177474976\n",
      "Step: 6600  \tValid loss: 0.4938446581363678\n",
      "Step: 6700  \tTraining loss: 0.5458564162254333\n",
      "Step: 6700  \tTraining accuracy: 0.7394652962684631\n",
      "Step: 6700  \tValid loss: 0.49384206533432007\n",
      "Step: 6800  \tTraining loss: 0.5457722544670105\n",
      "Step: 6800  \tTraining accuracy: 0.73959881067276\n",
      "Step: 6800  \tValid loss: 0.4938434660434723\n",
      "Step: 6900  \tTraining loss: 0.5456904768943787\n",
      "Step: 6900  \tTraining accuracy: 0.7397210597991943\n",
      "Step: 6900  \tValid loss: 0.4938470125198364\n",
      "Step: 7000  \tTraining loss: 0.5456112623214722\n",
      "Step: 7000  \tTraining accuracy: 0.7398397922515869\n",
      "Step: 7000  \tValid loss: 0.4938552975654602\n",
      "Step: 7100  \tTraining loss: 0.5455341935157776\n",
      "Step: 7100  \tTraining accuracy: 0.7399551272392273\n",
      "Step: 7100  \tValid loss: 0.4938667416572571\n",
      "Step: 7200  \tTraining loss: 0.5454595685005188\n",
      "Step: 7200  \tTraining accuracy: 0.7400743365287781\n",
      "Step: 7200  \tValid loss: 0.4938795864582062\n",
      "Step: 7300  \tTraining loss: 0.545386791229248\n",
      "Step: 7300  \tTraining accuracy: 0.7401902675628662\n",
      "Step: 7300  \tValid loss: 0.4938914477825165\n",
      "Step: 7400  \tTraining loss: 0.5453162789344788\n",
      "Step: 7400  \tTraining accuracy: 0.7403030395507812\n",
      "Step: 7400  \tValid loss: 0.49391689896583557\n",
      "Step: 7500  \tTraining loss: 0.54524827003479\n",
      "Step: 7500  \tTraining accuracy: 0.7404195666313171\n",
      "Step: 7500  \tValid loss: 0.49394112825393677\n",
      "Step: 7600  \tTraining loss: 0.5451822876930237\n",
      "Step: 7600  \tTraining accuracy: 0.7405397295951843\n",
      "Step: 7600  \tValid loss: 0.49396616220474243\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7406568\n",
      "Precision: 0.7\n",
      "Recall: 0.5268817\n",
      "F1 score: 0.6361469\n",
      "AUC: 0.69503695\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.740657        0.7  0.526882  0.636147  0.695037  0.545126      0.740685   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.493841       0.740538   0.550017      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  7686.0  \n",
      "8\n",
      "(2668, 4)\n",
      "(2668, 1)\n",
      "(1472, 4)\n",
      "(1472, 1)\n",
      "(1196, 4)\n",
      "(1196, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6512158513069153\n",
      "Step: 100  \tTraining accuracy: 0.6161919236183167\n",
      "Step: 100  \tValid loss: 0.6662845611572266\n",
      "Step: 200  \tTraining loss: 0.5586932301521301\n",
      "Step: 200  \tTraining accuracy: 0.6479260325431824\n",
      "Step: 200  \tValid loss: 0.5663149356842041\n",
      "Step: 300  \tTraining loss: 0.45594140887260437\n",
      "Step: 300  \tTraining accuracy: 0.6988755464553833\n",
      "Step: 300  \tValid loss: 0.4525226056575775\n",
      "Step: 400  \tTraining loss: 0.3880976140499115\n",
      "Step: 400  \tTraining accuracy: 0.739130437374115\n",
      "Step: 400  \tValid loss: 0.37728291749954224\n",
      "Step: 500  \tTraining loss: 0.353412002325058\n",
      "Step: 500  \tTraining accuracy: 0.7656588554382324\n",
      "Step: 500  \tValid loss: 0.33842524886131287\n",
      "Step: 600  \tTraining loss: 0.33657124638557434\n",
      "Step: 600  \tTraining accuracy: 0.7835968136787415\n",
      "Step: 600  \tValid loss: 0.3190663754940033\n",
      "Step: 700  \tTraining loss: 0.32821857929229736\n",
      "Step: 700  \tTraining accuracy: 0.7960442900657654\n",
      "Step: 700  \tValid loss: 0.30910706520080566\n",
      "Step: 800  \tTraining loss: 0.32385677099227905\n",
      "Step: 800  \tTraining accuracy: 0.8051474094390869\n",
      "Step: 800  \tValid loss: 0.30364617705345154\n",
      "Step: 900  \tTraining loss: 0.3211503326892853\n",
      "Step: 900  \tTraining accuracy: 0.8119543194770813\n",
      "Step: 900  \tValid loss: 0.30031317472457886\n",
      "Step: 1000  \tTraining loss: 0.31880447268486023\n",
      "Step: 1000  \tTraining accuracy: 0.8175057172775269\n",
      "Step: 1000  \tValid loss: 0.29786235094070435\n",
      "Step: 1100  \tTraining loss: 0.31604820489883423\n",
      "Step: 1100  \tTraining accuracy: 0.8222495913505554\n",
      "Step: 1100  \tValid loss: 0.2963200509548187\n",
      "Step: 1200  \tTraining loss: 0.3145293593406677\n",
      "Step: 1200  \tTraining accuracy: 0.8261195421218872\n",
      "Step: 1200  \tValid loss: 0.29436564445495605\n",
      "Step: 1300  \tTraining loss: 0.31367015838623047\n",
      "Step: 1300  \tTraining accuracy: 0.8293552994728088\n",
      "Step: 1300  \tValid loss: 0.29302388429641724\n",
      "Step: 1400  \tTraining loss: 0.3130490183830261\n",
      "Step: 1400  \tTraining accuracy: 0.8321256041526794\n",
      "Step: 1400  \tValid loss: 0.2921373248100281\n",
      "Step: 1500  \tTraining loss: 0.312565416097641\n",
      "Step: 1500  \tTraining accuracy: 0.8344749808311462\n",
      "Step: 1500  \tValid loss: 0.29144546389579773\n",
      "Step: 1600  \tTraining loss: 0.3121415078639984\n",
      "Step: 1600  \tTraining accuracy: 0.836569607257843\n",
      "Step: 1600  \tValid loss: 0.2907593250274658\n",
      "Step: 1700  \tTraining loss: 0.3117617070674896\n",
      "Step: 1700  \tTraining accuracy: 0.8383876085281372\n",
      "Step: 1700  \tValid loss: 0.2902267277240753\n",
      "Step: 1800  \tTraining loss: 0.31140264868736267\n",
      "Step: 1800  \tTraining accuracy: 0.8400300145149231\n",
      "Step: 1800  \tValid loss: 0.28974276781082153\n",
      "Step: 1900  \tTraining loss: 0.31105276942253113\n",
      "Step: 1900  \tTraining accuracy: 0.8414846658706665\n",
      "Step: 1900  \tValid loss: 0.28926199674606323\n",
      "Step: 2000  \tTraining loss: 0.310707151889801\n",
      "Step: 2000  \tTraining accuracy: 0.8428381681442261\n",
      "Step: 2000  \tValid loss: 0.2887943983078003\n",
      "Step: 2100  \tTraining loss: 0.31014731526374817\n",
      "Step: 2100  \tTraining accuracy: 0.8440871238708496\n",
      "Step: 2100  \tValid loss: 0.2889251410961151\n",
      "Step: 2200  \tTraining loss: 0.30969899892807007\n",
      "Step: 2200  \tTraining accuracy: 0.8452372550964355\n",
      "Step: 2200  \tValid loss: 0.2886759340763092\n",
      "Step: 2300  \tTraining loss: 0.3092435300350189\n",
      "Step: 2300  \tTraining accuracy: 0.8462601900100708\n",
      "Step: 2300  \tValid loss: 0.28833505511283875\n",
      "Step: 2400  \tTraining loss: 0.3087296485900879\n",
      "Step: 2400  \tTraining accuracy: 0.8471881151199341\n",
      "Step: 2400  \tValid loss: 0.28815335035324097\n",
      "Step: 2500  \tTraining loss: 0.3081842064857483\n",
      "Step: 2500  \tTraining accuracy: 0.8480479121208191\n",
      "Step: 2500  \tValid loss: 0.2881147563457489\n",
      "Step: 2600  \tTraining loss: 0.3077053427696228\n",
      "Step: 2600  \tTraining accuracy: 0.8488255739212036\n",
      "Step: 2600  \tValid loss: 0.28773826360702515\n",
      "Step: 2700  \tTraining loss: 0.30728626251220703\n",
      "Step: 2700  \tTraining accuracy: 0.8495091795921326\n",
      "Step: 2700  \tValid loss: 0.2874143719673157\n",
      "Step: 2800  \tTraining loss: 0.30689316987991333\n",
      "Step: 2800  \tTraining accuracy: 0.8501362800598145\n",
      "Step: 2800  \tValid loss: 0.287085622549057\n",
      "Step: 2900  \tTraining loss: 0.30652916431427\n",
      "Step: 2900  \tTraining accuracy: 0.8507391214370728\n",
      "Step: 2900  \tValid loss: 0.28682973980903625\n",
      "Step: 3000  \tTraining loss: 0.3061951696872711\n",
      "Step: 3000  \tTraining accuracy: 0.851275622844696\n",
      "Step: 3000  \tValid loss: 0.2866165041923523\n",
      "Step: 3100  \tTraining loss: 0.30588796734809875\n",
      "Step: 3100  \tTraining accuracy: 0.8517769575119019\n",
      "Step: 3100  \tValid loss: 0.28642335534095764\n",
      "Step: 3200  \tTraining loss: 0.3056071996688843\n",
      "Step: 3200  \tTraining accuracy: 0.8522703051567078\n",
      "Step: 3200  \tValid loss: 0.2862609028816223\n",
      "Step: 3300  \tTraining loss: 0.30535343289375305\n",
      "Step: 3300  \tTraining accuracy: 0.8527563214302063\n",
      "Step: 3300  \tValid loss: 0.28608787059783936\n",
      "Step: 3400  \tTraining loss: 0.3051206171512604\n",
      "Step: 3400  \tTraining accuracy: 0.8532189130783081\n",
      "Step: 3400  \tValid loss: 0.28590190410614014\n",
      "Step: 3500  \tTraining loss: 0.3049072027206421\n",
      "Step: 3500  \tTraining accuracy: 0.8536438345909119\n",
      "Step: 3500  \tValid loss: 0.28583478927612305\n",
      "Step: 3600  \tTraining loss: 0.3047106862068176\n",
      "Step: 3600  \tTraining accuracy: 0.8540289998054504\n",
      "Step: 3600  \tValid loss: 0.28573304414749146\n",
      "Step: 3700  \tTraining loss: 0.3045279085636139\n",
      "Step: 3700  \tTraining accuracy: 0.8543878793716431\n",
      "Step: 3700  \tValid loss: 0.28554654121398926\n",
      "Step: 3800  \tTraining loss: 0.3043597936630249\n",
      "Step: 3800  \tTraining accuracy: 0.8547226190567017\n",
      "Step: 3800  \tValid loss: 0.28548377752304077\n",
      "Step: 3900  \tTraining loss: 0.304203599691391\n",
      "Step: 3900  \tTraining accuracy: 0.855035126209259\n",
      "Step: 3900  \tValid loss: 0.28540724515914917\n",
      "Step: 4000  \tTraining loss: 0.3040587902069092\n",
      "Step: 4000  \tTraining accuracy: 0.8553365468978882\n",
      "Step: 4000  \tValid loss: 0.2853447496891022\n",
      "Step: 4100  \tTraining loss: 0.3039243221282959\n",
      "Step: 4100  \tTraining accuracy: 0.855627715587616\n",
      "Step: 4100  \tValid loss: 0.2852741777896881\n",
      "Step: 4200  \tTraining loss: 0.30379539728164673\n",
      "Step: 4200  \tTraining accuracy: 0.8559094071388245\n",
      "Step: 4200  \tValid loss: 0.28516438603401184\n",
      "Step: 4300  \tTraining loss: 0.30367740988731384\n",
      "Step: 4300  \tTraining accuracy: 0.8561733961105347\n",
      "Step: 4300  \tValid loss: 0.2851143777370453\n",
      "Step: 4400  \tTraining loss: 0.3035678267478943\n",
      "Step: 4400  \tTraining accuracy: 0.8564252257347107\n",
      "Step: 4400  \tValid loss: 0.2850998044013977\n",
      "Step: 4500  \tTraining loss: 0.3034650981426239\n",
      "Step: 4500  \tTraining accuracy: 0.8566573262214661\n",
      "Step: 4500  \tValid loss: 0.2850268483161926\n",
      "Step: 4600  \tTraining loss: 0.3033679127693176\n",
      "Step: 4600  \tTraining accuracy: 0.8568751215934753\n",
      "Step: 4600  \tValid loss: 0.2849797308444977\n",
      "Step: 4700  \tTraining loss: 0.30327385663986206\n",
      "Step: 4700  \tTraining accuracy: 0.8570956587791443\n",
      "Step: 4700  \tValid loss: 0.2849365770816803\n",
      "Step: 4800  \tTraining loss: 0.3031848669052124\n",
      "Step: 4800  \tTraining accuracy: 0.8573068976402283\n",
      "Step: 4800  \tValid loss: 0.28480809926986694\n",
      "Step: 4900  \tTraining loss: 0.3031063675880432\n",
      "Step: 4900  \tTraining accuracy: 0.8575055003166199\n",
      "Step: 4900  \tValid loss: 0.28486329317092896\n",
      "Step: 5000  \tTraining loss: 0.30302897095680237\n",
      "Step: 5000  \tTraining accuracy: 0.8576961755752563\n",
      "Step: 5000  \tValid loss: 0.2847573459148407\n",
      "Step: 5100  \tTraining loss: 0.3029589056968689\n",
      "Step: 5100  \tTraining accuracy: 0.8578866720199585\n",
      "Step: 5100  \tValid loss: 0.28474709391593933\n",
      "Step: 5200  \tTraining loss: 0.3028928339481354\n",
      "Step: 5200  \tTraining accuracy: 0.8580661416053772\n",
      "Step: 5200  \tValid loss: 0.28471630811691284\n",
      "Step: 5300  \tTraining loss: 0.3028308153152466\n",
      "Step: 5300  \tTraining accuracy: 0.858245849609375\n",
      "Step: 5300  \tValid loss: 0.28473222255706787\n",
      "Step: 5400  \tTraining loss: 0.3027719557285309\n",
      "Step: 5400  \tTraining accuracy: 0.8584189414978027\n",
      "Step: 5400  \tValid loss: 0.28469428420066833\n",
      "Step: 5500  \tTraining loss: 0.302716463804245\n",
      "Step: 5500  \tTraining accuracy: 0.8585787415504456\n",
      "Step: 5500  \tValid loss: 0.28467127680778503\n",
      "Step: 5600  \tTraining loss: 0.30266493558883667\n",
      "Step: 5600  \tTraining accuracy: 0.8587395548820496\n",
      "Step: 5600  \tValid loss: 0.28462332487106323\n",
      "Step: 5700  \tTraining loss: 0.3026145100593567\n",
      "Step: 5700  \tTraining accuracy: 0.8588913679122925\n",
      "Step: 5700  \tValid loss: 0.28464648127555847\n",
      "Step: 5800  \tTraining loss: 0.30256637930870056\n",
      "Step: 5800  \tTraining accuracy: 0.859041154384613\n",
      "Step: 5800  \tValid loss: 0.2845161557197571\n",
      "Step: 5900  \tTraining loss: 0.30252131819725037\n",
      "Step: 5900  \tTraining accuracy: 0.8591858148574829\n",
      "Step: 5900  \tValid loss: 0.28460365533828735\n",
      "Step: 6000  \tTraining loss: 0.30247560143470764\n",
      "Step: 6000  \tTraining accuracy: 0.8593255877494812\n",
      "Step: 6000  \tValid loss: 0.2845783829689026\n",
      "Step: 6100  \tTraining loss: 0.30243152379989624\n",
      "Step: 6100  \tTraining accuracy: 0.8594607710838318\n",
      "Step: 6100  \tValid loss: 0.28451672196388245\n",
      "Step: 6200  \tTraining loss: 0.30238860845565796\n",
      "Step: 6200  \tTraining accuracy: 0.859591543674469\n",
      "Step: 6200  \tValid loss: 0.28451529145240784\n",
      "Step: 6300  \tTraining loss: 0.3023468255996704\n",
      "Step: 6300  \tTraining accuracy: 0.8597181439399719\n",
      "Step: 6300  \tValid loss: 0.2844884991645813\n",
      "Step: 6400  \tTraining loss: 0.30230578780174255\n",
      "Step: 6400  \tTraining accuracy: 0.8598407506942749\n",
      "Step: 6400  \tValid loss: 0.2844599783420563\n",
      "Step: 6500  \tTraining loss: 0.30226513743400574\n",
      "Step: 6500  \tTraining accuracy: 0.8599624633789062\n",
      "Step: 6500  \tValid loss: 0.28443095088005066\n",
      "Step: 6600  \tTraining loss: 0.30222538113594055\n",
      "Step: 6600  \tTraining accuracy: 0.8600833415985107\n",
      "Step: 6600  \tValid loss: 0.28440961241722107\n",
      "Step: 6700  \tTraining loss: 0.30218592286109924\n",
      "Step: 6700  \tTraining accuracy: 0.8602005243301392\n",
      "Step: 6700  \tValid loss: 0.2843925952911377\n",
      "Step: 6800  \tTraining loss: 0.30214691162109375\n",
      "Step: 6800  \tTraining accuracy: 0.8603143095970154\n",
      "Step: 6800  \tValid loss: 0.2843720316886902\n",
      "Step: 6900  \tTraining loss: 0.3021085560321808\n",
      "Step: 6900  \tTraining accuracy: 0.8604274392127991\n",
      "Step: 6900  \tValid loss: 0.2843484580516815\n",
      "Step: 7000  \tTraining loss: 0.3020709156990051\n",
      "Step: 7000  \tTraining accuracy: 0.8605319857597351\n",
      "Step: 7000  \tValid loss: 0.28430235385894775\n",
      "Step: 7100  \tTraining loss: 0.30203357338905334\n",
      "Step: 7100  \tTraining accuracy: 0.8606334924697876\n",
      "Step: 7100  \tValid loss: 0.28429192304611206\n",
      "Step: 7200  \tTraining loss: 0.3019970953464508\n",
      "Step: 7200  \tTraining accuracy: 0.8607321977615356\n",
      "Step: 7200  \tValid loss: 0.2842569053173065\n",
      "Step: 7300  \tTraining loss: 0.30196118354797363\n",
      "Step: 7300  \tTraining accuracy: 0.8608282208442688\n",
      "Step: 7300  \tValid loss: 0.284264475107193\n",
      "Step: 7400  \tTraining loss: 0.3019254505634308\n",
      "Step: 7400  \tTraining accuracy: 0.8609190583229065\n",
      "Step: 7400  \tValid loss: 0.2842009663581848\n",
      "Step: 7500  \tTraining loss: 0.30188998579978943\n",
      "Step: 7500  \tTraining accuracy: 0.8610124588012695\n",
      "Step: 7500  \tValid loss: 0.2842421531677246\n",
      "Step: 7600  \tTraining loss: 0.30185458064079285\n",
      "Step: 7600  \tTraining accuracy: 0.8611034154891968\n",
      "Step: 7600  \tValid loss: 0.28422248363494873\n",
      "Step: 7700  \tTraining loss: 0.30181947350502014\n",
      "Step: 7700  \tTraining accuracy: 0.8611944317817688\n",
      "Step: 7700  \tValid loss: 0.28419655561447144\n",
      "Step: 7800  \tTraining loss: 0.30178406834602356\n",
      "Step: 7800  \tTraining accuracy: 0.8612855076789856\n",
      "Step: 7800  \tValid loss: 0.28419360518455505\n",
      "Step: 7900  \tTraining loss: 0.3017488420009613\n",
      "Step: 7900  \tTraining accuracy: 0.8613766431808472\n",
      "Step: 7900  \tValid loss: 0.2842024862766266\n",
      "Step: 8000  \tTraining loss: 0.30171337723731995\n",
      "Step: 8000  \tTraining accuracy: 0.8614702224731445\n",
      "Step: 8000  \tValid loss: 0.2841883897781372\n",
      "Step: 8100  \tTraining loss: 0.30167752504348755\n",
      "Step: 8100  \tTraining accuracy: 0.8615591526031494\n",
      "Step: 8100  \tValid loss: 0.284172385931015\n",
      "Step: 8200  \tTraining loss: 0.3016422986984253\n",
      "Step: 8200  \tTraining accuracy: 0.8616412878036499\n",
      "Step: 8200  \tValid loss: 0.2841591238975525\n",
      "Step: 8300  \tTraining loss: 0.3016073703765869\n",
      "Step: 8300  \tTraining accuracy: 0.861721396446228\n",
      "Step: 8300  \tValid loss: 0.28415733575820923\n",
      "Step: 8400  \tTraining loss: 0.3015725910663605\n",
      "Step: 8400  \tTraining accuracy: 0.8617973923683167\n",
      "Step: 8400  \tValid loss: 0.2841484844684601\n",
      "Step: 8500  \tTraining loss: 0.3015373647212982\n",
      "Step: 8500  \tTraining accuracy: 0.8618671298027039\n",
      "Step: 8500  \tValid loss: 0.2841847538948059\n",
      "Step: 8600  \tTraining loss: 0.301498144865036\n",
      "Step: 8600  \tTraining accuracy: 0.8619330525398254\n",
      "Step: 8600  \tValid loss: 0.28411486744880676\n",
      "Step: 8700  \tTraining loss: 0.30146047472953796\n",
      "Step: 8700  \tTraining accuracy: 0.8619974851608276\n",
      "Step: 8700  \tValid loss: 0.28408995270729065\n",
      "Step: 8800  \tTraining loss: 0.30142295360565186\n",
      "Step: 8800  \tTraining accuracy: 0.8620582818984985\n",
      "Step: 8800  \tValid loss: 0.28411567211151123\n",
      "Step: 8900  \tTraining loss: 0.30138519406318665\n",
      "Step: 8900  \tTraining accuracy: 0.8621197938919067\n",
      "Step: 8900  \tValid loss: 0.28410759568214417\n",
      "Step: 9000  \tTraining loss: 0.30134719610214233\n",
      "Step: 9000  \tTraining accuracy: 0.8621820211410522\n",
      "Step: 9000  \tValid loss: 0.28408390283584595\n",
      "Step: 9100  \tTraining loss: 0.3013102114200592\n",
      "Step: 9100  \tTraining accuracy: 0.8622429370880127\n",
      "Step: 9100  \tValid loss: 0.28407034277915955\n",
      "Step: 9200  \tTraining loss: 0.3012731373310089\n",
      "Step: 9200  \tTraining accuracy: 0.862306535243988\n",
      "Step: 9200  \tValid loss: 0.28410661220550537\n",
      "Step: 9300  \tTraining loss: 0.30123576521873474\n",
      "Step: 9300  \tTraining accuracy: 0.8623688220977783\n",
      "Step: 9300  \tValid loss: 0.2840849757194519\n",
      "Step: 9400  \tTraining loss: 0.3011983633041382\n",
      "Step: 9400  \tTraining accuracy: 0.8624277710914612\n",
      "Step: 9400  \tValid loss: 0.2841201722621918\n",
      "Step: 9500  \tTraining loss: 0.30115431547164917\n",
      "Step: 9500  \tTraining accuracy: 0.8624894022941589\n",
      "Step: 9500  \tValid loss: 0.284112811088562\n",
      "Step: 9600  \tTraining loss: 0.3011096119880676\n",
      "Step: 9600  \tTraining accuracy: 0.8625497221946716\n",
      "Step: 9600  \tValid loss: 0.2840934097766876\n",
      "Step: 9700  \tTraining loss: 0.3010667562484741\n",
      "Step: 9700  \tTraining accuracy: 0.8626108169555664\n",
      "Step: 9700  \tValid loss: 0.2841155529022217\n",
      "Step: 9800  \tTraining loss: 0.30102452635765076\n",
      "Step: 9800  \tTraining accuracy: 0.8626706004142761\n",
      "Step: 9800  \tValid loss: 0.2841227054595947\n",
      "Step: 9900  \tTraining loss: 0.3009822964668274\n",
      "Step: 9900  \tTraining accuracy: 0.8627291917800903\n",
      "Step: 9900  \tValid loss: 0.2841838300228119\n",
      "Step: 10000  \tTraining loss: 0.30093899369239807\n",
      "Step: 10000  \tTraining accuracy: 0.8627921938896179\n",
      "Step: 10000  \tValid loss: 0.28414374589920044\n",
      "Step: 10100  \tTraining loss: 0.3008953034877777\n",
      "Step: 10100  \tTraining accuracy: 0.86285400390625\n",
      "Step: 10100  \tValid loss: 0.2841825485229492\n",
      "Step: 10200  \tTraining loss: 0.3008510172367096\n",
      "Step: 10200  \tTraining accuracy: 0.8629109263420105\n",
      "Step: 10200  \tValid loss: 0.28416842222213745\n",
      "Step: 10300  \tTraining loss: 0.3008069396018982\n",
      "Step: 10300  \tTraining accuracy: 0.8629667162895203\n",
      "Step: 10300  \tValid loss: 0.2842516005039215\n",
      "Step: 10400  \tTraining loss: 0.3007611632347107\n",
      "Step: 10400  \tTraining accuracy: 0.8630232214927673\n",
      "Step: 10400  \tValid loss: 0.28418073058128357\n",
      "Step: 10500  \tTraining loss: 0.3007151186466217\n",
      "Step: 10500  \tTraining accuracy: 0.8630804419517517\n",
      "Step: 10500  \tValid loss: 0.28422480821609497\n",
      "Step: 10600  \tTraining loss: 0.300668865442276\n",
      "Step: 10600  \tTraining accuracy: 0.8631365299224854\n",
      "Step: 10600  \tValid loss: 0.2842229902744293\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.86319166\n",
      "Precision: 0.9011668\n",
      "Recall: 0.866095\n",
      "F1 score: 0.8460614\n",
      "AUC: 0.87054753\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.863192   0.901167  0.866095  0.846061  0.870548  0.300627       0.86316   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.284046       0.863115   0.332966      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  10688.0  \n",
      "9\n",
      "(754, 4)\n",
      "(754, 1)\n",
      "(400, 4)\n",
      "(400, 1)\n",
      "(325, 4)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6079267263412476\n",
      "Step: 100  \tTraining accuracy: 0.616710901260376\n",
      "Step: 100  \tValid loss: 0.6950052380561829\n",
      "Step: 200  \tTraining loss: 0.5379642844200134\n",
      "Step: 200  \tTraining accuracy: 0.6551724076271057\n",
      "Step: 200  \tValid loss: 0.6982361078262329\n",
      "Step: 300  \tTraining loss: 0.5230910181999207\n",
      "Step: 300  \tTraining accuracy: 0.7050107717514038\n",
      "Step: 300  \tValid loss: 0.7116925120353699\n",
      "Step: 400  \tTraining loss: 0.5090245604515076\n",
      "Step: 400  \tTraining accuracy: 0.7266422510147095\n",
      "Step: 400  \tValid loss: 0.6970555186271667\n",
      "Step: 500  \tTraining loss: 0.48918023705482483\n",
      "Step: 500  \tTraining accuracy: 0.7386806607246399\n",
      "Step: 500  \tValid loss: 0.6651517748832703\n",
      "Step: 600  \tTraining loss: 0.4706445038318634\n",
      "Step: 600  \tTraining accuracy: 0.7463492155075073\n",
      "Step: 600  \tValid loss: 0.6341992616653442\n",
      "Step: 700  \tTraining loss: 0.4601086378097534\n",
      "Step: 700  \tTraining accuracy: 0.7516618371009827\n",
      "Step: 700  \tValid loss: 0.614051878452301\n",
      "Step: 800  \tTraining loss: 0.45471689105033875\n",
      "Step: 800  \tTraining accuracy: 0.7555595636367798\n",
      "Step: 800  \tValid loss: 0.6022529006004333\n",
      "Step: 900  \tTraining loss: 0.45144808292388916\n",
      "Step: 900  \tTraining accuracy: 0.7585412263870239\n",
      "Step: 900  \tValid loss: 0.5951549410820007\n",
      "Step: 1000  \tTraining loss: 0.44914302229881287\n",
      "Step: 1000  \tTraining accuracy: 0.760895848274231\n",
      "Step: 1000  \tValid loss: 0.590851902961731\n",
      "Step: 1100  \tTraining loss: 0.44743359088897705\n",
      "Step: 1100  \tTraining accuracy: 0.7628023624420166\n",
      "Step: 1100  \tValid loss: 0.5878856778144836\n",
      "Step: 1200  \tTraining loss: 0.4459354877471924\n",
      "Step: 1200  \tTraining accuracy: 0.7643775939941406\n",
      "Step: 1200  \tValid loss: 0.5872223377227783\n",
      "Step: 1300  \tTraining loss: 0.4448966979980469\n",
      "Step: 1300  \tTraining accuracy: 0.7657009959220886\n",
      "Step: 1300  \tValid loss: 0.5855137705802917\n",
      "Step: 1400  \tTraining loss: 0.44408535957336426\n",
      "Step: 1400  \tTraining accuracy: 0.7668284773826599\n",
      "Step: 1400  \tValid loss: 0.5843984484672546\n",
      "Step: 1500  \tTraining loss: 0.44345295429229736\n",
      "Step: 1500  \tTraining accuracy: 0.7678471803665161\n",
      "Step: 1500  \tValid loss: 0.5835344791412354\n",
      "Step: 1600  \tTraining loss: 0.44294118881225586\n",
      "Step: 1600  \tTraining accuracy: 0.7687344551086426\n",
      "Step: 1600  \tValid loss: 0.5830085873603821\n",
      "Step: 1700  \tTraining loss: 0.4425126612186432\n",
      "Step: 1700  \tTraining accuracy: 0.7695143222808838\n",
      "Step: 1700  \tValid loss: 0.5824393630027771\n",
      "Step: 1800  \tTraining loss: 0.442141056060791\n",
      "Step: 1800  \tTraining accuracy: 0.770205020904541\n",
      "Step: 1800  \tValid loss: 0.5818564891815186\n",
      "Step: 1900  \tTraining loss: 0.44181597232818604\n",
      "Step: 1900  \tTraining accuracy: 0.7707846164703369\n",
      "Step: 1900  \tValid loss: 0.5815204977989197\n",
      "Step: 2000  \tTraining loss: 0.4415092468261719\n",
      "Step: 2000  \tTraining accuracy: 0.7713047862052917\n",
      "Step: 2000  \tValid loss: 0.5810494422912598\n",
      "Step: 2100  \tTraining loss: 0.4411892592906952\n",
      "Step: 2100  \tTraining accuracy: 0.7717742323875427\n",
      "Step: 2100  \tValid loss: 0.5805871486663818\n",
      "Step: 2200  \tTraining loss: 0.4407816231250763\n",
      "Step: 2200  \tTraining accuracy: 0.7722000479698181\n",
      "Step: 2200  \tValid loss: 0.5794157981872559\n",
      "Step: 2300  \tTraining loss: 0.4403015971183777\n",
      "Step: 2300  \tTraining accuracy: 0.7725880146026611\n",
      "Step: 2300  \tValid loss: 0.5779359936714172\n",
      "Step: 2400  \tTraining loss: 0.43984001874923706\n",
      "Step: 2400  \tTraining accuracy: 0.7729717493057251\n",
      "Step: 2400  \tValid loss: 0.5763442516326904\n",
      "Step: 2500  \tTraining loss: 0.43942487239837646\n",
      "Step: 2500  \tTraining accuracy: 0.7733241319656372\n",
      "Step: 2500  \tValid loss: 0.5748147368431091\n",
      "Step: 2600  \tTraining loss: 0.4390772879123688\n",
      "Step: 2600  \tTraining accuracy: 0.7736489176750183\n",
      "Step: 2600  \tValid loss: 0.5735839605331421\n",
      "Step: 2700  \tTraining loss: 0.43877044320106506\n",
      "Step: 2700  \tTraining accuracy: 0.7739492058753967\n",
      "Step: 2700  \tValid loss: 0.5726666450500488\n",
      "Step: 2800  \tTraining loss: 0.4384097456932068\n",
      "Step: 2800  \tTraining accuracy: 0.7742276191711426\n",
      "Step: 2800  \tValid loss: 0.5710353255271912\n",
      "Step: 2900  \tTraining loss: 0.43793535232543945\n",
      "Step: 2900  \tTraining accuracy: 0.7744865417480469\n",
      "Step: 2900  \tValid loss: 0.5703606009483337\n",
      "Step: 3000  \tTraining loss: 0.43755021691322327\n",
      "Step: 3000  \tTraining accuracy: 0.7747279405593872\n",
      "Step: 3000  \tValid loss: 0.5698389410972595\n",
      "Step: 3100  \tTraining loss: 0.43719321489334106\n",
      "Step: 3100  \tTraining accuracy: 0.7749534845352173\n",
      "Step: 3100  \tValid loss: 0.5686630010604858\n",
      "Step: 3200  \tTraining loss: 0.4368966221809387\n",
      "Step: 3200  \tTraining accuracy: 0.7751646637916565\n",
      "Step: 3200  \tValid loss: 0.5681940317153931\n",
      "Step: 3300  \tTraining loss: 0.4366344213485718\n",
      "Step: 3300  \tTraining accuracy: 0.7753629088401794\n",
      "Step: 3300  \tValid loss: 0.5675612092018127\n",
      "Step: 3400  \tTraining loss: 0.43640223145484924\n",
      "Step: 3400  \tTraining accuracy: 0.7755493521690369\n",
      "Step: 3400  \tValid loss: 0.5669770240783691\n",
      "Step: 3500  \tTraining loss: 0.4361981153488159\n",
      "Step: 3500  \tTraining accuracy: 0.7757444977760315\n",
      "Step: 3500  \tValid loss: 0.5663813352584839\n",
      "Step: 3600  \tTraining loss: 0.4360078275203705\n",
      "Step: 3600  \tTraining accuracy: 0.7759287357330322\n",
      "Step: 3600  \tValid loss: 0.5657812356948853\n",
      "Step: 3700  \tTraining loss: 0.4358159899711609\n",
      "Step: 3700  \tTraining accuracy: 0.7761028409004211\n",
      "Step: 3700  \tValid loss: 0.5653127431869507\n",
      "Step: 3800  \tTraining loss: 0.4356386363506317\n",
      "Step: 3800  \tTraining accuracy: 0.7762676477432251\n",
      "Step: 3800  \tValid loss: 0.5648391246795654\n",
      "Step: 3900  \tTraining loss: 0.4354725778102875\n",
      "Step: 3900  \tTraining accuracy: 0.7764239311218262\n",
      "Step: 3900  \tValid loss: 0.5643625259399414\n",
      "Step: 4000  \tTraining loss: 0.43528833985328674\n",
      "Step: 4000  \tTraining accuracy: 0.7765722870826721\n",
      "Step: 4000  \tValid loss: 0.5635793805122375\n",
      "Step: 4100  \tTraining loss: 0.4351186454296112\n",
      "Step: 4100  \tTraining accuracy: 0.7767133116722107\n",
      "Step: 4100  \tValid loss: 0.5634016394615173\n",
      "Step: 4200  \tTraining loss: 0.4349575638771057\n",
      "Step: 4200  \tTraining accuracy: 0.7768475413322449\n",
      "Step: 4200  \tValid loss: 0.5629956126213074\n",
      "Step: 4300  \tTraining loss: 0.4348014295101166\n",
      "Step: 4300  \tTraining accuracy: 0.7769754528999329\n",
      "Step: 4300  \tValid loss: 0.5626444816589355\n",
      "Step: 4400  \tTraining loss: 0.43465059995651245\n",
      "Step: 4400  \tTraining accuracy: 0.7770974636077881\n",
      "Step: 4400  \tValid loss: 0.5621942281723022\n",
      "Step: 4500  \tTraining loss: 0.4345041811466217\n",
      "Step: 4500  \tTraining accuracy: 0.7772140502929688\n",
      "Step: 4500  \tValid loss: 0.5618331432342529\n",
      "Step: 4600  \tTraining loss: 0.43430301547050476\n",
      "Step: 4600  \tTraining accuracy: 0.777325451374054\n",
      "Step: 4600  \tValid loss: 0.5613666772842407\n",
      "Step: 4700  \tTraining loss: 0.43413105607032776\n",
      "Step: 4700  \tTraining accuracy: 0.7774320840835571\n",
      "Step: 4700  \tValid loss: 0.561303436756134\n",
      "Step: 4800  \tTraining loss: 0.4339637756347656\n",
      "Step: 4800  \tTraining accuracy: 0.7775484919548035\n",
      "Step: 4800  \tValid loss: 0.5609816908836365\n",
      "Step: 4900  \tTraining loss: 0.4337974190711975\n",
      "Step: 4900  \tTraining accuracy: 0.777660071849823\n",
      "Step: 4900  \tValid loss: 0.5607778429985046\n",
      "Step: 5000  \tTraining loss: 0.4336323142051697\n",
      "Step: 5000  \tTraining accuracy: 0.7777671813964844\n",
      "Step: 5000  \tValid loss: 0.5604161620140076\n",
      "Step: 5100  \tTraining loss: 0.4334688186645508\n",
      "Step: 5100  \tTraining accuracy: 0.7778699994087219\n",
      "Step: 5100  \tValid loss: 0.5601834058761597\n",
      "Step: 5200  \tTraining loss: 0.4333053231239319\n",
      "Step: 5200  \tTraining accuracy: 0.7779688239097595\n",
      "Step: 5200  \tValid loss: 0.5599516034126282\n",
      "Step: 5300  \tTraining loss: 0.43314093351364136\n",
      "Step: 5300  \tTraining accuracy: 0.7780638933181763\n",
      "Step: 5300  \tValid loss: 0.5596706867218018\n",
      "Step: 5400  \tTraining loss: 0.43297526240348816\n",
      "Step: 5400  \tTraining accuracy: 0.7781554460525513\n",
      "Step: 5400  \tValid loss: 0.5594672560691833\n",
      "Step: 5500  \tTraining loss: 0.4328075051307678\n",
      "Step: 5500  \tTraining accuracy: 0.7782436013221741\n",
      "Step: 5500  \tValid loss: 0.5592190027236938\n",
      "Step: 5600  \tTraining loss: 0.43263787031173706\n",
      "Step: 5600  \tTraining accuracy: 0.7783285975456238\n",
      "Step: 5600  \tValid loss: 0.558999240398407\n",
      "Step: 5700  \tTraining loss: 0.43246588110923767\n",
      "Step: 5700  \tTraining accuracy: 0.7784106135368347\n",
      "Step: 5700  \tValid loss: 0.5588250756263733\n",
      "Step: 5800  \tTraining loss: 0.4322914481163025\n",
      "Step: 5800  \tTraining accuracy: 0.7784897089004517\n",
      "Step: 5800  \tValid loss: 0.5586021542549133\n",
      "Step: 5900  \tTraining loss: 0.4321146309375763\n",
      "Step: 5900  \tTraining accuracy: 0.7785661220550537\n",
      "Step: 5900  \tValid loss: 0.5584273338317871\n",
      "Step: 6000  \tTraining loss: 0.43193483352661133\n",
      "Step: 6000  \tTraining accuracy: 0.7786400318145752\n",
      "Step: 6000  \tValid loss: 0.5582684278488159\n",
      "Step: 6100  \tTraining loss: 0.43175116181373596\n",
      "Step: 6100  \tTraining accuracy: 0.7787114381790161\n",
      "Step: 6100  \tValid loss: 0.5581253170967102\n",
      "Step: 6200  \tTraining loss: 0.4315624237060547\n",
      "Step: 6200  \tTraining accuracy: 0.7787805199623108\n",
      "Step: 6200  \tValid loss: 0.5579675436019897\n",
      "Step: 6300  \tTraining loss: 0.43136724829673767\n",
      "Step: 6300  \tTraining accuracy: 0.7788473963737488\n",
      "Step: 6300  \tValid loss: 0.557858407497406\n",
      "Step: 6400  \tTraining loss: 0.43116724491119385\n",
      "Step: 6400  \tTraining accuracy: 0.7789121866226196\n",
      "Step: 6400  \tValid loss: 0.5578030943870544\n",
      "Step: 6500  \tTraining loss: 0.43096402287483215\n",
      "Step: 6500  \tTraining accuracy: 0.7789644598960876\n",
      "Step: 6500  \tValid loss: 0.5577767491340637\n",
      "Step: 6600  \tTraining loss: 0.4307651221752167\n",
      "Step: 6600  \tTraining accuracy: 0.7790151834487915\n",
      "Step: 6600  \tValid loss: 0.5577412247657776\n",
      "Step: 6700  \tTraining loss: 0.43057623505592346\n",
      "Step: 6700  \tTraining accuracy: 0.7790643572807312\n",
      "Step: 6700  \tValid loss: 0.5577801465988159\n",
      "Step: 6800  \tTraining loss: 0.43039944767951965\n",
      "Step: 6800  \tTraining accuracy: 0.7791120409965515\n",
      "Step: 6800  \tValid loss: 0.5578590631484985\n",
      "Step: 6900  \tTraining loss: 0.4302343428134918\n",
      "Step: 6900  \tTraining accuracy: 0.779158353805542\n",
      "Step: 6900  \tValid loss: 0.5579172372817993\n",
      "Step: 7000  \tTraining loss: 0.430078387260437\n",
      "Step: 7000  \tTraining accuracy: 0.7792033553123474\n",
      "Step: 7000  \tValid loss: 0.5579537749290466\n",
      "Step: 7100  \tTraining loss: 0.42993035912513733\n",
      "Step: 7100  \tTraining accuracy: 0.7792470455169678\n",
      "Step: 7100  \tValid loss: 0.5579912662506104\n",
      "Step: 7200  \tTraining loss: 0.4297902584075928\n",
      "Step: 7200  \tTraining accuracy: 0.7792895436286926\n",
      "Step: 7200  \tValid loss: 0.5579965710639954\n",
      "Step: 7300  \tTraining loss: 0.4296562969684601\n",
      "Step: 7300  \tTraining accuracy: 0.779330849647522\n",
      "Step: 7300  \tValid loss: 0.5579981207847595\n",
      "Step: 7400  \tTraining loss: 0.42952749133110046\n",
      "Step: 7400  \tTraining accuracy: 0.7793710231781006\n",
      "Step: 7400  \tValid loss: 0.5579689741134644\n",
      "Step: 7500  \tTraining loss: 0.42940354347229004\n",
      "Step: 7500  \tTraining accuracy: 0.779410183429718\n",
      "Step: 7500  \tValid loss: 0.5579158663749695\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7794572\n",
      "Precision: 0.82881004\n",
      "Recall: 0.8802661\n",
      "F1 score: 0.8029247\n",
      "AUC: 0.8048195\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.779457    0.82881  0.880266  0.802925  0.80482  0.429335      0.779184   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.557673       0.779362   0.546511      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  7556.0  \n",
      "10\n",
      "(957, 4)\n",
      "(957, 1)\n",
      "(528, 4)\n",
      "(528, 1)\n",
      "(429, 4)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6355557441711426\n",
      "Step: 100  \tTraining accuracy: 0.6321839094161987\n",
      "Step: 100  \tValid loss: 0.6480299234390259\n",
      "Step: 200  \tTraining loss: 0.5807902812957764\n",
      "Step: 200  \tTraining accuracy: 0.6394984126091003\n",
      "Step: 200  \tValid loss: 0.5872403979301453\n",
      "Step: 300  \tTraining loss: 0.518052875995636\n",
      "Step: 300  \tTraining accuracy: 0.6748171448707581\n",
      "Step: 300  \tValid loss: 0.5122804641723633\n",
      "Step: 400  \tTraining loss: 0.47361087799072266\n",
      "Step: 400  \tTraining accuracy: 0.701597273349762\n",
      "Step: 400  \tValid loss: 0.4548247754573822\n",
      "Step: 500  \tTraining loss: 0.45064499974250793\n",
      "Step: 500  \tTraining accuracy: 0.7208870053291321\n",
      "Step: 500  \tValid loss: 0.42180442810058594\n",
      "Step: 600  \tTraining loss: 0.4402829110622406\n",
      "Step: 600  \tTraining accuracy: 0.734302282333374\n",
      "Step: 600  \tValid loss: 0.40457525849342346\n",
      "Step: 700  \tTraining loss: 0.4357234239578247\n",
      "Step: 700  \tTraining accuracy: 0.744473934173584\n",
      "Step: 700  \tValid loss: 0.39555981755256653\n",
      "Step: 800  \tTraining loss: 0.4335947632789612\n",
      "Step: 800  \tTraining accuracy: 0.7525600790977478\n",
      "Step: 800  \tValid loss: 0.39063388109207153\n",
      "Step: 900  \tTraining loss: 0.4324350953102112\n",
      "Step: 900  \tTraining accuracy: 0.7587436437606812\n",
      "Step: 900  \tValid loss: 0.38777750730514526\n",
      "Step: 1000  \tTraining loss: 0.4316365122795105\n",
      "Step: 1000  \tTraining accuracy: 0.7638453245162964\n",
      "Step: 1000  \tValid loss: 0.3860047459602356\n",
      "Step: 1100  \tTraining loss: 0.4309512972831726\n",
      "Step: 1100  \tTraining accuracy: 0.7680748105049133\n",
      "Step: 1100  \tValid loss: 0.3848256468772888\n",
      "Step: 1200  \tTraining loss: 0.43028560280799866\n",
      "Step: 1200  \tTraining accuracy: 0.771568775177002\n",
      "Step: 1200  \tValid loss: 0.38398194313049316\n",
      "Step: 1300  \tTraining loss: 0.4296121597290039\n",
      "Step: 1300  \tTraining accuracy: 0.7748380303382874\n",
      "Step: 1300  \tValid loss: 0.38333654403686523\n",
      "Step: 1400  \tTraining loss: 0.42893508076667786\n",
      "Step: 1400  \tTraining accuracy: 0.7775842547416687\n",
      "Step: 1400  \tValid loss: 0.3828129470348358\n",
      "Step: 1500  \tTraining loss: 0.4282674193382263\n",
      "Step: 1500  \tTraining accuracy: 0.7800237536430359\n",
      "Step: 1500  \tValid loss: 0.382368803024292\n",
      "Step: 1600  \tTraining loss: 0.4276246130466461\n",
      "Step: 1600  \tTraining accuracy: 0.7821148037910461\n",
      "Step: 1600  \tValid loss: 0.3819811940193176\n",
      "Step: 1700  \tTraining loss: 0.4270164370536804\n",
      "Step: 1700  \tTraining accuracy: 0.7839523553848267\n",
      "Step: 1700  \tValid loss: 0.38163596391677856\n",
      "Step: 1800  \tTraining loss: 0.4264480173587799\n",
      "Step: 1800  \tTraining accuracy: 0.7855799198150635\n",
      "Step: 1800  \tValid loss: 0.38132619857788086\n",
      "Step: 1900  \tTraining loss: 0.42592117190361023\n",
      "Step: 1900  \tTraining accuracy: 0.7870597839355469\n",
      "Step: 1900  \tValid loss: 0.38104644417762756\n",
      "Step: 2000  \tTraining loss: 0.425432950258255\n",
      "Step: 2000  \tTraining accuracy: 0.7883878350257874\n",
      "Step: 2000  \tValid loss: 0.38078826665878296\n",
      "Step: 2100  \tTraining loss: 0.42497992515563965\n",
      "Step: 2100  \tTraining accuracy: 0.7896373271942139\n",
      "Step: 2100  \tValid loss: 0.38054990768432617\n",
      "Step: 2200  \tTraining loss: 0.42455706000328064\n",
      "Step: 2200  \tTraining accuracy: 0.7908191680908203\n",
      "Step: 2200  \tValid loss: 0.38032594323158264\n",
      "Step: 2300  \tTraining loss: 0.4241606593132019\n",
      "Step: 2300  \tTraining accuracy: 0.7918727397918701\n",
      "Step: 2300  \tValid loss: 0.3801172971725464\n",
      "Step: 2400  \tTraining loss: 0.4237879812717438\n",
      "Step: 2400  \tTraining accuracy: 0.792858898639679\n",
      "Step: 2400  \tValid loss: 0.379923552274704\n",
      "Step: 2500  \tTraining loss: 0.4234374463558197\n",
      "Step: 2500  \tTraining accuracy: 0.7938498258590698\n",
      "Step: 2500  \tValid loss: 0.3797438144683838\n",
      "Step: 2600  \tTraining loss: 0.42310744524002075\n",
      "Step: 2600  \tTraining accuracy: 0.7947220802307129\n",
      "Step: 2600  \tValid loss: 0.37957727909088135\n",
      "Step: 2700  \tTraining loss: 0.4227970540523529\n",
      "Step: 2700  \tTraining accuracy: 0.7955482006072998\n",
      "Step: 2700  \tValid loss: 0.37942278385162354\n",
      "Step: 2800  \tTraining loss: 0.42250511050224304\n",
      "Step: 2800  \tTraining accuracy: 0.7963332533836365\n",
      "Step: 2800  \tValid loss: 0.37927961349487305\n",
      "Step: 2900  \tTraining loss: 0.42223066091537476\n",
      "Step: 2900  \tTraining accuracy: 0.7970998287200928\n",
      "Step: 2900  \tValid loss: 0.3791470527648926\n",
      "Step: 3000  \tTraining loss: 0.42197251319885254\n",
      "Step: 3000  \tTraining accuracy: 0.7978144884109497\n",
      "Step: 3000  \tValid loss: 0.37902411818504333\n",
      "Step: 3100  \tTraining loss: 0.42172887921333313\n",
      "Step: 3100  \tTraining accuracy: 0.798430860042572\n",
      "Step: 3100  \tValid loss: 0.3789101839065552\n",
      "Step: 3200  \tTraining loss: 0.4214988946914673\n",
      "Step: 3200  \tTraining accuracy: 0.7989915609359741\n",
      "Step: 3200  \tValid loss: 0.3788042962551117\n",
      "Step: 3300  \tTraining loss: 0.42128074169158936\n",
      "Step: 3300  \tTraining accuracy: 0.7995337843894958\n",
      "Step: 3300  \tValid loss: 0.3787059187889099\n",
      "Step: 3400  \tTraining loss: 0.42107322812080383\n",
      "Step: 3400  \tTraining accuracy: 0.8000436425209045\n",
      "Step: 3400  \tValid loss: 0.37861448526382446\n",
      "Step: 3500  \tTraining loss: 0.42087456583976746\n",
      "Step: 3500  \tTraining accuracy: 0.8005088567733765\n",
      "Step: 3500  \tValid loss: 0.3785293400287628\n",
      "Step: 3600  \tTraining loss: 0.4206835925579071\n",
      "Step: 3600  \tTraining accuracy: 0.8009477853775024\n",
      "Step: 3600  \tValid loss: 0.37845006585121155\n",
      "Step: 3700  \tTraining loss: 0.42049893736839294\n",
      "Step: 3700  \tTraining accuracy: 0.801405668258667\n",
      "Step: 3700  \tValid loss: 0.37837666273117065\n",
      "Step: 3800  \tTraining loss: 0.42031949758529663\n",
      "Step: 3800  \tTraining accuracy: 0.8018669486045837\n",
      "Step: 3800  \tValid loss: 0.3783068060874939\n",
      "Step: 3900  \tTraining loss: 0.42014366388320923\n",
      "Step: 3900  \tTraining accuracy: 0.8022635579109192\n",
      "Step: 3900  \tValid loss: 0.3782408535480499\n",
      "Step: 4000  \tTraining loss: 0.41997066140174866\n",
      "Step: 4000  \tTraining accuracy: 0.80262690782547\n",
      "Step: 4000  \tValid loss: 0.378179132938385\n",
      "Step: 4100  \tTraining loss: 0.4197995364665985\n",
      "Step: 4100  \tTraining accuracy: 0.8029722571372986\n",
      "Step: 4100  \tValid loss: 0.3781193196773529\n",
      "Step: 4200  \tTraining loss: 0.41962936520576477\n",
      "Step: 4200  \tTraining accuracy: 0.8032884001731873\n",
      "Step: 4200  \tValid loss: 0.3780629634857178\n",
      "Step: 4300  \tTraining loss: 0.4194590747356415\n",
      "Step: 4300  \tTraining accuracy: 0.8035896420478821\n",
      "Step: 4300  \tValid loss: 0.3780074119567871\n",
      "Step: 4400  \tTraining loss: 0.41928818821907043\n",
      "Step: 4400  \tTraining accuracy: 0.8038890957832336\n",
      "Step: 4400  \tValid loss: 0.3779523968696594\n",
      "Step: 4500  \tTraining loss: 0.41911572217941284\n",
      "Step: 4500  \tTraining accuracy: 0.8041750192642212\n",
      "Step: 4500  \tValid loss: 0.3778981864452362\n",
      "Step: 4600  \tTraining loss: 0.418941468000412\n",
      "Step: 4600  \tTraining accuracy: 0.8044484257698059\n",
      "Step: 4600  \tValid loss: 0.3778446614742279\n",
      "Step: 4700  \tTraining loss: 0.4187646806240082\n",
      "Step: 4700  \tTraining accuracy: 0.8047212958335876\n",
      "Step: 4700  \tValid loss: 0.37779131531715393\n",
      "Step: 4800  \tTraining loss: 0.4185851514339447\n",
      "Step: 4800  \tTraining accuracy: 0.8049716949462891\n",
      "Step: 4800  \tValid loss: 0.3777380585670471\n",
      "Step: 4900  \tTraining loss: 0.4184029996395111\n",
      "Step: 4900  \tTraining accuracy: 0.8052225112915039\n",
      "Step: 4900  \tValid loss: 0.3776847720146179\n",
      "Step: 5000  \tTraining loss: 0.41821783781051636\n",
      "Step: 5000  \tTraining accuracy: 0.8054526448249817\n",
      "Step: 5000  \tValid loss: 0.37763121724128723\n",
      "Step: 5100  \tTraining loss: 0.4180298149585724\n",
      "Step: 5100  \tTraining accuracy: 0.8056633472442627\n",
      "Step: 5100  \tValid loss: 0.3775777816772461\n",
      "Step: 5200  \tTraining loss: 0.41783881187438965\n",
      "Step: 5200  \tTraining accuracy: 0.8058658242225647\n",
      "Step: 5200  \tValid loss: 0.3775242269039154\n",
      "Step: 5300  \tTraining loss: 0.41764509677886963\n",
      "Step: 5300  \tTraining accuracy: 0.8060606122016907\n",
      "Step: 5300  \tValid loss: 0.3774707019329071\n",
      "Step: 5400  \tTraining loss: 0.41744863986968994\n",
      "Step: 5400  \tTraining accuracy: 0.8062773942947388\n",
      "Step: 5400  \tValid loss: 0.37741783261299133\n",
      "Step: 5500  \tTraining loss: 0.41725000739097595\n",
      "Step: 5500  \tTraining accuracy: 0.8064862489700317\n",
      "Step: 5500  \tValid loss: 0.37736520171165466\n",
      "Step: 5600  \tTraining loss: 0.417048841714859\n",
      "Step: 5600  \tTraining accuracy: 0.806687593460083\n",
      "Step: 5600  \tValid loss: 0.37731343507766724\n",
      "Step: 5700  \tTraining loss: 0.4168458878993988\n",
      "Step: 5700  \tTraining accuracy: 0.8068724870681763\n",
      "Step: 5700  \tValid loss: 0.3772624433040619\n",
      "Step: 5800  \tTraining loss: 0.4166412055492401\n",
      "Step: 5800  \tTraining accuracy: 0.8070510029792786\n",
      "Step: 5800  \tValid loss: 0.37721171975135803\n",
      "Step: 5900  \tTraining loss: 0.4164348840713501\n",
      "Step: 5900  \tTraining accuracy: 0.8072234392166138\n",
      "Step: 5900  \tValid loss: 0.377163290977478\n",
      "Step: 6000  \tTraining loss: 0.4162272810935974\n",
      "Step: 6000  \tTraining accuracy: 0.807390034198761\n",
      "Step: 6000  \tValid loss: 0.37711626291275024\n",
      "Step: 6100  \tTraining loss: 0.4160182476043701\n",
      "Step: 6100  \tTraining accuracy: 0.8075597882270813\n",
      "Step: 6100  \tValid loss: 0.37707090377807617\n",
      "Step: 6200  \tTraining loss: 0.41580820083618164\n",
      "Step: 6200  \tTraining accuracy: 0.8077325224876404\n",
      "Step: 6200  \tValid loss: 0.3770272433757782\n",
      "Step: 6300  \tTraining loss: 0.41559696197509766\n",
      "Step: 6300  \tTraining accuracy: 0.807891309261322\n",
      "Step: 6300  \tValid loss: 0.3769853711128235\n",
      "Step: 6400  \tTraining loss: 0.415384978055954\n",
      "Step: 6400  \tTraining accuracy: 0.8080615997314453\n",
      "Step: 6400  \tValid loss: 0.3769453465938568\n",
      "Step: 6500  \tTraining loss: 0.4151722192764282\n",
      "Step: 6500  \tTraining accuracy: 0.8082265853881836\n",
      "Step: 6500  \tValid loss: 0.37690696120262146\n",
      "Step: 6600  \tTraining loss: 0.4149586260318756\n",
      "Step: 6600  \tTraining accuracy: 0.8083706498146057\n",
      "Step: 6600  \tValid loss: 0.3768703043460846\n",
      "Step: 6700  \tTraining loss: 0.4147442579269409\n",
      "Step: 6700  \tTraining accuracy: 0.8085024356842041\n",
      "Step: 6700  \tValid loss: 0.37683340907096863\n",
      "Step: 6800  \tTraining loss: 0.4145292341709137\n",
      "Step: 6800  \tTraining accuracy: 0.8086303472518921\n",
      "Step: 6800  \tValid loss: 0.37679919600486755\n",
      "Step: 6900  \tTraining loss: 0.41431352496147156\n",
      "Step: 6900  \tTraining accuracy: 0.8087621927261353\n",
      "Step: 6900  \tValid loss: 0.37676650285720825\n",
      "Step: 7000  \tTraining loss: 0.4140971302986145\n",
      "Step: 7000  \tTraining accuracy: 0.8088826537132263\n",
      "Step: 7000  \tValid loss: 0.3767348527908325\n",
      "Step: 7100  \tTraining loss: 0.4138796925544739\n",
      "Step: 7100  \tTraining accuracy: 0.8090294003486633\n",
      "Step: 7100  \tValid loss: 0.37670376896858215\n",
      "Step: 7200  \tTraining loss: 0.41366156935691833\n",
      "Step: 7200  \tTraining accuracy: 0.8091720342636108\n",
      "Step: 7200  \tValid loss: 0.37667274475097656\n",
      "Step: 7300  \tTraining loss: 0.4134426414966583\n",
      "Step: 7300  \tTraining accuracy: 0.8092963099479675\n",
      "Step: 7300  \tValid loss: 0.376641184091568\n",
      "Step: 7400  \tTraining loss: 0.413222998380661\n",
      "Step: 7400  \tTraining accuracy: 0.8094242811203003\n",
      "Step: 7400  \tValid loss: 0.3766110837459564\n",
      "Step: 7500  \tTraining loss: 0.413002610206604\n",
      "Step: 7500  \tTraining accuracy: 0.8095488548278809\n",
      "Step: 7500  \tValid loss: 0.3765772581100464\n",
      "Step: 7600  \tTraining loss: 0.41278108954429626\n",
      "Step: 7600  \tTraining accuracy: 0.8096631765365601\n",
      "Step: 7600  \tValid loss: 0.3765401542186737\n",
      "Step: 7700  \tTraining loss: 0.41255897283554077\n",
      "Step: 7700  \tTraining accuracy: 0.8097813725471497\n",
      "Step: 7700  \tValid loss: 0.3764995336532593\n",
      "Step: 7800  \tTraining loss: 0.4123360812664032\n",
      "Step: 7800  \tTraining accuracy: 0.8098965287208557\n",
      "Step: 7800  \tValid loss: 0.3764542043209076\n",
      "Step: 7900  \tTraining loss: 0.4121127128601074\n",
      "Step: 7900  \tTraining accuracy: 0.8100020885467529\n",
      "Step: 7900  \tValid loss: 0.37640368938446045\n",
      "Step: 8000  \tTraining loss: 0.4118889272212982\n",
      "Step: 8000  \tTraining accuracy: 0.81009840965271\n",
      "Step: 8000  \tValid loss: 0.37634745240211487\n",
      "Step: 8100  \tTraining loss: 0.41166529059410095\n",
      "Step: 8100  \tTraining accuracy: 0.8101987838745117\n",
      "Step: 8100  \tValid loss: 0.3762848973274231\n",
      "Step: 8200  \tTraining loss: 0.4114421606063843\n",
      "Step: 8200  \tTraining accuracy: 0.8102903366088867\n",
      "Step: 8200  \tValid loss: 0.37621572613716125\n",
      "Step: 8300  \tTraining loss: 0.411219984292984\n",
      "Step: 8300  \tTraining accuracy: 0.8103733062744141\n",
      "Step: 8300  \tValid loss: 0.37614238262176514\n",
      "Step: 8400  \tTraining loss: 0.41099971532821655\n",
      "Step: 8400  \tTraining accuracy: 0.8104605674743652\n",
      "Step: 8400  \tValid loss: 0.37606167793273926\n",
      "Step: 8500  \tTraining loss: 0.41078150272369385\n",
      "Step: 8500  \tTraining accuracy: 0.8105334043502808\n",
      "Step: 8500  \tValid loss: 0.3759748339653015\n",
      "Step: 8600  \tTraining loss: 0.4105660915374756\n",
      "Step: 8600  \tTraining accuracy: 0.8106045126914978\n",
      "Step: 8600  \tValid loss: 0.37588322162628174\n",
      "Step: 8700  \tTraining loss: 0.41035398840904236\n",
      "Step: 8700  \tTraining accuracy: 0.8106740117073059\n",
      "Step: 8700  \tValid loss: 0.37578827142715454\n",
      "Step: 8800  \tTraining loss: 0.41014525294303894\n",
      "Step: 8800  \tTraining accuracy: 0.8107419013977051\n",
      "Step: 8800  \tValid loss: 0.37569084763526917\n",
      "Step: 8900  \tTraining loss: 0.4099406599998474\n",
      "Step: 8900  \tTraining accuracy: 0.8108082413673401\n",
      "Step: 8900  \tValid loss: 0.3755919635295868\n",
      "Step: 9000  \tTraining loss: 0.4097399413585663\n",
      "Step: 9000  \tTraining accuracy: 0.8108789920806885\n",
      "Step: 9000  \tValid loss: 0.37549325823783875\n",
      "Step: 9100  \tTraining loss: 0.40954387187957764\n",
      "Step: 9100  \tTraining accuracy: 0.8109481334686279\n",
      "Step: 9100  \tValid loss: 0.3753955066204071\n",
      "Step: 9200  \tTraining loss: 0.4093518555164337\n",
      "Step: 9200  \tTraining accuracy: 0.8110214471817017\n",
      "Step: 9200  \tValid loss: 0.3752998113632202\n",
      "Step: 9300  \tTraining loss: 0.40916427969932556\n",
      "Step: 9300  \tTraining accuracy: 0.8111101984977722\n",
      "Step: 9300  \tValid loss: 0.3752073645591736\n",
      "Step: 9400  \tTraining loss: 0.40898096561431885\n",
      "Step: 9400  \tTraining accuracy: 0.8111969828605652\n",
      "Step: 9400  \tValid loss: 0.37511876225471497\n",
      "Step: 9500  \tTraining loss: 0.4088019132614136\n",
      "Step: 9500  \tTraining accuracy: 0.8112764358520508\n",
      "Step: 9500  \tValid loss: 0.3750343322753906\n",
      "Step: 9600  \tTraining loss: 0.4086267948150635\n",
      "Step: 9600  \tTraining accuracy: 0.8113542199134827\n",
      "Step: 9600  \tValid loss: 0.37495455145835876\n",
      "Step: 9700  \tTraining loss: 0.4084559381008148\n",
      "Step: 9700  \tTraining accuracy: 0.8114303946495056\n",
      "Step: 9700  \tValid loss: 0.3748798966407776\n",
      "Step: 9800  \tTraining loss: 0.40828850865364075\n",
      "Step: 9800  \tTraining accuracy: 0.8115049600601196\n",
      "Step: 9800  \tValid loss: 0.37481024861335754\n",
      "Step: 9900  \tTraining loss: 0.4081249237060547\n",
      "Step: 9900  \tTraining accuracy: 0.8115780353546143\n",
      "Step: 9900  \tValid loss: 0.37474584579467773\n",
      "Step: 10000  \tTraining loss: 0.4079650938510895\n",
      "Step: 10000  \tTraining accuracy: 0.811644434928894\n",
      "Step: 10000  \tValid loss: 0.37468621134757996\n",
      "Step: 10100  \tTraining loss: 0.407808780670166\n",
      "Step: 10100  \tTraining accuracy: 0.811709463596344\n",
      "Step: 10100  \tValid loss: 0.3746317923069\n",
      "Step: 10200  \tTraining loss: 0.40765565633773804\n",
      "Step: 10200  \tTraining accuracy: 0.8117732405662537\n",
      "Step: 10200  \tValid loss: 0.3745822608470917\n",
      "Step: 10300  \tTraining loss: 0.4075060486793518\n",
      "Step: 10300  \tTraining accuracy: 0.811835765838623\n",
      "Step: 10300  \tValid loss: 0.37453708052635193\n",
      "Step: 10400  \tTraining loss: 0.4073595702648163\n",
      "Step: 10400  \tTraining accuracy: 0.8118970990180969\n",
      "Step: 10400  \tValid loss: 0.374496728181839\n",
      "Step: 10500  \tTraining loss: 0.40721607208251953\n",
      "Step: 10500  \tTraining accuracy: 0.8119572401046753\n",
      "Step: 10500  \tValid loss: 0.3744606375694275\n",
      "Step: 10600  \tTraining loss: 0.40707576274871826\n",
      "Step: 10600  \tTraining accuracy: 0.8120162487030029\n",
      "Step: 10600  \tValid loss: 0.37442880868911743\n",
      "Step: 10700  \tTraining loss: 0.40693849325180054\n",
      "Step: 10700  \tTraining accuracy: 0.8120790123939514\n",
      "Step: 10700  \tValid loss: 0.37440094351768494\n",
      "Step: 10800  \tTraining loss: 0.40680384635925293\n",
      "Step: 10800  \tTraining accuracy: 0.8121503591537476\n",
      "Step: 10800  \tValid loss: 0.37437692284584045\n",
      "Step: 10900  \tTraining loss: 0.40667229890823364\n",
      "Step: 10900  \tTraining accuracy: 0.8122155666351318\n",
      "Step: 10900  \tValid loss: 0.3743564486503601\n",
      "Step: 11000  \tTraining loss: 0.4065433144569397\n",
      "Step: 11000  \tTraining accuracy: 0.8122748732566833\n",
      "Step: 11000  \tValid loss: 0.37433895468711853\n",
      "Step: 11100  \tTraining loss: 0.4064171016216278\n",
      "Step: 11100  \tTraining accuracy: 0.8123330473899841\n",
      "Step: 11100  \tValid loss: 0.3743249773979187\n",
      "Step: 11200  \tTraining loss: 0.4062933325767517\n",
      "Step: 11200  \tTraining accuracy: 0.812390148639679\n",
      "Step: 11200  \tValid loss: 0.3743140399456024\n",
      "Step: 11300  \tTraining loss: 0.4061722755432129\n",
      "Step: 11300  \tTraining accuracy: 0.8124462962150574\n",
      "Step: 11300  \tValid loss: 0.3743060827255249\n",
      "Step: 11400  \tTraining loss: 0.4060536324977875\n",
      "Step: 11400  \tTraining accuracy: 0.8125060200691223\n",
      "Step: 11400  \tValid loss: 0.37430092692375183\n",
      "Step: 11500  \tTraining loss: 0.40593740344047546\n",
      "Step: 11500  \tTraining accuracy: 0.8125647306442261\n",
      "Step: 11500  \tValid loss: 0.3742983937263489\n",
      "Step: 11600  \tTraining loss: 0.4058234691619873\n",
      "Step: 11600  \tTraining accuracy: 0.8126224279403687\n",
      "Step: 11600  \tValid loss: 0.3742983043193817\n",
      "Step: 11700  \tTraining loss: 0.4057117998600006\n",
      "Step: 11700  \tTraining accuracy: 0.81267911195755\n",
      "Step: 11700  \tValid loss: 0.3743005096912384\n",
      "Step: 11800  \tTraining loss: 0.40560248494148254\n",
      "Step: 11800  \tTraining accuracy: 0.812734842300415\n",
      "Step: 11800  \tValid loss: 0.37430498003959656\n",
      "Step: 11900  \tTraining loss: 0.4054953157901764\n",
      "Step: 11900  \tTraining accuracy: 0.8127896189689636\n",
      "Step: 11900  \tValid loss: 0.374311625957489\n",
      "Step: 12000  \tTraining loss: 0.4053902328014374\n",
      "Step: 12000  \tTraining accuracy: 0.8128347396850586\n",
      "Step: 12000  \tValid loss: 0.3743201196193695\n",
      "Step: 12100  \tTraining loss: 0.4052874743938446\n",
      "Step: 12100  \tTraining accuracy: 0.8128747940063477\n",
      "Step: 12100  \tValid loss: 0.3743303418159485\n",
      "Step: 12200  \tTraining loss: 0.4051866829395294\n",
      "Step: 12200  \tTraining accuracy: 0.8129141330718994\n",
      "Step: 12200  \tValid loss: 0.37434259057044983\n",
      "Step: 12300  \tTraining loss: 0.4050878882408142\n",
      "Step: 12300  \tTraining accuracy: 0.8129528760910034\n",
      "Step: 12300  \tValid loss: 0.3743562698364258\n",
      "Step: 12400  \tTraining loss: 0.40499114990234375\n",
      "Step: 12400  \tTraining accuracy: 0.8129910230636597\n",
      "Step: 12400  \tValid loss: 0.374371737241745\n",
      "Step: 12500  \tTraining loss: 0.40489649772644043\n",
      "Step: 12500  \tTraining accuracy: 0.8130285143852234\n",
      "Step: 12500  \tValid loss: 0.3743884563446045\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8130654\n",
      "Precision: 0.83554816\n",
      "Recall: 0.86130136\n",
      "F1 score: 0.8254053\n",
      "AUC: 0.79794294\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0  0.813065   0.835548  0.861301  0.825405  0.797943  0.40485       0.81307   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.374298       0.813034   0.415361      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  12549.0  \n",
      "11\n",
      "(754, 4)\n",
      "(754, 1)\n",
      "(416, 4)\n",
      "(416, 1)\n",
      "(338, 4)\n",
      "(338, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5633967518806458\n",
      "Step: 100  \tTraining accuracy: 0.7692307829856873\n",
      "Step: 100  \tValid loss: 0.5426212549209595\n",
      "Step: 200  \tTraining loss: 0.4435771703720093\n",
      "Step: 200  \tTraining accuracy: 0.7873563170433044\n",
      "Step: 200  \tValid loss: 0.4332212209701538\n",
      "Step: 300  \tTraining loss: 0.38616877794265747\n",
      "Step: 300  \tTraining accuracy: 0.7997347712516785\n",
      "Step: 300  \tValid loss: 0.3826780319213867\n",
      "Step: 400  \tTraining loss: 0.3739146888256073\n",
      "Step: 400  \tTraining accuracy: 0.8052292466163635\n",
      "Step: 400  \tValid loss: 0.3724091649055481\n",
      "Step: 500  \tTraining loss: 0.36871394515037537\n",
      "Step: 500  \tTraining accuracy: 0.8078396916389465\n",
      "Step: 500  \tValid loss: 0.36802834272384644\n",
      "Step: 600  \tTraining loss: 0.3652854561805725\n",
      "Step: 600  \tTraining accuracy: 0.8096213936805725\n",
      "Step: 600  \tValid loss: 0.3648099899291992\n",
      "Step: 700  \tTraining loss: 0.36256909370422363\n",
      "Step: 700  \tTraining accuracy: 0.8105488419532776\n",
      "Step: 700  \tValid loss: 0.36197221279144287\n",
      "Step: 800  \tTraining loss: 0.360249400138855\n",
      "Step: 800  \tTraining accuracy: 0.8111405968666077\n",
      "Step: 800  \tValid loss: 0.3593806028366089\n",
      "Step: 900  \tTraining loss: 0.3581840395927429\n",
      "Step: 900  \tTraining accuracy: 0.8115930557250977\n",
      "Step: 900  \tValid loss: 0.3570043444633484\n",
      "Step: 1000  \tTraining loss: 0.3563356399536133\n",
      "Step: 1000  \tTraining accuracy: 0.8120201230049133\n",
      "Step: 1000  \tValid loss: 0.35482266545295715\n",
      "Step: 1100  \tTraining loss: 0.35464411973953247\n",
      "Step: 1100  \tTraining accuracy: 0.8124289512634277\n",
      "Step: 1100  \tValid loss: 0.3528141975402832\n",
      "Step: 1200  \tTraining loss: 0.3530734181404114\n",
      "Step: 1200  \tTraining accuracy: 0.8127666711807251\n",
      "Step: 1200  \tValid loss: 0.35095757246017456\n",
      "Step: 1300  \tTraining loss: 0.35158321261405945\n",
      "Step: 1300  \tTraining accuracy: 0.813103437423706\n",
      "Step: 1300  \tValid loss: 0.34922754764556885\n",
      "Step: 1400  \tTraining loss: 0.3499883711338043\n",
      "Step: 1400  \tTraining accuracy: 0.8134394288063049\n",
      "Step: 1400  \tValid loss: 0.34747597575187683\n",
      "Step: 1500  \tTraining loss: 0.3478359580039978\n",
      "Step: 1500  \tTraining accuracy: 0.8138205409049988\n",
      "Step: 1500  \tValid loss: 0.3452235758304596\n",
      "Step: 1600  \tTraining loss: 0.34525904059410095\n",
      "Step: 1600  \tTraining accuracy: 0.8139813542366028\n",
      "Step: 1600  \tValid loss: 0.3421681821346283\n",
      "Step: 1700  \tTraining loss: 0.34260299801826477\n",
      "Step: 1700  \tTraining accuracy: 0.813881516456604\n",
      "Step: 1700  \tValid loss: 0.3389056324958801\n",
      "Step: 1800  \tTraining loss: 0.3399820029735565\n",
      "Step: 1800  \tTraining accuracy: 0.8138309717178345\n",
      "Step: 1800  \tValid loss: 0.3358544111251831\n",
      "Step: 1900  \tTraining loss: 0.3374268710613251\n",
      "Step: 1900  \tTraining accuracy: 0.8139293193817139\n",
      "Step: 1900  \tValid loss: 0.33303216099739075\n",
      "Step: 2000  \tTraining loss: 0.33497855067253113\n",
      "Step: 2000  \tTraining accuracy: 0.8139835596084595\n",
      "Step: 2000  \tValid loss: 0.330474317073822\n",
      "Step: 2100  \tTraining loss: 0.3326655924320221\n",
      "Step: 2100  \tTraining accuracy: 0.814000129699707\n",
      "Step: 2100  \tValid loss: 0.3282645344734192\n",
      "Step: 2200  \tTraining loss: 0.33054330945014954\n",
      "Step: 2200  \tTraining accuracy: 0.8141694068908691\n",
      "Step: 2200  \tValid loss: 0.3263230323791504\n",
      "Step: 2300  \tTraining loss: 0.328622967004776\n",
      "Step: 2300  \tTraining accuracy: 0.8144709467887878\n",
      "Step: 2300  \tValid loss: 0.3245396912097931\n",
      "Step: 2400  \tTraining loss: 0.32691410183906555\n",
      "Step: 2400  \tTraining accuracy: 0.8147468566894531\n",
      "Step: 2400  \tValid loss: 0.3228782117366791\n",
      "Step: 2500  \tTraining loss: 0.3253861665725708\n",
      "Step: 2500  \tTraining accuracy: 0.8151085376739502\n",
      "Step: 2500  \tValid loss: 0.3213997185230255\n",
      "Step: 2600  \tTraining loss: 0.3240184485912323\n",
      "Step: 2600  \tTraining accuracy: 0.8155718445777893\n",
      "Step: 2600  \tValid loss: 0.3199758231639862\n",
      "Step: 2700  \tTraining loss: 0.32287517189979553\n",
      "Step: 2700  \tTraining accuracy: 0.8160251975059509\n",
      "Step: 2700  \tValid loss: 0.31882843375205994\n",
      "Step: 2800  \tTraining loss: 0.3218866288661957\n",
      "Step: 2800  \tTraining accuracy: 0.8164938688278198\n",
      "Step: 2800  \tValid loss: 0.3178766071796417\n",
      "Step: 2900  \tTraining loss: 0.32101544737815857\n",
      "Step: 2900  \tTraining accuracy: 0.8169761300086975\n",
      "Step: 2900  \tValid loss: 0.3170124888420105\n",
      "Step: 3000  \tTraining loss: 0.3202540874481201\n",
      "Step: 3000  \tTraining accuracy: 0.817403256893158\n",
      "Step: 3000  \tValid loss: 0.3162603974342346\n",
      "Step: 3100  \tTraining loss: 0.3195897936820984\n",
      "Step: 3100  \tTraining accuracy: 0.8177805542945862\n",
      "Step: 3100  \tValid loss: 0.3155960738658905\n",
      "Step: 3200  \tTraining loss: 0.3189869821071625\n",
      "Step: 3200  \tTraining accuracy: 0.81815505027771\n",
      "Step: 3200  \tValid loss: 0.3150346875190735\n",
      "Step: 3300  \tTraining loss: 0.31844398379325867\n",
      "Step: 3300  \tTraining accuracy: 0.8185064196586609\n",
      "Step: 3300  \tValid loss: 0.3145279586315155\n",
      "Step: 3400  \tTraining loss: 0.31794801354408264\n",
      "Step: 3400  \tTraining accuracy: 0.8188566565513611\n",
      "Step: 3400  \tValid loss: 0.3141157031059265\n",
      "Step: 3500  \tTraining loss: 0.31749728322029114\n",
      "Step: 3500  \tTraining accuracy: 0.8191865682601929\n",
      "Step: 3500  \tValid loss: 0.313768595457077\n",
      "Step: 3600  \tTraining loss: 0.31708601117134094\n",
      "Step: 3600  \tTraining accuracy: 0.8194418549537659\n",
      "Step: 3600  \tValid loss: 0.31349337100982666\n",
      "Step: 3700  \tTraining loss: 0.31671375036239624\n",
      "Step: 3700  \tTraining accuracy: 0.8197558522224426\n",
      "Step: 3700  \tValid loss: 0.31330278515815735\n",
      "Step: 3800  \tTraining loss: 0.31638026237487793\n",
      "Step: 3800  \tTraining accuracy: 0.820070743560791\n",
      "Step: 3800  \tValid loss: 0.31315332651138306\n",
      "Step: 3900  \tTraining loss: 0.31607940793037415\n",
      "Step: 3900  \tTraining accuracy: 0.8203520774841309\n",
      "Step: 3900  \tValid loss: 0.313055157661438\n",
      "Step: 4000  \tTraining loss: 0.31580591201782227\n",
      "Step: 4000  \tTraining accuracy: 0.8206023573875427\n",
      "Step: 4000  \tValid loss: 0.3130200505256653\n",
      "Step: 4100  \tTraining loss: 0.3155621290206909\n",
      "Step: 4100  \tTraining accuracy: 0.8208566904067993\n",
      "Step: 4100  \tValid loss: 0.3129652440547943\n",
      "Step: 4200  \tTraining loss: 0.31533944606781006\n",
      "Step: 4200  \tTraining accuracy: 0.8210667371749878\n",
      "Step: 4200  \tValid loss: 0.3129590153694153\n",
      "Step: 4300  \tTraining loss: 0.31514355540275574\n",
      "Step: 4300  \tTraining accuracy: 0.8213293552398682\n",
      "Step: 4300  \tValid loss: 0.31298989057540894\n",
      "Step: 4400  \tTraining loss: 0.31497088074684143\n",
      "Step: 4400  \tTraining accuracy: 0.8215799331665039\n",
      "Step: 4400  \tValid loss: 0.31304991245269775\n",
      "Step: 4500  \tTraining loss: 0.3148181140422821\n",
      "Step: 4500  \tTraining accuracy: 0.8218042850494385\n",
      "Step: 4500  \tValid loss: 0.3131154775619507\n",
      "Step: 4600  \tTraining loss: 0.31468233466148376\n",
      "Step: 4600  \tTraining accuracy: 0.8220625519752502\n",
      "Step: 4600  \tValid loss: 0.31318527460098267\n",
      "Step: 4700  \tTraining loss: 0.31456494331359863\n",
      "Step: 4700  \tTraining accuracy: 0.8222954273223877\n",
      "Step: 4700  \tValid loss: 0.31329411268234253\n",
      "Step: 4800  \tTraining loss: 0.3144553005695343\n",
      "Step: 4800  \tTraining accuracy: 0.822518527507782\n",
      "Step: 4800  \tValid loss: 0.31338417530059814\n",
      "Step: 4900  \tTraining loss: 0.3143610954284668\n",
      "Step: 4900  \tTraining accuracy: 0.8227323889732361\n",
      "Step: 4900  \tValid loss: 0.3135196268558502\n",
      "Step: 5000  \tTraining loss: 0.3142751157283783\n",
      "Step: 5000  \tTraining accuracy: 0.8229510188102722\n",
      "Step: 5000  \tValid loss: 0.31365054845809937\n",
      "Step: 5100  \tTraining loss: 0.3142000138759613\n",
      "Step: 5100  \tTraining accuracy: 0.8231609463691711\n",
      "Step: 5100  \tValid loss: 0.31383514404296875\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.82337564\n",
      "Precision: 0.65\n",
      "Recall: 0.5229885\n",
      "F1 score: 0.7342204\n",
      "AUC: 0.7192529\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.823376       0.65  0.522988   0.73422  0.719253  0.314173       0.82336   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.312944       0.823289   0.298453      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  5137.0  \n",
      "12\n",
      "(754, 4)\n",
      "(754, 1)\n",
      "(400, 4)\n",
      "(400, 1)\n",
      "(325, 4)\n",
      "(325, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.513392984867096\n",
      "Step: 100  \tTraining accuracy: 0.7334217429161072\n",
      "Step: 100  \tValid loss: 0.5418165326118469\n",
      "Step: 200  \tTraining loss: 0.482361763715744\n",
      "Step: 200  \tTraining accuracy: 0.7313031554222107\n",
      "Step: 200  \tValid loss: 0.5157526135444641\n",
      "Step: 300  \tTraining loss: 0.4653097987174988\n",
      "Step: 300  \tTraining accuracy: 0.7308728694915771\n",
      "Step: 300  \tValid loss: 0.5024697780609131\n",
      "Step: 400  \tTraining loss: 0.45876044034957886\n",
      "Step: 400  \tTraining accuracy: 0.7331920862197876\n",
      "Step: 400  \tValid loss: 0.4975299835205078\n",
      "Step: 500  \tTraining loss: 0.44397830963134766\n",
      "Step: 500  \tTraining accuracy: 0.739130437374115\n",
      "Step: 500  \tValid loss: 0.4803806245326996\n",
      "Step: 600  \tTraining loss: 0.4344019293785095\n",
      "Step: 600  \tTraining accuracy: 0.7442631125450134\n",
      "Step: 600  \tValid loss: 0.46983054280281067\n",
      "Step: 700  \tTraining loss: 0.42671725153923035\n",
      "Step: 700  \tTraining accuracy: 0.7498961091041565\n",
      "Step: 700  \tValid loss: 0.4610496759414673\n",
      "Step: 800  \tTraining loss: 0.4203285574913025\n",
      "Step: 800  \tTraining accuracy: 0.7549293041229248\n",
      "Step: 800  \tValid loss: 0.4535750448703766\n",
      "Step: 900  \tTraining loss: 0.4151628613471985\n",
      "Step: 900  \tTraining accuracy: 0.7588590383529663\n",
      "Step: 900  \tValid loss: 0.4471753239631653\n",
      "Step: 1000  \tTraining loss: 0.41116636991500854\n",
      "Step: 1000  \tTraining accuracy: 0.7628154754638672\n",
      "Step: 1000  \tValid loss: 0.44245094060897827\n",
      "Step: 1100  \tTraining loss: 0.40810129046440125\n",
      "Step: 1100  \tTraining accuracy: 0.7662763595581055\n",
      "Step: 1100  \tValid loss: 0.4387381672859192\n",
      "Step: 1200  \tTraining loss: 0.4057248830795288\n",
      "Step: 1200  \tTraining accuracy: 0.7693708539009094\n",
      "Step: 1200  \tValid loss: 0.4358483850955963\n",
      "Step: 1300  \tTraining loss: 0.4038347899913788\n",
      "Step: 1300  \tTraining accuracy: 0.772186815738678\n",
      "Step: 1300  \tValid loss: 0.43362030386924744\n",
      "Step: 1400  \tTraining loss: 0.40197673439979553\n",
      "Step: 1400  \tTraining accuracy: 0.7745358347892761\n",
      "Step: 1400  \tValid loss: 0.4320294260978699\n",
      "Step: 1500  \tTraining loss: 0.4005342721939087\n",
      "Step: 1500  \tTraining accuracy: 0.7766076326370239\n",
      "Step: 1500  \tValid loss: 0.4302947521209717\n",
      "Step: 1600  \tTraining loss: 0.3993500769138336\n",
      "Step: 1600  \tTraining accuracy: 0.778455913066864\n",
      "Step: 1600  \tValid loss: 0.4288577139377594\n",
      "Step: 1700  \tTraining loss: 0.39839938282966614\n",
      "Step: 1700  \tTraining accuracy: 0.780203104019165\n",
      "Step: 1700  \tValid loss: 0.4278002083301544\n",
      "Step: 1800  \tTraining loss: 0.39761510491371155\n",
      "Step: 1800  \tTraining accuracy: 0.781827986240387\n",
      "Step: 1800  \tValid loss: 0.4270358383655548\n",
      "Step: 1900  \tTraining loss: 0.39681777358055115\n",
      "Step: 1900  \tTraining accuracy: 0.7833138704299927\n",
      "Step: 1900  \tValid loss: 0.4264141917228699\n",
      "Step: 2000  \tTraining loss: 0.39619797468185425\n",
      "Step: 2000  \tTraining accuracy: 0.7847166657447815\n",
      "Step: 2000  \tValid loss: 0.42564648389816284\n",
      "Step: 2100  \tTraining loss: 0.3956846296787262\n",
      "Step: 2100  \tTraining accuracy: 0.7859497666358948\n",
      "Step: 2100  \tValid loss: 0.4251834750175476\n",
      "Step: 2200  \tTraining loss: 0.39523983001708984\n",
      "Step: 2200  \tTraining accuracy: 0.7871310710906982\n",
      "Step: 2200  \tValid loss: 0.424801230430603\n",
      "Step: 2300  \tTraining loss: 0.3948473632335663\n",
      "Step: 2300  \tTraining accuracy: 0.7882373929023743\n",
      "Step: 2300  \tValid loss: 0.42452991008758545\n",
      "Step: 2400  \tTraining loss: 0.39449045062065125\n",
      "Step: 2400  \tTraining accuracy: 0.7892496585845947\n",
      "Step: 2400  \tValid loss: 0.42432647943496704\n",
      "Step: 2500  \tTraining loss: 0.3941628932952881\n",
      "Step: 2500  \tTraining accuracy: 0.7901517152786255\n",
      "Step: 2500  \tValid loss: 0.4241856634616852\n",
      "Step: 2600  \tTraining loss: 0.39385735988616943\n",
      "Step: 2600  \tTraining accuracy: 0.7909565567970276\n",
      "Step: 2600  \tValid loss: 0.424101859331131\n",
      "Step: 2700  \tTraining loss: 0.3935650587081909\n",
      "Step: 2700  \tTraining accuracy: 0.7917006611824036\n",
      "Step: 2700  \tValid loss: 0.42406752705574036\n",
      "Step: 2800  \tTraining loss: 0.39327436685562134\n",
      "Step: 2800  \tTraining accuracy: 0.7923907041549683\n",
      "Step: 2800  \tValid loss: 0.4240846335887909\n",
      "Step: 2900  \tTraining loss: 0.3929898142814636\n",
      "Step: 2900  \tTraining accuracy: 0.7930322885513306\n",
      "Step: 2900  \tValid loss: 0.424132376909256\n",
      "Step: 3000  \tTraining loss: 0.39271479845046997\n",
      "Step: 3000  \tTraining accuracy: 0.7936304211616516\n",
      "Step: 3000  \tValid loss: 0.42416250705718994\n",
      "Step: 3100  \tTraining loss: 0.39244431257247925\n",
      "Step: 3100  \tTraining accuracy: 0.7941893339157104\n",
      "Step: 3100  \tValid loss: 0.424234539270401\n",
      "Step: 3200  \tTraining loss: 0.39216187596321106\n",
      "Step: 3200  \tTraining accuracy: 0.7947342395782471\n",
      "Step: 3200  \tValid loss: 0.4244477450847626\n",
      "Step: 3300  \tTraining loss: 0.39181748032569885\n",
      "Step: 3300  \tTraining accuracy: 0.7952456474304199\n",
      "Step: 3300  \tValid loss: 0.4248103201389313\n",
      "Step: 3400  \tTraining loss: 0.39145803451538086\n",
      "Step: 3400  \tTraining accuracy: 0.795726478099823\n",
      "Step: 3400  \tValid loss: 0.42500361800193787\n",
      "Step: 3500  \tTraining loss: 0.39112257957458496\n",
      "Step: 3500  \tTraining accuracy: 0.7961598634719849\n",
      "Step: 3500  \tValid loss: 0.4251652657985687\n",
      "Step: 3600  \tTraining loss: 0.39081236720085144\n",
      "Step: 3600  \tTraining accuracy: 0.7965688705444336\n",
      "Step: 3600  \tValid loss: 0.42536699771881104\n",
      "Step: 3700  \tTraining loss: 0.3905393183231354\n",
      "Step: 3700  \tTraining accuracy: 0.7969369292259216\n",
      "Step: 3700  \tValid loss: 0.4255331754684448\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7972673\n",
      "Precision: 0.8401977\n",
      "Recall: 0.92224234\n",
      "F1 score: 0.8343815\n",
      "AUC: 0.71982765\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.797267   0.840198  0.922242  0.834382  0.719828  0.390489      0.797032   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.424058       0.797121   0.404503      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3719.0  \n",
      "13\n",
      "(957, 4)\n",
      "(957, 1)\n",
      "(528, 4)\n",
      "(528, 1)\n",
      "(429, 4)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6162155270576477\n",
      "Step: 100  \tTraining accuracy: 0.6823406219482422\n",
      "Step: 100  \tValid loss: 0.6519351005554199\n",
      "Step: 200  \tTraining loss: 0.5685313940048218\n",
      "Step: 200  \tTraining accuracy: 0.6729362607002258\n",
      "Step: 200  \tValid loss: 0.6037346720695496\n",
      "Step: 300  \tTraining loss: 0.4859299957752228\n",
      "Step: 300  \tTraining accuracy: 0.6756531000137329\n",
      "Step: 300  \tValid loss: 0.5154200196266174\n",
      "Step: 400  \tTraining loss: 0.4225582778453827\n",
      "Step: 400  \tTraining accuracy: 0.6995074152946472\n",
      "Step: 400  \tValid loss: 0.44724926352500916\n",
      "Step: 500  \tTraining loss: 0.38460391759872437\n",
      "Step: 500  \tTraining accuracy: 0.7288981676101685\n",
      "Step: 500  \tValid loss: 0.40489959716796875\n",
      "Step: 600  \tTraining loss: 0.36301887035369873\n",
      "Step: 600  \tTraining accuracy: 0.7509261965751648\n",
      "Step: 600  \tValid loss: 0.3796926438808441\n",
      "Step: 700  \tTraining loss: 0.350504994392395\n",
      "Step: 700  \tTraining accuracy: 0.7672212719917297\n",
      "Step: 700  \tValid loss: 0.3644043505191803\n",
      "Step: 800  \tTraining loss: 0.34274598956108093\n",
      "Step: 800  \tTraining accuracy: 0.7801463007926941\n",
      "Step: 800  \tValid loss: 0.35424527525901794\n",
      "Step: 900  \tTraining loss: 0.33752813935279846\n",
      "Step: 900  \tTraining accuracy: 0.7898457050323486\n",
      "Step: 900  \tValid loss: 0.3474119305610657\n",
      "Step: 1000  \tTraining loss: 0.3338620960712433\n",
      "Step: 1000  \tTraining accuracy: 0.7976681590080261\n",
      "Step: 1000  \tValid loss: 0.3423120677471161\n",
      "Step: 1100  \tTraining loss: 0.3312321901321411\n",
      "Step: 1100  \tTraining accuracy: 0.8042991757392883\n",
      "Step: 1100  \tValid loss: 0.3386421501636505\n",
      "Step: 1200  \tTraining loss: 0.32928532361984253\n",
      "Step: 1200  \tTraining accuracy: 0.8096860647201538\n",
      "Step: 1200  \tValid loss: 0.33581918478012085\n",
      "Step: 1300  \tTraining loss: 0.3278486728668213\n",
      "Step: 1300  \tTraining accuracy: 0.814294695854187\n",
      "Step: 1300  \tValid loss: 0.3336937129497528\n",
      "Step: 1400  \tTraining loss: 0.3267737627029419\n",
      "Step: 1400  \tTraining accuracy: 0.8182979226112366\n",
      "Step: 1400  \tValid loss: 0.33196136355400085\n",
      "Step: 1500  \tTraining loss: 0.3259441554546356\n",
      "Step: 1500  \tTraining accuracy: 0.8218210935592651\n",
      "Step: 1500  \tValid loss: 0.33067378401756287\n",
      "Step: 1600  \tTraining loss: 0.3252832889556885\n",
      "Step: 1600  \tTraining accuracy: 0.824822187423706\n",
      "Step: 1600  \tValid loss: 0.32963043451309204\n",
      "Step: 1700  \tTraining loss: 0.32472652196884155\n",
      "Step: 1700  \tTraining accuracy: 0.827617883682251\n",
      "Step: 1700  \tValid loss: 0.3288171589374542\n",
      "Step: 1800  \tTraining loss: 0.32429301738739014\n",
      "Step: 1800  \tTraining accuracy: 0.8300641775131226\n",
      "Step: 1800  \tValid loss: 0.3280605673789978\n",
      "Step: 1900  \tTraining loss: 0.32394152879714966\n",
      "Step: 1900  \tTraining accuracy: 0.832217812538147\n",
      "Step: 1900  \tValid loss: 0.3275013566017151\n",
      "Step: 2000  \tTraining loss: 0.323651522397995\n",
      "Step: 2000  \tTraining accuracy: 0.8342041373252869\n",
      "Step: 2000  \tValid loss: 0.3270987570285797\n",
      "Step: 2100  \tTraining loss: 0.32340896129608154\n",
      "Step: 2100  \tTraining accuracy: 0.8359201550483704\n",
      "Step: 2100  \tValid loss: 0.32676512002944946\n",
      "Step: 2200  \tTraining loss: 0.32320716977119446\n",
      "Step: 2200  \tTraining accuracy: 0.8374766111373901\n",
      "Step: 2200  \tValid loss: 0.32651498913764954\n",
      "Step: 2300  \tTraining loss: 0.32303351163864136\n",
      "Step: 2300  \tTraining accuracy: 0.8389179110527039\n",
      "Step: 2300  \tValid loss: 0.3263390362262726\n",
      "Step: 2400  \tTraining loss: 0.3228791654109955\n",
      "Step: 2400  \tTraining accuracy: 0.8402365446090698\n",
      "Step: 2400  \tValid loss: 0.32624351978302\n",
      "Step: 2500  \tTraining loss: 0.3227391541004181\n",
      "Step: 2500  \tTraining accuracy: 0.8414475321769714\n",
      "Step: 2500  \tValid loss: 0.3261946439743042\n",
      "Step: 2600  \tTraining loss: 0.32257938385009766\n",
      "Step: 2600  \tTraining accuracy: 0.8425635695457458\n",
      "Step: 2600  \tValid loss: 0.32615458965301514\n",
      "Step: 2700  \tTraining loss: 0.3224552869796753\n",
      "Step: 2700  \tTraining accuracy: 0.8435953259468079\n",
      "Step: 2700  \tValid loss: 0.3261113166809082\n",
      "Step: 2800  \tTraining loss: 0.3223430812358856\n",
      "Step: 2800  \tTraining accuracy: 0.8445520997047424\n",
      "Step: 2800  \tValid loss: 0.3260938227176666\n",
      "Step: 2900  \tTraining loss: 0.3222423791885376\n",
      "Step: 2900  \tTraining accuracy: 0.8454234004020691\n",
      "Step: 2900  \tValid loss: 0.3260941803455353\n",
      "Step: 3000  \tTraining loss: 0.3221484124660492\n",
      "Step: 3000  \tTraining accuracy: 0.8462355732917786\n",
      "Step: 3000  \tValid loss: 0.3261195123195648\n",
      "Step: 3100  \tTraining loss: 0.3220188021659851\n",
      "Step: 3100  \tTraining accuracy: 0.8469945192337036\n",
      "Step: 3100  \tValid loss: 0.32628095149993896\n",
      "Step: 3200  \tTraining loss: 0.3219279944896698\n",
      "Step: 3200  \tTraining accuracy: 0.8477053046226501\n",
      "Step: 3200  \tValid loss: 0.32624921202659607\n",
      "Step: 3300  \tTraining loss: 0.32184484601020813\n",
      "Step: 3300  \tTraining accuracy: 0.8483401536941528\n",
      "Step: 3300  \tValid loss: 0.3262617588043213\n",
      "Step: 3400  \tTraining loss: 0.3217684030532837\n",
      "Step: 3400  \tTraining accuracy: 0.8489371538162231\n",
      "Step: 3400  \tValid loss: 0.32631030678749084\n",
      "Step: 3500  \tTraining loss: 0.3216989040374756\n",
      "Step: 3500  \tTraining accuracy: 0.8494994640350342\n",
      "Step: 3500  \tValid loss: 0.3263672888278961\n",
      "Step: 3600  \tTraining loss: 0.32163381576538086\n",
      "Step: 3600  \tTraining accuracy: 0.8500301837921143\n",
      "Step: 3600  \tValid loss: 0.32644572854042053\n",
      "Step: 3700  \tTraining loss: 0.32157137989997864\n",
      "Step: 3700  \tTraining accuracy: 0.8505317568778992\n",
      "Step: 3700  \tValid loss: 0.3265283703804016\n",
      "Step: 3800  \tTraining loss: 0.3215113580226898\n",
      "Step: 3800  \tTraining accuracy: 0.8510066270828247\n",
      "Step: 3800  \tValid loss: 0.3266147971153259\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.85144323\n",
      "Precision: 0.8808824\n",
      "Recall: 0.91730475\n",
      "F1 score: 0.86868924\n",
      "AUC: 0.8254287\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.851443   0.880882  0.917305  0.868689  0.825429  0.321485      0.851345   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0   0.32607       0.851241   0.286787      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3845.0  \n",
      "14\n",
      "(1798, 4)\n",
      "(1798, 1)\n",
      "(992, 4)\n",
      "(992, 1)\n",
      "(806, 4)\n",
      "(806, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6182387471199036\n",
      "Step: 100  \tTraining accuracy: 0.6696329116821289\n",
      "Step: 100  \tValid loss: 0.6236015558242798\n",
      "Step: 200  \tTraining loss: 0.5441614389419556\n",
      "Step: 200  \tTraining accuracy: 0.6848350167274475\n",
      "Step: 200  \tValid loss: 0.5804994702339172\n",
      "Step: 300  \tTraining loss: 0.5231456756591797\n",
      "Step: 300  \tTraining accuracy: 0.7023359537124634\n",
      "Step: 300  \tValid loss: 0.5647026896476746\n",
      "Step: 400  \tTraining loss: 0.500105082988739\n",
      "Step: 400  \tTraining accuracy: 0.7115048170089722\n",
      "Step: 400  \tValid loss: 0.541263997554779\n",
      "Step: 500  \tTraining loss: 0.4756673276424408\n",
      "Step: 500  \tTraining accuracy: 0.7175256609916687\n",
      "Step: 500  \tValid loss: 0.5153727531433105\n",
      "Step: 600  \tTraining loss: 0.45516082644462585\n",
      "Step: 600  \tTraining accuracy: 0.72428959608078\n",
      "Step: 600  \tValid loss: 0.49424904584884644\n",
      "Step: 700  \tTraining loss: 0.44069570302963257\n",
      "Step: 700  \tTraining accuracy: 0.7317104339599609\n",
      "Step: 700  \tValid loss: 0.4804123342037201\n",
      "Step: 800  \tTraining loss: 0.43076103925704956\n",
      "Step: 800  \tTraining accuracy: 0.7385242581367493\n",
      "Step: 800  \tValid loss: 0.4717480540275574\n",
      "Step: 900  \tTraining loss: 0.4237106740474701\n",
      "Step: 900  \tTraining accuracy: 0.7448145151138306\n",
      "Step: 900  \tValid loss: 0.46613258123397827\n",
      "Step: 1000  \tTraining loss: 0.41864681243896484\n",
      "Step: 1000  \tTraining accuracy: 0.750278115272522\n",
      "Step: 1000  \tValid loss: 0.46233537793159485\n",
      "Step: 1100  \tTraining loss: 0.4150630235671997\n",
      "Step: 1100  \tTraining accuracy: 0.7549658417701721\n",
      "Step: 1100  \tValid loss: 0.4597208499908447\n",
      "Step: 1200  \tTraining loss: 0.41258442401885986\n",
      "Step: 1200  \tTraining accuracy: 0.7589834332466125\n",
      "Step: 1200  \tValid loss: 0.4579430818557739\n",
      "Step: 1300  \tTraining loss: 0.4109118580818176\n",
      "Step: 1300  \tTraining accuracy: 0.7625806331634521\n",
      "Step: 1300  \tValid loss: 0.456705242395401\n",
      "Step: 1400  \tTraining loss: 0.40978509187698364\n",
      "Step: 1400  \tTraining accuracy: 0.7657479643821716\n",
      "Step: 1400  \tValid loss: 0.4557967483997345\n",
      "Step: 1500  \tTraining loss: 0.4090122580528259\n",
      "Step: 1500  \tTraining accuracy: 0.7684975862503052\n",
      "Step: 1500  \tValid loss: 0.45507657527923584\n",
      "Step: 1600  \tTraining loss: 0.4084647595882416\n",
      "Step: 1600  \tTraining accuracy: 0.7711076736450195\n",
      "Step: 1600  \tValid loss: 0.45446136593818665\n",
      "Step: 1700  \tTraining loss: 0.4080609977245331\n",
      "Step: 1700  \tTraining accuracy: 0.7734182476997375\n",
      "Step: 1700  \tValid loss: 0.4539068341255188\n",
      "Step: 1800  \tTraining loss: 0.4077514410018921\n",
      "Step: 1800  \tTraining accuracy: 0.77540123462677\n",
      "Step: 1800  \tValid loss: 0.45339274406433105\n",
      "Step: 1900  \tTraining loss: 0.4075052738189697\n",
      "Step: 1900  \tTraining accuracy: 0.7771698236465454\n",
      "Step: 1900  \tValid loss: 0.4529094696044922\n",
      "Step: 2000  \tTraining loss: 0.4073033630847931\n",
      "Step: 2000  \tTraining accuracy: 0.778742790222168\n",
      "Step: 2000  \tValid loss: 0.4524535536766052\n",
      "Step: 2100  \tTraining loss: 0.407133549451828\n",
      "Step: 2100  \tTraining accuracy: 0.7801350951194763\n",
      "Step: 2100  \tValid loss: 0.4520232677459717\n",
      "Step: 2200  \tTraining loss: 0.40698760747909546\n",
      "Step: 2200  \tTraining accuracy: 0.7813591361045837\n",
      "Step: 2200  \tValid loss: 0.4516177475452423\n",
      "Step: 2300  \tTraining loss: 0.4068593680858612\n",
      "Step: 2300  \tTraining accuracy: 0.7824990749359131\n",
      "Step: 2300  \tValid loss: 0.4512360394001007\n",
      "Step: 2400  \tTraining loss: 0.406745046377182\n",
      "Step: 2400  \tTraining accuracy: 0.7835419774055481\n",
      "Step: 2400  \tValid loss: 0.45087698101997375\n",
      "Step: 2500  \tTraining loss: 0.4066411256790161\n",
      "Step: 2500  \tTraining accuracy: 0.7844884395599365\n",
      "Step: 2500  \tValid loss: 0.45053932070732117\n",
      "Step: 2600  \tTraining loss: 0.40654581785202026\n",
      "Step: 2600  \tTraining accuracy: 0.7853715419769287\n",
      "Step: 2600  \tValid loss: 0.4502219557762146\n",
      "Step: 2700  \tTraining loss: 0.4064570665359497\n",
      "Step: 2700  \tTraining accuracy: 0.7861775159835815\n",
      "Step: 2700  \tValid loss: 0.4499230682849884\n",
      "Step: 2800  \tTraining loss: 0.406373530626297\n",
      "Step: 2800  \tTraining accuracy: 0.7869248390197754\n",
      "Step: 2800  \tValid loss: 0.44964173436164856\n",
      "Step: 2900  \tTraining loss: 0.4062943756580353\n",
      "Step: 2900  \tTraining accuracy: 0.7876099944114685\n",
      "Step: 2900  \tValid loss: 0.4493761658668518\n",
      "Step: 3000  \tTraining loss: 0.40621834993362427\n",
      "Step: 3000  \tTraining accuracy: 0.7882487177848816\n",
      "Step: 3000  \tValid loss: 0.4491254389286041\n",
      "Step: 3100  \tTraining loss: 0.4061449468135834\n",
      "Step: 3100  \tTraining accuracy: 0.7888455390930176\n",
      "Step: 3100  \tValid loss: 0.4488885700702667\n",
      "Step: 3200  \tTraining loss: 0.4060733914375305\n",
      "Step: 3200  \tTraining accuracy: 0.7894044518470764\n",
      "Step: 3200  \tValid loss: 0.44866475462913513\n",
      "Step: 3300  \tTraining loss: 0.40598732233047485\n",
      "Step: 3300  \tTraining accuracy: 0.7899289727210999\n",
      "Step: 3300  \tValid loss: 0.4484173655509949\n",
      "Step: 3400  \tTraining loss: 0.405864953994751\n",
      "Step: 3400  \tTraining accuracy: 0.7904222011566162\n",
      "Step: 3400  \tValid loss: 0.4480847418308258\n",
      "Step: 3500  \tTraining loss: 0.40571823716163635\n",
      "Step: 3500  \tTraining accuracy: 0.7908868193626404\n",
      "Step: 3500  \tValid loss: 0.4477463662624359\n",
      "Step: 3600  \tTraining loss: 0.4056021273136139\n",
      "Step: 3600  \tTraining accuracy: 0.7913095951080322\n",
      "Step: 3600  \tValid loss: 0.44748416543006897\n",
      "Step: 3700  \tTraining loss: 0.4055071175098419\n",
      "Step: 3700  \tTraining accuracy: 0.7917168140411377\n",
      "Step: 3700  \tValid loss: 0.4472958445549011\n",
      "Step: 3800  \tTraining loss: 0.4054206311702728\n",
      "Step: 3800  \tTraining accuracy: 0.7921023368835449\n",
      "Step: 3800  \tValid loss: 0.4471627473831177\n",
      "Step: 3900  \tTraining loss: 0.40534380078315735\n",
      "Step: 3900  \tTraining accuracy: 0.7924678325653076\n",
      "Step: 3900  \tValid loss: 0.4470245838165283\n",
      "Step: 4000  \tTraining loss: 0.4052712321281433\n",
      "Step: 4000  \tTraining accuracy: 0.7928218245506287\n",
      "Step: 4000  \tValid loss: 0.44689086079597473\n",
      "Step: 4100  \tTraining loss: 0.40520286560058594\n",
      "Step: 4100  \tTraining accuracy: 0.7931583523750305\n",
      "Step: 4100  \tValid loss: 0.4467543363571167\n",
      "Step: 4200  \tTraining loss: 0.40513893961906433\n",
      "Step: 4200  \tTraining accuracy: 0.7934787273406982\n",
      "Step: 4200  \tValid loss: 0.4466676414012909\n",
      "Step: 4300  \tTraining loss: 0.40507546067237854\n",
      "Step: 4300  \tTraining accuracy: 0.793783962726593\n",
      "Step: 4300  \tValid loss: 0.4465370178222656\n",
      "Step: 4400  \tTraining loss: 0.40501341223716736\n",
      "Step: 4400  \tTraining accuracy: 0.7940815687179565\n",
      "Step: 4400  \tValid loss: 0.44642752408981323\n",
      "Step: 4500  \tTraining loss: 0.40495216846466064\n",
      "Step: 4500  \tTraining accuracy: 0.7943595051765442\n",
      "Step: 4500  \tValid loss: 0.44630929827690125\n",
      "Step: 4600  \tTraining loss: 0.4048916697502136\n",
      "Step: 4600  \tTraining accuracy: 0.7946252822875977\n",
      "Step: 4600  \tValid loss: 0.44620582461357117\n",
      "Step: 4700  \tTraining loss: 0.40483102202415466\n",
      "Step: 4700  \tTraining accuracy: 0.7948796153068542\n",
      "Step: 4700  \tValid loss: 0.4460948705673218\n",
      "Step: 4800  \tTraining loss: 0.40477097034454346\n",
      "Step: 4800  \tTraining accuracy: 0.7951232194900513\n",
      "Step: 4800  \tValid loss: 0.445992112159729\n",
      "Step: 4900  \tTraining loss: 0.4047107398509979\n",
      "Step: 4900  \tTraining accuracy: 0.795356810092926\n",
      "Step: 4900  \tValid loss: 0.4458896517753601\n",
      "Step: 5000  \tTraining loss: 0.4046505391597748\n",
      "Step: 5000  \tTraining accuracy: 0.7955865859985352\n",
      "Step: 5000  \tValid loss: 0.445786714553833\n",
      "Step: 5100  \tTraining loss: 0.40458914637565613\n",
      "Step: 5100  \tTraining accuracy: 0.7958072423934937\n",
      "Step: 5100  \tValid loss: 0.44566866755485535\n",
      "Step: 5200  \tTraining loss: 0.4045267701148987\n",
      "Step: 5200  \tTraining accuracy: 0.7960193157196045\n",
      "Step: 5200  \tValid loss: 0.44553694128990173\n",
      "Step: 5300  \tTraining loss: 0.40446314215660095\n",
      "Step: 5300  \tTraining accuracy: 0.7962233424186707\n",
      "Step: 5300  \tValid loss: 0.4453785717487335\n",
      "Step: 5400  \tTraining loss: 0.4043946862220764\n",
      "Step: 5400  \tTraining accuracy: 0.7964196801185608\n",
      "Step: 5400  \tValid loss: 0.44519901275634766\n",
      "Step: 5500  \tTraining loss: 0.4043242037296295\n",
      "Step: 5500  \tTraining accuracy: 0.7966190576553345\n",
      "Step: 5500  \tValid loss: 0.44499796628952026\n",
      "Step: 5600  \tTraining loss: 0.4042520225048065\n",
      "Step: 5600  \tTraining accuracy: 0.7968112826347351\n",
      "Step: 5600  \tValid loss: 0.44480711221694946\n",
      "Step: 5700  \tTraining loss: 0.40417924523353577\n",
      "Step: 5700  \tTraining accuracy: 0.7969966530799866\n",
      "Step: 5700  \tValid loss: 0.44462037086486816\n",
      "Step: 5800  \tTraining loss: 0.40410590171813965\n",
      "Step: 5800  \tTraining accuracy: 0.7971755862236023\n",
      "Step: 5800  \tValid loss: 0.44446247816085815\n",
      "Step: 5900  \tTraining loss: 0.4040314555168152\n",
      "Step: 5900  \tTraining accuracy: 0.7973484396934509\n",
      "Step: 5900  \tValid loss: 0.4443255364894867\n",
      "Step: 6000  \tTraining loss: 0.4039561450481415\n",
      "Step: 6000  \tTraining accuracy: 0.7975154519081116\n",
      "Step: 6000  \tValid loss: 0.4441975951194763\n",
      "Step: 6100  \tTraining loss: 0.4038811922073364\n",
      "Step: 6100  \tTraining accuracy: 0.7976769208908081\n",
      "Step: 6100  \tValid loss: 0.4440392553806305\n",
      "Step: 6200  \tTraining loss: 0.4038061499595642\n",
      "Step: 6200  \tTraining accuracy: 0.7978332042694092\n",
      "Step: 6200  \tValid loss: 0.44387808442115784\n",
      "Step: 6300  \tTraining loss: 0.40373218059539795\n",
      "Step: 6300  \tTraining accuracy: 0.7979888916015625\n",
      "Step: 6300  \tValid loss: 0.4437296688556671\n",
      "Step: 6400  \tTraining loss: 0.4036579132080078\n",
      "Step: 6400  \tTraining accuracy: 0.7981396913528442\n",
      "Step: 6400  \tValid loss: 0.4435557425022125\n",
      "Step: 6500  \tTraining loss: 0.4035835862159729\n",
      "Step: 6500  \tTraining accuracy: 0.7982857823371887\n",
      "Step: 6500  \tValid loss: 0.44339999556541443\n",
      "Step: 6600  \tTraining loss: 0.4035095274448395\n",
      "Step: 6600  \tTraining accuracy: 0.798427402973175\n",
      "Step: 6600  \tValid loss: 0.4432150423526764\n",
      "Step: 6700  \tTraining loss: 0.4034363329410553\n",
      "Step: 6700  \tTraining accuracy: 0.7985647916793823\n",
      "Step: 6700  \tValid loss: 0.44306060671806335\n",
      "Step: 6800  \tTraining loss: 0.40336355566978455\n",
      "Step: 6800  \tTraining accuracy: 0.7987063527107239\n",
      "Step: 6800  \tValid loss: 0.4429226219654083\n",
      "Step: 6900  \tTraining loss: 0.4032905697822571\n",
      "Step: 6900  \tTraining accuracy: 0.7988438010215759\n",
      "Step: 6900  \tValid loss: 0.44278404116630554\n",
      "Step: 7000  \tTraining loss: 0.4032173156738281\n",
      "Step: 7000  \tTraining accuracy: 0.798977255821228\n",
      "Step: 7000  \tValid loss: 0.4426824748516083\n",
      "Step: 7100  \tTraining loss: 0.40314385294914246\n",
      "Step: 7100  \tTraining accuracy: 0.7991069555282593\n",
      "Step: 7100  \tValid loss: 0.4425772726535797\n",
      "Step: 7200  \tTraining loss: 0.4030700922012329\n",
      "Step: 7200  \tTraining accuracy: 0.7992330193519592\n",
      "Step: 7200  \tValid loss: 0.44247934222221375\n",
      "Step: 7300  \tTraining loss: 0.4029960334300995\n",
      "Step: 7300  \tTraining accuracy: 0.7993556261062622\n",
      "Step: 7300  \tValid loss: 0.4423873722553253\n",
      "Step: 7400  \tTraining loss: 0.4029221832752228\n",
      "Step: 7400  \tTraining accuracy: 0.7994710803031921\n",
      "Step: 7400  \tValid loss: 0.4422714114189148\n",
      "Step: 7500  \tTraining loss: 0.40284812450408936\n",
      "Step: 7500  \tTraining accuracy: 0.7995834350585938\n",
      "Step: 7500  \tValid loss: 0.44211453199386597\n",
      "Step: 7600  \tTraining loss: 0.40277421474456787\n",
      "Step: 7600  \tTraining accuracy: 0.7996928095817566\n",
      "Step: 7600  \tValid loss: 0.44199931621551514\n",
      "Step: 7700  \tTraining loss: 0.40269994735717773\n",
      "Step: 7700  \tTraining accuracy: 0.7998029589653015\n",
      "Step: 7700  \tValid loss: 0.4418801963329315\n",
      "Step: 7800  \tTraining loss: 0.40262582898139954\n",
      "Step: 7800  \tTraining accuracy: 0.7999030947685242\n",
      "Step: 7800  \tValid loss: 0.4417732059955597\n",
      "Step: 7900  \tTraining loss: 0.40255144238471985\n",
      "Step: 7900  \tTraining accuracy: 0.8000007271766663\n",
      "Step: 7900  \tValid loss: 0.4416252374649048\n",
      "Step: 8000  \tTraining loss: 0.40247705578804016\n",
      "Step: 8000  \tTraining accuracy: 0.8000958561897278\n",
      "Step: 8000  \tValid loss: 0.4415280818939209\n",
      "Step: 8100  \tTraining loss: 0.402401864528656\n",
      "Step: 8100  \tTraining accuracy: 0.8001886010169983\n",
      "Step: 8100  \tValid loss: 0.44137734174728394\n",
      "Step: 8200  \tTraining loss: 0.4023268520832062\n",
      "Step: 8200  \tTraining accuracy: 0.8002756834030151\n",
      "Step: 8200  \tValid loss: 0.44127583503723145\n",
      "Step: 8300  \tTraining loss: 0.4022522568702698\n",
      "Step: 8300  \tTraining accuracy: 0.8003606796264648\n",
      "Step: 8300  \tValid loss: 0.4411734342575073\n",
      "Step: 8400  \tTraining loss: 0.40217673778533936\n",
      "Step: 8400  \tTraining accuracy: 0.8004435896873474\n",
      "Step: 8400  \tValid loss: 0.4409986436367035\n",
      "Step: 8500  \tTraining loss: 0.40210190415382385\n",
      "Step: 8500  \tTraining accuracy: 0.8005245923995972\n",
      "Step: 8500  \tValid loss: 0.4409189522266388\n",
      "Step: 8600  \tTraining loss: 0.4020256996154785\n",
      "Step: 8600  \tTraining accuracy: 0.8006036877632141\n",
      "Step: 8600  \tValid loss: 0.4407382309436798\n",
      "Step: 8700  \tTraining loss: 0.40195003151893616\n",
      "Step: 8700  \tTraining accuracy: 0.800680935382843\n",
      "Step: 8700  \tValid loss: 0.4406299889087677\n",
      "Step: 8800  \tTraining loss: 0.4018743634223938\n",
      "Step: 8800  \tTraining accuracy: 0.8007563948631287\n",
      "Step: 8800  \tValid loss: 0.4404889941215515\n",
      "Step: 8900  \tTraining loss: 0.4017983675003052\n",
      "Step: 8900  \tTraining accuracy: 0.8008270263671875\n",
      "Step: 8900  \tValid loss: 0.4403783977031708\n",
      "Step: 9000  \tTraining loss: 0.40172237157821655\n",
      "Step: 9000  \tTraining accuracy: 0.8008961081504822\n",
      "Step: 9000  \tValid loss: 0.44028738141059875\n",
      "Step: 9100  \tTraining loss: 0.4016455113887787\n",
      "Step: 9100  \tTraining accuracy: 0.8009636402130127\n",
      "Step: 9100  \tValid loss: 0.4401575028896332\n",
      "Step: 9200  \tTraining loss: 0.40156838297843933\n",
      "Step: 9200  \tTraining accuracy: 0.8010296821594238\n",
      "Step: 9200  \tValid loss: 0.4400297701358795\n",
      "Step: 9300  \tTraining loss: 0.40149250626564026\n",
      "Step: 9300  \tTraining accuracy: 0.8010973334312439\n",
      "Step: 9300  \tValid loss: 0.43992650508880615\n",
      "Step: 9400  \tTraining loss: 0.40141505002975464\n",
      "Step: 9400  \tTraining accuracy: 0.8011634945869446\n",
      "Step: 9400  \tValid loss: 0.4398037791252136\n",
      "Step: 9500  \tTraining loss: 0.40133675932884216\n",
      "Step: 9500  \tTraining accuracy: 0.8012282848358154\n",
      "Step: 9500  \tValid loss: 0.4396740198135376\n",
      "Step: 9600  \tTraining loss: 0.40125805139541626\n",
      "Step: 9600  \tTraining accuracy: 0.8012917041778564\n",
      "Step: 9600  \tValid loss: 0.43955156207084656\n",
      "Step: 9700  \tTraining loss: 0.4011792540550232\n",
      "Step: 9700  \tTraining accuracy: 0.8013567328453064\n",
      "Step: 9700  \tValid loss: 0.43941983580589294\n",
      "Step: 9800  \tTraining loss: 0.401101291179657\n",
      "Step: 9800  \tTraining accuracy: 0.8014203906059265\n",
      "Step: 9800  \tValid loss: 0.4393364489078522\n",
      "Step: 9900  \tTraining loss: 0.4010204076766968\n",
      "Step: 9900  \tTraining accuracy: 0.8014827370643616\n",
      "Step: 9900  \tValid loss: 0.43920671939849854\n",
      "Step: 10000  \tTraining loss: 0.4009401202201843\n",
      "Step: 10000  \tTraining accuracy: 0.8015466928482056\n",
      "Step: 10000  \tValid loss: 0.4390949010848999\n",
      "Step: 10100  \tTraining loss: 0.40085914731025696\n",
      "Step: 10100  \tTraining accuracy: 0.8016120791435242\n",
      "Step: 10100  \tValid loss: 0.4389955401420593\n",
      "Step: 10200  \tTraining loss: 0.40077733993530273\n",
      "Step: 10200  \tTraining accuracy: 0.8016762137413025\n",
      "Step: 10200  \tValid loss: 0.4389062225818634\n",
      "Step: 10300  \tTraining loss: 0.40069490671157837\n",
      "Step: 10300  \tTraining accuracy: 0.8017390370368958\n",
      "Step: 10300  \tValid loss: 0.4388144016265869\n",
      "Step: 10400  \tTraining loss: 0.4006125032901764\n",
      "Step: 10400  \tTraining accuracy: 0.8018007278442383\n",
      "Step: 10400  \tValid loss: 0.43875887989997864\n",
      "Step: 10500  \tTraining loss: 0.4005279242992401\n",
      "Step: 10500  \tTraining accuracy: 0.8018611669540405\n",
      "Step: 10500  \tValid loss: 0.43860873579978943\n",
      "Step: 10600  \tTraining loss: 0.40044352412223816\n",
      "Step: 10600  \tTraining accuracy: 0.8019152283668518\n",
      "Step: 10600  \tValid loss: 0.43849873542785645\n",
      "Step: 10700  \tTraining loss: 0.4003583788871765\n",
      "Step: 10700  \tTraining accuracy: 0.8019682765007019\n",
      "Step: 10700  \tValid loss: 0.4384009540081024\n",
      "Step: 10800  \tTraining loss: 0.40027207136154175\n",
      "Step: 10800  \tTraining accuracy: 0.8020229339599609\n",
      "Step: 10800  \tValid loss: 0.43830692768096924\n",
      "Step: 10900  \tTraining loss: 0.4001847207546234\n",
      "Step: 10900  \tTraining accuracy: 0.8020765781402588\n",
      "Step: 10900  \tValid loss: 0.4382156431674957\n",
      "Step: 11000  \tTraining loss: 0.40009623765945435\n",
      "Step: 11000  \tTraining accuracy: 0.8021292090415955\n",
      "Step: 11000  \tValid loss: 0.4381268620491028\n",
      "Step: 11100  \tTraining loss: 0.4000054597854614\n",
      "Step: 11100  \tTraining accuracy: 0.8021808862686157\n",
      "Step: 11100  \tValid loss: 0.438052237033844\n",
      "Step: 11200  \tTraining loss: 0.39991018176078796\n",
      "Step: 11200  \tTraining accuracy: 0.8022316694259644\n",
      "Step: 11200  \tValid loss: 0.43799304962158203\n",
      "Step: 11300  \tTraining loss: 0.3998169004917145\n",
      "Step: 11300  \tTraining accuracy: 0.8022815585136414\n",
      "Step: 11300  \tValid loss: 0.43788158893585205\n",
      "Step: 11400  \tTraining loss: 0.399723082780838\n",
      "Step: 11400  \tTraining accuracy: 0.8023305535316467\n",
      "Step: 11400  \tValid loss: 0.43778494000434875\n",
      "Step: 11500  \tTraining loss: 0.3996279239654541\n",
      "Step: 11500  \tTraining accuracy: 0.8023786544799805\n",
      "Step: 11500  \tValid loss: 0.43769022822380066\n",
      "Step: 11600  \tTraining loss: 0.3995308578014374\n",
      "Step: 11600  \tTraining accuracy: 0.8024259805679321\n",
      "Step: 11600  \tValid loss: 0.43760013580322266\n",
      "Step: 11700  \tTraining loss: 0.39943259954452515\n",
      "Step: 11700  \tTraining accuracy: 0.8024724721908569\n",
      "Step: 11700  \tValid loss: 0.43753865361213684\n",
      "Step: 11800  \tTraining loss: 0.3993305563926697\n",
      "Step: 11800  \tTraining accuracy: 0.8025181889533997\n",
      "Step: 11800  \tValid loss: 0.4374017119407654\n",
      "Step: 11900  \tTraining loss: 0.39922672510147095\n",
      "Step: 11900  \tTraining accuracy: 0.8025654554367065\n",
      "Step: 11900  \tValid loss: 0.43731021881103516\n",
      "Step: 12000  \tTraining loss: 0.39912113547325134\n",
      "Step: 12000  \tTraining accuracy: 0.8026142716407776\n",
      "Step: 12000  \tValid loss: 0.4372686445713043\n",
      "Step: 12100  \tTraining loss: 0.3990122675895691\n",
      "Step: 12100  \tTraining accuracy: 0.8026622533798218\n",
      "Step: 12100  \tValid loss: 0.4371792674064636\n",
      "Step: 12200  \tTraining loss: 0.39890167117118835\n",
      "Step: 12200  \tTraining accuracy: 0.8027094602584839\n",
      "Step: 12200  \tValid loss: 0.4371117055416107\n",
      "Step: 12300  \tTraining loss: 0.39878880977630615\n",
      "Step: 12300  \tTraining accuracy: 0.8027558922767639\n",
      "Step: 12300  \tValid loss: 0.4370378255844116\n",
      "Step: 12400  \tTraining loss: 0.39867380261421204\n",
      "Step: 12400  \tTraining accuracy: 0.8027970790863037\n",
      "Step: 12400  \tValid loss: 0.436966210603714\n",
      "Step: 12500  \tTraining loss: 0.3985563814640045\n",
      "Step: 12500  \tTraining accuracy: 0.802837610244751\n",
      "Step: 12500  \tValid loss: 0.4369015097618103\n",
      "Step: 12600  \tTraining loss: 0.39843666553497314\n",
      "Step: 12600  \tTraining accuracy: 0.8028774857521057\n",
      "Step: 12600  \tValid loss: 0.4368375241756439\n",
      "Step: 12700  \tTraining loss: 0.39831453561782837\n",
      "Step: 12700  \tTraining accuracy: 0.8029189109802246\n",
      "Step: 12700  \tValid loss: 0.4367726147174835\n",
      "Step: 12800  \tTraining loss: 0.3981899321079254\n",
      "Step: 12800  \tTraining accuracy: 0.8029597401618958\n",
      "Step: 12800  \tValid loss: 0.4367091655731201\n",
      "Step: 12900  \tTraining loss: 0.39806288480758667\n",
      "Step: 12900  \tTraining accuracy: 0.8029998540878296\n",
      "Step: 12900  \tValid loss: 0.43664076924324036\n",
      "Step: 13000  \tTraining loss: 0.3979332447052002\n",
      "Step: 13000  \tTraining accuracy: 0.8030415773391724\n",
      "Step: 13000  \tValid loss: 0.4365771412849426\n",
      "Step: 13100  \tTraining loss: 0.39780130982398987\n",
      "Step: 13100  \tTraining accuracy: 0.8030847311019897\n",
      "Step: 13100  \tValid loss: 0.4365147650241852\n",
      "Step: 13200  \tTraining loss: 0.3976668417453766\n",
      "Step: 13200  \tTraining accuracy: 0.8031272888183594\n",
      "Step: 13200  \tValid loss: 0.43645691871643066\n",
      "Step: 13300  \tTraining loss: 0.39752981066703796\n",
      "Step: 13300  \tTraining accuracy: 0.8031691312789917\n",
      "Step: 13300  \tValid loss: 0.4364025890827179\n",
      "Step: 13400  \tTraining loss: 0.3973904848098755\n",
      "Step: 13400  \tTraining accuracy: 0.8032082915306091\n",
      "Step: 13400  \tValid loss: 0.4363498091697693\n",
      "Step: 13500  \tTraining loss: 0.39724886417388916\n",
      "Step: 13500  \tTraining accuracy: 0.8032469153404236\n",
      "Step: 13500  \tValid loss: 0.4362999498844147\n",
      "Step: 13600  \tTraining loss: 0.39710506796836853\n",
      "Step: 13600  \tTraining accuracy: 0.8032828569412231\n",
      "Step: 13600  \tValid loss: 0.43625232577323914\n",
      "Step: 13700  \tTraining loss: 0.3969590663909912\n",
      "Step: 13700  \tTraining accuracy: 0.8033223748207092\n",
      "Step: 13700  \tValid loss: 0.4362080991268158\n",
      "Step: 13800  \tTraining loss: 0.3968108296394348\n",
      "Step: 13800  \tTraining accuracy: 0.8033653497695923\n",
      "Step: 13800  \tValid loss: 0.4361650347709656\n",
      "Step: 13900  \tTraining loss: 0.3966609835624695\n",
      "Step: 13900  \tTraining accuracy: 0.8034057021141052\n",
      "Step: 13900  \tValid loss: 0.4361225962638855\n",
      "Step: 14000  \tTraining loss: 0.39650899171829224\n",
      "Step: 14000  \tTraining accuracy: 0.8034454584121704\n",
      "Step: 14000  \tValid loss: 0.43608957529067993\n",
      "Step: 14100  \tTraining loss: 0.39635539054870605\n",
      "Step: 14100  \tTraining accuracy: 0.8034807443618774\n",
      "Step: 14100  \tValid loss: 0.4360601603984833\n",
      "Step: 14200  \tTraining loss: 0.39620012044906616\n",
      "Step: 14200  \tTraining accuracy: 0.8035115599632263\n",
      "Step: 14200  \tValid loss: 0.436029851436615\n",
      "Step: 14300  \tTraining loss: 0.3960433900356293\n",
      "Step: 14300  \tTraining accuracy: 0.8035419583320618\n",
      "Step: 14300  \tValid loss: 0.436000257730484\n",
      "Step: 14400  \tTraining loss: 0.3958852291107178\n",
      "Step: 14400  \tTraining accuracy: 0.8035699725151062\n",
      "Step: 14400  \tValid loss: 0.4359850585460663\n",
      "Step: 14500  \tTraining loss: 0.3957258462905884\n",
      "Step: 14500  \tTraining accuracy: 0.803597629070282\n",
      "Step: 14500  \tValid loss: 0.4359470307826996\n",
      "Step: 14600  \tTraining loss: 0.39556556940078735\n",
      "Step: 14600  \tTraining accuracy: 0.8036267757415771\n",
      "Step: 14600  \tValid loss: 0.43592163920402527\n",
      "Step: 14700  \tTraining loss: 0.39540424942970276\n",
      "Step: 14700  \tTraining accuracy: 0.8036555647850037\n",
      "Step: 14700  \tValid loss: 0.43589577078819275\n",
      "Step: 14800  \tTraining loss: 0.39524397253990173\n",
      "Step: 14800  \tTraining accuracy: 0.8036801815032959\n",
      "Step: 14800  \tValid loss: 0.43586665391921997\n",
      "Step: 14900  \tTraining loss: 0.39507919549942017\n",
      "Step: 14900  \tTraining accuracy: 0.8037044405937195\n",
      "Step: 14900  \tValid loss: 0.43584221601486206\n",
      "Step: 15000  \tTraining loss: 0.39491572976112366\n",
      "Step: 15000  \tTraining accuracy: 0.8037265539169312\n",
      "Step: 15000  \tValid loss: 0.43581900000572205\n",
      "Step: 15100  \tTraining loss: 0.3947518765926361\n",
      "Step: 15100  \tTraining accuracy: 0.803750216960907\n",
      "Step: 15100  \tValid loss: 0.4357823431491852\n",
      "Step: 15200  \tTraining loss: 0.3945876359939575\n",
      "Step: 15200  \tTraining accuracy: 0.8037735223770142\n",
      "Step: 15200  \tValid loss: 0.43575814366340637\n",
      "Step: 15300  \tTraining loss: 0.39442333579063416\n",
      "Step: 15300  \tTraining accuracy: 0.8037965893745422\n",
      "Step: 15300  \tValid loss: 0.4357258975505829\n",
      "Step: 15400  \tTraining loss: 0.3942593038082123\n",
      "Step: 15400  \tTraining accuracy: 0.8038192987442017\n",
      "Step: 15400  \tValid loss: 0.43571728467941284\n",
      "Step: 15500  \tTraining loss: 0.3940942585468292\n",
      "Step: 15500  \tTraining accuracy: 0.8038435578346252\n",
      "Step: 15500  \tValid loss: 0.4356658458709717\n",
      "Step: 15600  \tTraining loss: 0.39392974972724915\n",
      "Step: 15600  \tTraining accuracy: 0.8038656711578369\n",
      "Step: 15600  \tValid loss: 0.4356239140033722\n",
      "Step: 15700  \tTraining loss: 0.393766850233078\n",
      "Step: 15700  \tTraining accuracy: 0.8038875460624695\n",
      "Step: 15700  \tValid loss: 0.43563657999038696\n",
      "Step: 15800  \tTraining loss: 0.3936012387275696\n",
      "Step: 15800  \tTraining accuracy: 0.8039073348045349\n",
      "Step: 15800  \tValid loss: 0.4355658292770386\n",
      "Step: 15900  \tTraining loss: 0.3934375047683716\n",
      "Step: 15900  \tTraining accuracy: 0.8039286732673645\n",
      "Step: 15900  \tValid loss: 0.4355229437351227\n",
      "Step: 16000  \tTraining loss: 0.39327406883239746\n",
      "Step: 16000  \tTraining accuracy: 0.8039497137069702\n",
      "Step: 16000  \tValid loss: 0.4354783892631531\n",
      "Step: 16100  \tTraining loss: 0.3931126296520233\n",
      "Step: 16100  \tTraining accuracy: 0.8039705157279968\n",
      "Step: 16100  \tValid loss: 0.43543297052383423\n",
      "Step: 16200  \tTraining loss: 0.392948716878891\n",
      "Step: 16200  \tTraining accuracy: 0.8039910197257996\n",
      "Step: 16200  \tValid loss: 0.4354153573513031\n",
      "Step: 16300  \tTraining loss: 0.39278677105903625\n",
      "Step: 16300  \tTraining accuracy: 0.8040112853050232\n",
      "Step: 16300  \tValid loss: 0.43535515666007996\n",
      "Step: 16400  \tTraining loss: 0.3926253914833069\n",
      "Step: 16400  \tTraining accuracy: 0.8040330410003662\n",
      "Step: 16400  \tValid loss: 0.43530818819999695\n",
      "Step: 16500  \tTraining loss: 0.3924647569656372\n",
      "Step: 16500  \tTraining accuracy: 0.8040544986724854\n",
      "Step: 16500  \tValid loss: 0.43525585532188416\n",
      "Step: 16600  \tTraining loss: 0.3923046290874481\n",
      "Step: 16600  \tTraining accuracy: 0.8040757179260254\n",
      "Step: 16600  \tValid loss: 0.4352019131183624\n",
      "Step: 16700  \tTraining loss: 0.3921452462673187\n",
      "Step: 16700  \tTraining accuracy: 0.8040983080863953\n",
      "Step: 16700  \tValid loss: 0.4351697266101837\n",
      "Step: 16800  \tTraining loss: 0.3919867277145386\n",
      "Step: 16800  \tTraining accuracy: 0.8041239976882935\n",
      "Step: 16800  \tValid loss: 0.4351159334182739\n",
      "Step: 16900  \tTraining loss: 0.3918288052082062\n",
      "Step: 16900  \tTraining accuracy: 0.804149329662323\n",
      "Step: 16900  \tValid loss: 0.4350980222225189\n",
      "Step: 17000  \tTraining loss: 0.3916718363761902\n",
      "Step: 17000  \tTraining accuracy: 0.8041727542877197\n",
      "Step: 17000  \tValid loss: 0.4350535571575165\n",
      "Step: 17100  \tTraining loss: 0.3915157914161682\n",
      "Step: 17100  \tTraining accuracy: 0.8041959404945374\n",
      "Step: 17100  \tValid loss: 0.43500709533691406\n",
      "Step: 17200  \tTraining loss: 0.3913605213165283\n",
      "Step: 17200  \tTraining accuracy: 0.8042188286781311\n",
      "Step: 17200  \tValid loss: 0.4349660873413086\n",
      "Step: 17300  \tTraining loss: 0.3912073075771332\n",
      "Step: 17300  \tTraining accuracy: 0.804241418838501\n",
      "Step: 17300  \tValid loss: 0.4349030554294586\n",
      "Step: 17400  \tTraining loss: 0.39105239510536194\n",
      "Step: 17400  \tTraining accuracy: 0.8042653799057007\n",
      "Step: 17400  \tValid loss: 0.43482884764671326\n",
      "Step: 17500  \tTraining loss: 0.3908982276916504\n",
      "Step: 17500  \tTraining accuracy: 0.8042890429496765\n",
      "Step: 17500  \tValid loss: 0.43467679619789124\n",
      "Step: 17600  \tTraining loss: 0.3907448351383209\n",
      "Step: 17600  \tTraining accuracy: 0.8043140769004822\n",
      "Step: 17600  \tValid loss: 0.43453553318977356\n",
      "Step: 17700  \tTraining loss: 0.39059415459632874\n",
      "Step: 17700  \tTraining accuracy: 0.804337203502655\n",
      "Step: 17700  \tValid loss: 0.4344788193702698\n",
      "Step: 17800  \tTraining loss: 0.3904418647289276\n",
      "Step: 17800  \tTraining accuracy: 0.8043616414070129\n",
      "Step: 17800  \tValid loss: 0.4344460666179657\n",
      "Step: 17900  \tTraining loss: 0.39029189944267273\n",
      "Step: 17900  \tTraining accuracy: 0.8043826818466187\n",
      "Step: 17900  \tValid loss: 0.43439632654190063\n",
      "Step: 18000  \tTraining loss: 0.39014217257499695\n",
      "Step: 18000  \tTraining accuracy: 0.8044066429138184\n",
      "Step: 18000  \tValid loss: 0.4343779981136322\n",
      "Step: 18100  \tTraining loss: 0.3899935781955719\n",
      "Step: 18100  \tTraining accuracy: 0.8044303059577942\n",
      "Step: 18100  \tValid loss: 0.4343295693397522\n",
      "Step: 18200  \tTraining loss: 0.3898463845252991\n",
      "Step: 18200  \tTraining accuracy: 0.8044536709785461\n",
      "Step: 18200  \tValid loss: 0.43436381220817566\n",
      "Step: 18300  \tTraining loss: 0.38969823718070984\n",
      "Step: 18300  \tTraining accuracy: 0.8044783473014832\n",
      "Step: 18300  \tValid loss: 0.43425899744033813\n",
      "Step: 18400  \tTraining loss: 0.3895516097545624\n",
      "Step: 18400  \tTraining accuracy: 0.8045027256011963\n",
      "Step: 18400  \tValid loss: 0.4342014491558075\n",
      "Step: 18500  \tTraining loss: 0.38940560817718506\n",
      "Step: 18500  \tTraining accuracy: 0.8045253753662109\n",
      "Step: 18500  \tValid loss: 0.4341939687728882\n",
      "Step: 18600  \tTraining loss: 0.389260470867157\n",
      "Step: 18600  \tTraining accuracy: 0.8045462369918823\n",
      "Step: 18600  \tValid loss: 0.43414393067359924\n",
      "Step: 18700  \tTraining loss: 0.38911569118499756\n",
      "Step: 18700  \tTraining accuracy: 0.8045668601989746\n",
      "Step: 18700  \tValid loss: 0.4341309070587158\n",
      "Step: 18800  \tTraining loss: 0.38897186517715454\n",
      "Step: 18800  \tTraining accuracy: 0.8045873045921326\n",
      "Step: 18800  \tValid loss: 0.434079110622406\n",
      "Step: 18900  \tTraining loss: 0.3888285756111145\n",
      "Step: 18900  \tTraining accuracy: 0.8046075105667114\n",
      "Step: 18900  \tValid loss: 0.43407079577445984\n",
      "Step: 19000  \tTraining loss: 0.38868609070777893\n",
      "Step: 19000  \tTraining accuracy: 0.804627537727356\n",
      "Step: 19000  \tValid loss: 0.4340215027332306\n",
      "Step: 19100  \tTraining loss: 0.38854435086250305\n",
      "Step: 19100  \tTraining accuracy: 0.8046429753303528\n",
      "Step: 19100  \tValid loss: 0.43401360511779785\n",
      "Step: 19200  \tTraining loss: 0.3884066343307495\n",
      "Step: 19200  \tTraining accuracy: 0.8046596646308899\n",
      "Step: 19200  \tValid loss: 0.4339067339897156\n",
      "Step: 19300  \tTraining loss: 0.3882625997066498\n",
      "Step: 19300  \tTraining accuracy: 0.8046761751174927\n",
      "Step: 19300  \tValid loss: 0.43395406007766724\n",
      "Step: 19400  \tTraining loss: 0.3881225287914276\n",
      "Step: 19400  \tTraining accuracy: 0.8046925663948059\n",
      "Step: 19400  \tValid loss: 0.43395140767097473\n",
      "Step: 19500  \tTraining loss: 0.3879830837249756\n",
      "Step: 19500  \tTraining accuracy: 0.80470871925354\n",
      "Step: 19500  \tValid loss: 0.4338991045951843\n",
      "Step: 19600  \tTraining loss: 0.3878439962863922\n",
      "Step: 19600  \tTraining accuracy: 0.80472332239151\n",
      "Step: 19600  \tValid loss: 0.43390560150146484\n",
      "Step: 19700  \tTraining loss: 0.38770580291748047\n",
      "Step: 19700  \tTraining accuracy: 0.804739236831665\n",
      "Step: 19700  \tValid loss: 0.4339160919189453\n",
      "Step: 19800  \tTraining loss: 0.3875707685947418\n",
      "Step: 19800  \tTraining accuracy: 0.804754912853241\n",
      "Step: 19800  \tValid loss: 0.4338124692440033\n",
      "Step: 19900  \tTraining loss: 0.38743066787719727\n",
      "Step: 19900  \tTraining accuracy: 0.8047704696655273\n",
      "Step: 19900  \tValid loss: 0.43388134241104126\n",
      "Step: 20000  \tTraining loss: 0.38729390501976013\n",
      "Step: 20000  \tTraining accuracy: 0.8047859072685242\n",
      "Step: 20000  \tValid loss: 0.4338876008987427\n",
      "Step: 20100  \tTraining loss: 0.3871575593948364\n",
      "Step: 20100  \tTraining accuracy: 0.8047997355461121\n",
      "Step: 20100  \tValid loss: 0.4338589310646057\n",
      "Step: 20200  \tTraining loss: 0.3870217800140381\n",
      "Step: 20200  \tTraining accuracy: 0.8048134446144104\n",
      "Step: 20200  \tValid loss: 0.4338313341140747\n",
      "Step: 20300  \tTraining loss: 0.3868862986564636\n",
      "Step: 20300  \tTraining accuracy: 0.8048270344734192\n",
      "Step: 20300  \tValid loss: 0.4338223338127136\n",
      "Step: 20400  \tTraining loss: 0.386751264333725\n",
      "Step: 20400  \tTraining accuracy: 0.8048418760299683\n",
      "Step: 20400  \tValid loss: 0.43378904461860657\n",
      "Step: 20500  \tTraining loss: 0.38661709427833557\n",
      "Step: 20500  \tTraining accuracy: 0.8048551678657532\n",
      "Step: 20500  \tValid loss: 0.43375861644744873\n",
      "Step: 20600  \tTraining loss: 0.38648292422294617\n",
      "Step: 20600  \tTraining accuracy: 0.8048683404922485\n",
      "Step: 20600  \tValid loss: 0.43373656272888184\n",
      "Step: 20700  \tTraining loss: 0.3863495886325836\n",
      "Step: 20700  \tTraining accuracy: 0.8048813939094543\n",
      "Step: 20700  \tValid loss: 0.43373048305511475\n",
      "Step: 20800  \tTraining loss: 0.38621655106544495\n",
      "Step: 20800  \tTraining accuracy: 0.8048943281173706\n",
      "Step: 20800  \tValid loss: 0.43370139598846436\n",
      "Step: 20900  \tTraining loss: 0.38608381152153015\n",
      "Step: 20900  \tTraining accuracy: 0.8049057722091675\n",
      "Step: 20900  \tValid loss: 0.4336719214916229\n",
      "Step: 21000  \tTraining loss: 0.3859512507915497\n",
      "Step: 21000  \tTraining accuracy: 0.8049171566963196\n",
      "Step: 21000  \tValid loss: 0.4336339235305786\n",
      "Step: 21100  \tTraining loss: 0.38581952452659607\n",
      "Step: 21100  \tTraining accuracy: 0.8049284219741821\n",
      "Step: 21100  \tValid loss: 0.43365806341171265\n",
      "Step: 21200  \tTraining loss: 0.3856879472732544\n",
      "Step: 21200  \tTraining accuracy: 0.8049395680427551\n",
      "Step: 21200  \tValid loss: 0.43363916873931885\n",
      "Step: 21300  \tTraining loss: 0.3855569660663605\n",
      "Step: 21300  \tTraining accuracy: 0.8049492835998535\n",
      "Step: 21300  \tValid loss: 0.4335743188858032\n",
      "Step: 21400  \tTraining loss: 0.3854261040687561\n",
      "Step: 21400  \tTraining accuracy: 0.8049602508544922\n",
      "Step: 21400  \tValid loss: 0.4336390197277069\n",
      "Step: 21500  \tTraining loss: 0.385296106338501\n",
      "Step: 21500  \tTraining accuracy: 0.8049723505973816\n",
      "Step: 21500  \tValid loss: 0.4336337149143219\n",
      "Step: 21600  \tTraining loss: 0.38516655564308167\n",
      "Step: 21600  \tTraining accuracy: 0.8049843907356262\n",
      "Step: 21600  \tValid loss: 0.43362870812416077\n",
      "Step: 21700  \tTraining loss: 0.38503754138946533\n",
      "Step: 21700  \tTraining accuracy: 0.8049963116645813\n",
      "Step: 21700  \tValid loss: 0.4336302578449249\n",
      "Step: 21800  \tTraining loss: 0.3849087655544281\n",
      "Step: 21800  \tTraining accuracy: 0.8050081133842468\n",
      "Step: 21800  \tValid loss: 0.4336008131504059\n",
      "Step: 21900  \tTraining loss: 0.38478249311447144\n",
      "Step: 21900  \tTraining accuracy: 0.8050312995910645\n",
      "Step: 21900  \tValid loss: 0.4334518313407898\n",
      "Step: 22000  \tTraining loss: 0.38465288281440735\n",
      "Step: 22000  \tTraining accuracy: 0.8050516843795776\n",
      "Step: 22000  \tValid loss: 0.4336015284061432\n",
      "Step: 22100  \tTraining loss: 0.38452577590942383\n",
      "Step: 22100  \tTraining accuracy: 0.8050718903541565\n",
      "Step: 22100  \tValid loss: 0.43358513712882996\n",
      "Step: 22200  \tTraining loss: 0.38439932465553284\n",
      "Step: 22200  \tTraining accuracy: 0.8050931692123413\n",
      "Step: 22200  \tValid loss: 0.4335857629776001\n",
      "Step: 22300  \tTraining loss: 0.3842734098434448\n",
      "Step: 22300  \tTraining accuracy: 0.8051155209541321\n",
      "Step: 22300  \tValid loss: 0.43361613154411316\n",
      "Step: 22400  \tTraining loss: 0.38414931297302246\n",
      "Step: 22400  \tTraining accuracy: 0.8051389455795288\n",
      "Step: 22400  \tValid loss: 0.4336632192134857\n",
      "Step: 22500  \tTraining loss: 0.38402315974235535\n",
      "Step: 22500  \tTraining accuracy: 0.8051633834838867\n",
      "Step: 22500  \tValid loss: 0.43366166949272156\n",
      "Step: 22600  \tTraining loss: 0.3838992714881897\n",
      "Step: 22600  \tTraining accuracy: 0.8051875829696655\n",
      "Step: 22600  \tValid loss: 0.43370598554611206\n",
      "Step: 22700  \tTraining loss: 0.38377660512924194\n",
      "Step: 22700  \tTraining accuracy: 0.8052127957344055\n",
      "Step: 22700  \tValid loss: 0.43379321694374084\n",
      "Step: 22800  \tTraining loss: 0.3836536407470703\n",
      "Step: 22800  \tTraining accuracy: 0.8052378296852112\n",
      "Step: 22800  \tValid loss: 0.43382543325424194\n",
      "Step: 22900  \tTraining loss: 0.3835311830043793\n",
      "Step: 22900  \tTraining accuracy: 0.805262565612793\n",
      "Step: 22900  \tValid loss: 0.4337819814682007\n",
      "Step: 23000  \tTraining loss: 0.38340988755226135\n",
      "Step: 23000  \tTraining accuracy: 0.8052871823310852\n",
      "Step: 23000  \tValid loss: 0.4338305592536926\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8053103\n",
      "Precision: 0.8484188\n",
      "Recall: 0.8294243\n",
      "F1 score: 0.7961936\n",
      "AUC: 0.83389825\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0   0.80531   0.848419  0.829424  0.796194  0.833898  0.383362      0.805249   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.433441        0.80525   0.534588      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  23040.0  \n",
      "15\n",
      "(870, 4)\n",
      "(870, 1)\n",
      "(480, 4)\n",
      "(480, 1)\n",
      "(390, 4)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5663670897483826\n",
      "Step: 100  \tTraining accuracy: 0.7103448510169983\n",
      "Step: 100  \tValid loss: 0.5716964602470398\n",
      "Step: 200  \tTraining loss: 0.549081027507782\n",
      "Step: 200  \tTraining accuracy: 0.7122605443000793\n",
      "Step: 200  \tValid loss: 0.5593273639678955\n",
      "Step: 300  \tTraining loss: 0.5380834341049194\n",
      "Step: 300  \tTraining accuracy: 0.7165517210960388\n",
      "Step: 300  \tValid loss: 0.5513375401496887\n",
      "Step: 400  \tTraining loss: 0.5294469594955444\n",
      "Step: 400  \tTraining accuracy: 0.7218390703201294\n",
      "Step: 400  \tValid loss: 0.5426968932151794\n",
      "Step: 500  \tTraining loss: 0.5200627446174622\n",
      "Step: 500  \tTraining accuracy: 0.7270753383636475\n",
      "Step: 500  \tValid loss: 0.5318461060523987\n",
      "Step: 600  \tTraining loss: 0.5098690986633301\n",
      "Step: 600  \tTraining accuracy: 0.7311390042304993\n",
      "Step: 600  \tValid loss: 0.5198260545730591\n",
      "Step: 700  \tTraining loss: 0.49922049045562744\n",
      "Step: 700  \tTraining accuracy: 0.735366940498352\n",
      "Step: 700  \tValid loss: 0.5071104764938354\n",
      "Step: 800  \tTraining loss: 0.48847106099128723\n",
      "Step: 800  \tTraining accuracy: 0.7394636273384094\n",
      "Step: 800  \tValid loss: 0.4944089651107788\n",
      "Step: 900  \tTraining loss: 0.4780034124851227\n",
      "Step: 900  \tTraining accuracy: 0.7430020570755005\n",
      "Step: 900  \tValid loss: 0.48218852281570435\n",
      "Step: 1000  \tTraining loss: 0.4680749773979187\n",
      "Step: 1000  \tTraining accuracy: 0.7457955479621887\n",
      "Step: 1000  \tValid loss: 0.4710875451564789\n",
      "Step: 1100  \tTraining loss: 0.45920053124427795\n",
      "Step: 1100  \tTraining accuracy: 0.7484948039054871\n",
      "Step: 1100  \tValid loss: 0.4610092043876648\n",
      "Step: 1200  \tTraining loss: 0.4515668749809265\n",
      "Step: 1200  \tTraining accuracy: 0.7511743903160095\n",
      "Step: 1200  \tValid loss: 0.4524651765823364\n",
      "Step: 1300  \tTraining loss: 0.44548726081848145\n",
      "Step: 1300  \tTraining accuracy: 0.7537471055984497\n",
      "Step: 1300  \tValid loss: 0.44561782479286194\n",
      "Step: 1400  \tTraining loss: 0.4408033490180969\n",
      "Step: 1400  \tTraining accuracy: 0.7557684183120728\n",
      "Step: 1400  \tValid loss: 0.4402139484882355\n",
      "Step: 1500  \tTraining loss: 0.4370821416378021\n",
      "Step: 1500  \tTraining accuracy: 0.7574316263198853\n",
      "Step: 1500  \tValid loss: 0.43588241934776306\n",
      "Step: 1600  \tTraining loss: 0.4340972304344177\n",
      "Step: 1600  \tTraining accuracy: 0.7590285539627075\n",
      "Step: 1600  \tValid loss: 0.4325559735298157\n",
      "Step: 1700  \tTraining loss: 0.43165454268455505\n",
      "Step: 1700  \tTraining accuracy: 0.7603622674942017\n",
      "Step: 1700  \tValid loss: 0.4299660623073578\n",
      "Step: 1800  \tTraining loss: 0.42960795760154724\n",
      "Step: 1800  \tTraining accuracy: 0.7616420388221741\n",
      "Step: 1800  \tValid loss: 0.4278419613838196\n",
      "Step: 1900  \tTraining loss: 0.42769259214401245\n",
      "Step: 1900  \tTraining accuracy: 0.7627524137496948\n",
      "Step: 1900  \tValid loss: 0.4261151850223541\n",
      "Step: 2000  \tTraining loss: 0.426005095243454\n",
      "Step: 2000  \tTraining accuracy: 0.7638078331947327\n",
      "Step: 2000  \tValid loss: 0.42461591958999634\n",
      "Step: 2100  \tTraining loss: 0.4245509207248688\n",
      "Step: 2100  \tTraining accuracy: 0.7648163437843323\n",
      "Step: 2100  \tValid loss: 0.4234127700328827\n",
      "Step: 2200  \tTraining loss: 0.4231894016265869\n",
      "Step: 2200  \tTraining accuracy: 0.7656241655349731\n",
      "Step: 2200  \tValid loss: 0.42246177792549133\n",
      "Step: 2300  \tTraining loss: 0.4219151735305786\n",
      "Step: 2300  \tTraining accuracy: 0.7664623260498047\n",
      "Step: 2300  \tValid loss: 0.42156651616096497\n",
      "Step: 2400  \tTraining loss: 0.42064952850341797\n",
      "Step: 2400  \tTraining accuracy: 0.7672780752182007\n",
      "Step: 2400  \tValid loss: 0.42080581188201904\n",
      "Step: 2500  \tTraining loss: 0.41938045620918274\n",
      "Step: 2500  \tTraining accuracy: 0.7679802775382996\n",
      "Step: 2500  \tValid loss: 0.4201619327068329\n",
      "Step: 2600  \tTraining loss: 0.4180666506290436\n",
      "Step: 2600  \tTraining accuracy: 0.7686049342155457\n",
      "Step: 2600  \tValid loss: 0.4194483458995819\n",
      "Step: 2700  \tTraining loss: 0.4167380630970001\n",
      "Step: 2700  \tTraining accuracy: 0.7692474722862244\n",
      "Step: 2700  \tValid loss: 0.41901299357414246\n",
      "Step: 2800  \tTraining loss: 0.4153854548931122\n",
      "Step: 2800  \tTraining accuracy: 0.7699059844017029\n",
      "Step: 2800  \tValid loss: 0.4185377061367035\n",
      "Step: 2900  \tTraining loss: 0.41403114795684814\n",
      "Step: 2900  \tTraining accuracy: 0.7704980969429016\n",
      "Step: 2900  \tValid loss: 0.4181802570819855\n",
      "Step: 3000  \tTraining loss: 0.41268426179885864\n",
      "Step: 3000  \tTraining accuracy: 0.7710111141204834\n",
      "Step: 3000  \tValid loss: 0.4178958535194397\n",
      "Step: 3100  \tTraining loss: 0.4113227128982544\n",
      "Step: 3100  \tTraining accuracy: 0.7715281844139099\n",
      "Step: 3100  \tValid loss: 0.41768378019332886\n",
      "Step: 3200  \tTraining loss: 0.41003113985061646\n",
      "Step: 3200  \tTraining accuracy: 0.7720306515693665\n",
      "Step: 3200  \tValid loss: 0.41755661368370056\n",
      "Step: 3300  \tTraining loss: 0.40878674387931824\n",
      "Step: 3300  \tTraining accuracy: 0.7725198864936829\n",
      "Step: 3300  \tValid loss: 0.4175289273262024\n",
      "Step: 3400  \tTraining loss: 0.40765538811683655\n",
      "Step: 3400  \tTraining accuracy: 0.7730485796928406\n",
      "Step: 3400  \tValid loss: 0.4175752103328705\n",
      "Step: 3500  \tTraining loss: 0.40665411949157715\n",
      "Step: 3500  \tTraining accuracy: 0.773546576499939\n",
      "Step: 3500  \tValid loss: 0.41764405369758606\n",
      "Step: 3600  \tTraining loss: 0.40577036142349243\n",
      "Step: 3600  \tTraining accuracy: 0.7740488648414612\n",
      "Step: 3600  \tValid loss: 0.41784217953681946\n",
      "Step: 3700  \tTraining loss: 0.40497663617134094\n",
      "Step: 3700  \tTraining accuracy: 0.7745236754417419\n",
      "Step: 3700  \tValid loss: 0.4180798828601837\n",
      "Step: 3800  \tTraining loss: 0.40430527925491333\n",
      "Step: 3800  \tTraining accuracy: 0.7749885320663452\n",
      "Step: 3800  \tValid loss: 0.4183724820613861\n",
      "Step: 3900  \tTraining loss: 0.40372928977012634\n",
      "Step: 3900  \tTraining accuracy: 0.7754291892051697\n",
      "Step: 3900  \tValid loss: 0.4187256693840027\n",
      "Step: 4000  \tTraining loss: 0.40323007106781006\n",
      "Step: 4000  \tTraining accuracy: 0.7758620977401733\n",
      "Step: 4000  \tValid loss: 0.418948233127594\n",
      "Step: 4100  \tTraining loss: 0.4027271866798401\n",
      "Step: 4100  \tTraining accuracy: 0.7763161659240723\n",
      "Step: 4100  \tValid loss: 0.4193750321865082\n",
      "Step: 4200  \tTraining loss: 0.40230974555015564\n",
      "Step: 4200  \tTraining accuracy: 0.7767345309257507\n",
      "Step: 4200  \tValid loss: 0.4197121858596802\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7771467\n",
      "Precision: 0.84876543\n",
      "Recall: 0.8899676\n",
      "F1 score: 0.79556245\n",
      "AUC: 0.75053936\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.777147   0.848765  0.889968  0.795562  0.750539  0.402127      0.776765   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.417473       0.776667   0.501179      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4244.0  \n",
      "16\n",
      "(1624, 4)\n",
      "(1624, 1)\n",
      "(880, 4)\n",
      "(880, 1)\n",
      "(715, 4)\n",
      "(715, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6627896428108215\n",
      "Step: 100  \tTraining accuracy: 0.6102216839790344\n",
      "Step: 100  \tValid loss: 0.6601206660270691\n",
      "Step: 200  \tTraining loss: 0.5904068946838379\n",
      "Step: 200  \tTraining accuracy: 0.6444352865219116\n",
      "Step: 200  \tValid loss: 0.5843443274497986\n",
      "Step: 300  \tTraining loss: 0.5061118006706238\n",
      "Step: 300  \tTraining accuracy: 0.6869263052940369\n",
      "Step: 300  \tValid loss: 0.49838995933532715\n",
      "Step: 400  \tTraining loss: 0.4389285445213318\n",
      "Step: 400  \tTraining accuracy: 0.7262654304504395\n",
      "Step: 400  \tValid loss: 0.42874589562416077\n",
      "Step: 500  \tTraining loss: 0.3936154842376709\n",
      "Step: 500  \tTraining accuracy: 0.7537931203842163\n",
      "Step: 500  \tValid loss: 0.380655974149704\n",
      "Step: 600  \tTraining loss: 0.37009143829345703\n",
      "Step: 600  \tTraining accuracy: 0.7717704176902771\n",
      "Step: 600  \tValid loss: 0.3550119698047638\n",
      "Step: 700  \tTraining loss: 0.36007246375083923\n",
      "Step: 700  \tTraining accuracy: 0.784506618976593\n",
      "Step: 700  \tValid loss: 0.3434164524078369\n",
      "Step: 800  \tTraining loss: 0.35491102933883667\n",
      "Step: 800  \tTraining accuracy: 0.7939313650131226\n",
      "Step: 800  \tValid loss: 0.3374010920524597\n",
      "Step: 900  \tTraining loss: 0.35169896483421326\n",
      "Step: 900  \tTraining accuracy: 0.8012858033180237\n",
      "Step: 900  \tValid loss: 0.33376869559288025\n",
      "Step: 1000  \tTraining loss: 0.3494062125682831\n",
      "Step: 1000  \tTraining accuracy: 0.8073868155479431\n",
      "Step: 1000  \tValid loss: 0.3313506245613098\n",
      "Step: 1100  \tTraining loss: 0.3475651144981384\n",
      "Step: 1100  \tTraining accuracy: 0.8122671246528625\n",
      "Step: 1100  \tValid loss: 0.3296019732952118\n",
      "Step: 1200  \tTraining loss: 0.3459758758544922\n",
      "Step: 1200  \tTraining accuracy: 0.8163529634475708\n",
      "Step: 1200  \tValid loss: 0.328143835067749\n",
      "Step: 1300  \tTraining loss: 0.3445545732975006\n",
      "Step: 1300  \tTraining accuracy: 0.8197605013847351\n",
      "Step: 1300  \tValid loss: 0.32689860463142395\n",
      "Step: 1400  \tTraining loss: 0.34331297874450684\n",
      "Step: 1400  \tTraining accuracy: 0.8226633667945862\n",
      "Step: 1400  \tValid loss: 0.32592344284057617\n",
      "Step: 1500  \tTraining loss: 0.34226351976394653\n",
      "Step: 1500  \tTraining accuracy: 0.8250803351402283\n",
      "Step: 1500  \tValid loss: 0.32502681016921997\n",
      "Step: 1600  \tTraining loss: 0.34133392572402954\n",
      "Step: 1600  \tTraining accuracy: 0.8272055387496948\n",
      "Step: 1600  \tValid loss: 0.3242615759372711\n",
      "Step: 1700  \tTraining loss: 0.34049078822135925\n",
      "Step: 1700  \tTraining accuracy: 0.8290543556213379\n",
      "Step: 1700  \tValid loss: 0.32354021072387695\n",
      "Step: 1800  \tTraining loss: 0.3397732377052307\n",
      "Step: 1800  \tTraining accuracy: 0.8307452201843262\n",
      "Step: 1800  \tValid loss: 0.32303017377853394\n",
      "Step: 1900  \tTraining loss: 0.3391733467578888\n",
      "Step: 1900  \tTraining accuracy: 0.8323204517364502\n",
      "Step: 1900  \tValid loss: 0.32258546352386475\n",
      "Step: 2000  \tTraining loss: 0.3386499285697937\n",
      "Step: 2000  \tTraining accuracy: 0.8337023258209229\n",
      "Step: 2000  \tValid loss: 0.32219067215919495\n",
      "Step: 2100  \tTraining loss: 0.33819279074668884\n",
      "Step: 2100  \tTraining accuracy: 0.8349190950393677\n",
      "Step: 2100  \tValid loss: 0.32184746861457825\n",
      "Step: 2200  \tTraining loss: 0.33778688311576843\n",
      "Step: 2200  \tTraining accuracy: 0.8360227346420288\n",
      "Step: 2200  \tValid loss: 0.3215463161468506\n",
      "Step: 2300  \tTraining loss: 0.33742469549179077\n",
      "Step: 2300  \tTraining accuracy: 0.8370696306228638\n",
      "Step: 2300  \tValid loss: 0.3212905824184418\n",
      "Step: 2400  \tTraining loss: 0.3371005356311798\n",
      "Step: 2400  \tTraining accuracy: 0.8380539417266846\n",
      "Step: 2400  \tValid loss: 0.32105013728141785\n",
      "Step: 2500  \tTraining loss: 0.33681100606918335\n",
      "Step: 2500  \tTraining accuracy: 0.838945209980011\n",
      "Step: 2500  \tValid loss: 0.3208354115486145\n",
      "Step: 2600  \tTraining loss: 0.33655184507369995\n",
      "Step: 2600  \tTraining accuracy: 0.8397666215896606\n",
      "Step: 2600  \tValid loss: 0.32063499093055725\n",
      "Step: 2700  \tTraining loss: 0.33631986379623413\n",
      "Step: 2700  \tTraining accuracy: 0.8405260443687439\n",
      "Step: 2700  \tValid loss: 0.3204759657382965\n",
      "Step: 2800  \tTraining loss: 0.3361135423183441\n",
      "Step: 2800  \tTraining accuracy: 0.8412415385246277\n",
      "Step: 2800  \tValid loss: 0.3203517496585846\n",
      "Step: 2900  \tTraining loss: 0.3359296917915344\n",
      "Step: 2900  \tTraining accuracy: 0.8419067859649658\n",
      "Step: 2900  \tValid loss: 0.32022133469581604\n",
      "Step: 3000  \tTraining loss: 0.33576586842536926\n",
      "Step: 3000  \tTraining accuracy: 0.8425269722938538\n",
      "Step: 3000  \tValid loss: 0.3201361298561096\n",
      "Step: 3100  \tTraining loss: 0.3356180489063263\n",
      "Step: 3100  \tTraining accuracy: 0.8430657386779785\n",
      "Step: 3100  \tValid loss: 0.3200730085372925\n",
      "Step: 3200  \tTraining loss: 0.33548468351364136\n",
      "Step: 3200  \tTraining accuracy: 0.8435506224632263\n",
      "Step: 3200  \tValid loss: 0.3200172185897827\n",
      "Step: 3300  \tTraining loss: 0.33536583185195923\n",
      "Step: 3300  \tTraining accuracy: 0.8440247774124146\n",
      "Step: 3300  \tValid loss: 0.3199754059314728\n",
      "Step: 3400  \tTraining loss: 0.33525919914245605\n",
      "Step: 3400  \tTraining accuracy: 0.8444706201553345\n",
      "Step: 3400  \tValid loss: 0.3199292719364166\n",
      "Step: 3500  \tTraining loss: 0.3351619243621826\n",
      "Step: 3500  \tTraining accuracy: 0.8448905944824219\n",
      "Step: 3500  \tValid loss: 0.31991133093833923\n",
      "Step: 3600  \tTraining loss: 0.33507195115089417\n",
      "Step: 3600  \tTraining accuracy: 0.8452694416046143\n",
      "Step: 3600  \tValid loss: 0.31989461183547974\n",
      "Step: 3700  \tTraining loss: 0.3349877595901489\n",
      "Step: 3700  \tTraining accuracy: 0.8456275463104248\n",
      "Step: 3700  \tValid loss: 0.3198925256729126\n",
      "Step: 3800  \tTraining loss: 0.33490750193595886\n",
      "Step: 3800  \tTraining accuracy: 0.8459665179252625\n",
      "Step: 3800  \tValid loss: 0.3199077248573303\n",
      "Step: 3900  \tTraining loss: 0.33482903242111206\n",
      "Step: 3900  \tTraining accuracy: 0.8462798595428467\n",
      "Step: 3900  \tValid loss: 0.31992098689079285\n",
      "Step: 4000  \tTraining loss: 0.3347516655921936\n",
      "Step: 4000  \tTraining accuracy: 0.8465851545333862\n",
      "Step: 4000  \tValid loss: 0.3199189305305481\n",
      "Step: 4100  \tTraining loss: 0.3346738815307617\n",
      "Step: 4100  \tTraining accuracy: 0.8468830585479736\n",
      "Step: 4100  \tValid loss: 0.31993567943573\n",
      "Step: 4200  \tTraining loss: 0.33459439873695374\n",
      "Step: 4200  \tTraining accuracy: 0.8471665978431702\n",
      "Step: 4200  \tValid loss: 0.3199511766433716\n",
      "Step: 4300  \tTraining loss: 0.3345125615596771\n",
      "Step: 4300  \tTraining accuracy: 0.8474368453025818\n",
      "Step: 4300  \tValid loss: 0.3199642598628998\n",
      "Step: 4400  \tTraining loss: 0.3344274163246155\n",
      "Step: 4400  \tTraining accuracy: 0.8476945757865906\n",
      "Step: 4400  \tValid loss: 0.31996825337409973\n",
      "Step: 4500  \tTraining loss: 0.3343372941017151\n",
      "Step: 4500  \tTraining accuracy: 0.8479408025741577\n",
      "Step: 4500  \tValid loss: 0.3199806809425354\n",
      "Step: 4600  \tTraining loss: 0.334242045879364\n",
      "Step: 4600  \tTraining accuracy: 0.8481898307800293\n",
      "Step: 4600  \tValid loss: 0.31997570395469666\n",
      "Step: 4700  \tTraining loss: 0.3341429829597473\n",
      "Step: 4700  \tTraining accuracy: 0.8484215140342712\n",
      "Step: 4700  \tValid loss: 0.3199930489063263\n",
      "Step: 4800  \tTraining loss: 0.3340407609939575\n",
      "Step: 4800  \tTraining accuracy: 0.8486433625221252\n",
      "Step: 4800  \tValid loss: 0.32001641392707825\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.84885615\n",
      "Precision: 0.84931505\n",
      "Recall: 0.8378378\n",
      "F1 score: 0.8430816\n",
      "AUC: 0.8567017\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.848856   0.849315  0.837838  0.843082  0.856702  0.333982      0.848756   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.319881       0.848651   0.346942      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4855.0  \n",
      "17\n",
      "(783, 4)\n",
      "(783, 1)\n",
      "(432, 4)\n",
      "(432, 1)\n",
      "(351, 4)\n",
      "(351, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4363342225551605\n",
      "Step: 100  \tTraining accuracy: 0.8339719176292419\n",
      "Step: 100  \tValid loss: 0.5343548655509949\n",
      "Step: 200  \tTraining loss: 0.40327760577201843\n",
      "Step: 200  \tTraining accuracy: 0.8152405023574829\n",
      "Step: 200  \tValid loss: 0.5561193823814392\n",
      "Step: 300  \tTraining loss: 0.39972105622291565\n",
      "Step: 300  \tTraining accuracy: 0.8122605085372925\n",
      "Step: 300  \tValid loss: 0.5604178309440613\n",
      "Step: 400  \tTraining loss: 0.3988604247570038\n",
      "Step: 400  \tTraining accuracy: 0.810983419418335\n",
      "Step: 400  \tValid loss: 0.562042772769928\n",
      "Step: 500  \tTraining loss: 0.3983170986175537\n",
      "Step: 500  \tTraining accuracy: 0.8105576634407043\n",
      "Step: 500  \tValid loss: 0.5623692870140076\n",
      "Step: 600  \tTraining loss: 0.3978290855884552\n",
      "Step: 600  \tTraining accuracy: 0.8102867603302002\n",
      "Step: 600  \tValid loss: 0.5623505711555481\n",
      "Step: 700  \tTraining loss: 0.3973633348941803\n",
      "Step: 700  \tTraining accuracy: 0.8100992441177368\n",
      "Step: 700  \tValid loss: 0.5621896386146545\n",
      "Step: 800  \tTraining loss: 0.3969131410121918\n",
      "Step: 800  \tTraining accuracy: 0.809876561164856\n",
      "Step: 800  \tValid loss: 0.5619531273841858\n",
      "Step: 900  \tTraining loss: 0.3964846134185791\n",
      "Step: 900  \tTraining accuracy: 0.8096311092376709\n",
      "Step: 900  \tValid loss: 0.5617275834083557\n",
      "Step: 1000  \tTraining loss: 0.39607691764831543\n",
      "Step: 1000  \tTraining accuracy: 0.8093701601028442\n",
      "Step: 1000  \tValid loss: 0.5614902973175049\n",
      "Step: 1100  \tTraining loss: 0.39568614959716797\n",
      "Step: 1100  \tTraining accuracy: 0.8092197179794312\n",
      "Step: 1100  \tValid loss: 0.5612600445747375\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.80909544\n",
      "Precision: 0.8404669\n",
      "Recall: 0.992343\n",
      "F1 score: 0.87614125\n",
      "AUC: 0.5230946\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.809095   0.840467  0.992343  0.876141  0.523095  0.395682      0.807849   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.534355       0.809098   0.463094      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  1100.0  \n",
      "18\n",
      "(1189, 4)\n",
      "(1189, 1)\n",
      "(640, 4)\n",
      "(640, 1)\n",
      "(520, 4)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5480197072029114\n",
      "Step: 100  \tTraining accuracy: 0.7846930027008057\n",
      "Step: 100  \tValid loss: 0.6008706092834473\n",
      "Step: 200  \tTraining loss: 0.5187016129493713\n",
      "Step: 200  \tTraining accuracy: 0.7685132622718811\n",
      "Step: 200  \tValid loss: 0.5786080360412598\n",
      "Step: 300  \tTraining loss: 0.501011073589325\n",
      "Step: 300  \tTraining accuracy: 0.7652454376220703\n",
      "Step: 300  \tValid loss: 0.5536907911300659\n",
      "Step: 400  \tTraining loss: 0.4936426281929016\n",
      "Step: 400  \tTraining accuracy: 0.7638416886329651\n",
      "Step: 400  \tValid loss: 0.5392381548881531\n",
      "Step: 500  \tTraining loss: 0.4909053444862366\n",
      "Step: 500  \tTraining accuracy: 0.7630609273910522\n",
      "Step: 500  \tValid loss: 0.532061755657196\n",
      "Step: 600  \tTraining loss: 0.48998382687568665\n",
      "Step: 600  \tTraining accuracy: 0.7625637650489807\n",
      "Step: 600  \tValid loss: 0.5299299955368042\n",
      "Step: 700  \tTraining loss: 0.48927101492881775\n",
      "Step: 700  \tTraining accuracy: 0.7622194886207581\n",
      "Step: 700  \tValid loss: 0.5288317799568176\n",
      "Step: 800  \tTraining loss: 0.48853498697280884\n",
      "Step: 800  \tTraining accuracy: 0.7619668841362\n",
      "Step: 800  \tValid loss: 0.5282525420188904\n",
      "Step: 900  \tTraining loss: 0.48765555024147034\n",
      "Step: 900  \tTraining accuracy: 0.7617737054824829\n",
      "Step: 900  \tValid loss: 0.5278060436248779\n",
      "Step: 1000  \tTraining loss: 0.4865133762359619\n",
      "Step: 1000  \tTraining accuracy: 0.761665940284729\n",
      "Step: 1000  \tValid loss: 0.5272303819656372\n",
      "Step: 1100  \tTraining loss: 0.48510706424713135\n",
      "Step: 1100  \tTraining accuracy: 0.7615381479263306\n",
      "Step: 1100  \tValid loss: 0.52530437707901\n",
      "Step: 1200  \tTraining loss: 0.4840223789215088\n",
      "Step: 1200  \tTraining accuracy: 0.7613955736160278\n",
      "Step: 1200  \tValid loss: 0.5250610113143921\n",
      "Step: 1300  \tTraining loss: 0.483330637216568\n",
      "Step: 1300  \tTraining accuracy: 0.7612077593803406\n",
      "Step: 1300  \tValid loss: 0.5255383849143982\n",
      "Step: 1400  \tTraining loss: 0.48290497064590454\n",
      "Step: 1400  \tTraining accuracy: 0.761110782623291\n",
      "Step: 1400  \tValid loss: 0.5264540910720825\n",
      "Step: 1500  \tTraining loss: 0.48264187574386597\n",
      "Step: 1500  \tTraining accuracy: 0.7610564827919006\n",
      "Step: 1500  \tValid loss: 0.5266175270080566\n",
      "Step: 1600  \tTraining loss: 0.4824436902999878\n",
      "Step: 1600  \tTraining accuracy: 0.7609817981719971\n",
      "Step: 1600  \tValid loss: 0.5266973972320557\n",
      "Step: 1700  \tTraining loss: 0.4822801351547241\n",
      "Step: 1700  \tTraining accuracy: 0.7609161138534546\n",
      "Step: 1700  \tValid loss: 0.5265339016914368\n",
      "Step: 1800  \tTraining loss: 0.48212090134620667\n",
      "Step: 1800  \tTraining accuracy: 0.7608579397201538\n",
      "Step: 1800  \tValid loss: 0.5262963175773621\n",
      "Step: 1900  \tTraining loss: 0.48197105526924133\n",
      "Step: 1900  \tTraining accuracy: 0.7607830762863159\n",
      "Step: 1900  \tValid loss: 0.5262834429740906\n",
      "Step: 2000  \tTraining loss: 0.48182472586631775\n",
      "Step: 2000  \tTraining accuracy: 0.7607158422470093\n",
      "Step: 2000  \tValid loss: 0.5261573791503906\n",
      "Step: 2100  \tTraining loss: 0.48168158531188965\n",
      "Step: 2100  \tTraining accuracy: 0.7606551647186279\n",
      "Step: 2100  \tValid loss: 0.5260471105575562\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7606002\n",
      "Precision: 0.78746825\n",
      "Recall: 0.99678457\n",
      "F1 score: 0.8498286\n",
      "AUC: 0.5081579\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0    0.7606   0.787468  0.996785  0.849829  0.508158  0.481628      0.759979   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.524883       0.760398   0.530231      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2138.0  \n",
      "19\n",
      "(899, 4)\n",
      "(899, 1)\n",
      "(480, 4)\n",
      "(480, 1)\n",
      "(390, 4)\n",
      "(390, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.44772613048553467\n",
      "Step: 100  \tTraining accuracy: 0.8264738321304321\n",
      "Step: 100  \tValid loss: 0.45403656363487244\n",
      "Step: 200  \tTraining loss: 0.43989840149879456\n",
      "Step: 200  \tTraining accuracy: 0.8294602632522583\n",
      "Step: 200  \tValid loss: 0.45225557684898376\n",
      "Step: 300  \tTraining loss: 0.4386059641838074\n",
      "Step: 300  \tTraining accuracy: 0.8300653696060181\n",
      "Step: 300  \tValid loss: 0.45121219754219055\n",
      "Step: 400  \tTraining loss: 0.4373738765716553\n",
      "Step: 400  \tTraining accuracy: 0.8303254842758179\n",
      "Step: 400  \tValid loss: 0.4502234160900116\n",
      "Step: 500  \tTraining loss: 0.43612322211265564\n",
      "Step: 500  \tTraining accuracy: 0.8304702043533325\n",
      "Step: 500  \tValid loss: 0.44915062189102173\n",
      "Step: 600  \tTraining loss: 0.43496230244636536\n",
      "Step: 600  \tTraining accuracy: 0.8305624127388\n",
      "Step: 600  \tValid loss: 0.44850799441337585\n",
      "Step: 700  \tTraining loss: 0.43389567732810974\n",
      "Step: 700  \tTraining accuracy: 0.8306262493133545\n",
      "Step: 700  \tValid loss: 0.4478079676628113\n",
      "Step: 800  \tTraining loss: 0.43285465240478516\n",
      "Step: 800  \tTraining accuracy: 0.830673098564148\n",
      "Step: 800  \tValid loss: 0.4471000134944916\n",
      "Step: 900  \tTraining loss: 0.431932657957077\n",
      "Step: 900  \tTraining accuracy: 0.8307753801345825\n",
      "Step: 900  \tValid loss: 0.44680655002593994\n",
      "Step: 1000  \tTraining loss: 0.43099361658096313\n",
      "Step: 1000  \tTraining accuracy: 0.8309155702590942\n",
      "Step: 1000  \tValid loss: 0.4464431703090668\n",
      "Step: 1100  \tTraining loss: 0.43017813563346863\n",
      "Step: 1100  \tTraining accuracy: 0.8310828804969788\n",
      "Step: 1100  \tValid loss: 0.44622039794921875\n",
      "Step: 1200  \tTraining loss: 0.42963674664497375\n",
      "Step: 1200  \tTraining accuracy: 0.8314667344093323\n",
      "Step: 1200  \tValid loss: 0.44643837213516235\n",
      "Step: 1300  \tTraining loss: 0.429193913936615\n",
      "Step: 1300  \tTraining accuracy: 0.8318344354629517\n",
      "Step: 1300  \tValid loss: 0.4467141032218933\n",
      "Step: 1400  \tTraining loss: 0.42881348729133606\n",
      "Step: 1400  \tTraining accuracy: 0.8321476578712463\n",
      "Step: 1400  \tValid loss: 0.4470347762107849\n",
      "Step: 1500  \tTraining loss: 0.42847341299057007\n",
      "Step: 1500  \tTraining accuracy: 0.8323787450790405\n",
      "Step: 1500  \tValid loss: 0.44739580154418945\n",
      "Step: 1600  \tTraining loss: 0.42815667390823364\n",
      "Step: 1600  \tTraining accuracy: 0.8323977589607239\n",
      "Step: 1600  \tValid loss: 0.4477675259113312\n",
      "Step: 1700  \tTraining loss: 0.42785799503326416\n",
      "Step: 1700  \tTraining accuracy: 0.8323459625244141\n",
      "Step: 1700  \tValid loss: 0.4481515884399414\n",
      "Step: 1800  \tTraining loss: 0.4275689125061035\n",
      "Step: 1800  \tTraining accuracy: 0.83223557472229\n",
      "Step: 1800  \tValid loss: 0.4484640657901764\n",
      "Step: 1900  \tTraining loss: 0.42727914452552795\n",
      "Step: 1900  \tTraining accuracy: 0.8321370482444763\n",
      "Step: 1900  \tValid loss: 0.44876497983932495\n",
      "Step: 2000  \tTraining loss: 0.42698433995246887\n",
      "Step: 2000  \tTraining accuracy: 0.8320486545562744\n",
      "Step: 2000  \tValid loss: 0.44906944036483765\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8319689\n",
      "Precision: 0.8306998\n",
      "Recall: 0.9905787\n",
      "F1 score: 0.9050023\n",
      "AUC: 0.5145201\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0  0.831969     0.8307  0.990579  0.905002  0.51452  0.426919      0.832137   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.446039        0.83235   0.402898      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2021.0  \n",
      "20\n",
      "(899, 4)\n",
      "(899, 1)\n",
      "(496, 4)\n",
      "(496, 1)\n",
      "(403, 4)\n",
      "(403, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.632557213306427\n",
      "Step: 100  \tTraining accuracy: 0.6696329116821289\n",
      "Step: 100  \tValid loss: 0.6264060735702515\n",
      "Step: 200  \tTraining loss: 0.5870394110679626\n",
      "Step: 200  \tTraining accuracy: 0.6714868545532227\n",
      "Step: 200  \tValid loss: 0.5829775333404541\n",
      "Step: 300  \tTraining loss: 0.554046630859375\n",
      "Step: 300  \tTraining accuracy: 0.6823136806488037\n",
      "Step: 300  \tValid loss: 0.5523476600646973\n",
      "Step: 400  \tTraining loss: 0.521101713180542\n",
      "Step: 400  \tTraining accuracy: 0.6934689283370972\n",
      "Step: 400  \tValid loss: 0.5233381390571594\n",
      "Step: 500  \tTraining loss: 0.49303436279296875\n",
      "Step: 500  \tTraining accuracy: 0.704733669757843\n",
      "Step: 500  \tValid loss: 0.5002983808517456\n",
      "Step: 600  \tTraining loss: 0.47347456216812134\n",
      "Step: 600  \tTraining accuracy: 0.7145313024520874\n",
      "Step: 600  \tValid loss: 0.4857975244522095\n",
      "Step: 700  \tTraining loss: 0.4619712233543396\n",
      "Step: 700  \tTraining accuracy: 0.7213142514228821\n",
      "Step: 700  \tValid loss: 0.47906190156936646\n",
      "Step: 800  \tTraining loss: 0.4558727443218231\n",
      "Step: 800  \tTraining accuracy: 0.7265109419822693\n",
      "Step: 800  \tValid loss: 0.4771065413951874\n",
      "Step: 900  \tTraining loss: 0.4527442157268524\n",
      "Step: 900  \tTraining accuracy: 0.7308120131492615\n",
      "Step: 900  \tValid loss: 0.47731342911720276\n",
      "Step: 1000  \tTraining loss: 0.45097580552101135\n",
      "Step: 1000  \tTraining accuracy: 0.7341490387916565\n",
      "Step: 1000  \tValid loss: 0.4780227541923523\n",
      "Step: 1100  \tTraining loss: 0.44984129071235657\n",
      "Step: 1100  \tTraining accuracy: 0.7368504405021667\n",
      "Step: 1100  \tValid loss: 0.47842928767204285\n",
      "Step: 1200  \tTraining loss: 0.4483857750892639\n",
      "Step: 1200  \tTraining accuracy: 0.7392271757125854\n",
      "Step: 1200  \tValid loss: 0.47746914625167847\n",
      "Step: 1300  \tTraining loss: 0.44689875841140747\n",
      "Step: 1300  \tTraining accuracy: 0.7412235736846924\n",
      "Step: 1300  \tValid loss: 0.47664278745651245\n",
      "Step: 1400  \tTraining loss: 0.44578081369400024\n",
      "Step: 1400  \tTraining accuracy: 0.742883026599884\n",
      "Step: 1400  \tValid loss: 0.4761619567871094\n",
      "Step: 1500  \tTraining loss: 0.44466668367385864\n",
      "Step: 1500  \tTraining accuracy: 0.7443135976791382\n",
      "Step: 1500  \tValid loss: 0.47530239820480347\n",
      "Step: 1600  \tTraining loss: 0.4434778392314911\n",
      "Step: 1600  \tTraining accuracy: 0.7455954551696777\n",
      "Step: 1600  \tValid loss: 0.47439390420913696\n",
      "Step: 1700  \tTraining loss: 0.44271066784858704\n",
      "Step: 1700  \tTraining accuracy: 0.7467893362045288\n",
      "Step: 1700  \tValid loss: 0.4743519425392151\n",
      "Step: 1800  \tTraining loss: 0.44205695390701294\n",
      "Step: 1800  \tTraining accuracy: 0.7479103803634644\n",
      "Step: 1800  \tValid loss: 0.4739915132522583\n",
      "Step: 1900  \tTraining loss: 0.4414166808128357\n",
      "Step: 1900  \tTraining accuracy: 0.7488500475883484\n",
      "Step: 1900  \tValid loss: 0.47349581122398376\n",
      "Step: 2000  \tTraining loss: 0.4408402442932129\n",
      "Step: 2000  \tTraining accuracy: 0.7496363520622253\n",
      "Step: 2000  \tValid loss: 0.47288379073143005\n",
      "Step: 2100  \tTraining loss: 0.44034114480018616\n",
      "Step: 2100  \tTraining accuracy: 0.7503730654716492\n",
      "Step: 2100  \tValid loss: 0.4724828600883484\n",
      "Step: 2200  \tTraining loss: 0.43987205624580383\n",
      "Step: 2200  \tTraining accuracy: 0.7510671019554138\n",
      "Step: 2200  \tValid loss: 0.47194647789001465\n",
      "Step: 2300  \tTraining loss: 0.4394162595272064\n",
      "Step: 2300  \tTraining accuracy: 0.751724123954773\n",
      "Step: 2300  \tValid loss: 0.47158241271972656\n",
      "Step: 2400  \tTraining loss: 0.43881216645240784\n",
      "Step: 2400  \tTraining accuracy: 0.7523252964019775\n",
      "Step: 2400  \tValid loss: 0.47057729959487915\n",
      "Step: 2500  \tTraining loss: 0.4379687011241913\n",
      "Step: 2500  \tTraining accuracy: 0.7529454231262207\n",
      "Step: 2500  \tValid loss: 0.46953269839286804\n",
      "Step: 2600  \tTraining loss: 0.43722444772720337\n",
      "Step: 2600  \tTraining accuracy: 0.7536914944648743\n",
      "Step: 2600  \tValid loss: 0.469950407743454\n",
      "Step: 2700  \tTraining loss: 0.43679413199424744\n",
      "Step: 2700  \tTraining accuracy: 0.7543811798095703\n",
      "Step: 2700  \tValid loss: 0.4701451063156128\n",
      "Step: 2800  \tTraining loss: 0.4363931715488434\n",
      "Step: 2800  \tTraining accuracy: 0.7551016211509705\n",
      "Step: 2800  \tValid loss: 0.4699240028858185\n",
      "Step: 2900  \tTraining loss: 0.43589502573013306\n",
      "Step: 2900  \tTraining accuracy: 0.755810558795929\n",
      "Step: 2900  \tValid loss: 0.4688819944858551\n",
      "Step: 3000  \tTraining loss: 0.4354375898838043\n",
      "Step: 3000  \tTraining accuracy: 0.7564713954925537\n",
      "Step: 3000  \tValid loss: 0.4683198034763336\n",
      "Step: 3100  \tTraining loss: 0.4349288046360016\n",
      "Step: 3100  \tTraining accuracy: 0.7571436166763306\n",
      "Step: 3100  \tValid loss: 0.46752074360847473\n",
      "Step: 3200  \tTraining loss: 0.4342433214187622\n",
      "Step: 3200  \tTraining accuracy: 0.7577555179595947\n",
      "Step: 3200  \tValid loss: 0.46628648042678833\n",
      "Step: 3300  \tTraining loss: 0.4338083267211914\n",
      "Step: 3300  \tTraining accuracy: 0.7583468556404114\n",
      "Step: 3300  \tValid loss: 0.4663807451725006\n",
      "Step: 3400  \tTraining loss: 0.4334709048271179\n",
      "Step: 3400  \tTraining accuracy: 0.758902907371521\n",
      "Step: 3400  \tValid loss: 0.46660473942756653\n",
      "Step: 3500  \tTraining loss: 0.43315890431404114\n",
      "Step: 3500  \tTraining accuracy: 0.7594589591026306\n",
      "Step: 3500  \tValid loss: 0.46644043922424316\n",
      "Step: 3600  \tTraining loss: 0.4328669011592865\n",
      "Step: 3600  \tTraining accuracy: 0.7599837183952332\n",
      "Step: 3600  \tValid loss: 0.46610620617866516\n",
      "Step: 3700  \tTraining loss: 0.4325934648513794\n",
      "Step: 3700  \tTraining accuracy: 0.760449230670929\n",
      "Step: 3700  \tValid loss: 0.4657632112503052\n",
      "Step: 3800  \tTraining loss: 0.43232104182243347\n",
      "Step: 3800  \tTraining accuracy: 0.7608750462532043\n",
      "Step: 3800  \tValid loss: 0.4653674364089966\n",
      "Step: 3900  \tTraining loss: 0.432073712348938\n",
      "Step: 3900  \tTraining accuracy: 0.7613076567649841\n",
      "Step: 3900  \tValid loss: 0.4650898575782776\n",
      "Step: 4000  \tTraining loss: 0.43185025453567505\n",
      "Step: 4000  \tTraining accuracy: 0.7617183923721313\n",
      "Step: 4000  \tValid loss: 0.4651067852973938\n",
      "Step: 4100  \tTraining loss: 0.4316421151161194\n",
      "Step: 4100  \tTraining accuracy: 0.7621362805366516\n",
      "Step: 4100  \tValid loss: 0.4650738537311554\n",
      "Step: 4200  \tTraining loss: 0.4314509928226471\n",
      "Step: 4200  \tTraining accuracy: 0.7625072002410889\n",
      "Step: 4200  \tValid loss: 0.4649721086025238\n",
      "Step: 4300  \tTraining loss: 0.43128010630607605\n",
      "Step: 4300  \tTraining accuracy: 0.7628607153892517\n",
      "Step: 4300  \tValid loss: 0.4649297893047333\n",
      "Step: 4400  \tTraining loss: 0.43112912774086\n",
      "Step: 4400  \tTraining accuracy: 0.7631979584693909\n",
      "Step: 4400  \tValid loss: 0.464947372674942\n",
      "Step: 4500  \tTraining loss: 0.4309650957584381\n",
      "Step: 4500  \tTraining accuracy: 0.7635200023651123\n",
      "Step: 4500  \tValid loss: 0.46446555852890015\n",
      "Step: 4600  \tTraining loss: 0.43081575632095337\n",
      "Step: 4600  \tTraining accuracy: 0.763827919960022\n",
      "Step: 4600  \tValid loss: 0.46417900919914246\n",
      "Step: 4700  \tTraining loss: 0.43067991733551025\n",
      "Step: 4700  \tTraining accuracy: 0.7641106843948364\n",
      "Step: 4700  \tValid loss: 0.4641283452510834\n",
      "Step: 4800  \tTraining loss: 0.4305534362792969\n",
      "Step: 4800  \tTraining accuracy: 0.764381468296051\n",
      "Step: 4800  \tValid loss: 0.46404320001602173\n",
      "Step: 4900  \tTraining loss: 0.43043607473373413\n",
      "Step: 4900  \tTraining accuracy: 0.7646526098251343\n",
      "Step: 4900  \tValid loss: 0.4639638364315033\n",
      "Step: 5000  \tTraining loss: 0.43032926321029663\n",
      "Step: 5000  \tTraining accuracy: 0.7649015188217163\n",
      "Step: 5000  \tValid loss: 0.4638778567314148\n",
      "Step: 5100  \tTraining loss: 0.43022963404655457\n",
      "Step: 5100  \tTraining accuracy: 0.7651405930519104\n",
      "Step: 5100  \tValid loss: 0.46378839015960693\n",
      "Step: 5200  \tTraining loss: 0.4301286041736603\n",
      "Step: 5200  \tTraining accuracy: 0.7653703689575195\n",
      "Step: 5200  \tValid loss: 0.46364426612854004\n",
      "Step: 5300  \tTraining loss: 0.43004512786865234\n",
      "Step: 5300  \tTraining accuracy: 0.7655913829803467\n",
      "Step: 5300  \tValid loss: 0.4637288451194763\n",
      "Step: 5400  \tTraining loss: 0.4299641251564026\n",
      "Step: 5400  \tTraining accuracy: 0.7658041715621948\n",
      "Step: 5400  \tValid loss: 0.4636921286582947\n",
      "Step: 5500  \tTraining loss: 0.42988744378089905\n",
      "Step: 5500  \tTraining accuracy: 0.7660091519355774\n",
      "Step: 5500  \tValid loss: 0.4636261463165283\n",
      "Step: 5600  \tTraining loss: 0.4298139214515686\n",
      "Step: 5600  \tTraining accuracy: 0.7661966681480408\n",
      "Step: 5600  \tValid loss: 0.4635917842388153\n",
      "Step: 5700  \tTraining loss: 0.4297429025173187\n",
      "Step: 5700  \tTraining accuracy: 0.766387403011322\n",
      "Step: 5700  \tValid loss: 0.4635506868362427\n",
      "Step: 5800  \tTraining loss: 0.429673433303833\n",
      "Step: 5800  \tTraining accuracy: 0.7665812373161316\n",
      "Step: 5800  \tValid loss: 0.46351125836372375\n",
      "Step: 5900  \tTraining loss: 0.429605633020401\n",
      "Step: 5900  \tTraining accuracy: 0.7667683959007263\n",
      "Step: 5900  \tValid loss: 0.46347302198410034\n",
      "Step: 6000  \tTraining loss: 0.42954006791114807\n",
      "Step: 6000  \tTraining accuracy: 0.7669585943222046\n",
      "Step: 6000  \tValid loss: 0.46344393491744995\n",
      "Step: 6100  \tTraining loss: 0.429477334022522\n",
      "Step: 6100  \tTraining accuracy: 0.7671517729759216\n",
      "Step: 6100  \tValid loss: 0.4634350836277008\n",
      "Step: 6200  \tTraining loss: 0.4294142723083496\n",
      "Step: 6200  \tTraining accuracy: 0.7673295736312866\n",
      "Step: 6200  \tValid loss: 0.46377164125442505\n",
      "Step: 6300  \tTraining loss: 0.4293288290500641\n",
      "Step: 6300  \tTraining accuracy: 0.7675016522407532\n",
      "Step: 6300  \tValid loss: 0.46368515491485596\n",
      "Step: 6400  \tTraining loss: 0.42925235629081726\n",
      "Step: 6400  \tTraining accuracy: 0.7676771283149719\n",
      "Step: 6400  \tValid loss: 0.46369031071662903\n",
      "Step: 6500  \tTraining loss: 0.4291824698448181\n",
      "Step: 6500  \tTraining accuracy: 0.7678471207618713\n",
      "Step: 6500  \tValid loss: 0.4637213945388794\n",
      "Step: 6600  \tTraining loss: 0.42911213636398315\n",
      "Step: 6600  \tTraining accuracy: 0.7680119276046753\n",
      "Step: 6600  \tValid loss: 0.4637620449066162\n",
      "Step: 6700  \tTraining loss: 0.42904141545295715\n",
      "Step: 6700  \tTraining accuracy: 0.7681718468666077\n",
      "Step: 6700  \tValid loss: 0.4637545645236969\n",
      "Step: 6800  \tTraining loss: 0.42897143959999084\n",
      "Step: 6800  \tTraining accuracy: 0.7683269381523132\n",
      "Step: 6800  \tValid loss: 0.46372565627098083\n",
      "Step: 6900  \tTraining loss: 0.4289017617702484\n",
      "Step: 6900  \tTraining accuracy: 0.7684775590896606\n",
      "Step: 6900  \tValid loss: 0.4637150168418884\n",
      "Step: 7000  \tTraining loss: 0.42883315682411194\n",
      "Step: 7000  \tTraining accuracy: 0.7686238288879395\n",
      "Step: 7000  \tValid loss: 0.46368661522865295\n",
      "Step: 7100  \tTraining loss: 0.42876482009887695\n",
      "Step: 7100  \tTraining accuracy: 0.768765926361084\n",
      "Step: 7100  \tValid loss: 0.4636479914188385\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7689041\n",
      "Precision: 0.861678\n",
      "Recall: 0.75848305\n",
      "F1 score: 0.7199293\n",
      "AUC: 0.8026084\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.768904   0.861678  0.758483  0.719929  0.802608  0.428712      0.768702   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.463413       0.768752      0.519      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  7176.0  \n",
      "21\n",
      "(957, 4)\n",
      "(957, 1)\n",
      "(528, 4)\n",
      "(528, 1)\n",
      "(429, 4)\n",
      "(429, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.610533595085144\n",
      "Step: 100  \tTraining accuracy: 0.6917450428009033\n",
      "Step: 100  \tValid loss: 0.6257883906364441\n",
      "Step: 200  \tTraining loss: 0.5008350610733032\n",
      "Step: 200  \tTraining accuracy: 0.7189132571220398\n",
      "Step: 200  \tValid loss: 0.5181028842926025\n",
      "Step: 300  \tTraining loss: 0.39570701122283936\n",
      "Step: 300  \tTraining accuracy: 0.7609195113182068\n",
      "Step: 300  \tValid loss: 0.41057825088500977\n",
      "Step: 400  \tTraining loss: 0.3295869529247284\n",
      "Step: 400  \tTraining accuracy: 0.7935512661933899\n",
      "Step: 400  \tValid loss: 0.3420955240726471\n",
      "Step: 500  \tTraining loss: 0.2939678430557251\n",
      "Step: 500  \tTraining accuracy: 0.8151631355285645\n",
      "Step: 500  \tValid loss: 0.30540990829467773\n",
      "Step: 600  \tTraining loss: 0.27420884370803833\n",
      "Step: 600  \tTraining accuracy: 0.8292961120605469\n",
      "Step: 600  \tValid loss: 0.2848552167415619\n",
      "Step: 700  \tTraining loss: 0.26251089572906494\n",
      "Step: 700  \tTraining accuracy: 0.8394823670387268\n",
      "Step: 700  \tValid loss: 0.27252477407455444\n",
      "Step: 800  \tTraining loss: 0.25514158606529236\n",
      "Step: 800  \tTraining accuracy: 0.8472309112548828\n",
      "Step: 800  \tValid loss: 0.2647280693054199\n",
      "Step: 900  \tTraining loss: 0.2502683699131012\n",
      "Step: 900  \tTraining accuracy: 0.8532177805900574\n",
      "Step: 900  \tValid loss: 0.25956782698631287\n",
      "Step: 1000  \tTraining loss: 0.2469254583120346\n",
      "Step: 1000  \tTraining accuracy: 0.8582192063331604\n",
      "Step: 1000  \tValid loss: 0.2559909224510193\n",
      "Step: 1100  \tTraining loss: 0.24455909430980682\n",
      "Step: 1100  \tTraining accuracy: 0.8621684908866882\n",
      "Step: 1100  \tValid loss: 0.25350135564804077\n",
      "Step: 1200  \tTraining loss: 0.2428545206785202\n",
      "Step: 1200  \tTraining accuracy: 0.8655217885971069\n",
      "Step: 1200  \tValid loss: 0.2516636252403259\n",
      "Step: 1300  \tTraining loss: 0.24159248173236847\n",
      "Step: 1300  \tTraining accuracy: 0.8683803677558899\n",
      "Step: 1300  \tValid loss: 0.25035205483436584\n",
      "Step: 1400  \tTraining loss: 0.24064980447292328\n",
      "Step: 1400  \tTraining accuracy: 0.8710089325904846\n",
      "Step: 1400  \tValid loss: 0.24932549893856049\n",
      "Step: 1500  \tTraining loss: 0.2399301379919052\n",
      "Step: 1500  \tTraining accuracy: 0.8732749819755554\n",
      "Step: 1500  \tValid loss: 0.2485554963350296\n",
      "Step: 1600  \tTraining loss: 0.2393723577260971\n",
      "Step: 1600  \tTraining accuracy: 0.8752822875976562\n",
      "Step: 1600  \tValid loss: 0.2479846030473709\n",
      "Step: 1700  \tTraining loss: 0.23893527686595917\n",
      "Step: 1700  \tTraining accuracy: 0.8770463466644287\n",
      "Step: 1700  \tValid loss: 0.2475091814994812\n",
      "Step: 1800  \tTraining loss: 0.23858588933944702\n",
      "Step: 1800  \tTraining accuracy: 0.8786982893943787\n",
      "Step: 1800  \tValid loss: 0.24714909493923187\n",
      "Step: 1900  \tTraining loss: 0.238301083445549\n",
      "Step: 1900  \tTraining accuracy: 0.8801717162132263\n",
      "Step: 1900  \tValid loss: 0.24686720967292786\n",
      "Step: 2000  \tTraining loss: 0.2380647361278534\n",
      "Step: 2000  \tTraining accuracy: 0.8814939856529236\n",
      "Step: 2000  \tValid loss: 0.24664948880672455\n",
      "Step: 2100  \tTraining loss: 0.2378666251897812\n",
      "Step: 2100  \tTraining accuracy: 0.882712721824646\n",
      "Step: 2100  \tValid loss: 0.24646423757076263\n",
      "Step: 2200  \tTraining loss: 0.2376968264579773\n",
      "Step: 2200  \tTraining accuracy: 0.8838181495666504\n",
      "Step: 2200  \tValid loss: 0.24630101025104523\n",
      "Step: 2300  \tTraining loss: 0.23754817247390747\n",
      "Step: 2300  \tTraining accuracy: 0.8848252892494202\n",
      "Step: 2300  \tValid loss: 0.24617229402065277\n",
      "Step: 2400  \tTraining loss: 0.2374165803194046\n",
      "Step: 2400  \tTraining accuracy: 0.8857021927833557\n",
      "Step: 2400  \tValid loss: 0.24607354402542114\n",
      "Step: 2500  \tTraining loss: 0.23729947209358215\n",
      "Step: 2500  \tTraining accuracy: 0.8865075707435608\n",
      "Step: 2500  \tValid loss: 0.24599330127239227\n",
      "Step: 2600  \tTraining loss: 0.23719172179698944\n",
      "Step: 2600  \tTraining accuracy: 0.887249767780304\n",
      "Step: 2600  \tValid loss: 0.2459012269973755\n",
      "Step: 2700  \tTraining loss: 0.2370922863483429\n",
      "Step: 2700  \tTraining accuracy: 0.8879359364509583\n",
      "Step: 2700  \tValid loss: 0.2458142340183258\n",
      "Step: 2800  \tTraining loss: 0.23699979484081268\n",
      "Step: 2800  \tTraining accuracy: 0.8885722160339355\n",
      "Step: 2800  \tValid loss: 0.24574458599090576\n",
      "Step: 2900  \tTraining loss: 0.2369110882282257\n",
      "Step: 2900  \tTraining accuracy: 0.8891638517379761\n",
      "Step: 2900  \tValid loss: 0.24563995003700256\n",
      "Step: 3000  \tTraining loss: 0.23682816326618195\n",
      "Step: 3000  \tTraining accuracy: 0.8897153735160828\n",
      "Step: 3000  \tValid loss: 0.24558962881565094\n",
      "Step: 3100  \tTraining loss: 0.23674792051315308\n",
      "Step: 3100  \tTraining accuracy: 0.8902307152748108\n",
      "Step: 3100  \tValid loss: 0.24552425742149353\n",
      "Step: 3200  \tTraining loss: 0.23667022585868835\n",
      "Step: 3200  \tTraining accuracy: 0.8907133936882019\n",
      "Step: 3200  \tValid loss: 0.24545453488826752\n",
      "Step: 3300  \tTraining loss: 0.23659439384937286\n",
      "Step: 3300  \tTraining accuracy: 0.8911663293838501\n",
      "Step: 3300  \tValid loss: 0.24538427591323853\n",
      "Step: 3400  \tTraining loss: 0.23652082681655884\n",
      "Step: 3400  \tTraining accuracy: 0.8915922045707703\n",
      "Step: 3400  \tValid loss: 0.24531665444374084\n",
      "Step: 3500  \tTraining loss: 0.2364490032196045\n",
      "Step: 3500  \tTraining accuracy: 0.8919782638549805\n",
      "Step: 3500  \tValid loss: 0.24525845050811768\n",
      "Step: 3600  \tTraining loss: 0.23637844622135162\n",
      "Step: 3600  \tTraining accuracy: 0.8923425674438477\n",
      "Step: 3600  \tValid loss: 0.24519923329353333\n",
      "Step: 3700  \tTraining loss: 0.23630893230438232\n",
      "Step: 3700  \tTraining accuracy: 0.8926869034767151\n",
      "Step: 3700  \tValid loss: 0.2451273649930954\n",
      "Step: 3800  \tTraining loss: 0.23624074459075928\n",
      "Step: 3800  \tTraining accuracy: 0.8930128812789917\n",
      "Step: 3800  \tValid loss: 0.24506685137748718\n",
      "Step: 3900  \tTraining loss: 0.23617330193519592\n",
      "Step: 3900  \tTraining accuracy: 0.8933219313621521\n",
      "Step: 3900  \tValid loss: 0.24499726295471191\n",
      "Step: 4000  \tTraining loss: 0.23610858619213104\n",
      "Step: 4000  \tTraining accuracy: 0.8936417698860168\n",
      "Step: 4000  \tValid loss: 0.24495188891887665\n",
      "Step: 4100  \tTraining loss: 0.23602569103240967\n",
      "Step: 4100  \tTraining accuracy: 0.8939458727836609\n",
      "Step: 4100  \tValid loss: 0.24473965167999268\n",
      "Step: 4200  \tTraining loss: 0.23591762781143188\n",
      "Step: 4200  \tTraining accuracy: 0.8942352533340454\n",
      "Step: 4200  \tValid loss: 0.24443401396274567\n",
      "Step: 4300  \tTraining loss: 0.23582391440868378\n",
      "Step: 4300  \tTraining accuracy: 0.8945110440254211\n",
      "Step: 4300  \tValid loss: 0.2442948818206787\n",
      "Step: 4400  \tTraining loss: 0.23573699593544006\n",
      "Step: 4400  \tTraining accuracy: 0.8947741389274597\n",
      "Step: 4400  \tValid loss: 0.24422091245651245\n",
      "Step: 4500  \tTraining loss: 0.23565417528152466\n",
      "Step: 4500  \tTraining accuracy: 0.8950254321098328\n",
      "Step: 4500  \tValid loss: 0.24416877329349518\n",
      "Step: 4600  \tTraining loss: 0.23557323217391968\n",
      "Step: 4600  \tTraining accuracy: 0.8952656388282776\n",
      "Step: 4600  \tValid loss: 0.24408309161663055\n",
      "Step: 4700  \tTraining loss: 0.2354942113161087\n",
      "Step: 4700  \tTraining accuracy: 0.8954955339431763\n",
      "Step: 4700  \tValid loss: 0.24400973320007324\n",
      "Step: 4800  \tTraining loss: 0.2354186773300171\n",
      "Step: 4800  \tTraining accuracy: 0.8957157731056213\n",
      "Step: 4800  \tValid loss: 0.24398072063922882\n",
      "Step: 4900  \tTraining loss: 0.23534861207008362\n",
      "Step: 4900  \tTraining accuracy: 0.8959268927574158\n",
      "Step: 4900  \tValid loss: 0.24398772418498993\n",
      "Step: 5000  \tTraining loss: 0.23527958989143372\n",
      "Step: 5000  \tTraining accuracy: 0.8961295485496521\n",
      "Step: 5000  \tValid loss: 0.2439463883638382\n",
      "Step: 5100  \tTraining loss: 0.23521165549755096\n",
      "Step: 5100  \tTraining accuracy: 0.896324098110199\n",
      "Step: 5100  \tValid loss: 0.24389775097370148\n",
      "Step: 5200  \tTraining loss: 0.23514500260353088\n",
      "Step: 5200  \tTraining accuracy: 0.8965111374855042\n",
      "Step: 5200  \tValid loss: 0.24384289979934692\n",
      "Step: 5300  \tTraining loss: 0.23507905006408691\n",
      "Step: 5300  \tTraining accuracy: 0.8966910243034363\n",
      "Step: 5300  \tValid loss: 0.2437724471092224\n",
      "Step: 5400  \tTraining loss: 0.23501409590244293\n",
      "Step: 5400  \tTraining accuracy: 0.8968642354011536\n",
      "Step: 5400  \tValid loss: 0.2437102049589157\n",
      "Step: 5500  \tTraining loss: 0.23495054244995117\n",
      "Step: 5500  \tTraining accuracy: 0.8970406651496887\n",
      "Step: 5500  \tValid loss: 0.24365095794200897\n",
      "Step: 5600  \tTraining loss: 0.23488861322402954\n",
      "Step: 5600  \tTraining accuracy: 0.8972107172012329\n",
      "Step: 5600  \tValid loss: 0.24358847737312317\n",
      "Step: 5700  \tTraining loss: 0.23482801020145416\n",
      "Step: 5700  \tTraining accuracy: 0.8973747491836548\n",
      "Step: 5700  \tValid loss: 0.24353279173374176\n",
      "Step: 5800  \tTraining loss: 0.23476585745811462\n",
      "Step: 5800  \tTraining accuracy: 0.8975421190261841\n",
      "Step: 5800  \tValid loss: 0.2434331178665161\n",
      "Step: 5900  \tTraining loss: 0.2346181720495224\n",
      "Step: 5900  \tTraining accuracy: 0.8977038264274597\n",
      "Step: 5900  \tValid loss: 0.2428606152534485\n",
      "Step: 6000  \tTraining loss: 0.23452316224575043\n",
      "Step: 6000  \tTraining accuracy: 0.8978601098060608\n",
      "Step: 6000  \tValid loss: 0.24290592968463898\n",
      "Step: 6100  \tTraining loss: 0.23445181548595428\n",
      "Step: 6100  \tTraining accuracy: 0.8980111479759216\n",
      "Step: 6100  \tValid loss: 0.24297034740447998\n",
      "Step: 6200  \tTraining loss: 0.23436424136161804\n",
      "Step: 6200  \tTraining accuracy: 0.8981573581695557\n",
      "Step: 6200  \tValid loss: 0.24305371940135956\n",
      "Step: 6300  \tTraining loss: 0.2342713177204132\n",
      "Step: 6300  \tTraining accuracy: 0.8982905149459839\n",
      "Step: 6300  \tValid loss: 0.2430354654788971\n",
      "Step: 6400  \tTraining loss: 0.23419547080993652\n",
      "Step: 6400  \tTraining accuracy: 0.8984194397926331\n",
      "Step: 6400  \tValid loss: 0.24309542775154114\n",
      "Step: 6500  \tTraining loss: 0.23412422835826874\n",
      "Step: 6500  \tTraining accuracy: 0.8985443711280823\n",
      "Step: 6500  \tValid loss: 0.24313710629940033\n",
      "Step: 6600  \tTraining loss: 0.23405799269676208\n",
      "Step: 6600  \tTraining accuracy: 0.8986575603485107\n",
      "Step: 6600  \tValid loss: 0.24316821992397308\n",
      "Step: 6700  \tTraining loss: 0.23399494588375092\n",
      "Step: 6700  \tTraining accuracy: 0.8987672924995422\n",
      "Step: 6700  \tValid loss: 0.24316449463367462\n",
      "Step: 6800  \tTraining loss: 0.23393309116363525\n",
      "Step: 6800  \tTraining accuracy: 0.8988738059997559\n",
      "Step: 6800  \tValid loss: 0.24315409362316132\n",
      "Step: 6900  \tTraining loss: 0.23387306928634644\n",
      "Step: 6900  \tTraining accuracy: 0.8989771604537964\n",
      "Step: 6900  \tValid loss: 0.24316276609897614\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8990776\n",
      "Precision: 0.9174528\n",
      "Recall: 0.8901602\n",
      "F1 score: 0.88550264\n",
      "AUC: 0.91142625\n",
      "   accuracy  precision   recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.899078   0.917453  0.89016  0.885503  0.911426  0.233864      0.898975   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.242805       0.898995   0.296096      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  6917.0  \n",
      "22\n",
      "(1015, 4)\n",
      "(1015, 1)\n",
      "(560, 4)\n",
      "(560, 1)\n",
      "(455, 4)\n",
      "(455, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6439917087554932\n",
      "Step: 100  \tTraining accuracy: 0.7261083722114563\n",
      "Step: 100  \tValid loss: 0.6575998663902283\n",
      "Step: 200  \tTraining loss: 0.5900543928146362\n",
      "Step: 200  \tTraining accuracy: 0.7274219989776611\n",
      "Step: 200  \tValid loss: 0.6266658306121826\n",
      "Step: 300  \tTraining loss: 0.5685297250747681\n",
      "Step: 300  \tTraining accuracy: 0.7310344576835632\n",
      "Step: 300  \tValid loss: 0.6169422268867493\n",
      "Step: 400  \tTraining loss: 0.5527149438858032\n",
      "Step: 400  \tTraining accuracy: 0.7338494062423706\n",
      "Step: 400  \tValid loss: 0.6060346364974976\n",
      "Step: 500  \tTraining loss: 0.5367745161056519\n",
      "Step: 500  \tTraining accuracy: 0.7376026511192322\n",
      "Step: 500  \tValid loss: 0.5913805365562439\n",
      "Step: 600  \tTraining loss: 0.5188594460487366\n",
      "Step: 600  \tTraining accuracy: 0.7411553859710693\n",
      "Step: 600  \tValid loss: 0.5734104514122009\n",
      "Step: 700  \tTraining loss: 0.5010529160499573\n",
      "Step: 700  \tTraining accuracy: 0.743842363357544\n",
      "Step: 700  \tValid loss: 0.555508553981781\n",
      "Step: 800  \tTraining loss: 0.48744848370552063\n",
      "Step: 800  \tTraining accuracy: 0.7456157803535461\n",
      "Step: 800  \tValid loss: 0.5421668291091919\n",
      "Step: 900  \tTraining loss: 0.47866520285606384\n",
      "Step: 900  \tTraining accuracy: 0.7464503049850464\n",
      "Step: 900  \tValid loss: 0.5337028503417969\n",
      "Step: 1000  \tTraining loss: 0.47319796681404114\n",
      "Step: 1000  \tTraining accuracy: 0.7469536066055298\n",
      "Step: 1000  \tValid loss: 0.5283631682395935\n",
      "Step: 1100  \tTraining loss: 0.4698639512062073\n",
      "Step: 1100  \tTraining accuracy: 0.7475486993789673\n",
      "Step: 1100  \tValid loss: 0.5250506401062012\n",
      "Step: 1200  \tTraining loss: 0.46785470843315125\n",
      "Step: 1200  \tTraining accuracy: 0.7482544183731079\n",
      "Step: 1200  \tValid loss: 0.5230732560157776\n",
      "Step: 1300  \tTraining loss: 0.4666333794593811\n",
      "Step: 1300  \tTraining accuracy: 0.7490837574005127\n",
      "Step: 1300  \tValid loss: 0.5219182968139648\n",
      "Step: 1400  \tTraining loss: 0.4658593237400055\n",
      "Step: 1400  \tTraining accuracy: 0.7497901916503906\n",
      "Step: 1400  \tValid loss: 0.5212312936782837\n",
      "Step: 1500  \tTraining loss: 0.46532970666885376\n",
      "Step: 1500  \tTraining accuracy: 0.7504671216011047\n",
      "Step: 1500  \tValid loss: 0.5207957625389099\n",
      "Step: 1600  \tTraining loss: 0.46492743492126465\n",
      "Step: 1600  \tTraining accuracy: 0.7510567307472229\n",
      "Step: 1600  \tValid loss: 0.5204854011535645\n",
      "Step: 1700  \tTraining loss: 0.46457400918006897\n",
      "Step: 1700  \tTraining accuracy: 0.7515748739242554\n",
      "Step: 1700  \tValid loss: 0.5201950073242188\n",
      "Step: 1800  \tTraining loss: 0.46424558758735657\n",
      "Step: 1800  \tTraining accuracy: 0.7521182298660278\n",
      "Step: 1800  \tValid loss: 0.5200639963150024\n",
      "Step: 1900  \tTraining loss: 0.46392494440078735\n",
      "Step: 1900  \tTraining accuracy: 0.7526028752326965\n",
      "Step: 1900  \tValid loss: 0.519818902015686\n",
      "Step: 2000  \tTraining loss: 0.46359726786613464\n",
      "Step: 2000  \tTraining accuracy: 0.753012478351593\n",
      "Step: 2000  \tValid loss: 0.5195959210395813\n",
      "Step: 2100  \tTraining loss: 0.463262140750885\n",
      "Step: 2100  \tTraining accuracy: 0.7533581852912903\n",
      "Step: 2100  \tValid loss: 0.5194120407104492\n",
      "Step: 2200  \tTraining loss: 0.4629209339618683\n",
      "Step: 2200  \tTraining accuracy: 0.7536487579345703\n",
      "Step: 2200  \tValid loss: 0.5192524194717407\n",
      "Step: 2300  \tTraining loss: 0.462578684091568\n",
      "Step: 2300  \tTraining accuracy: 0.75389164686203\n",
      "Step: 2300  \tValid loss: 0.5191556811332703\n",
      "Step: 2400  \tTraining loss: 0.46223559975624084\n",
      "Step: 2400  \tTraining accuracy: 0.7540718913078308\n",
      "Step: 2400  \tValid loss: 0.519079864025116\n",
      "Step: 2500  \tTraining loss: 0.46189412474632263\n",
      "Step: 2500  \tTraining accuracy: 0.7542374730110168\n",
      "Step: 2500  \tValid loss: 0.5190401077270508\n",
      "Step: 2600  \tTraining loss: 0.4615573585033417\n",
      "Step: 2600  \tTraining accuracy: 0.7544093728065491\n",
      "Step: 2600  \tValid loss: 0.5190295577049255\n",
      "Step: 2700  \tTraining loss: 0.4612290561199188\n",
      "Step: 2700  \tTraining accuracy: 0.7546426057815552\n",
      "Step: 2700  \tValid loss: 0.5190364122390747\n",
      "Step: 2800  \tTraining loss: 0.46091198921203613\n",
      "Step: 2800  \tTraining accuracy: 0.7548410296440125\n",
      "Step: 2800  \tValid loss: 0.5190602540969849\n",
      "Step: 2900  \tTraining loss: 0.4606083035469055\n",
      "Step: 2900  \tTraining accuracy: 0.7550255060195923\n",
      "Step: 2900  \tValid loss: 0.51910400390625\n",
      "Step: 3000  \tTraining loss: 0.4603193700313568\n",
      "Step: 3000  \tTraining accuracy: 0.7552141547203064\n",
      "Step: 3000  \tValid loss: 0.5191584229469299\n",
      "Step: 3100  \tTraining loss: 0.46004581451416016\n",
      "Step: 3100  \tTraining accuracy: 0.7553581595420837\n",
      "Step: 3100  \tValid loss: 0.5192294716835022\n",
      "Step: 3200  \tTraining loss: 0.45978787541389465\n",
      "Step: 3200  \tTraining accuracy: 0.7554929852485657\n",
      "Step: 3200  \tValid loss: 0.5193126797676086\n",
      "Step: 3300  \tTraining loss: 0.4595450460910797\n",
      "Step: 3300  \tTraining accuracy: 0.7556195259094238\n",
      "Step: 3300  \tValid loss: 0.5194051265716553\n",
      "Step: 3400  \tTraining loss: 0.4593164920806885\n",
      "Step: 3400  \tTraining accuracy: 0.7557532787322998\n",
      "Step: 3400  \tValid loss: 0.5195029973983765\n",
      "Step: 3500  \tTraining loss: 0.4589080214500427\n",
      "Step: 3500  \tTraining accuracy: 0.7558792233467102\n",
      "Step: 3500  \tValid loss: 0.519694983959198\n",
      "Step: 3600  \tTraining loss: 0.4568311274051666\n",
      "Step: 3600  \tTraining accuracy: 0.756011962890625\n",
      "Step: 3600  \tValid loss: 0.5196059942245483\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7561509\n",
      "Precision: 0.7339246\n",
      "Recall: 0.73719376\n",
      "F1 score: 0.7578312\n",
      "AUC: 0.7625899\n",
      "   accuracy  precision    recall  f1_score      auc     loss  accuracy_val  \\\n",
      "0  0.756151   0.733925  0.737194  0.757831  0.76259  0.45668      0.756021   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.519026       0.756247   0.435966      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3626.0  \n",
      "23\n",
      "(841, 4)\n",
      "(841, 1)\n",
      "(464, 4)\n",
      "(464, 1)\n",
      "(377, 4)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5952174663543701\n",
      "Step: 100  \tTraining accuracy: 0.7241379022598267\n",
      "Step: 100  \tValid loss: 0.612415075302124\n",
      "Step: 200  \tTraining loss: 0.5759196877479553\n",
      "Step: 200  \tTraining accuracy: 0.7213634848594666\n",
      "Step: 200  \tValid loss: 0.5967912077903748\n",
      "Step: 300  \tTraining loss: 0.5590624213218689\n",
      "Step: 300  \tTraining accuracy: 0.7212842106819153\n",
      "Step: 300  \tValid loss: 0.5772984027862549\n",
      "Step: 400  \tTraining loss: 0.5487397909164429\n",
      "Step: 400  \tTraining accuracy: 0.7232885956764221\n",
      "Step: 400  \tValid loss: 0.5626786351203918\n",
      "Step: 500  \tTraining loss: 0.541556715965271\n",
      "Step: 500  \tTraining accuracy: 0.7267802953720093\n",
      "Step: 500  \tValid loss: 0.5519428849220276\n",
      "Step: 600  \tTraining loss: 0.5364055037498474\n",
      "Step: 600  \tTraining accuracy: 0.7297589182853699\n",
      "Step: 600  \tValid loss: 0.5440795421600342\n",
      "Step: 700  \tTraining loss: 0.5325720310211182\n",
      "Step: 700  \tTraining accuracy: 0.7323698997497559\n",
      "Step: 700  \tValid loss: 0.538267195224762\n",
      "Step: 800  \tTraining loss: 0.5295335650444031\n",
      "Step: 800  \tTraining accuracy: 0.7342845797538757\n",
      "Step: 800  \tValid loss: 0.533906102180481\n",
      "Step: 900  \tTraining loss: 0.5268349647521973\n",
      "Step: 900  \tTraining accuracy: 0.7359585762023926\n",
      "Step: 900  \tValid loss: 0.5305852293968201\n",
      "Step: 1000  \tTraining loss: 0.523924708366394\n",
      "Step: 1000  \tTraining accuracy: 0.737530529499054\n",
      "Step: 1000  \tValid loss: 0.5277807712554932\n",
      "Step: 1100  \tTraining loss: 0.5201321840286255\n",
      "Step: 1100  \tTraining accuracy: 0.7389729022979736\n",
      "Step: 1100  \tValid loss: 0.5247600078582764\n",
      "Step: 1200  \tTraining loss: 0.5151478052139282\n",
      "Step: 1200  \tTraining accuracy: 0.740267813205719\n",
      "Step: 1200  \tValid loss: 0.5207324624061584\n",
      "Step: 1300  \tTraining loss: 0.5094922184944153\n",
      "Step: 1300  \tTraining accuracy: 0.742021381855011\n",
      "Step: 1300  \tValid loss: 0.5157390832901001\n",
      "Step: 1400  \tTraining loss: 0.504037082195282\n",
      "Step: 1400  \tTraining accuracy: 0.7439556121826172\n",
      "Step: 1400  \tValid loss: 0.5105108022689819\n",
      "Step: 1500  \tTraining loss: 0.499275803565979\n",
      "Step: 1500  \tTraining accuracy: 0.7457050085067749\n",
      "Step: 1500  \tValid loss: 0.505597710609436\n",
      "Step: 1600  \tTraining loss: 0.4953404366970062\n",
      "Step: 1600  \tTraining accuracy: 0.7474204897880554\n",
      "Step: 1600  \tValid loss: 0.5012475848197937\n",
      "Step: 1700  \tTraining loss: 0.49217915534973145\n",
      "Step: 1700  \tTraining accuracy: 0.7491081953048706\n",
      "Step: 1700  \tValid loss: 0.4975138306617737\n",
      "Step: 1800  \tTraining loss: 0.4896700084209442\n",
      "Step: 1800  \tTraining accuracy: 0.7508068680763245\n",
      "Step: 1800  \tValid loss: 0.4943525493144989\n",
      "Step: 1900  \tTraining loss: 0.48768073320388794\n",
      "Step: 1900  \tTraining accuracy: 0.7524182796478271\n",
      "Step: 1900  \tValid loss: 0.49168917536735535\n",
      "Step: 2000  \tTraining loss: 0.48609569668769836\n",
      "Step: 2000  \tTraining accuracy: 0.7539254426956177\n",
      "Step: 2000  \tValid loss: 0.4894479811191559\n",
      "Step: 2100  \tTraining loss: 0.4848231077194214\n",
      "Step: 2100  \tTraining accuracy: 0.7554015517234802\n",
      "Step: 2100  \tValid loss: 0.4875603914260864\n",
      "Step: 2200  \tTraining loss: 0.48379337787628174\n",
      "Step: 2200  \tTraining accuracy: 0.7568785548210144\n",
      "Step: 2200  \tValid loss: 0.4859671890735626\n",
      "Step: 2300  \tTraining loss: 0.4829530119895935\n",
      "Step: 2300  \tTraining accuracy: 0.7582507729530334\n",
      "Step: 2300  \tValid loss: 0.48461857438087463\n",
      "Step: 2400  \tTraining loss: 0.4822622239589691\n",
      "Step: 2400  \tTraining accuracy: 0.7596579790115356\n",
      "Step: 2400  \tValid loss: 0.48347318172454834\n",
      "Step: 2500  \tTraining loss: 0.48169001936912537\n",
      "Step: 2500  \tTraining accuracy: 0.7609745264053345\n",
      "Step: 2500  \tValid loss: 0.4824966788291931\n",
      "Step: 2600  \tTraining loss: 0.48121318221092224\n",
      "Step: 2600  \tTraining accuracy: 0.7621878981590271\n",
      "Step: 2600  \tValid loss: 0.4816615879535675\n",
      "Step: 2700  \tTraining loss: 0.4808129370212555\n",
      "Step: 2700  \tTraining accuracy: 0.7634217739105225\n",
      "Step: 2700  \tValid loss: 0.4809444546699524\n",
      "Step: 2800  \tTraining loss: 0.4804753065109253\n",
      "Step: 2800  \tTraining accuracy: 0.7646308541297913\n",
      "Step: 2800  \tValid loss: 0.4803270697593689\n",
      "Step: 2900  \tTraining loss: 0.48018839955329895\n",
      "Step: 2900  \tTraining accuracy: 0.7657341957092285\n",
      "Step: 2900  \tValid loss: 0.4797932803630829\n",
      "Step: 3000  \tTraining loss: 0.47994378209114075\n",
      "Step: 3000  \tTraining accuracy: 0.7667828798294067\n",
      "Step: 3000  \tValid loss: 0.47933056950569153\n",
      "Step: 3100  \tTraining loss: 0.4797336161136627\n",
      "Step: 3100  \tTraining accuracy: 0.7677628397941589\n",
      "Step: 3100  \tValid loss: 0.4789283275604248\n",
      "Step: 3200  \tTraining loss: 0.4795522093772888\n",
      "Step: 3200  \tTraining accuracy: 0.768661618232727\n",
      "Step: 3200  \tValid loss: 0.478577584028244\n",
      "Step: 3300  \tTraining loss: 0.4793947637081146\n",
      "Step: 3300  \tTraining accuracy: 0.7694869041442871\n",
      "Step: 3300  \tValid loss: 0.4782709777355194\n",
      "Step: 3400  \tTraining loss: 0.47925740480422974\n",
      "Step: 3400  \tTraining accuracy: 0.7702450752258301\n",
      "Step: 3400  \tValid loss: 0.47800183296203613\n",
      "Step: 3500  \tTraining loss: 0.47913652658462524\n",
      "Step: 3500  \tTraining accuracy: 0.7709593772888184\n",
      "Step: 3500  \tValid loss: 0.47776544094085693\n",
      "Step: 3600  \tTraining loss: 0.4790298044681549\n",
      "Step: 3600  \tTraining accuracy: 0.7716166377067566\n",
      "Step: 3600  \tValid loss: 0.47755682468414307\n",
      "Step: 3700  \tTraining loss: 0.47893470525741577\n",
      "Step: 3700  \tTraining accuracy: 0.7722704410552979\n",
      "Step: 3700  \tValid loss: 0.47737252712249756\n",
      "Step: 3800  \tTraining loss: 0.47884947061538696\n",
      "Step: 3800  \tTraining accuracy: 0.7728577256202698\n",
      "Step: 3800  \tValid loss: 0.477209210395813\n",
      "Step: 3900  \tTraining loss: 0.4787727892398834\n",
      "Step: 3900  \tTraining accuracy: 0.7733989953994751\n",
      "Step: 3900  \tValid loss: 0.4770635962486267\n",
      "Step: 4000  \tTraining loss: 0.4787030518054962\n",
      "Step: 4000  \tTraining accuracy: 0.7739129066467285\n",
      "Step: 4000  \tValid loss: 0.476934015750885\n",
      "Step: 4100  \tTraining loss: 0.4786390960216522\n",
      "Step: 4100  \tTraining accuracy: 0.7744160890579224\n",
      "Step: 4100  \tValid loss: 0.4768179655075073\n",
      "Step: 4200  \tTraining loss: 0.4785798490047455\n",
      "Step: 4200  \tTraining accuracy: 0.7748950719833374\n",
      "Step: 4200  \tValid loss: 0.4767138361930847\n",
      "Step: 4300  \tTraining loss: 0.4785251021385193\n",
      "Step: 4300  \tTraining accuracy: 0.7753374576568604\n",
      "Step: 4300  \tValid loss: 0.47662001848220825\n",
      "Step: 4400  \tTraining loss: 0.4784732758998871\n",
      "Step: 4400  \tTraining accuracy: 0.7757595777511597\n",
      "Step: 4400  \tValid loss: 0.476535439491272\n",
      "Step: 4500  \tTraining loss: 0.4784247875213623\n",
      "Step: 4500  \tTraining accuracy: 0.7761626839637756\n",
      "Step: 4500  \tValid loss: 0.4764585793018341\n",
      "Step: 4600  \tTraining loss: 0.47837838530540466\n",
      "Step: 4600  \tTraining accuracy: 0.7765611410140991\n",
      "Step: 4600  \tValid loss: 0.47638872265815735\n",
      "Step: 4700  \tTraining loss: 0.4783340394496918\n",
      "Step: 4700  \tTraining accuracy: 0.7769424319267273\n",
      "Step: 4700  \tValid loss: 0.4763246774673462\n",
      "Step: 4800  \tTraining loss: 0.4782911241054535\n",
      "Step: 4800  \tTraining accuracy: 0.7773076891899109\n",
      "Step: 4800  \tValid loss: 0.476266086101532\n",
      "Step: 4900  \tTraining loss: 0.4782494604587555\n",
      "Step: 4900  \tTraining accuracy: 0.7776579260826111\n",
      "Step: 4900  \tValid loss: 0.4762120842933655\n",
      "Step: 5000  \tTraining loss: 0.4782085716724396\n",
      "Step: 5000  \tTraining accuracy: 0.7779939770698547\n",
      "Step: 5000  \tValid loss: 0.47616222500801086\n",
      "Step: 5100  \tTraining loss: 0.4781685471534729\n",
      "Step: 5100  \tTraining accuracy: 0.7783167362213135\n",
      "Step: 5100  \tValid loss: 0.47611573338508606\n",
      "Step: 5200  \tTraining loss: 0.47812891006469727\n",
      "Step: 5200  \tTraining accuracy: 0.7786269187927246\n",
      "Step: 5200  \tValid loss: 0.4760726988315582\n",
      "Step: 5300  \tTraining loss: 0.47808966040611267\n",
      "Step: 5300  \tTraining accuracy: 0.7789252996444702\n",
      "Step: 5300  \tValid loss: 0.4760320484638214\n",
      "Step: 5400  \tTraining loss: 0.4780505895614624\n",
      "Step: 5400  \tTraining accuracy: 0.7792125344276428\n",
      "Step: 5400  \tValid loss: 0.47599390149116516\n",
      "Step: 5500  \tTraining loss: 0.47801145911216736\n",
      "Step: 5500  \tTraining accuracy: 0.779489278793335\n",
      "Step: 5500  \tValid loss: 0.47595787048339844\n",
      "Step: 5600  \tTraining loss: 0.4779721796512604\n",
      "Step: 5600  \tTraining accuracy: 0.7797559499740601\n",
      "Step: 5600  \tValid loss: 0.4759238064289093\n",
      "Step: 5700  \tTraining loss: 0.4779328405857086\n",
      "Step: 5700  \tTraining accuracy: 0.7800132632255554\n",
      "Step: 5700  \tValid loss: 0.47589150071144104\n",
      "Step: 5800  \tTraining loss: 0.47789305448532104\n",
      "Step: 5800  \tTraining accuracy: 0.7802719473838806\n",
      "Step: 5800  \tValid loss: 0.475860595703125\n",
      "Step: 5900  \tTraining loss: 0.4778529405593872\n",
      "Step: 5900  \tTraining accuracy: 0.7805217504501343\n",
      "Step: 5900  \tValid loss: 0.4758310616016388\n",
      "Step: 6000  \tTraining loss: 0.47781237959861755\n",
      "Step: 6000  \tTraining accuracy: 0.7807632088661194\n",
      "Step: 6000  \tValid loss: 0.4758024215698242\n",
      "Step: 6100  \tTraining loss: 0.477771133184433\n",
      "Step: 6100  \tTraining accuracy: 0.7809966206550598\n",
      "Step: 6100  \tValid loss: 0.47577497363090515\n",
      "Step: 6200  \tTraining loss: 0.47772952914237976\n",
      "Step: 6200  \tTraining accuracy: 0.7812225222587585\n",
      "Step: 6200  \tValid loss: 0.4757486581802368\n",
      "Step: 6300  \tTraining loss: 0.47768712043762207\n",
      "Step: 6300  \tTraining accuracy: 0.7814411520957947\n",
      "Step: 6300  \tValid loss: 0.4757232367992401\n",
      "Step: 6400  \tTraining loss: 0.4776441156864166\n",
      "Step: 6400  \tTraining accuracy: 0.7816528677940369\n",
      "Step: 6400  \tValid loss: 0.47569841146469116\n",
      "Step: 6500  \tTraining loss: 0.4776003956794739\n",
      "Step: 6500  \tTraining accuracy: 0.7818580865859985\n",
      "Step: 6500  \tValid loss: 0.47567427158355713\n",
      "Step: 6600  \tTraining loss: 0.4775560796260834\n",
      "Step: 6600  \tTraining accuracy: 0.782056987285614\n",
      "Step: 6600  \tValid loss: 0.4756508469581604\n",
      "Step: 6700  \tTraining loss: 0.47751060128211975\n",
      "Step: 6700  \tTraining accuracy: 0.782249927520752\n",
      "Step: 6700  \tValid loss: 0.4756278991699219\n",
      "Step: 6800  \tTraining loss: 0.47746458649635315\n",
      "Step: 6800  \tTraining accuracy: 0.7824371457099915\n",
      "Step: 6800  \tValid loss: 0.47560563683509827\n",
      "Step: 6900  \tTraining loss: 0.4774176776409149\n",
      "Step: 6900  \tTraining accuracy: 0.7826188802719116\n",
      "Step: 6900  \tValid loss: 0.4755837321281433\n",
      "Step: 7000  \tTraining loss: 0.4773698151111603\n",
      "Step: 7000  \tTraining accuracy: 0.7827954292297363\n",
      "Step: 7000  \tValid loss: 0.4755626618862152\n",
      "Step: 7100  \tTraining loss: 0.4773213863372803\n",
      "Step: 7100  \tTraining accuracy: 0.7829753756523132\n",
      "Step: 7100  \tValid loss: 0.4755418002605438\n",
      "Step: 7200  \tTraining loss: 0.4772717356681824\n",
      "Step: 7200  \tTraining accuracy: 0.7831502556800842\n",
      "Step: 7200  \tValid loss: 0.47552141547203064\n",
      "Step: 7300  \tTraining loss: 0.47722136974334717\n",
      "Step: 7300  \tTraining accuracy: 0.7833203673362732\n",
      "Step: 7300  \tValid loss: 0.47550174593925476\n",
      "Step: 7400  \tTraining loss: 0.4771699011325836\n",
      "Step: 7400  \tTraining accuracy: 0.7834858298301697\n",
      "Step: 7400  \tValid loss: 0.4754820764064789\n",
      "Step: 7500  \tTraining loss: 0.47711771726608276\n",
      "Step: 7500  \tTraining accuracy: 0.783646821975708\n",
      "Step: 7500  \tValid loss: 0.4754634201526642\n",
      "Step: 7600  \tTraining loss: 0.4770645201206207\n",
      "Step: 7600  \tTraining accuracy: 0.7838035821914673\n",
      "Step: 7600  \tValid loss: 0.4754447638988495\n",
      "Step: 7700  \tTraining loss: 0.47701042890548706\n",
      "Step: 7700  \tTraining accuracy: 0.7839562296867371\n",
      "Step: 7700  \tValid loss: 0.47542664408683777\n",
      "Step: 7800  \tTraining loss: 0.4769555628299713\n",
      "Step: 7800  \tTraining accuracy: 0.7841049432754517\n",
      "Step: 7800  \tValid loss: 0.4754091501235962\n",
      "Step: 7900  \tTraining loss: 0.4768996834754944\n",
      "Step: 7900  \tTraining accuracy: 0.7842498421669006\n",
      "Step: 7900  \tValid loss: 0.4753919541835785\n",
      "Step: 8000  \tTraining loss: 0.47684288024902344\n",
      "Step: 8000  \tTraining accuracy: 0.7843911647796631\n",
      "Step: 8000  \tValid loss: 0.47537535429000854\n",
      "Step: 8100  \tTraining loss: 0.476785272359848\n",
      "Step: 8100  \tTraining accuracy: 0.784528911113739\n",
      "Step: 8100  \tValid loss: 0.4753594696521759\n",
      "Step: 8200  \tTraining loss: 0.4767267107963562\n",
      "Step: 8200  \tTraining accuracy: 0.7846633195877075\n",
      "Step: 8200  \tValid loss: 0.47534382343292236\n",
      "Step: 8300  \tTraining loss: 0.476667195558548\n",
      "Step: 8300  \tTraining accuracy: 0.7847944498062134\n",
      "Step: 8300  \tValid loss: 0.4753287732601166\n",
      "Step: 8400  \tTraining loss: 0.4766068756580353\n",
      "Step: 8400  \tTraining accuracy: 0.7849224209785461\n",
      "Step: 8400  \tValid loss: 0.4753143787384033\n",
      "Step: 8500  \tTraining loss: 0.4765458405017853\n",
      "Step: 8500  \tTraining accuracy: 0.7850474119186401\n",
      "Step: 8500  \tValid loss: 0.4753004014492035\n",
      "Step: 8600  \tTraining loss: 0.47648394107818604\n",
      "Step: 8600  \tTraining accuracy: 0.7851694226264954\n",
      "Step: 8600  \tValid loss: 0.4752868711948395\n",
      "Step: 8700  \tTraining loss: 0.4764211177825928\n",
      "Step: 8700  \tTraining accuracy: 0.7852886319160461\n",
      "Step: 8700  \tValid loss: 0.4752742648124695\n",
      "Step: 8800  \tTraining loss: 0.47635751962661743\n",
      "Step: 8800  \tTraining accuracy: 0.785405158996582\n",
      "Step: 8800  \tValid loss: 0.4752620458602905\n",
      "Step: 8900  \tTraining loss: 0.4762931168079376\n",
      "Step: 8900  \tTraining accuracy: 0.785519003868103\n",
      "Step: 8900  \tValid loss: 0.47525057196617126\n",
      "Step: 9000  \tTraining loss: 0.4762279689311981\n",
      "Step: 9000  \tTraining accuracy: 0.7856302857398987\n",
      "Step: 9000  \tValid loss: 0.47523972392082214\n",
      "Step: 9100  \tTraining loss: 0.4761621356010437\n",
      "Step: 9100  \tTraining accuracy: 0.7857391834259033\n",
      "Step: 9100  \tValid loss: 0.4752293825149536\n",
      "Step: 9200  \tTraining loss: 0.4760955274105072\n",
      "Step: 9200  \tTraining accuracy: 0.7858456373214722\n",
      "Step: 9200  \tValid loss: 0.47521984577178955\n",
      "Step: 9300  \tTraining loss: 0.476028174161911\n",
      "Step: 9300  \tTraining accuracy: 0.7859498262405396\n",
      "Step: 9300  \tValid loss: 0.47521093487739563\n",
      "Step: 9400  \tTraining loss: 0.4759601652622223\n",
      "Step: 9400  \tTraining accuracy: 0.7860517501831055\n",
      "Step: 9400  \tValid loss: 0.4752029478549957\n",
      "Step: 9500  \tTraining loss: 0.4758913815021515\n",
      "Step: 9500  \tTraining accuracy: 0.7861578464508057\n",
      "Step: 9500  \tValid loss: 0.47519543766975403\n",
      "Step: 9600  \tTraining loss: 0.4758220314979553\n",
      "Step: 9600  \tTraining accuracy: 0.7862616777420044\n",
      "Step: 9600  \tValid loss: 0.4751887023448944\n",
      "Step: 9700  \tTraining loss: 0.47575199604034424\n",
      "Step: 9700  \tTraining accuracy: 0.7863633632659912\n",
      "Step: 9700  \tValid loss: 0.4751830995082855\n",
      "Step: 9800  \tTraining loss: 0.4756813049316406\n",
      "Step: 9800  \tTraining accuracy: 0.7864691019058228\n",
      "Step: 9800  \tValid loss: 0.4751777648925781\n",
      "Step: 9900  \tTraining loss: 0.4756101071834564\n",
      "Step: 9900  \tTraining accuracy: 0.7865726947784424\n",
      "Step: 9900  \tValid loss: 0.47517338395118713\n",
      "Step: 10000  \tTraining loss: 0.4755381941795349\n",
      "Step: 10000  \tTraining accuracy: 0.7866741418838501\n",
      "Step: 10000  \tValid loss: 0.4751700758934021\n",
      "Step: 10100  \tTraining loss: 0.47546565532684326\n",
      "Step: 10100  \tTraining accuracy: 0.7867736220359802\n",
      "Step: 10100  \tValid loss: 0.47516748309135437\n",
      "Step: 10200  \tTraining loss: 0.4753926992416382\n",
      "Step: 10200  \tTraining accuracy: 0.7868769764900208\n",
      "Step: 10200  \tValid loss: 0.47516563534736633\n",
      "Step: 10300  \tTraining loss: 0.4753189980983734\n",
      "Step: 10300  \tTraining accuracy: 0.7869783639907837\n",
      "Step: 10300  \tValid loss: 0.47516483068466187\n",
      "Step: 10400  \tTraining loss: 0.4752449691295624\n",
      "Step: 10400  \tTraining accuracy: 0.7870777249336243\n",
      "Step: 10400  \tValid loss: 0.47516506910324097\n",
      "Step: 10500  \tTraining loss: 0.4751703143119812\n",
      "Step: 10500  \tTraining accuracy: 0.7871752381324768\n",
      "Step: 10500  \tValid loss: 0.47516587376594543\n",
      "Step: 10600  \tTraining loss: 0.47509509325027466\n",
      "Step: 10600  \tTraining accuracy: 0.7872708439826965\n",
      "Step: 10600  \tValid loss: 0.47516798973083496\n",
      "Step: 10700  \tTraining loss: 0.47501933574676514\n",
      "Step: 10700  \tTraining accuracy: 0.7873647212982178\n",
      "Step: 10700  \tValid loss: 0.4751709997653961\n",
      "Step: 10800  \tTraining loss: 0.47494322061538696\n",
      "Step: 10800  \tTraining accuracy: 0.7874568104743958\n",
      "Step: 10800  \tValid loss: 0.4751748740673065\n",
      "Step: 10900  \tTraining loss: 0.47486650943756104\n",
      "Step: 10900  \tTraining accuracy: 0.7875526547431946\n",
      "Step: 10900  \tValid loss: 0.475180059671402\n",
      "Step: 11000  \tTraining loss: 0.47478941082954407\n",
      "Step: 11000  \tTraining accuracy: 0.7876522541046143\n",
      "Step: 11000  \tValid loss: 0.47518599033355713\n",
      "Step: 11100  \tTraining loss: 0.4747116267681122\n",
      "Step: 11100  \tTraining accuracy: 0.7877500057220459\n",
      "Step: 11100  \tValid loss: 0.4751930832862854\n",
      "Step: 11200  \tTraining loss: 0.47463372349739075\n",
      "Step: 11200  \tTraining accuracy: 0.7878459692001343\n",
      "Step: 11200  \tValid loss: 0.4752010703086853\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.78794026\n",
      "Precision: 0.80833334\n",
      "Recall: 0.95566505\n",
      "F1 score: 0.8537502\n",
      "AUC: 0.6804187\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0   0.78794   0.808333  0.955665   0.85375  0.680419  0.47457      0.787869   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.475165       0.787846   0.486478      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  11280.0  \n",
      "24\n",
      "(1189, 4)\n",
      "(1189, 1)\n",
      "(640, 4)\n",
      "(640, 1)\n",
      "(520, 4)\n",
      "(520, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6662123203277588\n",
      "Step: 100  \tTraining accuracy: 0.6089150309562683\n",
      "Step: 100  \tValid loss: 0.6663749814033508\n",
      "Step: 200  \tTraining loss: 0.6629893183708191\n",
      "Step: 200  \tTraining accuracy: 0.6325607895851135\n",
      "Step: 200  \tValid loss: 0.6643787622451782\n",
      "Step: 300  \tTraining loss: 0.6588634848594666\n",
      "Step: 300  \tTraining accuracy: 0.6386954188346863\n",
      "Step: 300  \tValid loss: 0.6605506539344788\n",
      "Step: 400  \tTraining loss: 0.6537162065505981\n",
      "Step: 400  \tTraining accuracy: 0.64303058385849\n",
      "Step: 400  \tValid loss: 0.6540986895561218\n",
      "Step: 500  \tTraining loss: 0.6471463441848755\n",
      "Step: 500  \tTraining accuracy: 0.6469532251358032\n",
      "Step: 500  \tValid loss: 0.6420007944107056\n",
      "Step: 600  \tTraining loss: 0.6371423006057739\n",
      "Step: 600  \tTraining accuracy: 0.6500695943832397\n",
      "Step: 600  \tValid loss: 0.6268755197525024\n",
      "Step: 700  \tTraining loss: 0.6334078907966614\n",
      "Step: 700  \tTraining accuracy: 0.6526859998703003\n",
      "Step: 700  \tValid loss: 0.6225404739379883\n",
      "Step: 800  \tTraining loss: 0.6311179995536804\n",
      "Step: 800  \tTraining accuracy: 0.6543216705322266\n",
      "Step: 800  \tValid loss: 0.6198803782463074\n",
      "Step: 900  \tTraining loss: 0.6296192407608032\n",
      "Step: 900  \tTraining accuracy: 0.6559731960296631\n",
      "Step: 900  \tValid loss: 0.6180145144462585\n",
      "Step: 1000  \tTraining loss: 0.6286165118217468\n",
      "Step: 1000  \tTraining accuracy: 0.6570085287094116\n",
      "Step: 1000  \tValid loss: 0.6168200373649597\n",
      "Step: 1100  \tTraining loss: 0.6280349493026733\n",
      "Step: 1100  \tTraining accuracy: 0.6579683423042297\n",
      "Step: 1100  \tValid loss: 0.6157472133636475\n",
      "Step: 1200  \tTraining loss: 0.6275455355644226\n",
      "Step: 1200  \tTraining accuracy: 0.6585392951965332\n",
      "Step: 1200  \tValid loss: 0.6146270036697388\n",
      "Step: 1300  \tTraining loss: 0.627256453037262\n",
      "Step: 1300  \tTraining accuracy: 0.6590189337730408\n",
      "Step: 1300  \tValid loss: 0.6138555407524109\n",
      "Step: 1400  \tTraining loss: 0.6266468167304993\n",
      "Step: 1400  \tTraining accuracy: 0.6597113013267517\n",
      "Step: 1400  \tValid loss: 0.61266028881073\n",
      "Step: 1500  \tTraining loss: 0.6262043714523315\n",
      "Step: 1500  \tTraining accuracy: 0.6602787971496582\n",
      "Step: 1500  \tValid loss: 0.6112998723983765\n",
      "Step: 1600  \tTraining loss: 0.625856876373291\n",
      "Step: 1600  \tTraining accuracy: 0.6608280539512634\n",
      "Step: 1600  \tValid loss: 0.6103754043579102\n",
      "Step: 1700  \tTraining loss: 0.6254684925079346\n",
      "Step: 1700  \tTraining accuracy: 0.6614396572113037\n",
      "Step: 1700  \tValid loss: 0.6095604300498962\n",
      "Step: 1800  \tTraining loss: 0.6250704526901245\n",
      "Step: 1800  \tTraining accuracy: 0.6619327664375305\n",
      "Step: 1800  \tValid loss: 0.6087344288825989\n",
      "Step: 1900  \tTraining loss: 0.6246752142906189\n",
      "Step: 1900  \tTraining accuracy: 0.6624646186828613\n",
      "Step: 1900  \tValid loss: 0.6080068349838257\n",
      "Step: 2000  \tTraining loss: 0.6243197321891785\n",
      "Step: 2000  \tTraining accuracy: 0.6628327965736389\n",
      "Step: 2000  \tValid loss: 0.6074215173721313\n",
      "Step: 2100  \tTraining loss: 0.6239756941795349\n",
      "Step: 2100  \tTraining accuracy: 0.6631443500518799\n",
      "Step: 2100  \tValid loss: 0.6069172620773315\n",
      "Step: 2200  \tTraining loss: 0.6236324906349182\n",
      "Step: 2200  \tTraining accuracy: 0.6635060906410217\n",
      "Step: 2200  \tValid loss: 0.6064435243606567\n",
      "Step: 2300  \tTraining loss: 0.6232454180717468\n",
      "Step: 2300  \tTraining accuracy: 0.6637978553771973\n",
      "Step: 2300  \tValid loss: 0.6059517860412598\n",
      "Step: 2400  \tTraining loss: 0.6227498054504395\n",
      "Step: 2400  \tTraining accuracy: 0.6640466451644897\n",
      "Step: 2400  \tValid loss: 0.6052592396736145\n",
      "Step: 2500  \tTraining loss: 0.6222153306007385\n",
      "Step: 2500  \tTraining accuracy: 0.6641361713409424\n",
      "Step: 2500  \tValid loss: 0.6044764518737793\n",
      "Step: 2600  \tTraining loss: 0.6216461062431335\n",
      "Step: 2600  \tTraining accuracy: 0.6642854809761047\n",
      "Step: 2600  \tValid loss: 0.6038249731063843\n",
      "Step: 2700  \tTraining loss: 0.6210465431213379\n",
      "Step: 2700  \tTraining accuracy: 0.6644234657287598\n",
      "Step: 2700  \tValid loss: 0.603143036365509\n",
      "Step: 2800  \tTraining loss: 0.6204695701599121\n",
      "Step: 2800  \tTraining accuracy: 0.6646133661270142\n",
      "Step: 2800  \tValid loss: 0.6025389432907104\n",
      "Step: 2900  \tTraining loss: 0.6199131011962891\n",
      "Step: 2900  \tTraining accuracy: 0.6647152900695801\n",
      "Step: 2900  \tValid loss: 0.6020054817199707\n",
      "Step: 3000  \tTraining loss: 0.6193842887878418\n",
      "Step: 3000  \tTraining accuracy: 0.664738118648529\n",
      "Step: 3000  \tValid loss: 0.6014686822891235\n",
      "Step: 3100  \tTraining loss: 0.6188766956329346\n",
      "Step: 3100  \tTraining accuracy: 0.6648013591766357\n",
      "Step: 3100  \tValid loss: 0.6010245680809021\n",
      "Step: 3200  \tTraining loss: 0.618353009223938\n",
      "Step: 3200  \tTraining accuracy: 0.6649416089057922\n",
      "Step: 3200  \tValid loss: 0.6006823778152466\n",
      "Step: 3300  \tTraining loss: 0.6177867650985718\n",
      "Step: 3300  \tTraining accuracy: 0.6650994420051575\n",
      "Step: 3300  \tValid loss: 0.600460946559906\n",
      "Step: 3400  \tTraining loss: 0.6172620058059692\n",
      "Step: 3400  \tTraining accuracy: 0.6653240919113159\n",
      "Step: 3400  \tValid loss: 0.6003983616828918\n",
      "Step: 3500  \tTraining loss: 0.6167781949043274\n",
      "Step: 3500  \tTraining accuracy: 0.6655357480049133\n",
      "Step: 3500  \tValid loss: 0.600105345249176\n",
      "Step: 3600  \tTraining loss: 0.6163317561149597\n",
      "Step: 3600  \tTraining accuracy: 0.6657594442367554\n",
      "Step: 3600  \tValid loss: 0.5998233556747437\n",
      "Step: 3700  \tTraining loss: 0.6159167885780334\n",
      "Step: 3700  \tTraining accuracy: 0.6659941673278809\n",
      "Step: 3700  \tValid loss: 0.5995961427688599\n",
      "Step: 3800  \tTraining loss: 0.6155387759208679\n",
      "Step: 3800  \tTraining accuracy: 0.6661937236785889\n",
      "Step: 3800  \tValid loss: 0.599441409111023\n",
      "Step: 3900  \tTraining loss: 0.6151827573776245\n",
      "Step: 3900  \tTraining accuracy: 0.666382908821106\n",
      "Step: 3900  \tValid loss: 0.5991291999816895\n",
      "Step: 4000  \tTraining loss: 0.6148408651351929\n",
      "Step: 4000  \tTraining accuracy: 0.6665624976158142\n",
      "Step: 4000  \tValid loss: 0.5990561246871948\n",
      "Step: 4100  \tTraining loss: 0.6145413517951965\n",
      "Step: 4100  \tTraining accuracy: 0.6667647361755371\n",
      "Step: 4100  \tValid loss: 0.5989651679992676\n",
      "Step: 4200  \tTraining loss: 0.6142780184745789\n",
      "Step: 4200  \tTraining accuracy: 0.6669470071792603\n",
      "Step: 4200  \tValid loss: 0.5988036394119263\n",
      "Step: 4300  \tTraining loss: 0.6140390038490295\n",
      "Step: 4300  \tTraining accuracy: 0.6671707630157471\n",
      "Step: 4300  \tValid loss: 0.5986745953559875\n",
      "Step: 4400  \tTraining loss: 0.6138196587562561\n",
      "Step: 4400  \tTraining accuracy: 0.6673940420150757\n",
      "Step: 4400  \tValid loss: 0.5986027121543884\n",
      "Step: 4500  \tTraining loss: 0.6136201620101929\n",
      "Step: 4500  \tTraining accuracy: 0.6675881147384644\n",
      "Step: 4500  \tValid loss: 0.5984748005867004\n",
      "Step: 4600  \tTraining loss: 0.613438069820404\n",
      "Step: 4600  \tTraining accuracy: 0.6677549481391907\n",
      "Step: 4600  \tValid loss: 0.5983604192733765\n",
      "Step: 4700  \tTraining loss: 0.6132711172103882\n",
      "Step: 4700  \tTraining accuracy: 0.6679512858390808\n",
      "Step: 4700  \tValid loss: 0.5982967615127563\n",
      "Step: 4800  \tTraining loss: 0.6131185293197632\n",
      "Step: 4800  \tTraining accuracy: 0.6681482791900635\n",
      "Step: 4800  \tValid loss: 0.5982376933097839\n",
      "Step: 4900  \tTraining loss: 0.6129785776138306\n",
      "Step: 4900  \tTraining accuracy: 0.6683371067047119\n",
      "Step: 4900  \tValid loss: 0.5981747508049011\n",
      "Step: 5000  \tTraining loss: 0.6128508448600769\n",
      "Step: 5000  \tTraining accuracy: 0.6685011386871338\n",
      "Step: 5000  \tValid loss: 0.5981200933456421\n",
      "Step: 5100  \tTraining loss: 0.6127341985702515\n",
      "Step: 5100  \tTraining accuracy: 0.6686671376228333\n",
      "Step: 5100  \tValid loss: 0.598068356513977\n",
      "Step: 5200  \tTraining loss: 0.6126279234886169\n",
      "Step: 5200  \tTraining accuracy: 0.6688101291656494\n",
      "Step: 5200  \tValid loss: 0.5980189442634583\n",
      "Step: 5300  \tTraining loss: 0.6125312447547913\n",
      "Step: 5300  \tTraining accuracy: 0.6689395904541016\n",
      "Step: 5300  \tValid loss: 0.5979846715927124\n",
      "Step: 5400  \tTraining loss: 0.6124439239501953\n",
      "Step: 5400  \tTraining accuracy: 0.669072151184082\n",
      "Step: 5400  \tValid loss: 0.5979374647140503\n",
      "Step: 5500  \tTraining loss: 0.6123635768890381\n",
      "Step: 5500  \tTraining accuracy: 0.6691998243331909\n",
      "Step: 5500  \tValid loss: 0.5979047417640686\n",
      "Step: 5600  \tTraining loss: 0.6122905611991882\n",
      "Step: 5600  \tTraining accuracy: 0.6693152785301208\n",
      "Step: 5600  \tValid loss: 0.5978571772575378\n",
      "Step: 5700  \tTraining loss: 0.6122227311134338\n",
      "Step: 5700  \tTraining accuracy: 0.669434130191803\n",
      "Step: 5700  \tValid loss: 0.5978177189826965\n",
      "Step: 5800  \tTraining loss: 0.6121603846549988\n",
      "Step: 5800  \tTraining accuracy: 0.6695266366004944\n",
      "Step: 5800  \tValid loss: 0.5977780222892761\n",
      "Step: 5900  \tTraining loss: 0.6121034622192383\n",
      "Step: 5900  \tTraining accuracy: 0.6696160435676575\n",
      "Step: 5900  \tValid loss: 0.5977405309677124\n",
      "Step: 6000  \tTraining loss: 0.6120507717132568\n",
      "Step: 6000  \tTraining accuracy: 0.669695258140564\n",
      "Step: 6000  \tValid loss: 0.5976995825767517\n",
      "Step: 6100  \tTraining loss: 0.6120020747184753\n",
      "Step: 6100  \tTraining accuracy: 0.6697788834571838\n",
      "Step: 6100  \tValid loss: 0.5976576805114746\n",
      "Step: 6200  \tTraining loss: 0.611956000328064\n",
      "Step: 6200  \tTraining accuracy: 0.6698528528213501\n",
      "Step: 6200  \tValid loss: 0.5976219773292542\n",
      "Step: 6300  \tTraining loss: 0.6119137406349182\n",
      "Step: 6300  \tTraining accuracy: 0.6699244976043701\n",
      "Step: 6300  \tValid loss: 0.5975828170776367\n",
      "Step: 6400  \tTraining loss: 0.6118735671043396\n",
      "Step: 6400  \tTraining accuracy: 0.6699938178062439\n",
      "Step: 6400  \tValid loss: 0.5975481271743774\n",
      "Step: 6500  \tTraining loss: 0.6118358969688416\n",
      "Step: 6500  \tTraining accuracy: 0.6700610518455505\n",
      "Step: 6500  \tValid loss: 0.5975157618522644\n",
      "Step: 6600  \tTraining loss: 0.6118001341819763\n",
      "Step: 6600  \tTraining accuracy: 0.670113205909729\n",
      "Step: 6600  \tValid loss: 0.5974851846694946\n",
      "Step: 6700  \tTraining loss: 0.6117667555809021\n",
      "Step: 6700  \tTraining accuracy: 0.6701509952545166\n",
      "Step: 6700  \tValid loss: 0.5974502563476562\n",
      "Step: 6800  \tTraining loss: 0.6117350459098816\n",
      "Step: 6800  \tTraining accuracy: 0.6701939702033997\n",
      "Step: 6800  \tValid loss: 0.5974181294441223\n",
      "Step: 6900  \tTraining loss: 0.6117045283317566\n",
      "Step: 6900  \tTraining accuracy: 0.6702170372009277\n",
      "Step: 6900  \tValid loss: 0.5973856449127197\n",
      "Step: 7000  \tTraining loss: 0.6116754412651062\n",
      "Step: 7000  \tTraining accuracy: 0.670251727104187\n",
      "Step: 7000  \tValid loss: 0.5973590016365051\n",
      "Step: 7100  \tTraining loss: 0.6116471886634827\n",
      "Step: 7100  \tTraining accuracy: 0.6702854037284851\n",
      "Step: 7100  \tValid loss: 0.5973300933837891\n",
      "Step: 7200  \tTraining loss: 0.6116203665733337\n",
      "Step: 7200  \tTraining accuracy: 0.670312225818634\n",
      "Step: 7200  \tValid loss: 0.5973020792007446\n",
      "Step: 7300  \tTraining loss: 0.611594021320343\n",
      "Step: 7300  \tTraining accuracy: 0.6703323721885681\n",
      "Step: 7300  \tValid loss: 0.597277045249939\n",
      "Step: 7400  \tTraining loss: 0.6115686893463135\n",
      "Step: 7400  \tTraining accuracy: 0.6703578233718872\n",
      "Step: 7400  \tValid loss: 0.5972521901130676\n",
      "Step: 7500  \tTraining loss: 0.6115441918373108\n",
      "Step: 7500  \tTraining accuracy: 0.670382559299469\n",
      "Step: 7500  \tValid loss: 0.5972254276275635\n",
      "Step: 7600  \tTraining loss: 0.6115202903747559\n",
      "Step: 7600  \tTraining accuracy: 0.6704122424125671\n",
      "Step: 7600  \tValid loss: 0.5972010493278503\n",
      "Step: 7700  \tTraining loss: 0.6114967465400696\n",
      "Step: 7700  \tTraining accuracy: 0.6704356670379639\n",
      "Step: 7700  \tValid loss: 0.5971776247024536\n",
      "Step: 7800  \tTraining loss: 0.6114732623100281\n",
      "Step: 7800  \tTraining accuracy: 0.6704639196395874\n",
      "Step: 7800  \tValid loss: 0.5971558690071106\n",
      "Step: 7900  \tTraining loss: 0.6114509701728821\n",
      "Step: 7900  \tTraining accuracy: 0.6704914569854736\n",
      "Step: 7900  \tValid loss: 0.5971346497535706\n",
      "Step: 8000  \tTraining loss: 0.6114276051521301\n",
      "Step: 8000  \tTraining accuracy: 0.6705183386802673\n",
      "Step: 8000  \tValid loss: 0.5971173644065857\n",
      "Step: 8100  \tTraining loss: 0.6114059090614319\n",
      "Step: 8100  \tTraining accuracy: 0.6705498099327087\n",
      "Step: 8100  \tValid loss: 0.5970937013626099\n",
      "Step: 8200  \tTraining loss: 0.6113840937614441\n",
      "Step: 8200  \tTraining accuracy: 0.6705805063247681\n",
      "Step: 8200  \tValid loss: 0.5970780253410339\n",
      "Step: 8300  \tTraining loss: 0.611362636089325\n",
      "Step: 8300  \tTraining accuracy: 0.6706104278564453\n",
      "Step: 8300  \tValid loss: 0.597061812877655\n",
      "Step: 8400  \tTraining loss: 0.6113409996032715\n",
      "Step: 8400  \tTraining accuracy: 0.6706345677375793\n",
      "Step: 8400  \tValid loss: 0.5970460176467896\n",
      "Step: 8500  \tTraining loss: 0.6113194227218628\n",
      "Step: 8500  \tTraining accuracy: 0.6706631779670715\n",
      "Step: 8500  \tValid loss: 0.597033679485321\n",
      "Step: 8600  \tTraining loss: 0.611298143863678\n",
      "Step: 8600  \tTraining accuracy: 0.6706911325454712\n",
      "Step: 8600  \tValid loss: 0.5970202684402466\n",
      "Step: 8700  \tTraining loss: 0.6112765073776245\n",
      "Step: 8700  \tTraining accuracy: 0.6707184314727783\n",
      "Step: 8700  \tValid loss: 0.5970093607902527\n",
      "Step: 8800  \tTraining loss: 0.6112558245658875\n",
      "Step: 8800  \tTraining accuracy: 0.6707451343536377\n",
      "Step: 8800  \tValid loss: 0.5969972610473633\n",
      "Step: 8900  \tTraining loss: 0.6112342476844788\n",
      "Step: 8900  \tTraining accuracy: 0.6707711815834045\n",
      "Step: 8900  \tValid loss: 0.5969877243041992\n",
      "Step: 9000  \tTraining loss: 0.6112134456634521\n",
      "Step: 9000  \tTraining accuracy: 0.6708014011383057\n",
      "Step: 9000  \tValid loss: 0.5969763994216919\n",
      "Step: 9100  \tTraining loss: 0.6111913323402405\n",
      "Step: 9100  \tTraining accuracy: 0.670831024646759\n",
      "Step: 9100  \tValid loss: 0.5969710946083069\n",
      "Step: 9200  \tTraining loss: 0.6111698746681213\n",
      "Step: 9200  \tTraining accuracy: 0.6708552837371826\n",
      "Step: 9200  \tValid loss: 0.5969654321670532\n",
      "Step: 9300  \tTraining loss: 0.6111478209495544\n",
      "Step: 9300  \tTraining accuracy: 0.6708744168281555\n",
      "Step: 9300  \tValid loss: 0.5969579815864563\n",
      "Step: 9400  \tTraining loss: 0.6111268997192383\n",
      "Step: 9400  \tTraining accuracy: 0.6708931922912598\n",
      "Step: 9400  \tValid loss: 0.5969518423080444\n",
      "Step: 9500  \tTraining loss: 0.6111048460006714\n",
      "Step: 9500  \tTraining accuracy: 0.6709114909172058\n",
      "Step: 9500  \tValid loss: 0.5969465970993042\n",
      "Step: 9600  \tTraining loss: 0.6110826730728149\n",
      "Step: 9600  \tTraining accuracy: 0.6709339022636414\n",
      "Step: 9600  \tValid loss: 0.5969444513320923\n",
      "Step: 9700  \tTraining loss: 0.6110594868659973\n",
      "Step: 9700  \tTraining accuracy: 0.6709558963775635\n",
      "Step: 9700  \tValid loss: 0.5969429612159729\n",
      "Step: 9800  \tTraining loss: 0.6110365986824036\n",
      "Step: 9800  \tTraining accuracy: 0.6709773540496826\n",
      "Step: 9800  \tValid loss: 0.5969434976577759\n",
      "Step: 9900  \tTraining loss: 0.6110131740570068\n",
      "Step: 9900  \tTraining accuracy: 0.6709984540939331\n",
      "Step: 9900  \tValid loss: 0.5969419479370117\n",
      "Step: 10000  \tTraining loss: 0.6109901070594788\n",
      "Step: 10000  \tTraining accuracy: 0.6710190773010254\n",
      "Step: 10000  \tValid loss: 0.5969406366348267\n",
      "Step: 10100  \tTraining loss: 0.6109658479690552\n",
      "Step: 10100  \tTraining accuracy: 0.6710392832756042\n",
      "Step: 10100  \tValid loss: 0.5969363451004028\n",
      "Step: 10200  \tTraining loss: 0.6109426021575928\n",
      "Step: 10200  \tTraining accuracy: 0.6710591316223145\n",
      "Step: 10200  \tValid loss: 0.5969407558441162\n",
      "Step: 10300  \tTraining loss: 0.6109172701835632\n",
      "Step: 10300  \tTraining accuracy: 0.6710744500160217\n",
      "Step: 10300  \tValid loss: 0.5969432592391968\n",
      "Step: 10400  \tTraining loss: 0.6108919382095337\n",
      "Step: 10400  \tTraining accuracy: 0.6710894107818604\n",
      "Step: 10400  \tValid loss: 0.5969434976577759\n",
      "Step: 10500  \tTraining loss: 0.6108661890029907\n",
      "Step: 10500  \tTraining accuracy: 0.6711041331291199\n",
      "Step: 10500  \tValid loss: 0.5969487428665161\n",
      "Step: 10600  \tTraining loss: 0.6108412146568298\n",
      "Step: 10600  \tTraining accuracy: 0.6711226105690002\n",
      "Step: 10600  \tValid loss: 0.5969501733779907\n",
      "Step: 10700  \tTraining loss: 0.6108141541481018\n",
      "Step: 10700  \tTraining accuracy: 0.671136736869812\n",
      "Step: 10700  \tValid loss: 0.596955418586731\n",
      "Step: 10800  \tTraining loss: 0.6107878684997559\n",
      "Step: 10800  \tTraining accuracy: 0.6711545586585999\n",
      "Step: 10800  \tValid loss: 0.5969603657722473\n",
      "Step: 10900  \tTraining loss: 0.6107603311538696\n",
      "Step: 10900  \tTraining accuracy: 0.671172022819519\n",
      "Step: 10900  \tValid loss: 0.5969656705856323\n",
      "Step: 11000  \tTraining loss: 0.6107318997383118\n",
      "Step: 11000  \tTraining accuracy: 0.6711891889572144\n",
      "Step: 11000  \tValid loss: 0.5969758033752441\n",
      "Step: 11100  \tTraining loss: 0.6107032299041748\n",
      "Step: 11100  \tTraining accuracy: 0.6712099313735962\n",
      "Step: 11100  \tValid loss: 0.596980094909668\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.67123026\n",
      "Precision: 0.676307\n",
      "Recall: 0.839779\n",
      "F1 score: 0.7436056\n",
      "AUC: 0.6069863\n",
      "   accuracy  precision    recall  f1_score       auc     loss  accuracy_val  \\\n",
      "0   0.67123   0.676307  0.839779  0.743606  0.606986  0.61069      0.671292   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.596934       0.671325   0.571705      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  11146.0  \n",
      "25\n",
      "(1421, 4)\n",
      "(1421, 1)\n",
      "(768, 4)\n",
      "(768, 1)\n",
      "(624, 4)\n",
      "(624, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.663788378238678\n",
      "Step: 100  \tTraining accuracy: 0.6291344165802002\n",
      "Step: 100  \tValid loss: 0.6607473492622375\n",
      "Step: 200  \tTraining loss: 0.6109423041343689\n",
      "Step: 200  \tTraining accuracy: 0.6587151885032654\n",
      "Step: 200  \tValid loss: 0.5998027920722961\n",
      "Step: 300  \tTraining loss: 0.5819194912910461\n",
      "Step: 300  \tTraining accuracy: 0.6722009181976318\n",
      "Step: 300  \tValid loss: 0.5692729949951172\n",
      "Step: 400  \tTraining loss: 0.5750082731246948\n",
      "Step: 400  \tTraining accuracy: 0.6807302236557007\n",
      "Step: 400  \tValid loss: 0.5648283958435059\n",
      "Step: 500  \tTraining loss: 0.5731676816940308\n",
      "Step: 500  \tTraining accuracy: 0.6872090101242065\n",
      "Step: 500  \tValid loss: 0.5649057030677795\n",
      "Step: 600  \tTraining loss: 0.5718122720718384\n",
      "Step: 600  \tTraining accuracy: 0.6907529234886169\n",
      "Step: 600  \tValid loss: 0.564333438873291\n",
      "Step: 700  \tTraining loss: 0.5710728168487549\n",
      "Step: 700  \tTraining accuracy: 0.6933165788650513\n",
      "Step: 700  \tValid loss: 0.5643024444580078\n",
      "Step: 800  \tTraining loss: 0.5704507827758789\n",
      "Step: 800  \tTraining accuracy: 0.6952917575836182\n",
      "Step: 800  \tValid loss: 0.5638930797576904\n",
      "Step: 900  \tTraining loss: 0.5698816180229187\n",
      "Step: 900  \tTraining accuracy: 0.6969279050827026\n",
      "Step: 900  \tValid loss: 0.5633392930030823\n",
      "Step: 1000  \tTraining loss: 0.569106936454773\n",
      "Step: 1000  \tTraining accuracy: 0.6984441876411438\n",
      "Step: 1000  \tValid loss: 0.562221348285675\n",
      "Step: 1100  \tTraining loss: 0.5684037804603577\n",
      "Step: 1100  \tTraining accuracy: 0.6996378898620605\n",
      "Step: 1100  \tValid loss: 0.5618583559989929\n",
      "Step: 1200  \tTraining loss: 0.567779541015625\n",
      "Step: 1200  \tTraining accuracy: 0.7005932331085205\n",
      "Step: 1200  \tValid loss: 0.5613394975662231\n",
      "Step: 1300  \tTraining loss: 0.5672634243965149\n",
      "Step: 1300  \tTraining accuracy: 0.701424241065979\n",
      "Step: 1300  \tValid loss: 0.5607799291610718\n",
      "Step: 1400  \tTraining loss: 0.5668646097183228\n",
      "Step: 1400  \tTraining accuracy: 0.7021321654319763\n",
      "Step: 1400  \tValid loss: 0.5602858662605286\n",
      "Step: 1500  \tTraining loss: 0.5665198564529419\n",
      "Step: 1500  \tTraining accuracy: 0.7026199102401733\n",
      "Step: 1500  \tValid loss: 0.559899091720581\n",
      "Step: 1600  \tTraining loss: 0.5661820769309998\n",
      "Step: 1600  \tTraining accuracy: 0.7030906081199646\n",
      "Step: 1600  \tValid loss: 0.5596746802330017\n",
      "Step: 1700  \tTraining loss: 0.5658953189849854\n",
      "Step: 1700  \tTraining accuracy: 0.7035473585128784\n",
      "Step: 1700  \tValid loss: 0.5595181584358215\n",
      "Step: 1800  \tTraining loss: 0.5656592845916748\n",
      "Step: 1800  \tTraining accuracy: 0.7039316296577454\n",
      "Step: 1800  \tValid loss: 0.5593097805976868\n",
      "Step: 1900  \tTraining loss: 0.5654528737068176\n",
      "Step: 1900  \tTraining accuracy: 0.7042742967605591\n",
      "Step: 1900  \tValid loss: 0.5591134428977966\n",
      "Step: 2000  \tTraining loss: 0.5652122497558594\n",
      "Step: 2000  \tTraining accuracy: 0.7044907808303833\n",
      "Step: 2000  \tValid loss: 0.5587596297264099\n",
      "Step: 2100  \tTraining loss: 0.5650294423103333\n",
      "Step: 2100  \tTraining accuracy: 0.7047034502029419\n",
      "Step: 2100  \tValid loss: 0.5584929585456848\n",
      "Step: 2200  \tTraining loss: 0.5648759603500366\n",
      "Step: 2200  \tTraining accuracy: 0.7049459218978882\n",
      "Step: 2200  \tValid loss: 0.5583507418632507\n",
      "Step: 2300  \tTraining loss: 0.564737856388092\n",
      "Step: 2300  \tTraining accuracy: 0.7051668763160706\n",
      "Step: 2300  \tValid loss: 0.5582501292228699\n",
      "Step: 2400  \tTraining loss: 0.5646072626113892\n",
      "Step: 2400  \tTraining accuracy: 0.7053539156913757\n",
      "Step: 2400  \tValid loss: 0.558256208896637\n",
      "Step: 2500  \tTraining loss: 0.5644807815551758\n",
      "Step: 2500  \tTraining accuracy: 0.7055256366729736\n",
      "Step: 2500  \tValid loss: 0.5582489371299744\n",
      "Step: 2600  \tTraining loss: 0.5643504858016968\n",
      "Step: 2600  \tTraining accuracy: 0.7056839466094971\n",
      "Step: 2600  \tValid loss: 0.5582700371742249\n",
      "Step: 2700  \tTraining loss: 0.5642082691192627\n",
      "Step: 2700  \tTraining accuracy: 0.7058436870574951\n",
      "Step: 2700  \tValid loss: 0.558262050151825\n",
      "Step: 2800  \tTraining loss: 0.5640192031860352\n",
      "Step: 2800  \tTraining accuracy: 0.7060564756393433\n",
      "Step: 2800  \tValid loss: 0.5582045912742615\n",
      "Step: 2900  \tTraining loss: 0.5638670921325684\n",
      "Step: 2900  \tTraining accuracy: 0.706291675567627\n",
      "Step: 2900  \tValid loss: 0.558094322681427\n",
      "Step: 3000  \tTraining loss: 0.5637010931968689\n",
      "Step: 3000  \tTraining accuracy: 0.7064989805221558\n",
      "Step: 3000  \tValid loss: 0.5579835772514343\n",
      "Step: 3100  \tTraining loss: 0.5635108947753906\n",
      "Step: 3100  \tTraining accuracy: 0.706692636013031\n",
      "Step: 3100  \tValid loss: 0.5579900741577148\n",
      "Step: 3200  \tTraining loss: 0.5633642673492432\n",
      "Step: 3200  \tTraining accuracy: 0.7068740129470825\n",
      "Step: 3200  \tValid loss: 0.55799400806427\n",
      "Step: 3300  \tTraining loss: 0.5632272958755493\n",
      "Step: 3300  \tTraining accuracy: 0.7070770263671875\n",
      "Step: 3300  \tValid loss: 0.5579218864440918\n",
      "Step: 3400  \tTraining loss: 0.5630999803543091\n",
      "Step: 3400  \tTraining accuracy: 0.7072784900665283\n",
      "Step: 3400  \tValid loss: 0.5578597187995911\n",
      "Step: 3500  \tTraining loss: 0.5629794001579285\n",
      "Step: 3500  \tTraining accuracy: 0.7074683308601379\n",
      "Step: 3500  \tValid loss: 0.5577996373176575\n",
      "Step: 3600  \tTraining loss: 0.5628593564033508\n",
      "Step: 3600  \tTraining accuracy: 0.7076675295829773\n",
      "Step: 3600  \tValid loss: 0.5577579140663147\n",
      "Step: 3700  \tTraining loss: 0.5627450942993164\n",
      "Step: 3700  \tTraining accuracy: 0.7079044580459595\n",
      "Step: 3700  \tValid loss: 0.5576968789100647\n",
      "Step: 3800  \tTraining loss: 0.5626381039619446\n",
      "Step: 3800  \tTraining accuracy: 0.7081287503242493\n",
      "Step: 3800  \tValid loss: 0.5576394200325012\n",
      "Step: 3900  \tTraining loss: 0.5625366568565369\n",
      "Step: 3900  \tTraining accuracy: 0.7083414196968079\n",
      "Step: 3900  \tValid loss: 0.557563304901123\n",
      "Step: 4000  \tTraining loss: 0.5624386072158813\n",
      "Step: 4000  \tTraining accuracy: 0.7085433006286621\n",
      "Step: 4000  \tValid loss: 0.5575277209281921\n",
      "Step: 4100  \tTraining loss: 0.5623437762260437\n",
      "Step: 4100  \tTraining accuracy: 0.7087352275848389\n",
      "Step: 4100  \tValid loss: 0.5574801564216614\n",
      "Step: 4200  \tTraining loss: 0.5622444152832031\n",
      "Step: 4200  \tTraining accuracy: 0.7089093327522278\n",
      "Step: 4200  \tValid loss: 0.5573742985725403\n",
      "Step: 4300  \tTraining loss: 0.5621514916419983\n",
      "Step: 4300  \tTraining accuracy: 0.7091087102890015\n",
      "Step: 4300  \tValid loss: 0.5573666095733643\n",
      "Step: 4400  \tTraining loss: 0.5620607733726501\n",
      "Step: 4400  \tTraining accuracy: 0.709274411201477\n",
      "Step: 4400  \tValid loss: 0.5573441982269287\n",
      "Step: 4500  \tTraining loss: 0.5619723200798035\n",
      "Step: 4500  \tTraining accuracy: 0.7094326615333557\n",
      "Step: 4500  \tValid loss: 0.5573121905326843\n",
      "Step: 4600  \tTraining loss: 0.5618858933448792\n",
      "Step: 4600  \tTraining accuracy: 0.7095839381217957\n",
      "Step: 4600  \tValid loss: 0.5572898387908936\n",
      "Step: 4700  \tTraining loss: 0.5618033409118652\n",
      "Step: 4700  \tTraining accuracy: 0.7097210884094238\n",
      "Step: 4700  \tValid loss: 0.5572155117988586\n",
      "Step: 4800  \tTraining loss: 0.5617212057113647\n",
      "Step: 4800  \tTraining accuracy: 0.7098599076271057\n",
      "Step: 4800  \tValid loss: 0.5571814179420471\n",
      "Step: 4900  \tTraining loss: 0.5616418719291687\n",
      "Step: 4900  \tTraining accuracy: 0.7099857330322266\n",
      "Step: 4900  \tValid loss: 0.5570929050445557\n",
      "Step: 5000  \tTraining loss: 0.5615607500076294\n",
      "Step: 5000  \tTraining accuracy: 0.7101207971572876\n",
      "Step: 5000  \tValid loss: 0.5570700168609619\n",
      "Step: 5100  \tTraining loss: 0.5614837408065796\n",
      "Step: 5100  \tTraining accuracy: 0.7102434635162354\n",
      "Step: 5100  \tValid loss: 0.5570130348205566\n",
      "Step: 5200  \tTraining loss: 0.5614075660705566\n",
      "Step: 5200  \tTraining accuracy: 0.710368275642395\n",
      "Step: 5200  \tValid loss: 0.5569870471954346\n",
      "Step: 5300  \tTraining loss: 0.5613329410552979\n",
      "Step: 5300  \tTraining accuracy: 0.710481584072113\n",
      "Step: 5300  \tValid loss: 0.5569282174110413\n",
      "Step: 5400  \tTraining loss: 0.5612595081329346\n",
      "Step: 5400  \tTraining accuracy: 0.7106039524078369\n",
      "Step: 5400  \tValid loss: 0.5568826794624329\n",
      "Step: 5500  \tTraining loss: 0.5611869692802429\n",
      "Step: 5500  \tTraining accuracy: 0.7107217907905579\n",
      "Step: 5500  \tValid loss: 0.5568510890007019\n",
      "Step: 5600  \tTraining loss: 0.5611139535903931\n",
      "Step: 5600  \tTraining accuracy: 0.7108290195465088\n",
      "Step: 5600  \tValid loss: 0.5567980408668518\n",
      "Step: 5700  \tTraining loss: 0.5610392093658447\n",
      "Step: 5700  \tTraining accuracy: 0.7109387516975403\n",
      "Step: 5700  \tValid loss: 0.5567875504493713\n",
      "Step: 5800  \tTraining loss: 0.5609668493270874\n",
      "Step: 5800  \tTraining accuracy: 0.7110446095466614\n",
      "Step: 5800  \tValid loss: 0.5567583441734314\n",
      "Step: 5900  \tTraining loss: 0.5608969926834106\n",
      "Step: 5900  \tTraining accuracy: 0.711146891117096\n",
      "Step: 5900  \tValid loss: 0.5566976070404053\n",
      "Step: 6000  \tTraining loss: 0.5608273148536682\n",
      "Step: 6000  \tTraining accuracy: 0.7112457156181335\n",
      "Step: 6000  \tValid loss: 0.5567168593406677\n",
      "Step: 6100  \tTraining loss: 0.5607572793960571\n",
      "Step: 6100  \tTraining accuracy: 0.7113354206085205\n",
      "Step: 6100  \tValid loss: 0.5566806197166443\n",
      "Step: 6200  \tTraining loss: 0.5606881976127625\n",
      "Step: 6200  \tTraining accuracy: 0.7114279866218567\n",
      "Step: 6200  \tValid loss: 0.5566332340240479\n",
      "Step: 6300  \tTraining loss: 0.5606094002723694\n",
      "Step: 6300  \tTraining accuracy: 0.7115232348442078\n",
      "Step: 6300  \tValid loss: 0.5567078590393066\n",
      "Step: 6400  \tTraining loss: 0.560524046421051\n",
      "Step: 6400  \tTraining accuracy: 0.711609959602356\n",
      "Step: 6400  \tValid loss: 0.5566201210021973\n",
      "Step: 6500  \tTraining loss: 0.5604518055915833\n",
      "Step: 6500  \tTraining accuracy: 0.7117104530334473\n",
      "Step: 6500  \tValid loss: 0.5565866827964783\n",
      "Step: 6600  \tTraining loss: 0.5603830814361572\n",
      "Step: 6600  \tTraining accuracy: 0.711807906627655\n",
      "Step: 6600  \tValid loss: 0.5565765500068665\n",
      "Step: 6700  \tTraining loss: 0.5603173971176147\n",
      "Step: 6700  \tTraining accuracy: 0.7119024395942688\n",
      "Step: 6700  \tValid loss: 0.5565283894538879\n",
      "Step: 6800  \tTraining loss: 0.5602594614028931\n",
      "Step: 6800  \tTraining accuracy: 0.7119941711425781\n",
      "Step: 6800  \tValid loss: 0.5564806461334229\n",
      "Step: 6900  \tTraining loss: 0.5602044463157654\n",
      "Step: 6900  \tTraining accuracy: 0.7120832204818726\n",
      "Step: 6900  \tValid loss: 0.5564243793487549\n",
      "Step: 7000  \tTraining loss: 0.5601500272750854\n",
      "Step: 7000  \tTraining accuracy: 0.7121697068214417\n",
      "Step: 7000  \tValid loss: 0.5563938021659851\n",
      "Step: 7100  \tTraining loss: 0.5600965023040771\n",
      "Step: 7100  \tTraining accuracy: 0.7122487425804138\n",
      "Step: 7100  \tValid loss: 0.5563609004020691\n",
      "Step: 7200  \tTraining loss: 0.5600466728210449\n",
      "Step: 7200  \tTraining accuracy: 0.7123255133628845\n",
      "Step: 7200  \tValid loss: 0.5563023686408997\n",
      "Step: 7300  \tTraining loss: 0.5599958300590515\n",
      "Step: 7300  \tTraining accuracy: 0.7124001383781433\n",
      "Step: 7300  \tValid loss: 0.5562980771064758\n",
      "Step: 7400  \tTraining loss: 0.5599486231803894\n",
      "Step: 7400  \tTraining accuracy: 0.7124679684638977\n",
      "Step: 7400  \tValid loss: 0.5562841892242432\n",
      "Step: 7500  \tTraining loss: 0.5599018335342407\n",
      "Step: 7500  \tTraining accuracy: 0.7125387191772461\n",
      "Step: 7500  \tValid loss: 0.556255042552948\n",
      "Step: 7600  \tTraining loss: 0.5598561763763428\n",
      "Step: 7600  \tTraining accuracy: 0.7126122713088989\n",
      "Step: 7600  \tValid loss: 0.55623459815979\n",
      "Step: 7700  \tTraining loss: 0.5598114728927612\n",
      "Step: 7700  \tTraining accuracy: 0.7126793265342712\n",
      "Step: 7700  \tValid loss: 0.5562077164649963\n",
      "Step: 7800  \tTraining loss: 0.5597679018974304\n",
      "Step: 7800  \tTraining accuracy: 0.7127445936203003\n",
      "Step: 7800  \tValid loss: 0.5561818480491638\n",
      "Step: 7900  \tTraining loss: 0.5597244501113892\n",
      "Step: 7900  \tTraining accuracy: 0.7128081917762756\n",
      "Step: 7900  \tValid loss: 0.5561657547950745\n",
      "Step: 8000  \tTraining loss: 0.559681236743927\n",
      "Step: 8000  \tTraining accuracy: 0.7128702402114868\n",
      "Step: 8000  \tValid loss: 0.5561622977256775\n",
      "Step: 8100  \tTraining loss: 0.5596389770507812\n",
      "Step: 8100  \tTraining accuracy: 0.7129350900650024\n",
      "Step: 8100  \tValid loss: 0.5561345219612122\n",
      "Step: 8200  \tTraining loss: 0.5595965385437012\n",
      "Step: 8200  \tTraining accuracy: 0.7129984498023987\n",
      "Step: 8200  \tValid loss: 0.5561333894729614\n",
      "Step: 8300  \tTraining loss: 0.5595560669898987\n",
      "Step: 8300  \tTraining accuracy: 0.7130644917488098\n",
      "Step: 8300  \tValid loss: 0.5560910701751709\n",
      "Step: 8400  \tTraining loss: 0.559514582157135\n",
      "Step: 8400  \tTraining accuracy: 0.7131289839744568\n",
      "Step: 8400  \tValid loss: 0.5560938715934753\n",
      "Step: 8500  \tTraining loss: 0.5594736933708191\n",
      "Step: 8500  \tTraining accuracy: 0.7131961584091187\n",
      "Step: 8500  \tValid loss: 0.5560494065284729\n",
      "Step: 8600  \tTraining loss: 0.5594323873519897\n",
      "Step: 8600  \tTraining accuracy: 0.7132576107978821\n",
      "Step: 8600  \tValid loss: 0.5560262203216553\n",
      "Step: 8700  \tTraining loss: 0.5593907237052917\n",
      "Step: 8700  \tTraining accuracy: 0.7133176326751709\n",
      "Step: 8700  \tValid loss: 0.5559943914413452\n",
      "Step: 8800  \tTraining loss: 0.5593494772911072\n",
      "Step: 8800  \tTraining accuracy: 0.7133762836456299\n",
      "Step: 8800  \tValid loss: 0.5559899806976318\n",
      "Step: 8900  \tTraining loss: 0.5593096613883972\n",
      "Step: 8900  \tTraining accuracy: 0.7134295701980591\n",
      "Step: 8900  \tValid loss: 0.5559685826301575\n",
      "Step: 9000  \tTraining loss: 0.5592710375785828\n",
      "Step: 9000  \tTraining accuracy: 0.7134777307510376\n",
      "Step: 9000  \tValid loss: 0.5559545755386353\n",
      "Step: 9100  \tTraining loss: 0.5592324137687683\n",
      "Step: 9100  \tTraining accuracy: 0.7135248184204102\n",
      "Step: 9100  \tValid loss: 0.5559452772140503\n",
      "Step: 9200  \tTraining loss: 0.5591942071914673\n",
      "Step: 9200  \tTraining accuracy: 0.7135708928108215\n",
      "Step: 9200  \tValid loss: 0.5559560656547546\n",
      "Step: 9300  \tTraining loss: 0.5591572523117065\n",
      "Step: 9300  \tTraining accuracy: 0.7136159539222717\n",
      "Step: 9300  \tValid loss: 0.5559300780296326\n",
      "Step: 9400  \tTraining loss: 0.559118390083313\n",
      "Step: 9400  \tTraining accuracy: 0.7136600613594055\n",
      "Step: 9400  \tValid loss: 0.5559577941894531\n",
      "Step: 9500  \tTraining loss: 0.5590820908546448\n",
      "Step: 9500  \tTraining accuracy: 0.7137032151222229\n",
      "Step: 9500  \tValid loss: 0.5559709668159485\n",
      "Step: 9600  \tTraining loss: 0.5590459704399109\n",
      "Step: 9600  \tTraining accuracy: 0.7137454748153687\n",
      "Step: 9600  \tValid loss: 0.5559636354446411\n",
      "Step: 9700  \tTraining loss: 0.5590085983276367\n",
      "Step: 9700  \tTraining accuracy: 0.7137868404388428\n",
      "Step: 9700  \tValid loss: 0.5559810400009155\n",
      "Step: 9800  \tTraining loss: 0.5589717030525208\n",
      "Step: 9800  \tTraining accuracy: 0.71382737159729\n",
      "Step: 9800  \tValid loss: 0.556006908416748\n",
      "Step: 9900  \tTraining loss: 0.5589346885681152\n",
      "Step: 9900  \tTraining accuracy: 0.7138707041740417\n",
      "Step: 9900  \tValid loss: 0.5560267567634583\n",
      "Step: 10000  \tTraining loss: 0.5588973164558411\n",
      "Step: 10000  \tTraining accuracy: 0.7139131426811218\n",
      "Step: 10000  \tValid loss: 0.5560497045516968\n",
      "Step: 10100  \tTraining loss: 0.5588598847389221\n",
      "Step: 10100  \tTraining accuracy: 0.713954746723175\n",
      "Step: 10100  \tValid loss: 0.5560700297355652\n",
      "Step: 10200  \tTraining loss: 0.5588233470916748\n",
      "Step: 10200  \tTraining accuracy: 0.7139955163002014\n",
      "Step: 10200  \tValid loss: 0.5560794472694397\n",
      "Step: 10300  \tTraining loss: 0.5587858557701111\n",
      "Step: 10300  \tTraining accuracy: 0.7140320539474487\n",
      "Step: 10300  \tValid loss: 0.5560879111289978\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7140679\n",
      "Precision: 0.7009202\n",
      "Recall: 0.6851574\n",
      "F1 score: 0.70594734\n",
      "AUC: 0.7132684\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.714068    0.70092  0.685157  0.705947  0.713268  0.558785      0.714063   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0   0.55593       0.714009    0.58743      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  10300.0  \n",
      "26\n",
      "(870, 4)\n",
      "(870, 1)\n",
      "(464, 4)\n",
      "(464, 1)\n",
      "(377, 4)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6626532077789307\n",
      "Step: 100  \tTraining accuracy: 0.5701149702072144\n",
      "Step: 100  \tValid loss: 0.6635416150093079\n",
      "Step: 200  \tTraining loss: 0.6363211870193481\n",
      "Step: 200  \tTraining accuracy: 0.5931809544563293\n",
      "Step: 200  \tValid loss: 0.6366830468177795\n",
      "Step: 300  \tTraining loss: 0.6065533757209778\n",
      "Step: 300  \tTraining accuracy: 0.6251164674758911\n",
      "Step: 300  \tValid loss: 0.606077253818512\n",
      "Step: 400  \tTraining loss: 0.5836626887321472\n",
      "Step: 400  \tTraining accuracy: 0.6455105543136597\n",
      "Step: 400  \tValid loss: 0.5832124948501587\n",
      "Step: 500  \tTraining loss: 0.5675171613693237\n",
      "Step: 500  \tTraining accuracy: 0.658672571182251\n",
      "Step: 500  \tValid loss: 0.5691967010498047\n",
      "Step: 600  \tTraining loss: 0.5571192502975464\n",
      "Step: 600  \tTraining accuracy: 0.6687533259391785\n",
      "Step: 600  \tValid loss: 0.5630775690078735\n",
      "Step: 700  \tTraining loss: 0.5514724254608154\n",
      "Step: 700  \tTraining accuracy: 0.6751077771186829\n",
      "Step: 700  \tValid loss: 0.5598125457763672\n",
      "Step: 800  \tTraining loss: 0.5477921962738037\n",
      "Step: 800  \tTraining accuracy: 0.6803144812583923\n",
      "Step: 800  \tValid loss: 0.5571303367614746\n",
      "Step: 900  \tTraining loss: 0.545245885848999\n",
      "Step: 900  \tTraining accuracy: 0.68436598777771\n",
      "Step: 900  \tValid loss: 0.5550069212913513\n",
      "Step: 1000  \tTraining loss: 0.5423958897590637\n",
      "Step: 1000  \tTraining accuracy: 0.6876267790794373\n",
      "Step: 1000  \tValid loss: 0.5550712943077087\n",
      "Step: 1100  \tTraining loss: 0.540407121181488\n",
      "Step: 1100  \tTraining accuracy: 0.6907119154930115\n",
      "Step: 1100  \tValid loss: 0.5538742542266846\n",
      "Step: 1200  \tTraining loss: 0.5389569997787476\n",
      "Step: 1200  \tTraining accuracy: 0.6933624744415283\n",
      "Step: 1200  \tValid loss: 0.552457869052887\n",
      "Step: 1300  \tTraining loss: 0.5378642082214355\n",
      "Step: 1300  \tTraining accuracy: 0.6954957246780396\n",
      "Step: 1300  \tValid loss: 0.5512443780899048\n",
      "Step: 1400  \tTraining loss: 0.5369156002998352\n",
      "Step: 1400  \tTraining accuracy: 0.6975295543670654\n",
      "Step: 1400  \tValid loss: 0.5506659746170044\n",
      "Step: 1500  \tTraining loss: 0.5362330079078674\n",
      "Step: 1500  \tTraining accuracy: 0.6993635296821594\n",
      "Step: 1500  \tValid loss: 0.54991614818573\n",
      "Step: 1600  \tTraining loss: 0.5357053279876709\n",
      "Step: 1600  \tTraining accuracy: 0.7008855938911438\n",
      "Step: 1600  \tValid loss: 0.5492813587188721\n",
      "Step: 1700  \tTraining loss: 0.5352281928062439\n",
      "Step: 1700  \tTraining accuracy: 0.7020817399024963\n",
      "Step: 1700  \tValid loss: 0.5489586591720581\n",
      "Step: 1800  \tTraining loss: 0.5346540212631226\n",
      "Step: 1800  \tTraining accuracy: 0.7032412886619568\n",
      "Step: 1800  \tValid loss: 0.5486298203468323\n",
      "Step: 1900  \tTraining loss: 0.5341678857803345\n",
      "Step: 1900  \tTraining accuracy: 0.7042124271392822\n",
      "Step: 1900  \tValid loss: 0.548212468624115\n",
      "Step: 2000  \tTraining loss: 0.5337333083152771\n",
      "Step: 2000  \tTraining accuracy: 0.705143928527832\n",
      "Step: 2000  \tValid loss: 0.5479675531387329\n",
      "Step: 2100  \tTraining loss: 0.5333728790283203\n",
      "Step: 2100  \tTraining accuracy: 0.7060130834579468\n",
      "Step: 2100  \tValid loss: 0.54775470495224\n",
      "Step: 2200  \tTraining loss: 0.5330457091331482\n",
      "Step: 2200  \tTraining accuracy: 0.7067742943763733\n",
      "Step: 2200  \tValid loss: 0.5475336909294128\n",
      "Step: 2300  \tTraining loss: 0.5327275991439819\n",
      "Step: 2300  \tTraining accuracy: 0.707493782043457\n",
      "Step: 2300  \tValid loss: 0.5474616289138794\n",
      "Step: 2400  \tTraining loss: 0.5324196815490723\n",
      "Step: 2400  \tTraining accuracy: 0.7081520557403564\n",
      "Step: 2400  \tValid loss: 0.5475090742111206\n",
      "Step: 2500  \tTraining loss: 0.5320679545402527\n",
      "Step: 2500  \tTraining accuracy: 0.7086851000785828\n",
      "Step: 2500  \tValid loss: 0.5477157831192017\n",
      "Step: 2600  \tTraining loss: 0.531762421131134\n",
      "Step: 2600  \tTraining accuracy: 0.7091763019561768\n",
      "Step: 2600  \tValid loss: 0.5479200482368469\n",
      "Step: 2700  \tTraining loss: 0.5314147472381592\n",
      "Step: 2700  \tTraining accuracy: 0.709674596786499\n",
      "Step: 2700  \tValid loss: 0.5479065179824829\n",
      "Step: 2800  \tTraining loss: 0.5310837626457214\n",
      "Step: 2800  \tTraining accuracy: 0.7101365923881531\n",
      "Step: 2800  \tValid loss: 0.5480090975761414\n",
      "Step: 2900  \tTraining loss: 0.530763566493988\n",
      "Step: 2900  \tTraining accuracy: 0.7106072306632996\n",
      "Step: 2900  \tValid loss: 0.5481418967247009\n",
      "Step: 3000  \tTraining loss: 0.5304455161094666\n",
      "Step: 3000  \tTraining accuracy: 0.7110459804534912\n",
      "Step: 3000  \tValid loss: 0.5483149886131287\n",
      "Step: 3100  \tTraining loss: 0.5301249027252197\n",
      "Step: 3100  \tTraining accuracy: 0.7114176154136658\n",
      "Step: 3100  \tValid loss: 0.5484366416931152\n",
      "Step: 3200  \tTraining loss: 0.5298052430152893\n",
      "Step: 3200  \tTraining accuracy: 0.711728572845459\n",
      "Step: 3200  \tValid loss: 0.5485660433769226\n",
      "Step: 3300  \tTraining loss: 0.5294855833053589\n",
      "Step: 3300  \tTraining accuracy: 0.7120383977890015\n",
      "Step: 3300  \tValid loss: 0.5486986041069031\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.71232975\n",
      "Precision: 0.6910569\n",
      "Recall: 0.6818182\n",
      "F1 score: 0.70753616\n",
      "AUC: 0.72598976\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0   0.71233   0.691057  0.681818  0.707536  0.72599  0.529413      0.712024   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.547434       0.711995   0.582477      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  3322.0  \n",
      "27\n",
      "(870, 4)\n",
      "(870, 1)\n",
      "(480, 4)\n",
      "(480, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 4)\n",
      "(390, 1)\n",
      "Step: 100  \tTraining loss: 0.6528242230415344\n",
      "Step: 100  \tTraining accuracy: 0.6022988557815552\n",
      "Step: 100  \tValid loss: 0.6590091586112976\n",
      "Step: 200  \tTraining loss: 0.6265718340873718\n",
      "Step: 200  \tTraining accuracy: 0.6226053833961487\n",
      "Step: 200  \tValid loss: 0.6225759983062744\n",
      "Step: 300  \tTraining loss: 0.609664797782898\n",
      "Step: 300  \tTraining accuracy: 0.6482758522033691\n",
      "Step: 300  \tValid loss: 0.5984506607055664\n",
      "Step: 400  \tTraining loss: 0.5950245261192322\n",
      "Step: 400  \tTraining accuracy: 0.6688013076782227\n",
      "Step: 400  \tValid loss: 0.5791441202163696\n",
      "Step: 500  \tTraining loss: 0.5829203724861145\n",
      "Step: 500  \tTraining accuracy: 0.6804597973823547\n",
      "Step: 500  \tValid loss: 0.5630893707275391\n",
      "Step: 600  \tTraining loss: 0.5741315484046936\n",
      "Step: 600  \tTraining accuracy: 0.6880877614021301\n",
      "Step: 600  \tValid loss: 0.5501444339752197\n",
      "Step: 700  \tTraining loss: 0.5680840015411377\n",
      "Step: 700  \tTraining accuracy: 0.6940760612487793\n",
      "Step: 700  \tValid loss: 0.5400815606117249\n",
      "Step: 800  \tTraining loss: 0.5640099048614502\n",
      "Step: 800  \tTraining accuracy: 0.6990804672241211\n",
      "Step: 800  \tValid loss: 0.5323117971420288\n",
      "Step: 900  \tTraining loss: 0.5612495541572571\n",
      "Step: 900  \tTraining accuracy: 0.7032454609870911\n",
      "Step: 900  \tValid loss: 0.5262986421585083\n",
      "Step: 1000  \tTraining loss: 0.5593461394309998\n",
      "Step: 1000  \tTraining accuracy: 0.7063521146774292\n",
      "Step: 1000  \tValid loss: 0.5215890407562256\n",
      "Step: 1100  \tTraining loss: 0.5579968690872192\n",
      "Step: 1100  \tTraining accuracy: 0.7089217305183411\n",
      "Step: 1100  \tValid loss: 0.5178264379501343\n",
      "Step: 1200  \tTraining loss: 0.5569925308227539\n",
      "Step: 1200  \tTraining accuracy: 0.7109944820404053\n",
      "Step: 1200  \tValid loss: 0.5147930979728699\n",
      "Step: 1300  \tTraining loss: 0.5562052726745605\n",
      "Step: 1300  \tTraining accuracy: 0.7131034731864929\n",
      "Step: 1300  \tValid loss: 0.5123058557510376\n",
      "Step: 1400  \tTraining loss: 0.5555571913719177\n",
      "Step: 1400  \tTraining accuracy: 0.7152405381202698\n",
      "Step: 1400  \tValid loss: 0.5102378129959106\n",
      "Step: 1500  \tTraining loss: 0.5550030469894409\n",
      "Step: 1500  \tTraining accuracy: 0.7172017693519592\n",
      "Step: 1500  \tValid loss: 0.5084978342056274\n",
      "Step: 1600  \tTraining loss: 0.5545167326927185\n",
      "Step: 1600  \tTraining accuracy: 0.7187986373901367\n",
      "Step: 1600  \tValid loss: 0.507020890712738\n",
      "Step: 1700  \tTraining loss: 0.5540836453437805\n",
      "Step: 1700  \tTraining accuracy: 0.7201671600341797\n",
      "Step: 1700  \tValid loss: 0.50576251745224\n",
      "Step: 1800  \tTraining loss: 0.5536981225013733\n",
      "Step: 1800  \tTraining accuracy: 0.7214449644088745\n",
      "Step: 1800  \tValid loss: 0.5046982169151306\n",
      "Step: 1900  \tTraining loss: 0.5533508062362671\n",
      "Step: 1900  \tTraining accuracy: 0.7226778268814087\n",
      "Step: 1900  \tValid loss: 0.5037807822227478\n",
      "Step: 2000  \tTraining loss: 0.5530372858047485\n",
      "Step: 2000  \tTraining accuracy: 0.7238137125968933\n",
      "Step: 2000  \tValid loss: 0.502996563911438\n",
      "Step: 2100  \tTraining loss: 0.5527529716491699\n",
      "Step: 2100  \tTraining accuracy: 0.7248387932777405\n",
      "Step: 2100  \tValid loss: 0.5023289322853088\n",
      "Step: 2200  \tTraining loss: 0.552494466304779\n",
      "Step: 2200  \tTraining accuracy: 0.725768506526947\n",
      "Step: 2200  \tValid loss: 0.5017591714859009\n",
      "Step: 2300  \tTraining loss: 0.5522574782371521\n",
      "Step: 2300  \tTraining accuracy: 0.7266156077384949\n",
      "Step: 2300  \tValid loss: 0.5012721419334412\n",
      "Step: 2400  \tTraining loss: 0.5520402789115906\n",
      "Step: 2400  \tTraining accuracy: 0.7273905873298645\n",
      "Step: 2400  \tValid loss: 0.5008646845817566\n",
      "Step: 2500  \tTraining loss: 0.5518391728401184\n",
      "Step: 2500  \tTraining accuracy: 0.7281022667884827\n",
      "Step: 2500  \tValid loss: 0.5005064606666565\n",
      "Step: 2600  \tTraining loss: 0.5516512989997864\n",
      "Step: 2600  \tTraining accuracy: 0.7288483381271362\n",
      "Step: 2600  \tValid loss: 0.500198483467102\n",
      "Step: 2700  \tTraining loss: 0.5514745116233826\n",
      "Step: 2700  \tTraining accuracy: 0.7295597195625305\n",
      "Step: 2700  \tValid loss: 0.499933123588562\n",
      "Step: 2800  \tTraining loss: 0.5513068437576294\n",
      "Step: 2800  \tTraining accuracy: 0.7302194237709045\n",
      "Step: 2800  \tValid loss: 0.49970194697380066\n",
      "Step: 2900  \tTraining loss: 0.5511446595191956\n",
      "Step: 2900  \tTraining accuracy: 0.7308530211448669\n",
      "Step: 2900  \tValid loss: 0.49949899315834045\n",
      "Step: 3000  \tTraining loss: 0.5509870052337646\n",
      "Step: 3000  \tTraining accuracy: 0.7314630746841431\n",
      "Step: 3000  \tValid loss: 0.4993216097354889\n",
      "Step: 3100  \tTraining loss: 0.5508314967155457\n",
      "Step: 3100  \tTraining accuracy: 0.7320142984390259\n",
      "Step: 3100  \tValid loss: 0.4991631805896759\n",
      "Step: 3200  \tTraining loss: 0.5506765842437744\n",
      "Step: 3200  \tTraining accuracy: 0.7325305342674255\n",
      "Step: 3200  \tValid loss: 0.4990226924419403\n",
      "Step: 3300  \tTraining loss: 0.5505238175392151\n",
      "Step: 3300  \tTraining accuracy: 0.7330150604248047\n",
      "Step: 3300  \tValid loss: 0.4988981783390045\n",
      "Step: 3400  \tTraining loss: 0.5503739714622498\n",
      "Step: 3400  \tTraining accuracy: 0.7334705591201782\n",
      "Step: 3400  \tValid loss: 0.4987855851650238\n",
      "Step: 3500  \tTraining loss: 0.5502287745475769\n",
      "Step: 3500  \tTraining accuracy: 0.7339164018630981\n",
      "Step: 3500  \tValid loss: 0.49868878722190857\n",
      "Step: 3600  \tTraining loss: 0.5500898957252502\n",
      "Step: 3600  \tTraining accuracy: 0.7343370318412781\n",
      "Step: 3600  \tValid loss: 0.498606413602829\n",
      "Step: 3700  \tTraining loss: 0.5499580502510071\n",
      "Step: 3700  \tTraining accuracy: 0.7347347140312195\n",
      "Step: 3700  \tValid loss: 0.49853768944740295\n",
      "Step: 3800  \tTraining loss: 0.549833357334137\n",
      "Step: 3800  \tTraining accuracy: 0.7350957989692688\n",
      "Step: 3800  \tValid loss: 0.49848026037216187\n",
      "Step: 3900  \tTraining loss: 0.5497130155563354\n",
      "Step: 3900  \tTraining accuracy: 0.7354530692100525\n",
      "Step: 3900  \tValid loss: 0.49843698740005493\n",
      "Step: 4000  \tTraining loss: 0.5496002435684204\n",
      "Step: 4000  \tTraining accuracy: 0.7357922196388245\n",
      "Step: 4000  \tValid loss: 0.49839961528778076\n",
      "Step: 4100  \tTraining loss: 0.5494933128356934\n",
      "Step: 4100  \tTraining accuracy: 0.7361146807670593\n",
      "Step: 4100  \tValid loss: 0.4983721077442169\n",
      "Step: 4200  \tTraining loss: 0.54939204454422\n",
      "Step: 4200  \tTraining accuracy: 0.7364076972007751\n",
      "Step: 4200  \tValid loss: 0.4983481764793396\n",
      "Step: 4300  \tTraining loss: 0.5492956638336182\n",
      "Step: 4300  \tTraining accuracy: 0.7366869449615479\n",
      "Step: 4300  \tValid loss: 0.498331218957901\n",
      "Step: 4400  \tTraining loss: 0.5492041707038879\n",
      "Step: 4400  \tTraining accuracy: 0.7369533777236938\n",
      "Step: 4400  \tValid loss: 0.49831780791282654\n",
      "Step: 4500  \tTraining loss: 0.5491172671318054\n",
      "Step: 4500  \tTraining accuracy: 0.73720782995224\n",
      "Step: 4500  \tValid loss: 0.49831098318099976\n",
      "Step: 4600  \tTraining loss: 0.5490334033966064\n",
      "Step: 4600  \tTraining accuracy: 0.7374510765075684\n",
      "Step: 4600  \tValid loss: 0.4982984662055969\n",
      "Step: 4700  \tTraining loss: 0.548953115940094\n",
      "Step: 4700  \tTraining accuracy: 0.7376838326454163\n",
      "Step: 4700  \tValid loss: 0.4982958436012268\n",
      "Step: 4800  \tTraining loss: 0.5488419532775879\n",
      "Step: 4800  \tTraining accuracy: 0.7378947138786316\n",
      "Step: 4800  \tValid loss: 0.49827665090560913\n",
      "Step: 4900  \tTraining loss: 0.5487233996391296\n",
      "Step: 4900  \tTraining accuracy: 0.7381206154823303\n",
      "Step: 4900  \tValid loss: 0.49823588132858276\n",
      "Step: 5000  \tTraining loss: 0.5486090183258057\n",
      "Step: 5000  \tTraining accuracy: 0.7383373975753784\n",
      "Step: 5000  \tValid loss: 0.4982132315635681\n",
      "Step: 5100  \tTraining loss: 0.5484943389892578\n",
      "Step: 5100  \tTraining accuracy: 0.7385455965995789\n",
      "Step: 5100  \tValid loss: 0.49822378158569336\n",
      "Step: 5200  \tTraining loss: 0.5483877658843994\n",
      "Step: 5200  \tTraining accuracy: 0.7387345433235168\n",
      "Step: 5200  \tValid loss: 0.4982638657093048\n",
      "Step: 5300  \tTraining loss: 0.5482870936393738\n",
      "Step: 5300  \tTraining accuracy: 0.7389271855354309\n",
      "Step: 5300  \tValid loss: 0.49829787015914917\n",
      "Step: 5400  \tTraining loss: 0.5481900572776794\n",
      "Step: 5400  \tTraining accuracy: 0.7391019463539124\n",
      "Step: 5400  \tValid loss: 0.4983461797237396\n",
      "Step: 5500  \tTraining loss: 0.548108696937561\n",
      "Step: 5500  \tTraining accuracy: 0.7392702698707581\n",
      "Step: 5500  \tValid loss: 0.49833762645721436\n",
      "Step: 5600  \tTraining loss: 0.5480334162712097\n",
      "Step: 5600  \tTraining accuracy: 0.7394325137138367\n",
      "Step: 5600  \tValid loss: 0.4983459413051605\n",
      "Step: 5700  \tTraining loss: 0.547962486743927\n",
      "Step: 5700  \tTraining accuracy: 0.7395890355110168\n",
      "Step: 5700  \tValid loss: 0.4983600676059723\n",
      "Step: 5800  \tTraining loss: 0.547895073890686\n",
      "Step: 5800  \tTraining accuracy: 0.7397301197052002\n",
      "Step: 5800  \tValid loss: 0.49837830662727356\n",
      "Step: 5900  \tTraining loss: 0.547831654548645\n",
      "Step: 5900  \tTraining accuracy: 0.7398663759231567\n",
      "Step: 5900  \tValid loss: 0.4983949661254883\n",
      "Step: 6000  \tTraining loss: 0.5477714538574219\n",
      "Step: 6000  \tTraining accuracy: 0.7399980425834656\n",
      "Step: 6000  \tValid loss: 0.4984114468097687\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.7401254\n",
      "Precision: 0.7683824\n",
      "Recall: 0.8069498\n",
      "F1 score: 0.75824517\n",
      "AUC: 0.7244977\n",
      "   accuracy  precision   recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.740125   0.768382  0.80695  0.758245  0.724498  0.547745      0.740125   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.498208       0.740021   0.494305      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  6044.0  \n",
      "28\n",
      "(870, 4)\n",
      "(870, 1)\n",
      "(464, 4)\n",
      "(464, 1)\n",
      "(377, 4)\n",
      "(377, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6728076338768005\n",
      "Step: 100  \tTraining accuracy: 0.5735632181167603\n",
      "Step: 100  \tValid loss: 0.6892799735069275\n",
      "Step: 200  \tTraining loss: 0.6496520042419434\n",
      "Step: 200  \tTraining accuracy: 0.5792328715324402\n",
      "Step: 200  \tValid loss: 0.6745184659957886\n",
      "Step: 300  \tTraining loss: 0.623713493347168\n",
      "Step: 300  \tTraining accuracy: 0.587604820728302\n",
      "Step: 300  \tValid loss: 0.6634125709533691\n",
      "Step: 400  \tTraining loss: 0.6089038252830505\n",
      "Step: 400  \tTraining accuracy: 0.5965350866317749\n",
      "Step: 400  \tValid loss: 0.6627678871154785\n",
      "Step: 500  \tTraining loss: 0.6022481322288513\n",
      "Step: 500  \tTraining accuracy: 0.6029297113418579\n",
      "Step: 500  \tValid loss: 0.6652249097824097\n",
      "Step: 600  \tTraining loss: 0.5983465909957886\n",
      "Step: 600  \tTraining accuracy: 0.6084880828857422\n",
      "Step: 600  \tValid loss: 0.6653705835342407\n",
      "Step: 700  \tTraining loss: 0.5940011739730835\n",
      "Step: 700  \tTraining accuracy: 0.6131465435028076\n",
      "Step: 700  \tValid loss: 0.6599606275558472\n",
      "Step: 800  \tTraining loss: 0.591029703617096\n",
      "Step: 800  \tTraining accuracy: 0.6173425912857056\n",
      "Step: 800  \tValid loss: 0.6573660373687744\n",
      "Step: 900  \tTraining loss: 0.5884873270988464\n",
      "Step: 900  \tTraining accuracy: 0.6211017966270447\n",
      "Step: 900  \tValid loss: 0.6545716524124146\n",
      "Step: 1000  \tTraining loss: 0.5858400464057922\n",
      "Step: 1000  \tTraining accuracy: 0.6250537633895874\n",
      "Step: 1000  \tValid loss: 0.6511751413345337\n",
      "Step: 1100  \tTraining loss: 0.5829187631607056\n",
      "Step: 1100  \tTraining accuracy: 0.6285873055458069\n",
      "Step: 1100  \tValid loss: 0.647158682346344\n",
      "Step: 1200  \tTraining loss: 0.5799381732940674\n",
      "Step: 1200  \tTraining accuracy: 0.6320146322250366\n",
      "Step: 1200  \tValid loss: 0.6429401636123657\n",
      "Step: 1300  \tTraining loss: 0.5771884918212891\n",
      "Step: 1300  \tTraining accuracy: 0.635221004486084\n",
      "Step: 1300  \tValid loss: 0.6387556791305542\n",
      "Step: 1400  \tTraining loss: 0.5748664736747742\n",
      "Step: 1400  \tTraining accuracy: 0.6378228664398193\n",
      "Step: 1400  \tValid loss: 0.6351903080940247\n",
      "Step: 1500  \tTraining loss: 0.5729721784591675\n",
      "Step: 1500  \tTraining accuracy: 0.6403480768203735\n",
      "Step: 1500  \tValid loss: 0.6322543025016785\n",
      "Step: 1600  \tTraining loss: 0.5714598298072815\n",
      "Step: 1600  \tTraining accuracy: 0.6424722075462341\n",
      "Step: 1600  \tValid loss: 0.6298688650131226\n",
      "Step: 1700  \tTraining loss: 0.5702579617500305\n",
      "Step: 1700  \tTraining accuracy: 0.6445160508155823\n",
      "Step: 1700  \tValid loss: 0.6279301047325134\n",
      "Step: 1800  \tTraining loss: 0.5692993998527527\n",
      "Step: 1800  \tTraining accuracy: 0.6464265584945679\n",
      "Step: 1800  \tValid loss: 0.6264455318450928\n",
      "Step: 1900  \tTraining loss: 0.5685148239135742\n",
      "Step: 1900  \tTraining accuracy: 0.6483200788497925\n",
      "Step: 1900  \tValid loss: 0.6252554059028625\n",
      "Step: 2000  \tTraining loss: 0.5678410530090332\n",
      "Step: 2000  \tTraining accuracy: 0.6501093506813049\n",
      "Step: 2000  \tValid loss: 0.6243960857391357\n",
      "Step: 2100  \tTraining loss: 0.5672665238380432\n",
      "Step: 2100  \tTraining accuracy: 0.6517241597175598\n",
      "Step: 2100  \tValid loss: 0.6236113905906677\n",
      "Step: 2200  \tTraining loss: 0.5667665600776672\n",
      "Step: 2200  \tTraining accuracy: 0.6532159447669983\n",
      "Step: 2200  \tValid loss: 0.6229979395866394\n",
      "Step: 2300  \tTraining loss: 0.5663226842880249\n",
      "Step: 2300  \tTraining accuracy: 0.654549241065979\n",
      "Step: 2300  \tValid loss: 0.6224802136421204\n",
      "Step: 2400  \tTraining loss: 0.5659171342849731\n",
      "Step: 2400  \tTraining accuracy: 0.6557691097259521\n",
      "Step: 2400  \tValid loss: 0.6220018863677979\n",
      "Step: 2500  \tTraining loss: 0.5655449628829956\n",
      "Step: 2500  \tTraining accuracy: 0.6569370627403259\n",
      "Step: 2500  \tValid loss: 0.6215248107910156\n",
      "Step: 2600  \tTraining loss: 0.5651949644088745\n",
      "Step: 2600  \tTraining accuracy: 0.6580593585968018\n",
      "Step: 2600  \tValid loss: 0.6210854649543762\n",
      "Step: 2700  \tTraining loss: 0.564867377281189\n",
      "Step: 2700  \tTraining accuracy: 0.6591189503669739\n",
      "Step: 2700  \tValid loss: 0.6206565499305725\n",
      "Step: 2800  \tTraining loss: 0.5642380118370056\n",
      "Step: 2800  \tTraining accuracy: 0.6600803136825562\n",
      "Step: 2800  \tValid loss: 0.619749903678894\n",
      "Step: 2900  \tTraining loss: 0.5636298656463623\n",
      "Step: 2900  \tTraining accuracy: 0.6609947085380554\n",
      "Step: 2900  \tValid loss: 0.6190415620803833\n",
      "Step: 3000  \tTraining loss: 0.5631271600723267\n",
      "Step: 3000  \tTraining accuracy: 0.6618273258209229\n",
      "Step: 3000  \tValid loss: 0.6185956597328186\n",
      "Step: 3100  \tTraining loss: 0.5626434683799744\n",
      "Step: 3100  \tTraining accuracy: 0.6626436710357666\n",
      "Step: 3100  \tValid loss: 0.618131160736084\n",
      "Step: 3200  \tTraining loss: 0.5620651245117188\n",
      "Step: 3200  \tTraining accuracy: 0.663463830947876\n",
      "Step: 3200  \tValid loss: 0.6176450252532959\n",
      "Step: 3300  \tTraining loss: 0.5614511370658875\n",
      "Step: 3300  \tTraining accuracy: 0.6642515659332275\n",
      "Step: 3300  \tValid loss: 0.6172690391540527\n",
      "Step: 3400  \tTraining loss: 0.5609005093574524\n",
      "Step: 3400  \tTraining accuracy: 0.6649224758148193\n",
      "Step: 3400  \tValid loss: 0.6168390512466431\n",
      "Step: 3500  \tTraining loss: 0.5604090690612793\n",
      "Step: 3500  \tTraining accuracy: 0.6655036807060242\n",
      "Step: 3500  \tValid loss: 0.6164050698280334\n",
      "Step: 3600  \tTraining loss: 0.5599650740623474\n",
      "Step: 3600  \tTraining accuracy: 0.6660357117652893\n",
      "Step: 3600  \tValid loss: 0.6156277656555176\n",
      "Step: 3700  \tTraining loss: 0.5592601299285889\n",
      "Step: 3700  \tTraining accuracy: 0.6665546298027039\n",
      "Step: 3700  \tValid loss: 0.6146270036697388\n",
      "Step: 3800  \tTraining loss: 0.5585940480232239\n",
      "Step: 3800  \tTraining accuracy: 0.6670458316802979\n",
      "Step: 3800  \tValid loss: 0.6138625741004944\n",
      "Step: 3900  \tTraining loss: 0.5582451820373535\n",
      "Step: 3900  \tTraining accuracy: 0.6674811840057373\n",
      "Step: 3900  \tValid loss: 0.6134338974952698\n",
      "Step: 4000  \tTraining loss: 0.5578848719596863\n",
      "Step: 4000  \tTraining accuracy: 0.6679241061210632\n",
      "Step: 4000  \tValid loss: 0.6128630638122559\n",
      "Step: 4100  \tTraining loss: 0.5575805306434631\n",
      "Step: 4100  \tTraining accuracy: 0.6684028506278992\n",
      "Step: 4100  \tValid loss: 0.6125179529190063\n",
      "Step: 4200  \tTraining loss: 0.5572983026504517\n",
      "Step: 4200  \tTraining accuracy: 0.6688444018363953\n",
      "Step: 4200  \tValid loss: 0.6121397614479065\n",
      "Step: 4300  \tTraining loss: 0.5570318698883057\n",
      "Step: 4300  \tTraining accuracy: 0.6692652702331543\n",
      "Step: 4300  \tValid loss: 0.611792266368866\n",
      "Step: 4400  \tTraining loss: 0.5567124485969543\n",
      "Step: 4400  \tTraining accuracy: 0.6696667075157166\n",
      "Step: 4400  \tValid loss: 0.6112298369407654\n",
      "Step: 4500  \tTraining loss: 0.5563284754753113\n",
      "Step: 4500  \tTraining accuracy: 0.6700501441955566\n",
      "Step: 4500  \tValid loss: 0.6107913255691528\n",
      "Step: 4600  \tTraining loss: 0.5560581684112549\n",
      "Step: 4600  \tTraining accuracy: 0.6704038977622986\n",
      "Step: 4600  \tValid loss: 0.610441267490387\n",
      "Step: 4700  \tTraining loss: 0.5558074116706848\n",
      "Step: 4700  \tTraining accuracy: 0.6707675457000732\n",
      "Step: 4700  \tValid loss: 0.609967827796936\n",
      "Step: 4800  \tTraining loss: 0.5555791854858398\n",
      "Step: 4800  \tTraining accuracy: 0.6711405515670776\n",
      "Step: 4800  \tValid loss: 0.6097748279571533\n",
      "Step: 4900  \tTraining loss: 0.555360734462738\n",
      "Step: 4900  \tTraining accuracy: 0.6714378595352173\n",
      "Step: 4900  \tValid loss: 0.6095370054244995\n",
      "Step: 5000  \tTraining loss: 0.5551556348800659\n",
      "Step: 5000  \tTraining accuracy: 0.6717585921287537\n",
      "Step: 5000  \tValid loss: 0.6093177199363708\n",
      "Step: 5100  \tTraining loss: 0.5549603700637817\n",
      "Step: 5100  \tTraining accuracy: 0.67204350233078\n",
      "Step: 5100  \tValid loss: 0.6091647148132324\n",
      "Step: 5200  \tTraining loss: 0.5547729134559631\n",
      "Step: 5200  \tTraining accuracy: 0.6723173260688782\n",
      "Step: 5200  \tValid loss: 0.6089898347854614\n",
      "Step: 5300  \tTraining loss: 0.5545955896377563\n",
      "Step: 5300  \tTraining accuracy: 0.6725696325302124\n",
      "Step: 5300  \tValid loss: 0.6088611483573914\n",
      "Step: 5400  \tTraining loss: 0.5544266700744629\n",
      "Step: 5400  \tTraining accuracy: 0.6728233695030212\n",
      "Step: 5400  \tValid loss: 0.6086920499801636\n",
      "Step: 5500  \tTraining loss: 0.5542688965797424\n",
      "Step: 5500  \tTraining accuracy: 0.6730678677558899\n",
      "Step: 5500  \tValid loss: 0.6085841655731201\n",
      "Step: 5600  \tTraining loss: 0.5541123151779175\n",
      "Step: 5600  \tTraining accuracy: 0.6733245849609375\n",
      "Step: 5600  \tValid loss: 0.6084455847740173\n",
      "Step: 5700  \tTraining loss: 0.5539621114730835\n",
      "Step: 5700  \tTraining accuracy: 0.6736135482788086\n",
      "Step: 5700  \tValid loss: 0.6082759499549866\n",
      "Step: 5800  \tTraining loss: 0.5538196563720703\n",
      "Step: 5800  \tTraining accuracy: 0.6738924980163574\n",
      "Step: 5800  \tValid loss: 0.6081957221031189\n",
      "Step: 5900  \tTraining loss: 0.5536820292472839\n",
      "Step: 5900  \tTraining accuracy: 0.6742018461227417\n",
      "Step: 5900  \tValid loss: 0.6080384850502014\n",
      "Step: 6000  \tTraining loss: 0.5535498857498169\n",
      "Step: 6000  \tTraining accuracy: 0.6744909882545471\n",
      "Step: 6000  \tValid loss: 0.6079599857330322\n",
      "Step: 6100  \tTraining loss: 0.5534166693687439\n",
      "Step: 6100  \tTraining accuracy: 0.6747705936431885\n",
      "Step: 6100  \tValid loss: 0.6077421307563782\n",
      "Step: 6200  \tTraining loss: 0.5532881021499634\n",
      "Step: 6200  \tTraining accuracy: 0.6750410795211792\n",
      "Step: 6200  \tValid loss: 0.6075777411460876\n",
      "Step: 6300  \tTraining loss: 0.5530104637145996\n",
      "Step: 6300  \tTraining accuracy: 0.6752935647964478\n",
      "Step: 6300  \tValid loss: 0.607575535774231\n",
      "Step: 6400  \tTraining loss: 0.5528700351715088\n",
      "Step: 6400  \tTraining accuracy: 0.6755473613739014\n",
      "Step: 6400  \tValid loss: 0.6075443029403687\n",
      "Step: 6500  \tTraining loss: 0.5527341961860657\n",
      "Step: 6500  \tTraining accuracy: 0.6758022904396057\n",
      "Step: 6500  \tValid loss: 0.6074424982070923\n",
      "Step: 6600  \tTraining loss: 0.5525248646736145\n",
      "Step: 6600  \tTraining accuracy: 0.6760315895080566\n",
      "Step: 6600  \tValid loss: 0.6076695919036865\n",
      "Step: 6700  \tTraining loss: 0.5523004531860352\n",
      "Step: 6700  \tTraining accuracy: 0.6762627959251404\n",
      "Step: 6700  \tValid loss: 0.6079054474830627\n",
      "Step: 6800  \tTraining loss: 0.5520445704460144\n",
      "Step: 6800  \tTraining accuracy: 0.6764698028564453\n",
      "Step: 6800  \tValid loss: 0.6085264086723328\n",
      "Step: 6900  \tTraining loss: 0.5518421530723572\n",
      "Step: 6900  \tTraining accuracy: 0.6766793727874756\n",
      "Step: 6900  \tValid loss: 0.608778178691864\n",
      "Step: 7000  \tTraining loss: 0.5516848564147949\n",
      "Step: 7000  \tTraining accuracy: 0.6768828630447388\n",
      "Step: 7000  \tValid loss: 0.608765721321106\n",
      "Step: 7100  \tTraining loss: 0.5515413284301758\n",
      "Step: 7100  \tTraining accuracy: 0.6770805716514587\n",
      "Step: 7100  \tValid loss: 0.6087738275527954\n",
      "Step: 7200  \tTraining loss: 0.5514024496078491\n",
      "Step: 7200  \tTraining accuracy: 0.6772645711898804\n",
      "Step: 7200  \tValid loss: 0.6087523102760315\n",
      "Step: 7300  \tTraining loss: 0.55126953125\n",
      "Step: 7300  \tTraining accuracy: 0.6774354577064514\n",
      "Step: 7300  \tValid loss: 0.6088274121284485\n",
      "Step: 7400  \tTraining loss: 0.5511388182640076\n",
      "Step: 7400  \tTraining accuracy: 0.6776096820831299\n",
      "Step: 7400  \tValid loss: 0.6088442802429199\n",
      "Step: 7500  \tTraining loss: 0.5510134696960449\n",
      "Step: 7500  \tTraining accuracy: 0.6777791976928711\n",
      "Step: 7500  \tValid loss: 0.6088579893112183\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.6779442\n",
      "Precision: 0.7218814\n",
      "Recall: 0.73388773\n",
      "F1 score: 0.6835355\n",
      "AUC: 0.69213665\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.677944   0.721881  0.733888  0.683536  0.692137  0.550934      0.677818   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.607363       0.677799   0.597653      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  7564.0  \n",
      "29\n",
      "(1798, 4)\n",
      "(1798, 1)\n",
      "(992, 4)\n",
      "(992, 1)\n",
      "(806, 4)\n",
      "(806, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5577059984207153\n",
      "Step: 100  \tTraining accuracy: 0.7525027990341187\n",
      "Step: 100  \tValid loss: 0.5678500533103943\n",
      "Step: 200  \tTraining loss: 0.4849386215209961\n",
      "Step: 200  \tTraining accuracy: 0.7658509612083435\n",
      "Step: 200  \tValid loss: 0.5124959349632263\n",
      "Step: 300  \tTraining loss: 0.4668704569339752\n",
      "Step: 300  \tTraining accuracy: 0.7776418328285217\n",
      "Step: 300  \tValid loss: 0.5005437135696411\n",
      "Step: 400  \tTraining loss: 0.4512878358364105\n",
      "Step: 400  \tTraining accuracy: 0.7834101319313049\n",
      "Step: 400  \tValid loss: 0.486924946308136\n",
      "Step: 500  \tTraining loss: 0.43450459837913513\n",
      "Step: 500  \tTraining accuracy: 0.7880361080169678\n",
      "Step: 500  \tValid loss: 0.47139206528663635\n",
      "Step: 600  \tTraining loss: 0.41686204075813293\n",
      "Step: 600  \tTraining accuracy: 0.791232705116272\n",
      "Step: 600  \tValid loss: 0.4544384479522705\n",
      "Step: 700  \tTraining loss: 0.3999515175819397\n",
      "Step: 700  \tTraining accuracy: 0.7938307523727417\n",
      "Step: 700  \tValid loss: 0.43817138671875\n",
      "Step: 800  \tTraining loss: 0.3854236304759979\n",
      "Step: 800  \tTraining accuracy: 0.7961809635162354\n",
      "Step: 800  \tValid loss: 0.42505964636802673\n",
      "Step: 900  \tTraining loss: 0.37412866950035095\n",
      "Step: 900  \tTraining accuracy: 0.7988941669464111\n",
      "Step: 900  \tValid loss: 0.41631895303726196\n",
      "Step: 1000  \tTraining loss: 0.36596572399139404\n",
      "Step: 1000  \tTraining accuracy: 0.8018558621406555\n",
      "Step: 1000  \tValid loss: 0.41165703535079956\n",
      "Step: 1100  \tTraining loss: 0.36026832461357117\n",
      "Step: 1100  \tTraining accuracy: 0.8049949407577515\n",
      "Step: 1100  \tValid loss: 0.4100356698036194\n",
      "Step: 1200  \tTraining loss: 0.3563620150089264\n",
      "Step: 1200  \tTraining accuracy: 0.8078299760818481\n",
      "Step: 1200  \tValid loss: 0.4103397727012634\n",
      "Step: 1300  \tTraining loss: 0.35357439517974854\n",
      "Step: 1300  \tTraining accuracy: 0.8104115724563599\n",
      "Step: 1300  \tValid loss: 0.41171160340309143\n",
      "Step: 1400  \tTraining loss: 0.35162055492401123\n",
      "Step: 1400  \tTraining accuracy: 0.8128373026847839\n",
      "Step: 1400  \tValid loss: 0.4127577543258667\n",
      "Step: 1500  \tTraining loss: 0.3498908579349518\n",
      "Step: 1500  \tTraining accuracy: 0.8149284720420837\n",
      "Step: 1500  \tValid loss: 0.41345450282096863\n",
      "Step: 1600  \tTraining loss: 0.34782278537750244\n",
      "Step: 1600  \tTraining accuracy: 0.8167856931686401\n",
      "Step: 1600  \tValid loss: 0.4127645790576935\n",
      "Step: 1700  \tTraining loss: 0.34669968485832214\n",
      "Step: 1700  \tTraining accuracy: 0.818316638469696\n",
      "Step: 1700  \tValid loss: 0.41475987434387207\n",
      "Step: 1800  \tTraining loss: 0.34575730562210083\n",
      "Step: 1800  \tTraining accuracy: 0.8197044134140015\n",
      "Step: 1800  \tValid loss: 0.41636523604393005\n",
      "Step: 1900  \tTraining loss: 0.34523430466651917\n",
      "Step: 1900  \tTraining accuracy: 0.820897102355957\n",
      "Step: 1900  \tValid loss: 0.4175961911678314\n",
      "Step: 2000  \tTraining loss: 0.34480729699134827\n",
      "Step: 2000  \tTraining accuracy: 0.8219531774520874\n",
      "Step: 2000  \tValid loss: 0.4184204041957855\n",
      "Step: 2100  \tTraining loss: 0.3444632291793823\n",
      "Step: 2100  \tTraining accuracy: 0.8229604959487915\n",
      "Step: 2100  \tValid loss: 0.41900283098220825\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8238611\n",
      "Precision: 0.86285096\n",
      "Recall: 0.85\n",
      "F1 score: 0.81767994\n",
      "AUC: 0.8509907\n",
      "   accuracy  precision  recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.823861   0.862851    0.85   0.81768  0.850991  0.344331      0.823216   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.409938       0.823131   0.350799      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2138.0  \n",
      "30\n",
      "(2378, 4)\n",
      "(2378, 1)\n",
      "(1312, 4)\n",
      "(1312, 1)\n",
      "(1066, 4)\n",
      "(1066, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6628414392471313\n",
      "Step: 100  \tTraining accuracy: 0.5984020233154297\n",
      "Step: 100  \tValid loss: 0.6549548506736755\n",
      "Step: 200  \tTraining loss: 0.6391163468360901\n",
      "Step: 200  \tTraining accuracy: 0.6138211488723755\n",
      "Step: 200  \tValid loss: 0.6302985548973083\n",
      "Step: 300  \tTraining loss: 0.6122719645500183\n",
      "Step: 300  \tTraining accuracy: 0.6373423337936401\n",
      "Step: 300  \tValid loss: 0.6012568473815918\n",
      "Step: 400  \tTraining loss: 0.5973035097122192\n",
      "Step: 400  \tTraining accuracy: 0.6566141843795776\n",
      "Step: 400  \tValid loss: 0.5816212296485901\n",
      "Step: 500  \tTraining loss: 0.5902460217475891\n",
      "Step: 500  \tTraining accuracy: 0.6691430807113647\n",
      "Step: 500  \tValid loss: 0.5697503685951233\n",
      "Step: 600  \tTraining loss: 0.5819286108016968\n",
      "Step: 600  \tTraining accuracy: 0.6775364875793457\n",
      "Step: 600  \tValid loss: 0.5566189885139465\n",
      "Step: 700  \tTraining loss: 0.5740280747413635\n",
      "Step: 700  \tTraining accuracy: 0.6848030090332031\n",
      "Step: 700  \tValid loss: 0.5441359281539917\n",
      "Step: 800  \tTraining loss: 0.5695953369140625\n",
      "Step: 800  \tTraining accuracy: 0.6912811994552612\n",
      "Step: 800  \tValid loss: 0.536938488483429\n",
      "Step: 900  \tTraining loss: 0.5670665502548218\n",
      "Step: 900  \tTraining accuracy: 0.6965072154998779\n",
      "Step: 900  \tValid loss: 0.5325304269790649\n",
      "Step: 1000  \tTraining loss: 0.5656819343566895\n",
      "Step: 1000  \tTraining accuracy: 0.7008985877037048\n",
      "Step: 1000  \tValid loss: 0.5300353169441223\n",
      "Step: 1100  \tTraining loss: 0.5648905634880066\n",
      "Step: 1100  \tTraining accuracy: 0.7044735550880432\n",
      "Step: 1100  \tValid loss: 0.528574526309967\n",
      "Step: 1200  \tTraining loss: 0.564338743686676\n",
      "Step: 1200  \tTraining accuracy: 0.7076278924942017\n",
      "Step: 1200  \tValid loss: 0.5277225375175476\n",
      "Step: 1300  \tTraining loss: 0.5638610124588013\n",
      "Step: 1300  \tTraining accuracy: 0.7104625701904297\n",
      "Step: 1300  \tValid loss: 0.5270717144012451\n",
      "Step: 1400  \tTraining loss: 0.5634856224060059\n",
      "Step: 1400  \tTraining accuracy: 0.7128772735595703\n",
      "Step: 1400  \tValid loss: 0.526581346988678\n",
      "Step: 1500  \tTraining loss: 0.5631685256958008\n",
      "Step: 1500  \tTraining accuracy: 0.7149444818496704\n",
      "Step: 1500  \tValid loss: 0.5262291431427002\n",
      "Step: 1600  \tTraining loss: 0.5628855228424072\n",
      "Step: 1600  \tTraining accuracy: 0.7167720198631287\n",
      "Step: 1600  \tValid loss: 0.5258826613426208\n",
      "Step: 1700  \tTraining loss: 0.5626159310340881\n",
      "Step: 1700  \tTraining accuracy: 0.7183780670166016\n",
      "Step: 1700  \tValid loss: 0.5255319476127625\n",
      "Step: 1800  \tTraining loss: 0.5623514652252197\n",
      "Step: 1800  \tTraining accuracy: 0.7197885513305664\n",
      "Step: 1800  \tValid loss: 0.5252332091331482\n",
      "Step: 1900  \tTraining loss: 0.5620840191841125\n",
      "Step: 1900  \tTraining accuracy: 0.721046507358551\n",
      "Step: 1900  \tValid loss: 0.524928629398346\n",
      "Step: 2000  \tTraining loss: 0.5618051290512085\n",
      "Step: 2000  \tTraining accuracy: 0.7221646904945374\n",
      "Step: 2000  \tValid loss: 0.5246422290802002\n",
      "Step: 2100  \tTraining loss: 0.5615049600601196\n",
      "Step: 2100  \tTraining accuracy: 0.7231943011283875\n",
      "Step: 2100  \tValid loss: 0.5243756175041199\n",
      "Step: 2200  \tTraining loss: 0.5611793398857117\n",
      "Step: 2200  \tTraining accuracy: 0.7241183519363403\n",
      "Step: 2200  \tValid loss: 0.524132251739502\n",
      "Step: 2300  \tTraining loss: 0.5608255863189697\n",
      "Step: 2300  \tTraining accuracy: 0.7249789834022522\n",
      "Step: 2300  \tValid loss: 0.5238525867462158\n",
      "Step: 2400  \tTraining loss: 0.5604150295257568\n",
      "Step: 2400  \tTraining accuracy: 0.725757360458374\n",
      "Step: 2400  \tValid loss: 0.5238038301467896\n",
      "Step: 2500  \tTraining loss: 0.5600095987319946\n",
      "Step: 2500  \tTraining accuracy: 0.7264808416366577\n",
      "Step: 2500  \tValid loss: 0.5235488414764404\n",
      "Step: 2600  \tTraining loss: 0.5595727562904358\n",
      "Step: 2600  \tTraining accuracy: 0.727196991443634\n",
      "Step: 2600  \tValid loss: 0.5231695175170898\n",
      "Step: 2700  \tTraining loss: 0.5591055750846863\n",
      "Step: 2700  \tTraining accuracy: 0.7278749942779541\n",
      "Step: 2700  \tValid loss: 0.5228748917579651\n",
      "Step: 2800  \tTraining loss: 0.5586442351341248\n",
      "Step: 2800  \tTraining accuracy: 0.7285190224647522\n",
      "Step: 2800  \tValid loss: 0.5225797891616821\n",
      "Step: 2900  \tTraining loss: 0.5582037568092346\n",
      "Step: 2900  \tTraining accuracy: 0.7291178107261658\n",
      "Step: 2900  \tValid loss: 0.5223061442375183\n",
      "Step: 3000  \tTraining loss: 0.5577626824378967\n",
      "Step: 3000  \tTraining accuracy: 0.7296902537345886\n",
      "Step: 3000  \tValid loss: 0.5220252275466919\n",
      "Step: 3100  \tTraining loss: 0.5573318004608154\n",
      "Step: 3100  \tTraining accuracy: 0.7302320599555969\n",
      "Step: 3100  \tValid loss: 0.521804690361023\n",
      "Step: 3200  \tTraining loss: 0.556919276714325\n",
      "Step: 3200  \tTraining accuracy: 0.7307595014572144\n",
      "Step: 3200  \tValid loss: 0.5216341018676758\n",
      "Step: 3300  \tTraining loss: 0.5565424561500549\n",
      "Step: 3300  \tTraining accuracy: 0.7312868237495422\n",
      "Step: 3300  \tValid loss: 0.5216135382652283\n",
      "Step: 3400  \tTraining loss: 0.5562306642532349\n",
      "Step: 3400  \tTraining accuracy: 0.7317575216293335\n",
      "Step: 3400  \tValid loss: 0.5215831995010376\n",
      "Step: 3500  \tTraining loss: 0.5559512972831726\n",
      "Step: 3500  \tTraining accuracy: 0.7321766018867493\n",
      "Step: 3500  \tValid loss: 0.521565318107605\n",
      "Step: 3600  \tTraining loss: 0.5557445287704468\n",
      "Step: 3600  \tTraining accuracy: 0.7325424551963806\n",
      "Step: 3600  \tValid loss: 0.5215611457824707\n",
      "Step: 3700  \tTraining loss: 0.5555781722068787\n",
      "Step: 3700  \tTraining accuracy: 0.732876718044281\n",
      "Step: 3700  \tValid loss: 0.5215804576873779\n",
      "Step: 3800  \tTraining loss: 0.5554371476173401\n",
      "Step: 3800  \tTraining accuracy: 0.7331763505935669\n",
      "Step: 3800  \tValid loss: 0.5215719938278198\n",
      "Step: 3900  \tTraining loss: 0.5553106665611267\n",
      "Step: 3900  \tTraining accuracy: 0.733465850353241\n",
      "Step: 3900  \tValid loss: 0.5216431617736816\n",
      "Step: 4000  \tTraining loss: 0.5551700592041016\n",
      "Step: 4000  \tTraining accuracy: 0.7337460517883301\n",
      "Step: 4000  \tValid loss: 0.5217229127883911\n",
      "Step: 4100  \tTraining loss: 0.555037796497345\n",
      "Step: 4100  \tTraining accuracy: 0.7339812517166138\n",
      "Step: 4100  \tValid loss: 0.5218331217765808\n",
      "Step: 4200  \tTraining loss: 0.5549355149269104\n",
      "Step: 4200  \tTraining accuracy: 0.7341949939727783\n",
      "Step: 4200  \tValid loss: 0.5219968557357788\n",
      "Step: 4300  \tTraining loss: 0.5548509359359741\n",
      "Step: 4300  \tTraining accuracy: 0.7343788743019104\n",
      "Step: 4300  \tValid loss: 0.5220742225646973\n",
      "Step: 4400  \tTraining loss: 0.5547747611999512\n",
      "Step: 4400  \tTraining accuracy: 0.7345542907714844\n",
      "Step: 4400  \tValid loss: 0.52217036485672\n",
      "Step: 4500  \tTraining loss: 0.5547049641609192\n",
      "Step: 4500  \tTraining accuracy: 0.734721839427948\n",
      "Step: 4500  \tValid loss: 0.5222079753875732\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.734882\n",
      "Precision: 0.7003891\n",
      "Recall: 0.565445\n",
      "F1 score: 0.65654\n",
      "AUC: 0.7015559\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.734882   0.700389  0.565445   0.65654  0.701556  0.554672      0.734955   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.521352       0.734834   0.516357      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  4548.0  \n",
      "31\n",
      "(1160, 4)\n",
      "(1160, 1)\n",
      "(624, 4)\n",
      "(624, 1)\n",
      "(507, 4)\n",
      "(507, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.5804717540740967\n",
      "Step: 100  \tTraining accuracy: 0.7525861859321594\n",
      "Step: 100  \tValid loss: 0.5981093049049377\n",
      "Step: 200  \tTraining loss: 0.4798114001750946\n",
      "Step: 200  \tTraining accuracy: 0.7586206793785095\n",
      "Step: 200  \tValid loss: 0.5207520723342896\n",
      "Step: 300  \tTraining loss: 0.413404643535614\n",
      "Step: 300  \tTraining accuracy: 0.7734239101409912\n",
      "Step: 300  \tValid loss: 0.4554818570613861\n",
      "Step: 400  \tTraining loss: 0.36491185426712036\n",
      "Step: 400  \tTraining accuracy: 0.7892443537712097\n",
      "Step: 400  \tValid loss: 0.404518187046051\n",
      "Step: 500  \tTraining loss: 0.3372894823551178\n",
      "Step: 500  \tTraining accuracy: 0.8027896285057068\n",
      "Step: 500  \tValid loss: 0.3757454454898834\n",
      "Step: 600  \tTraining loss: 0.32245486974716187\n",
      "Step: 600  \tTraining accuracy: 0.812366247177124\n",
      "Step: 600  \tValid loss: 0.3603035807609558\n",
      "Step: 700  \tTraining loss: 0.31368470191955566\n",
      "Step: 700  \tTraining accuracy: 0.819871187210083\n",
      "Step: 700  \tValid loss: 0.35072019696235657\n",
      "Step: 800  \tTraining loss: 0.30759283900260925\n",
      "Step: 800  \tTraining accuracy: 0.8256091475486755\n",
      "Step: 800  \tValid loss: 0.3434028625488281\n",
      "Step: 900  \tTraining loss: 0.30282604694366455\n",
      "Step: 900  \tTraining accuracy: 0.8309729099273682\n",
      "Step: 900  \tValid loss: 0.3371172547340393\n",
      "Step: 1000  \tTraining loss: 0.2989116311073303\n",
      "Step: 1000  \tTraining accuracy: 0.8357592225074768\n",
      "Step: 1000  \tValid loss: 0.3316464424133301\n",
      "Step: 1100  \tTraining loss: 0.29564806818962097\n",
      "Step: 1100  \tTraining accuracy: 0.8399667739868164\n",
      "Step: 1100  \tValid loss: 0.3269615173339844\n",
      "Step: 1200  \tTraining loss: 0.2929086685180664\n",
      "Step: 1200  \tTraining accuracy: 0.8436326384544373\n",
      "Step: 1200  \tValid loss: 0.3229817748069763\n",
      "Step: 1300  \tTraining loss: 0.29061803221702576\n",
      "Step: 1300  \tTraining accuracy: 0.8468518853187561\n",
      "Step: 1300  \tValid loss: 0.31960389018058777\n",
      "Step: 1400  \tTraining loss: 0.28872424364089966\n",
      "Step: 1400  \tTraining accuracy: 0.8496267199516296\n",
      "Step: 1400  \tValid loss: 0.316780149936676\n",
      "Step: 1500  \tTraining loss: 0.28717905282974243\n",
      "Step: 1500  \tTraining accuracy: 0.8520792126655579\n",
      "Step: 1500  \tValid loss: 0.31445425748825073\n",
      "Step: 1600  \tTraining loss: 0.2859295606613159\n",
      "Step: 1600  \tTraining accuracy: 0.854299783706665\n",
      "Step: 1600  \tValid loss: 0.312563419342041\n",
      "Step: 1700  \tTraining loss: 0.284919798374176\n",
      "Step: 1700  \tTraining accuracy: 0.8563306331634521\n",
      "Step: 1700  \tValid loss: 0.3110387325286865\n",
      "Step: 1800  \tTraining loss: 0.2841002643108368\n",
      "Step: 1800  \tTraining accuracy: 0.8581295013427734\n",
      "Step: 1800  \tValid loss: 0.3098098635673523\n",
      "Step: 1900  \tTraining loss: 0.2834288477897644\n",
      "Step: 1900  \tTraining accuracy: 0.859663188457489\n",
      "Step: 1900  \tValid loss: 0.30881601572036743\n",
      "Step: 2000  \tTraining loss: 0.28287273645401\n",
      "Step: 2000  \tTraining accuracy: 0.8610396385192871\n",
      "Step: 2000  \tValid loss: 0.308004766702652\n",
      "Step: 2100  \tTraining loss: 0.28240635991096497\n",
      "Step: 2100  \tTraining accuracy: 0.8622817993164062\n",
      "Step: 2100  \tValid loss: 0.3073362410068512\n",
      "Step: 2200  \tTraining loss: 0.28201013803482056\n",
      "Step: 2200  \tTraining accuracy: 0.8634085059165955\n",
      "Step: 2200  \tValid loss: 0.30677908658981323\n",
      "Step: 2300  \tTraining loss: 0.2816690504550934\n",
      "Step: 2300  \tTraining accuracy: 0.8645319938659668\n",
      "Step: 2300  \tValid loss: 0.306306391954422\n",
      "Step: 2400  \tTraining loss: 0.2813711166381836\n",
      "Step: 2400  \tTraining accuracy: 0.8655970692634583\n",
      "Step: 2400  \tValid loss: 0.30590254068374634\n",
      "Step: 2500  \tTraining loss: 0.2811078429222107\n",
      "Step: 2500  \tTraining accuracy: 0.866593062877655\n",
      "Step: 2500  \tValid loss: 0.30554819107055664\n",
      "Step: 2600  \tTraining loss: 0.2808712422847748\n",
      "Step: 2600  \tTraining accuracy: 0.8675109148025513\n",
      "Step: 2600  \tValid loss: 0.30523940920829773\n",
      "Step: 2700  \tTraining loss: 0.28065457940101624\n",
      "Step: 2700  \tTraining accuracy: 0.8684583306312561\n",
      "Step: 2700  \tValid loss: 0.3049652874469757\n",
      "Step: 2800  \tTraining loss: 0.2804521918296814\n",
      "Step: 2800  \tTraining accuracy: 0.8693209886550903\n",
      "Step: 2800  \tValid loss: 0.30471715331077576\n",
      "Step: 2900  \tTraining loss: 0.2802574038505554\n",
      "Step: 2900  \tTraining accuracy: 0.8701230883598328\n",
      "Step: 2900  \tValid loss: 0.30448853969573975\n",
      "Step: 3000  \tTraining loss: 0.28006672859191895\n",
      "Step: 3000  \tTraining accuracy: 0.8708708882331848\n",
      "Step: 3000  \tValid loss: 0.3042666018009186\n",
      "Step: 3100  \tTraining loss: 0.27987807989120483\n",
      "Step: 3100  \tTraining accuracy: 0.8715839385986328\n",
      "Step: 3100  \tValid loss: 0.30404341220855713\n",
      "Step: 3200  \tTraining loss: 0.2796858549118042\n",
      "Step: 3200  \tTraining accuracy: 0.872223973274231\n",
      "Step: 3200  \tValid loss: 0.3038262724876404\n",
      "Step: 3300  \tTraining loss: 0.279485285282135\n",
      "Step: 3300  \tTraining accuracy: 0.8728381395339966\n",
      "Step: 3300  \tValid loss: 0.30360761284828186\n",
      "Step: 3400  \tTraining loss: 0.2792709767818451\n",
      "Step: 3400  \tTraining accuracy: 0.8734155893325806\n",
      "Step: 3400  \tValid loss: 0.3033868372440338\n",
      "Step: 3500  \tTraining loss: 0.27903780341148376\n",
      "Step: 3500  \tTraining accuracy: 0.8739596009254456\n",
      "Step: 3500  \tValid loss: 0.30316001176834106\n",
      "Step: 3600  \tTraining loss: 0.27878057956695557\n",
      "Step: 3600  \tTraining accuracy: 0.8744729161262512\n",
      "Step: 3600  \tValid loss: 0.30292898416519165\n",
      "Step: 3700  \tTraining loss: 0.2784948945045471\n",
      "Step: 3700  \tTraining accuracy: 0.8749581575393677\n",
      "Step: 3700  \tValid loss: 0.30269506573677063\n",
      "Step: 3800  \tTraining loss: 0.2781771421432495\n",
      "Step: 3800  \tTraining accuracy: 0.8754175305366516\n",
      "Step: 3800  \tValid loss: 0.30245983600616455\n",
      "Step: 3900  \tTraining loss: 0.2778252959251404\n",
      "Step: 3900  \tTraining accuracy: 0.8758530020713806\n",
      "Step: 3900  \tValid loss: 0.3022291660308838\n",
      "Step: 4000  \tTraining loss: 0.2774384021759033\n",
      "Step: 4000  \tTraining accuracy: 0.8762664198875427\n",
      "Step: 4000  \tValid loss: 0.3020089566707611\n",
      "Step: 4100  \tTraining loss: 0.2770138382911682\n",
      "Step: 4100  \tTraining accuracy: 0.8766487240791321\n",
      "Step: 4100  \tValid loss: 0.30180126428604126\n",
      "Step: 4200  \tTraining loss: 0.27655017375946045\n",
      "Step: 4200  \tTraining accuracy: 0.8770125508308411\n",
      "Step: 4200  \tValid loss: 0.30161312222480774\n",
      "Step: 4300  \tTraining loss: 0.2760488986968994\n",
      "Step: 4300  \tTraining accuracy: 0.8773592710494995\n",
      "Step: 4300  \tValid loss: 0.3014492094516754\n",
      "Step: 4400  \tTraining loss: 0.27551907300949097\n",
      "Step: 4400  \tTraining accuracy: 0.8776900172233582\n",
      "Step: 4400  \tValid loss: 0.30131658911705017\n",
      "Step: 4500  \tTraining loss: 0.2749776542186737\n",
      "Step: 4500  \tTraining accuracy: 0.8780059814453125\n",
      "Step: 4500  \tValid loss: 0.3012199401855469\n",
      "Step: 4600  \tTraining loss: 0.27444344758987427\n",
      "Step: 4600  \tTraining accuracy: 0.8783079981803894\n",
      "Step: 4600  \tValid loss: 0.301159530878067\n",
      "Step: 4700  \tTraining loss: 0.2739269435405731\n",
      "Step: 4700  \tTraining accuracy: 0.8785970211029053\n",
      "Step: 4700  \tValid loss: 0.30112510919570923\n",
      "Step: 4800  \tTraining loss: 0.27343061566352844\n",
      "Step: 4800  \tTraining accuracy: 0.878873884677887\n",
      "Step: 4800  \tValid loss: 0.3011058270931244\n",
      "Step: 4900  \tTraining loss: 0.2729525864124298\n",
      "Step: 4900  \tTraining accuracy: 0.8791483640670776\n",
      "Step: 4900  \tValid loss: 0.30109214782714844\n",
      "Step: 5000  \tTraining loss: 0.2724892795085907\n",
      "Step: 5000  \tTraining accuracy: 0.8794117569923401\n",
      "Step: 5000  \tValid loss: 0.3010772168636322\n",
      "Step: 5100  \tTraining loss: 0.2720373272895813\n",
      "Step: 5100  \tTraining accuracy: 0.8796646595001221\n",
      "Step: 5100  \tValid loss: 0.30105653405189514\n",
      "Step: 5200  \tTraining loss: 0.2715945243835449\n",
      "Step: 5200  \tTraining accuracy: 0.8799077868461609\n",
      "Step: 5200  \tValid loss: 0.30102935433387756\n",
      "Step: 5300  \tTraining loss: 0.27115923166275024\n",
      "Step: 5300  \tTraining accuracy: 0.8801416754722595\n",
      "Step: 5300  \tValid loss: 0.30099496245384216\n",
      "Step: 5400  \tTraining loss: 0.2707306742668152\n",
      "Step: 5400  \tTraining accuracy: 0.8803667426109314\n",
      "Step: 5400  \tValid loss: 0.3009535074234009\n",
      "Step: 5500  \tTraining loss: 0.2703084945678711\n",
      "Step: 5500  \tTraining accuracy: 0.880583643913269\n",
      "Step: 5500  \tValid loss: 0.3009055554866791\n",
      "Step: 5600  \tTraining loss: 0.26989230513572693\n",
      "Step: 5600  \tTraining accuracy: 0.880784809589386\n",
      "Step: 5600  \tValid loss: 0.30085256695747375\n",
      "Step: 5700  \tTraining loss: 0.26948195695877075\n",
      "Step: 5700  \tTraining accuracy: 0.8809788823127747\n",
      "Step: 5700  \tValid loss: 0.3007945120334625\n",
      "Step: 5800  \tTraining loss: 0.26907768845558167\n",
      "Step: 5800  \tTraining accuracy: 0.8811661601066589\n",
      "Step: 5800  \tValid loss: 0.300732284784317\n",
      "Step: 5900  \tTraining loss: 0.26867911219596863\n",
      "Step: 5900  \tTraining accuracy: 0.881354570388794\n",
      "Step: 5900  \tValid loss: 0.3006667196750641\n",
      "Step: 6000  \tTraining loss: 0.26828664541244507\n",
      "Step: 6000  \tTraining accuracy: 0.881536602973938\n",
      "Step: 6000  \tValid loss: 0.30059874057769775\n",
      "Step: 6100  \tTraining loss: 0.26790037751197815\n",
      "Step: 6100  \tTraining accuracy: 0.8816981911659241\n",
      "Step: 6100  \tValid loss: 0.3005290925502777\n",
      "Step: 6200  \tTraining loss: 0.26751992106437683\n",
      "Step: 6200  \tTraining accuracy: 0.8818544745445251\n",
      "Step: 6200  \tValid loss: 0.30045923590660095\n",
      "Step: 6300  \tTraining loss: 0.26714494824409485\n",
      "Step: 6300  \tTraining accuracy: 0.8820058107376099\n",
      "Step: 6300  \tValid loss: 0.3003896176815033\n",
      "Step: 6400  \tTraining loss: 0.26677531003952026\n",
      "Step: 6400  \tTraining accuracy: 0.8821523785591125\n",
      "Step: 6400  \tValid loss: 0.3003186881542206\n",
      "Step: 6500  \tTraining loss: 0.266411155462265\n",
      "Step: 6500  \tTraining accuracy: 0.8822944164276123\n",
      "Step: 6500  \tValid loss: 0.30024877190589905\n",
      "Step: 6600  \tTraining loss: 0.26605358719825745\n",
      "Step: 6600  \tTraining accuracy: 0.8824321031570435\n",
      "Step: 6600  \tValid loss: 0.30018478631973267\n",
      "Step: 6700  \tTraining loss: 0.2657015919685364\n",
      "Step: 6700  \tTraining accuracy: 0.882585346698761\n",
      "Step: 6700  \tValid loss: 0.300139844417572\n",
      "Step: 6800  \tTraining loss: 0.2653593420982361\n",
      "Step: 6800  \tTraining accuracy: 0.8827340602874756\n",
      "Step: 6800  \tValid loss: 0.3000856041908264\n",
      "Step: 6900  \tTraining loss: 0.26502326130867004\n",
      "Step: 6900  \tTraining accuracy: 0.8828784227371216\n",
      "Step: 6900  \tValid loss: 0.3000331223011017\n",
      "Step: 7000  \tTraining loss: 0.26469358801841736\n",
      "Step: 7000  \tTraining accuracy: 0.8830186128616333\n",
      "Step: 7000  \tValid loss: 0.2999812960624695\n",
      "Step: 7100  \tTraining loss: 0.2643698453903198\n",
      "Step: 7100  \tTraining accuracy: 0.8831610083580017\n",
      "Step: 7100  \tValid loss: 0.2999321520328522\n",
      "Step: 7200  \tTraining loss: 0.2640521228313446\n",
      "Step: 7200  \tTraining accuracy: 0.883287250995636\n",
      "Step: 7200  \tValid loss: 0.2998867630958557\n",
      "Step: 7300  \tTraining loss: 0.26373958587646484\n",
      "Step: 7300  \tTraining accuracy: 0.8834099769592285\n",
      "Step: 7300  \tValid loss: 0.29984575510025024\n",
      "Step: 7400  \tTraining loss: 0.2634322941303253\n",
      "Step: 7400  \tTraining accuracy: 0.8835293650627136\n",
      "Step: 7400  \tValid loss: 0.29981064796447754\n",
      "Step: 7500  \tTraining loss: 0.2631296217441559\n",
      "Step: 7500  \tTraining accuracy: 0.8836514353752136\n",
      "Step: 7500  \tValid loss: 0.29978299140930176\n",
      "Step: 7600  \tTraining loss: 0.262830525636673\n",
      "Step: 7600  \tTraining accuracy: 0.8837702870368958\n",
      "Step: 7600  \tValid loss: 0.29976457357406616\n",
      "Step: 7700  \tTraining loss: 0.26253414154052734\n",
      "Step: 7700  \tTraining accuracy: 0.8838859796524048\n",
      "Step: 7700  \tValid loss: 0.29975759983062744\n",
      "Step: 7800  \tTraining loss: 0.262239009141922\n",
      "Step: 7800  \tTraining accuracy: 0.883998692035675\n",
      "Step: 7800  \tValid loss: 0.29976600408554077\n",
      "Step: 7900  \tTraining loss: 0.26194265484809875\n",
      "Step: 7900  \tTraining accuracy: 0.884103000164032\n",
      "Step: 7900  \tValid loss: 0.2997938394546509\n",
      "Step: 8000  \tTraining loss: 0.2616417706012726\n",
      "Step: 8000  \tTraining accuracy: 0.8842046856880188\n",
      "Step: 8000  \tValid loss: 0.2998495399951935\n",
      "Step: 8100  \tTraining loss: 0.2613317668437958\n",
      "Step: 8100  \tTraining accuracy: 0.884303867816925\n",
      "Step: 8100  \tValid loss: 0.2999437153339386\n",
      "Step: 8200  \tTraining loss: 0.26100581884384155\n",
      "Step: 8200  \tTraining accuracy: 0.8844005465507507\n",
      "Step: 8200  \tValid loss: 0.3000883162021637\n",
      "Step: 8300  \tTraining loss: 0.26065704226493835\n",
      "Step: 8300  \tTraining accuracy: 0.8844896554946899\n",
      "Step: 8300  \tValid loss: 0.30029383301734924\n",
      "Step: 8400  \tTraining loss: 0.26028332114219666\n",
      "Step: 8400  \tTraining accuracy: 0.8845765590667725\n",
      "Step: 8400  \tValid loss: 0.3005499243736267\n",
      "Step: 8500  \tTraining loss: 0.2598896324634552\n",
      "Step: 8500  \tTraining accuracy: 0.8846563100814819\n",
      "Step: 8500  \tValid loss: 0.30082276463508606\n",
      "Step: 8600  \tTraining loss: 0.2594892978668213\n",
      "Step: 8600  \tTraining accuracy: 0.8847341537475586\n",
      "Step: 8600  \tValid loss: 0.30108457803726196\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8848153\n",
      "Precision: 0.86440676\n",
      "Recall: 0.8680851\n",
      "F1 score: 0.8866939\n",
      "AUC: 0.88766575\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.884815   0.864407  0.868085  0.886694  0.887666  0.259098      0.884777   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.299758       0.884772   0.284412      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  8698.0  \n",
      "32\n",
      "(841, 4)\n",
      "(841, 1)\n",
      "(448, 4)\n",
      "(448, 1)\n",
      "(364, 4)\n",
      "(364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.6384605169296265\n",
      "Step: 100  \tTraining accuracy: 0.6492270827293396\n",
      "Step: 100  \tValid loss: 0.6884231567382812\n",
      "Step: 200  \tTraining loss: 0.6076171398162842\n",
      "Step: 200  \tTraining accuracy: 0.6343223452568054\n",
      "Step: 200  \tValid loss: 0.6672336459159851\n",
      "Step: 300  \tTraining loss: 0.5707219243049622\n",
      "Step: 300  \tTraining accuracy: 0.6474559903144836\n",
      "Step: 300  \tValid loss: 0.6272953748703003\n",
      "Step: 400  \tTraining loss: 0.5220334529876709\n",
      "Step: 400  \tTraining accuracy: 0.663103461265564\n",
      "Step: 400  \tValid loss: 0.5692936182022095\n",
      "Step: 500  \tTraining loss: 0.4774632453918457\n",
      "Step: 500  \tTraining accuracy: 0.67945796251297\n",
      "Step: 500  \tValid loss: 0.5176264047622681\n",
      "Step: 600  \tTraining loss: 0.4458889663219452\n",
      "Step: 600  \tTraining accuracy: 0.6947067975997925\n",
      "Step: 600  \tValid loss: 0.48266738653182983\n",
      "Step: 700  \tTraining loss: 0.42373690009117126\n",
      "Step: 700  \tTraining accuracy: 0.7073147892951965\n",
      "Step: 700  \tValid loss: 0.45889946818351746\n",
      "Step: 800  \tTraining loss: 0.4071900248527527\n",
      "Step: 800  \tTraining accuracy: 0.7182565331459045\n",
      "Step: 800  \tValid loss: 0.44159191846847534\n",
      "Step: 900  \tTraining loss: 0.3942127525806427\n",
      "Step: 900  \tTraining accuracy: 0.7276217341423035\n",
      "Step: 900  \tValid loss: 0.4283197820186615\n",
      "Step: 1000  \tTraining loss: 0.38375356793403625\n",
      "Step: 1000  \tTraining accuracy: 0.7353988885879517\n",
      "Step: 1000  \tValid loss: 0.4178411364555359\n",
      "Step: 1100  \tTraining loss: 0.3751908242702484\n",
      "Step: 1100  \tTraining accuracy: 0.7424442768096924\n",
      "Step: 1100  \tValid loss: 0.40943029522895813\n",
      "Step: 1200  \tTraining loss: 0.3681067228317261\n",
      "Step: 1200  \tTraining accuracy: 0.7481602430343628\n",
      "Step: 1200  \tValid loss: 0.40261414647102356\n",
      "Step: 1300  \tTraining loss: 0.3622003197669983\n",
      "Step: 1300  \tTraining accuracy: 0.7530589699745178\n",
      "Step: 1300  \tValid loss: 0.3970622420310974\n",
      "Step: 1400  \tTraining loss: 0.3572474718093872\n",
      "Step: 1400  \tTraining accuracy: 0.7577698230743408\n",
      "Step: 1400  \tValid loss: 0.39253416657447815\n",
      "Step: 1500  \tTraining loss: 0.3530775308609009\n",
      "Step: 1500  \tTraining accuracy: 0.7618730068206787\n",
      "Step: 1500  \tValid loss: 0.38884931802749634\n",
      "Step: 1600  \tTraining loss: 0.34955716133117676\n",
      "Step: 1600  \tTraining accuracy: 0.7656420469284058\n",
      "Step: 1600  \tValid loss: 0.3858652710914612\n",
      "Step: 1700  \tTraining loss: 0.34657880663871765\n",
      "Step: 1700  \tTraining accuracy: 0.769027829170227\n",
      "Step: 1700  \tValid loss: 0.3834654986858368\n",
      "Step: 1800  \tTraining loss: 0.3440554738044739\n",
      "Step: 1800  \tTraining accuracy: 0.7719576954841614\n",
      "Step: 1800  \tValid loss: 0.381549209356308\n",
      "Step: 1900  \tTraining loss: 0.3419152796268463\n",
      "Step: 1900  \tTraining accuracy: 0.7746036648750305\n",
      "Step: 1900  \tValid loss: 0.3800315856933594\n",
      "Step: 2000  \tTraining loss: 0.3400982916355133\n",
      "Step: 2000  \tTraining accuracy: 0.7769784331321716\n",
      "Step: 2000  \tValid loss: 0.37884029746055603\n",
      "Step: 2100  \tTraining loss: 0.33855485916137695\n",
      "Step: 2100  \tTraining accuracy: 0.7791215777397156\n",
      "Step: 2100  \tValid loss: 0.3778926432132721\n",
      "Step: 2200  \tTraining loss: 0.3372427821159363\n",
      "Step: 2200  \tTraining accuracy: 0.7809810638427734\n",
      "Step: 2200  \tValid loss: 0.37711480259895325\n",
      "Step: 2300  \tTraining loss: 0.3361261487007141\n",
      "Step: 2300  \tTraining accuracy: 0.7827290296554565\n",
      "Step: 2300  \tValid loss: 0.3765089213848114\n",
      "Step: 2400  \tTraining loss: 0.3351748287677765\n",
      "Step: 2400  \tTraining accuracy: 0.7843540906906128\n",
      "Step: 2400  \tValid loss: 0.37603750824928284\n",
      "Step: 2500  \tTraining loss: 0.3343628942966461\n",
      "Step: 2500  \tTraining accuracy: 0.7858465313911438\n",
      "Step: 2500  \tValid loss: 0.37566882371902466\n",
      "Step: 2600  \tTraining loss: 0.3336685299873352\n",
      "Step: 2600  \tTraining accuracy: 0.7872693538665771\n",
      "Step: 2600  \tValid loss: 0.37537696957588196\n",
      "Step: 2700  \tTraining loss: 0.33307337760925293\n",
      "Step: 2700  \tTraining accuracy: 0.7885620594024658\n",
      "Step: 2700  \tValid loss: 0.3751409351825714\n",
      "Step: 2800  \tTraining loss: 0.33256176114082336\n",
      "Step: 2800  \tTraining accuracy: 0.7897607088088989\n",
      "Step: 2800  \tValid loss: 0.37494558095932007\n",
      "Step: 2900  \tTraining loss: 0.33212044835090637\n",
      "Step: 2900  \tTraining accuracy: 0.7909177541732788\n",
      "Step: 2900  \tValid loss: 0.3747800290584564\n",
      "Step: 3000  \tTraining loss: 0.3317384719848633\n",
      "Step: 3000  \tTraining accuracy: 0.791996419429779\n",
      "Step: 3000  \tValid loss: 0.3746362030506134\n",
      "Step: 3100  \tTraining loss: 0.33140677213668823\n",
      "Step: 3100  \tTraining accuracy: 0.7930241227149963\n",
      "Step: 3100  \tValid loss: 0.37450718879699707\n",
      "Step: 3200  \tTraining loss: 0.3311176002025604\n",
      "Step: 3200  \tTraining accuracy: 0.794005811214447\n",
      "Step: 3200  \tValid loss: 0.3743884563446045\n",
      "Step: 3300  \tTraining loss: 0.3308645188808441\n",
      "Step: 3300  \tTraining accuracy: 0.7949643731117249\n",
      "Step: 3300  \tValid loss: 0.37427571415901184\n",
      "Step: 3400  \tTraining loss: 0.3306420147418976\n",
      "Step: 3400  \tTraining accuracy: 0.7958656549453735\n",
      "Step: 3400  \tValid loss: 0.37416872382164\n",
      "Step: 3500  \tTraining loss: 0.3304458558559418\n",
      "Step: 3500  \tTraining accuracy: 0.7967147827148438\n",
      "Step: 3500  \tValid loss: 0.37406307458877563\n",
      "Step: 3600  \tTraining loss: 0.3302720785140991\n",
      "Step: 3600  \tTraining accuracy: 0.7975159883499146\n",
      "Step: 3600  \tValid loss: 0.37395668029785156\n",
      "Step: 3700  \tTraining loss: 0.33011749386787415\n",
      "Step: 3700  \tTraining accuracy: 0.7982733845710754\n",
      "Step: 3700  \tValid loss: 0.37384819984436035\n",
      "Step: 3800  \tTraining loss: 0.3299795389175415\n",
      "Step: 3800  \tTraining accuracy: 0.7989581227302551\n",
      "Step: 3800  \tValid loss: 0.3737366497516632\n",
      "Step: 3900  \tTraining loss: 0.3298560082912445\n",
      "Step: 3900  \tTraining accuracy: 0.7995915412902832\n",
      "Step: 3900  \tValid loss: 0.37362125515937805\n",
      "Step: 4000  \tTraining loss: 0.32974478602409363\n",
      "Step: 4000  \tTraining accuracy: 0.8001776337623596\n",
      "Step: 4000  \tValid loss: 0.3735016882419586\n",
      "Step: 4100  \tTraining loss: 0.32964444160461426\n",
      "Step: 4100  \tTraining accuracy: 0.8007347583770752\n",
      "Step: 4100  \tValid loss: 0.37337779998779297\n",
      "Step: 4200  \tTraining loss: 0.32955363392829895\n",
      "Step: 4200  \tTraining accuracy: 0.8012504577636719\n",
      "Step: 4200  \tValid loss: 0.3732495903968811\n",
      "Step: 4300  \tTraining loss: 0.3294709324836731\n",
      "Step: 4300  \tTraining accuracy: 0.8017561435699463\n",
      "Step: 4300  \tValid loss: 0.37311792373657227\n",
      "Step: 4400  \tTraining loss: 0.32939550280570984\n",
      "Step: 4400  \tTraining accuracy: 0.8022525310516357\n",
      "Step: 4400  \tValid loss: 0.3729833960533142\n",
      "Step: 4500  \tTraining loss: 0.32932648062705994\n",
      "Step: 4500  \tTraining accuracy: 0.8027129769325256\n",
      "Step: 4500  \tValid loss: 0.37284597754478455\n",
      "Step: 4600  \tTraining loss: 0.32926300168037415\n",
      "Step: 4600  \tTraining accuracy: 0.8031531572341919\n",
      "Step: 4600  \tValid loss: 0.37270623445510864\n",
      "Step: 4700  \tTraining loss: 0.3292042911052704\n",
      "Step: 4700  \tTraining accuracy: 0.8035744428634644\n",
      "Step: 4700  \tValid loss: 0.37256526947021484\n",
      "Step: 4800  \tTraining loss: 0.32914990186691284\n",
      "Step: 4800  \tTraining accuracy: 0.8040034770965576\n",
      "Step: 4800  \tValid loss: 0.3724236488342285\n",
      "Step: 4900  \tTraining loss: 0.3290993869304657\n",
      "Step: 4900  \tTraining accuracy: 0.8044272661209106\n",
      "Step: 4900  \tValid loss: 0.3722825050354004\n",
      "Step: 5000  \tTraining loss: 0.32905203104019165\n",
      "Step: 5000  \tTraining accuracy: 0.8048339486122131\n",
      "Step: 5000  \tValid loss: 0.37214285135269165\n",
      "Step: 5100  \tTraining loss: 0.32900771498680115\n",
      "Step: 5100  \tTraining accuracy: 0.8052125573158264\n",
      "Step: 5100  \tValid loss: 0.37200573086738586\n",
      "Step: 5200  \tTraining loss: 0.32896578311920166\n",
      "Step: 5200  \tTraining accuracy: 0.8055764436721802\n",
      "Step: 5200  \tValid loss: 0.3718720078468323\n",
      "Step: 5300  \tTraining loss: 0.328926146030426\n",
      "Step: 5300  \tTraining accuracy: 0.8059380054473877\n",
      "Step: 5300  \tValid loss: 0.37174129486083984\n",
      "Step: 5400  \tTraining loss: 0.328888475894928\n",
      "Step: 5400  \tTraining accuracy: 0.8062860369682312\n",
      "Step: 5400  \tValid loss: 0.37161803245544434\n",
      "Step: 5500  \tTraining loss: 0.32885247468948364\n",
      "Step: 5500  \tTraining accuracy: 0.8066213130950928\n",
      "Step: 5500  \tValid loss: 0.37149736285209656\n",
      "Step: 5600  \tTraining loss: 0.3288179337978363\n",
      "Step: 5600  \tTraining accuracy: 0.8069663047790527\n",
      "Step: 5600  \tValid loss: 0.371380090713501\n",
      "Step: 5700  \tTraining loss: 0.3287845551967621\n",
      "Step: 5700  \tTraining accuracy: 0.8072990775108337\n",
      "Step: 5700  \tValid loss: 0.37126585841178894\n",
      "Step: 5800  \tTraining loss: 0.3287523090839386\n",
      "Step: 5800  \tTraining accuracy: 0.8076202869415283\n",
      "Step: 5800  \tValid loss: 0.3711552321910858\n",
      "Step: 5900  \tTraining loss: 0.32872095704078674\n",
      "Step: 5900  \tTraining accuracy: 0.8079305291175842\n",
      "Step: 5900  \tValid loss: 0.37104812264442444\n",
      "Step: 6000  \tTraining loss: 0.3286903202533722\n",
      "Step: 6000  \tTraining accuracy: 0.8082303404808044\n",
      "Step: 6000  \tValid loss: 0.3709447979927063\n",
      "Step: 6100  \tTraining loss: 0.32866019010543823\n",
      "Step: 6100  \tTraining accuracy: 0.8085201978683472\n",
      "Step: 6100  \tValid loss: 0.3708452582359314\n",
      "Step: 6200  \tTraining loss: 0.32863059639930725\n",
      "Step: 6200  \tTraining accuracy: 0.8088006973266602\n",
      "Step: 6200  \tValid loss: 0.3707495331764221\n",
      "Step: 6300  \tTraining loss: 0.32860130071640015\n",
      "Step: 6300  \tTraining accuracy: 0.8090721964836121\n",
      "Step: 6300  \tValid loss: 0.3706572949886322\n",
      "Step: 6400  \tTraining loss: 0.32857224345207214\n",
      "Step: 6400  \tTraining accuracy: 0.8093351125717163\n",
      "Step: 6400  \tValid loss: 0.3705691695213318\n",
      "Step: 6500  \tTraining loss: 0.3285432755947113\n",
      "Step: 6500  \tTraining accuracy: 0.8095899224281311\n",
      "Step: 6500  \tValid loss: 0.37048453092575073\n",
      "Step: 6600  \tTraining loss: 0.32851460576057434\n",
      "Step: 6600  \tTraining accuracy: 0.8098369240760803\n",
      "Step: 6600  \tValid loss: 0.370402067899704\n",
      "Step: 6700  \tTraining loss: 0.3284858763217926\n",
      "Step: 6700  \tTraining accuracy: 0.8100764751434326\n",
      "Step: 6700  \tValid loss: 0.37032124400138855\n",
      "Step: 6800  \tTraining loss: 0.3284570276737213\n",
      "Step: 6800  \tTraining accuracy: 0.8103089928627014\n",
      "Step: 6800  \tValid loss: 0.3702419400215149\n",
      "Step: 6900  \tTraining loss: 0.32842817902565\n",
      "Step: 6900  \tTraining accuracy: 0.810534656047821\n",
      "Step: 6900  \tValid loss: 0.3701634407043457\n",
      "Step: 7000  \tTraining loss: 0.32839927077293396\n",
      "Step: 7000  \tTraining accuracy: 0.8107538819313049\n",
      "Step: 7000  \tValid loss: 0.3700856566429138\n",
      "Step: 7100  \tTraining loss: 0.3283701539039612\n",
      "Step: 7100  \tTraining accuracy: 0.8109668493270874\n",
      "Step: 7100  \tValid loss: 0.37000802159309387\n",
      "Step: 7200  \tTraining loss: 0.32834091782569885\n",
      "Step: 7200  \tTraining accuracy: 0.8111739158630371\n",
      "Step: 7200  \tValid loss: 0.3699304759502411\n",
      "Step: 7300  \tTraining loss: 0.3283114731311798\n",
      "Step: 7300  \tTraining accuracy: 0.8113835453987122\n",
      "Step: 7300  \tValid loss: 0.36985284090042114\n",
      "Step: 7400  \tTraining loss: 0.32828181982040405\n",
      "Step: 7400  \tTraining accuracy: 0.8115875124931335\n",
      "Step: 7400  \tValid loss: 0.36977481842041016\n",
      "Step: 7500  \tTraining loss: 0.3282519578933716\n",
      "Step: 7500  \tTraining accuracy: 0.8117859959602356\n",
      "Step: 7500  \tValid loss: 0.36969661712646484\n",
      "Step: 7600  \tTraining loss: 0.3282219171524048\n",
      "Step: 7600  \tTraining accuracy: 0.8119792342185974\n",
      "Step: 7600  \tValid loss: 0.36961811780929565\n",
      "Step: 7700  \tTraining loss: 0.3281918168067932\n",
      "Step: 7700  \tTraining accuracy: 0.8121674060821533\n",
      "Step: 7700  \tValid loss: 0.3695394992828369\n",
      "Step: 7800  \tTraining loss: 0.3281613886356354\n",
      "Step: 7800  \tTraining accuracy: 0.8123507499694824\n",
      "Step: 7800  \tValid loss: 0.3694608807563782\n",
      "Step: 7900  \tTraining loss: 0.328130841255188\n",
      "Step: 7900  \tTraining accuracy: 0.8125293850898743\n",
      "Step: 7900  \tValid loss: 0.3693819046020508\n",
      "Step: 8000  \tTraining loss: 0.3281000852584839\n",
      "Step: 8000  \tTraining accuracy: 0.812703549861908\n",
      "Step: 8000  \tValid loss: 0.3693024218082428\n",
      "Step: 8100  \tTraining loss: 0.3280692994594574\n",
      "Step: 8100  \tTraining accuracy: 0.812873363494873\n",
      "Step: 8100  \tValid loss: 0.3692215085029602\n",
      "Step: 8200  \tTraining loss: 0.32803812623023987\n",
      "Step: 8200  \tTraining accuracy: 0.8130390048027039\n",
      "Step: 8200  \tValid loss: 0.3691408038139343\n",
      "Step: 8300  \tTraining loss: 0.3280068039894104\n",
      "Step: 8300  \tTraining accuracy: 0.8132006525993347\n",
      "Step: 8300  \tValid loss: 0.369058758020401\n",
      "Step: 8400  \tTraining loss: 0.32797524333000183\n",
      "Step: 8400  \tTraining accuracy: 0.8133584260940552\n",
      "Step: 8400  \tValid loss: 0.36897537112236023\n",
      "Step: 8500  \tTraining loss: 0.3279434144496918\n",
      "Step: 8500  \tTraining accuracy: 0.8135125041007996\n",
      "Step: 8500  \tValid loss: 0.3688906729221344\n",
      "Step: 8600  \tTraining loss: 0.327911376953125\n",
      "Step: 8600  \tTraining accuracy: 0.8136629462242126\n",
      "Step: 8600  \tValid loss: 0.3688039183616638\n",
      "Step: 8700  \tTraining loss: 0.3278791606426239\n",
      "Step: 8700  \tTraining accuracy: 0.813809871673584\n",
      "Step: 8700  \tValid loss: 0.3687155544757843\n",
      "Step: 8800  \tTraining loss: 0.327846497297287\n",
      "Step: 8800  \tTraining accuracy: 0.8139534592628479\n",
      "Step: 8800  \tValid loss: 0.36862578988075256\n",
      "Step: 8900  \tTraining loss: 0.32781362533569336\n",
      "Step: 8900  \tTraining accuracy: 0.814093828201294\n",
      "Step: 8900  \tValid loss: 0.36853402853012085\n",
      "Step: 9000  \tTraining loss: 0.3277803361415863\n",
      "Step: 9000  \tTraining accuracy: 0.8142310380935669\n",
      "Step: 9000  \tValid loss: 0.3684404194355011\n",
      "Step: 9100  \tTraining loss: 0.32774683833122253\n",
      "Step: 9100  \tTraining accuracy: 0.8143652677536011\n",
      "Step: 9100  \tValid loss: 0.3683452606201172\n",
      "Step: 9200  \tTraining loss: 0.32771289348602295\n",
      "Step: 9200  \tTraining accuracy: 0.8144899010658264\n",
      "Step: 9200  \tValid loss: 0.36824867129325867\n",
      "Step: 9300  \tTraining loss: 0.3276786208152771\n",
      "Step: 9300  \tTraining accuracy: 0.8146118521690369\n",
      "Step: 9300  \tValid loss: 0.368150532245636\n",
      "Step: 9400  \tTraining loss: 0.327644020318985\n",
      "Step: 9400  \tTraining accuracy: 0.8147311806678772\n",
      "Step: 9400  \tValid loss: 0.36805081367492676\n",
      "Step: 9500  \tTraining loss: 0.3276088833808899\n",
      "Step: 9500  \tTraining accuracy: 0.814848005771637\n",
      "Step: 9500  \tValid loss: 0.3679497539997101\n",
      "Step: 9600  \tTraining loss: 0.3275734782218933\n",
      "Step: 9600  \tTraining accuracy: 0.8149433732032776\n",
      "Step: 9600  \tValid loss: 0.36784785985946655\n",
      "Step: 9700  \tTraining loss: 0.32753750681877136\n",
      "Step: 9700  \tTraining accuracy: 0.8150367736816406\n",
      "Step: 9700  \tValid loss: 0.3677446246147156\n",
      "Step: 9800  \tTraining loss: 0.3275011479854584\n",
      "Step: 9800  \tTraining accuracy: 0.8151282668113708\n",
      "Step: 9800  \tValid loss: 0.3676409125328064\n",
      "Step: 9900  \tTraining loss: 0.3274642527103424\n",
      "Step: 9900  \tTraining accuracy: 0.8152117133140564\n",
      "Step: 9900  \tValid loss: 0.3675362467765808\n",
      "Step: 10000  \tTraining loss: 0.3274267911911011\n",
      "Step: 10000  \tTraining accuracy: 0.8152934908866882\n",
      "Step: 10000  \tValid loss: 0.3674312233924866\n",
      "Step: 10100  \tTraining loss: 0.3273888826370239\n",
      "Step: 10100  \tTraining accuracy: 0.8153736591339111\n",
      "Step: 10100  \tValid loss: 0.3673255145549774\n",
      "Step: 10200  \tTraining loss: 0.3273504078388214\n",
      "Step: 10200  \tTraining accuracy: 0.8154522776603699\n",
      "Step: 10200  \tValid loss: 0.3672184348106384\n",
      "Step: 10300  \tTraining loss: 0.32731151580810547\n",
      "Step: 10300  \tTraining accuracy: 0.8155293464660645\n",
      "Step: 10300  \tValid loss: 0.36711111664772034\n",
      "Step: 10400  \tTraining loss: 0.3272719085216522\n",
      "Step: 10400  \tTraining accuracy: 0.8156049251556396\n",
      "Step: 10400  \tValid loss: 0.367003470659256\n",
      "Step: 10500  \tTraining loss: 0.32723188400268555\n",
      "Step: 10500  \tTraining accuracy: 0.8156790137290955\n",
      "Step: 10500  \tValid loss: 0.3668951392173767\n",
      "Step: 10600  \tTraining loss: 0.32719114422798157\n",
      "Step: 10600  \tTraining accuracy: 0.8157517313957214\n",
      "Step: 10600  \tValid loss: 0.36678531765937805\n",
      "Step: 10700  \tTraining loss: 0.3271496593952179\n",
      "Step: 10700  \tTraining accuracy: 0.8158230781555176\n",
      "Step: 10700  \tValid loss: 0.36667579412460327\n",
      "Step: 10800  \tTraining loss: 0.32710742950439453\n",
      "Step: 10800  \tTraining accuracy: 0.8158931136131287\n",
      "Step: 10800  \tValid loss: 0.3665730655193329\n",
      "Step: 10900  \tTraining loss: 0.3270641565322876\n",
      "Step: 10900  \tTraining accuracy: 0.8159618377685547\n",
      "Step: 10900  \tValid loss: 0.36648544669151306\n",
      "Step: 11000  \tTraining loss: 0.3270198702812195\n",
      "Step: 11000  \tTraining accuracy: 0.8160293698310852\n",
      "Step: 11000  \tValid loss: 0.36641544103622437\n",
      "Step: 11100  \tTraining loss: 0.32697421312332153\n",
      "Step: 11100  \tTraining accuracy: 0.8160955905914307\n",
      "Step: 11100  \tValid loss: 0.3663616180419922\n",
      "Step: 11200  \tTraining loss: 0.3269272446632385\n",
      "Step: 11200  \tTraining accuracy: 0.8161606788635254\n",
      "Step: 11200  \tValid loss: 0.36632034182548523\n",
      "Step: 11300  \tTraining loss: 0.3268784284591675\n",
      "Step: 11300  \tTraining accuracy: 0.8162192106246948\n",
      "Step: 11300  \tValid loss: 0.3662879168987274\n",
      "Step: 11400  \tTraining loss: 0.32682761549949646\n",
      "Step: 11400  \tTraining accuracy: 0.8162767291069031\n",
      "Step: 11400  \tValid loss: 0.36626774072647095\n",
      "Step: 11500  \tTraining loss: 0.32677486538887024\n",
      "Step: 11500  \tTraining accuracy: 0.8163279294967651\n",
      "Step: 11500  \tValid loss: 0.3662678301334381\n",
      "Step: 11600  \tTraining loss: 0.32672035694122314\n",
      "Step: 11600  \tTraining accuracy: 0.8163782358169556\n",
      "Step: 11600  \tValid loss: 0.36629554629325867\n",
      "Step: 11700  \tTraining loss: 0.3266643285751343\n",
      "Step: 11700  \tTraining accuracy: 0.8164277076721191\n",
      "Step: 11700  \tValid loss: 0.3663533627986908\n",
      "Step: 11800  \tTraining loss: 0.3266071677207947\n",
      "Step: 11800  \tTraining accuracy: 0.8164763450622559\n",
      "Step: 11800  \tValid loss: 0.36643847823143005\n",
      "Step: 11900  \tTraining loss: 0.3265492916107178\n",
      "Step: 11900  \tTraining accuracy: 0.8165241479873657\n",
      "Step: 11900  \tValid loss: 0.3664441704750061\n",
      "Step: 12000  \tTraining loss: 0.32649120688438416\n",
      "Step: 12000  \tTraining accuracy: 0.8165711760520935\n",
      "Step: 12000  \tValid loss: 0.3663747012615204\n",
      "Step: 12100  \tTraining loss: 0.3264330327510834\n",
      "Step: 12100  \tTraining accuracy: 0.8166224360466003\n",
      "Step: 12100  \tValid loss: 0.36632031202316284\n",
      "Step: 12200  \tTraining loss: 0.3263753056526184\n",
      "Step: 12200  \tTraining accuracy: 0.8166678547859192\n",
      "Step: 12200  \tValid loss: 0.36627843976020813\n",
      "Step: 12300  \tTraining loss: 0.3263181746006012\n",
      "Step: 12300  \tTraining accuracy: 0.816712498664856\n",
      "Step: 12300  \tValid loss: 0.36624789237976074\n",
      "Step: 12400  \tTraining loss: 0.326261967420578\n",
      "Step: 12400  \tTraining accuracy: 0.8167466521263123\n",
      "Step: 12400  \tValid loss: 0.3662264049053192\n",
      "Step: 12500  \tTraining loss: 0.32620683312416077\n",
      "Step: 12500  \tTraining accuracy: 0.8167802691459656\n",
      "Step: 12500  \tValid loss: 0.3662126660346985\n",
      "Step: 12600  \tTraining loss: 0.32615286111831665\n",
      "Step: 12600  \tTraining accuracy: 0.8168133497238159\n",
      "Step: 12600  \tValid loss: 0.3662051856517792\n",
      "Step: 12700  \tTraining loss: 0.3261001408100128\n",
      "Step: 12700  \tTraining accuracy: 0.8168458938598633\n",
      "Step: 12700  \tValid loss: 0.366202175617218\n",
      "Step: 12800  \tTraining loss: 0.32604867219924927\n",
      "Step: 12800  \tTraining accuracy: 0.8168779611587524\n",
      "Step: 12800  \tValid loss: 0.36620238423347473\n",
      "Step: 12900  \tTraining loss: 0.32599854469299316\n",
      "Step: 12900  \tTraining accuracy: 0.8169094920158386\n",
      "Step: 12900  \tValid loss: 0.3662053942680359\n",
      "Step: 13000  \tTraining loss: 0.32594969868659973\n",
      "Step: 13000  \tTraining accuracy: 0.8169405460357666\n",
      "Step: 13000  \tValid loss: 0.36621004343032837\n",
      "Step: 13100  \tTraining loss: 0.3259020745754242\n",
      "Step: 13100  \tTraining accuracy: 0.8169711232185364\n",
      "Step: 13100  \tValid loss: 0.366216242313385\n",
      "Step: 13200  \tTraining loss: 0.32585570216178894\n",
      "Step: 13200  \tTraining accuracy: 0.817001223564148\n",
      "Step: 13200  \tValid loss: 0.36622366309165955\n",
      "Step: 13300  \tTraining loss: 0.3258105516433716\n",
      "Step: 13300  \tTraining accuracy: 0.8170354962348938\n",
      "Step: 13300  \tValid loss: 0.36623233556747437\n",
      "Step: 13400  \tTraining loss: 0.32576659321784973\n",
      "Step: 13400  \tTraining accuracy: 0.8170691728591919\n",
      "Step: 13400  \tValid loss: 0.3662415146827698\n",
      "Step: 13500  \tTraining loss: 0.3257236182689667\n",
      "Step: 13500  \tTraining accuracy: 0.8171024322509766\n",
      "Step: 13500  \tValid loss: 0.36625126004219055\n",
      "Step: 13600  \tTraining loss: 0.3256817162036896\n",
      "Step: 13600  \tTraining accuracy: 0.8171440362930298\n",
      "Step: 13600  \tValid loss: 0.3662613332271576\n",
      "Step: 13700  \tTraining loss: 0.32564079761505127\n",
      "Step: 13700  \tTraining accuracy: 0.81718510389328\n",
      "Step: 13700  \tValid loss: 0.36627140641212463\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.81723434\n",
      "Precision: 0.84063745\n",
      "Recall: 0.71525425\n",
      "F1 score: 0.7513766\n",
      "AUC: 0.8209971\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.817234   0.840637  0.715254  0.751377  0.820997  0.325612      0.817103   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.366202        0.81709   0.558656      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  13772.0  \n",
      "33\n",
      "(928, 4)\n",
      "(928, 1)\n",
      "(512, 4)\n",
      "(512, 1)\n",
      "(416, 4)\n",
      "(416, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.637735903263092\n",
      "Step: 100  \tTraining accuracy: 0.6045258641242981\n",
      "Step: 100  \tValid loss: 0.6341037154197693\n",
      "Step: 200  \tTraining loss: 0.5409770607948303\n",
      "Step: 200  \tTraining accuracy: 0.6476293206214905\n",
      "Step: 200  \tValid loss: 0.5424214601516724\n",
      "Step: 300  \tTraining loss: 0.5216916799545288\n",
      "Step: 300  \tTraining accuracy: 0.6915948390960693\n",
      "Step: 300  \tValid loss: 0.5290107131004333\n",
      "Step: 400  \tTraining loss: 0.5148395895957947\n",
      "Step: 400  \tTraining accuracy: 0.7158251404762268\n",
      "Step: 400  \tValid loss: 0.5223792791366577\n",
      "Step: 500  \tTraining loss: 0.5088873505592346\n",
      "Step: 500  \tTraining accuracy: 0.7302442789077759\n",
      "Step: 500  \tValid loss: 0.5169719457626343\n",
      "Step: 600  \tTraining loss: 0.5032863020896912\n",
      "Step: 600  \tTraining accuracy: 0.739811897277832\n",
      "Step: 600  \tValid loss: 0.5124488472938538\n",
      "Step: 700  \tTraining loss: 0.49814489483833313\n",
      "Step: 700  \tTraining accuracy: 0.7465185523033142\n",
      "Step: 700  \tValid loss: 0.5085431337356567\n",
      "Step: 800  \tTraining loss: 0.4937134087085724\n",
      "Step: 800  \tTraining accuracy: 0.7514367699623108\n",
      "Step: 800  \tValid loss: 0.5055183172225952\n",
      "Step: 900  \tTraining loss: 0.48964330554008484\n",
      "Step: 900  \tTraining accuracy: 0.7555146813392639\n",
      "Step: 900  \tValid loss: 0.503188967704773\n",
      "Step: 1000  \tTraining loss: 0.4856340289115906\n",
      "Step: 1000  \tTraining accuracy: 0.7586206793785095\n",
      "Step: 1000  \tValid loss: 0.4996083378791809\n",
      "Step: 1100  \tTraining loss: 0.4832291007041931\n",
      "Step: 1100  \tTraining accuracy: 0.7612376809120178\n",
      "Step: 1100  \tValid loss: 0.49774956703186035\n",
      "Step: 1200  \tTraining loss: 0.4816325306892395\n",
      "Step: 1200  \tTraining accuracy: 0.7633526921272278\n",
      "Step: 1200  \tValid loss: 0.4972872734069824\n",
      "Step: 1300  \tTraining loss: 0.4801193177700043\n",
      "Step: 1300  \tTraining accuracy: 0.7650862336158752\n",
      "Step: 1300  \tValid loss: 0.49666428565979004\n",
      "Step: 1400  \tTraining loss: 0.47900593280792236\n",
      "Step: 1400  \tTraining accuracy: 0.7666028141975403\n",
      "Step: 1400  \tValid loss: 0.4961478114128113\n",
      "Step: 1500  \tTraining loss: 0.47775787115097046\n",
      "Step: 1500  \tTraining accuracy: 0.7679473757743835\n",
      "Step: 1500  \tValid loss: 0.495940625667572\n",
      "Step: 1600  \tTraining loss: 0.47694215178489685\n",
      "Step: 1600  \tTraining accuracy: 0.7692574858665466\n",
      "Step: 1600  \tValid loss: 0.4959581196308136\n",
      "Step: 1700  \tTraining loss: 0.4761814773082733\n",
      "Step: 1700  \tTraining accuracy: 0.770441472530365\n",
      "Step: 1700  \tValid loss: 0.49638500809669495\n",
      "Step: 1800  \tTraining loss: 0.4748583436012268\n",
      "Step: 1800  \tTraining accuracy: 0.7715517282485962\n",
      "Step: 1800  \tValid loss: 0.4968947470188141\n",
      "Step: 1900  \tTraining loss: 0.47353190183639526\n",
      "Step: 1900  \tTraining accuracy: 0.7725419402122498\n",
      "Step: 1900  \tValid loss: 0.49727869033813477\n",
      "Step: 2000  \tTraining loss: 0.4725842773914337\n",
      "Step: 2000  \tTraining accuracy: 0.773430585861206\n",
      "Step: 2000  \tValid loss: 0.4973321855068207\n",
      "Step: 2100  \tTraining loss: 0.47142285108566284\n",
      "Step: 2100  \tTraining accuracy: 0.7742325663566589\n",
      "Step: 2100  \tValid loss: 0.49732398986816406\n",
      "Step: 2200  \tTraining loss: 0.46988946199417114\n",
      "Step: 2200  \tTraining accuracy: 0.7749849557876587\n",
      "Step: 2200  \tValid loss: 0.4975000321865082\n",
      "Step: 2300  \tTraining loss: 0.4681675434112549\n",
      "Step: 2300  \tTraining accuracy: 0.7757423520088196\n",
      "Step: 2300  \tValid loss: 0.4980175197124481\n",
      "Step: 2400  \tTraining loss: 0.46590062975883484\n",
      "Step: 2400  \tTraining accuracy: 0.7765269875526428\n",
      "Step: 2400  \tValid loss: 0.4982767701148987\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.77726954\n",
      "Precision: 0.8286938\n",
      "Recall: 0.7818182\n",
      "F1 score: 0.7546463\n",
      "AUC: 0.79853034\n",
      "   accuracy  precision    recall  f1_score      auc      loss  accuracy_val  \\\n",
      "0   0.77727   0.828694  0.781818  0.754646  0.79853  0.465524       0.77685   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.495552       0.776685   0.468031      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  2430.0  \n",
      "34\n",
      "(986, 4)\n",
      "(986, 1)\n",
      "(544, 4)\n",
      "(544, 1)\n",
      "(442, 4)\n",
      "(442, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4570630192756653\n",
      "Step: 100  \tTraining accuracy: 0.8316429853439331\n",
      "Step: 100  \tValid loss: 0.4951138198375702\n",
      "Step: 200  \tTraining loss: 0.4312709867954254\n",
      "Step: 200  \tTraining accuracy: 0.8272481560707092\n",
      "Step: 200  \tValid loss: 0.4905506670475006\n",
      "Step: 300  \tTraining loss: 0.4211341142654419\n",
      "Step: 300  \tTraining accuracy: 0.8263691663742065\n",
      "Step: 300  \tValid loss: 0.47784462571144104\n",
      "Step: 400  \tTraining loss: 0.4002071022987366\n",
      "Step: 400  \tTraining accuracy: 0.826282262802124\n",
      "Step: 400  \tValid loss: 0.4570713937282562\n",
      "Step: 500  \tTraining loss: 0.3774603307247162\n",
      "Step: 500  \tTraining accuracy: 0.8273608088493347\n",
      "Step: 500  \tValid loss: 0.4385218918323517\n",
      "Step: 600  \tTraining loss: 0.36026832461357117\n",
      "Step: 600  \tTraining accuracy: 0.8300756216049194\n",
      "Step: 600  \tValid loss: 0.4246295988559723\n",
      "Step: 700  \tTraining loss: 0.3494839370250702\n",
      "Step: 700  \tTraining accuracy: 0.8328132033348083\n",
      "Step: 700  \tValid loss: 0.4162343144416809\n",
      "Step: 800  \tTraining loss: 0.3432793617248535\n",
      "Step: 800  \tTraining accuracy: 0.8346179723739624\n",
      "Step: 800  \tValid loss: 0.41183310747146606\n",
      "Step: 900  \tTraining loss: 0.33973631262779236\n",
      "Step: 900  \tTraining accuracy: 0.8356997966766357\n",
      "Step: 900  \tValid loss: 0.4098581373691559\n",
      "Step: 1000  \tTraining loss: 0.33767029643058777\n",
      "Step: 1000  \tTraining accuracy: 0.836660623550415\n",
      "Step: 1000  \tValid loss: 0.4089295566082001\n",
      "Step: 1100  \tTraining loss: 0.33644190430641174\n",
      "Step: 1100  \tTraining accuracy: 0.837390124797821\n",
      "Step: 1100  \tValid loss: 0.40828177332878113\n",
      "Step: 1200  \tTraining loss: 0.33564770221710205\n",
      "Step: 1200  \tTraining accuracy: 0.837992787361145\n",
      "Step: 1200  \tValid loss: 0.4081535041332245\n",
      "Step: 1300  \tTraining loss: 0.33503225445747375\n",
      "Step: 1300  \tTraining accuracy: 0.8385395407676697\n",
      "Step: 1300  \tValid loss: 0.40779781341552734\n",
      "Step: 1400  \tTraining loss: 0.33441588282585144\n",
      "Step: 1400  \tTraining accuracy: 0.8390053510665894\n",
      "Step: 1400  \tValid loss: 0.40708640217781067\n",
      "Step: 1500  \tTraining loss: 0.3337351679801941\n",
      "Step: 1500  \tTraining accuracy: 0.8394068479537964\n",
      "Step: 1500  \tValid loss: 0.40614935755729675\n",
      "Step: 1600  \tTraining loss: 0.33297836780548096\n",
      "Step: 1600  \tTraining accuracy: 0.839691162109375\n",
      "Step: 1600  \tValid loss: 0.40497303009033203\n",
      "Step: 1700  \tTraining loss: 0.3321859538555145\n",
      "Step: 1700  \tTraining accuracy: 0.8399409651756287\n",
      "Step: 1700  \tValid loss: 0.40375491976737976\n",
      "Step: 1800  \tTraining loss: 0.331379771232605\n",
      "Step: 1800  \tTraining accuracy: 0.8401622772216797\n",
      "Step: 1800  \tValid loss: 0.4025259017944336\n",
      "Step: 1900  \tTraining loss: 0.33063262701034546\n",
      "Step: 1900  \tTraining accuracy: 0.8403047919273376\n",
      "Step: 1900  \tValid loss: 0.4014548063278198\n",
      "Step: 2000  \tTraining loss: 0.32994917035102844\n",
      "Step: 2000  \tTraining accuracy: 0.8404327034950256\n",
      "Step: 2000  \tValid loss: 0.4004199504852295\n",
      "Step: 2100  \tTraining loss: 0.3293333351612091\n",
      "Step: 2100  \tTraining accuracy: 0.8405728936195374\n",
      "Step: 2100  \tValid loss: 0.39956989884376526\n",
      "Step: 2200  \tTraining loss: 0.3287854492664337\n",
      "Step: 2200  \tTraining accuracy: 0.8406764268875122\n",
      "Step: 2200  \tValid loss: 0.3986680209636688\n",
      "Step: 2300  \tTraining loss: 0.32827621698379517\n",
      "Step: 2300  \tTraining accuracy: 0.8407707810401917\n",
      "Step: 2300  \tValid loss: 0.39791417121887207\n",
      "Step: 2400  \tTraining loss: 0.3277813494205475\n",
      "Step: 2400  \tTraining accuracy: 0.8408355116844177\n",
      "Step: 2400  \tValid loss: 0.3971603512763977\n",
      "Step: 2500  \tTraining loss: 0.3273364007472992\n",
      "Step: 2500  \tTraining accuracy: 0.8408949971199036\n",
      "Step: 2500  \tValid loss: 0.396562397480011\n",
      "Step: 2600  \tTraining loss: 0.32694217562675476\n",
      "Step: 2600  \tTraining accuracy: 0.8409497737884521\n",
      "Step: 2600  \tValid loss: 0.39605972170829773\n",
      "Step: 2700  \tTraining loss: 0.3265870213508606\n",
      "Step: 2700  \tTraining accuracy: 0.8409813046455383\n",
      "Step: 2700  \tValid loss: 0.39564749598503113\n",
      "Step: 2800  \tTraining loss: 0.32627034187316895\n",
      "Step: 2800  \tTraining accuracy: 0.8410474061965942\n",
      "Step: 2800  \tValid loss: 0.3953331708908081\n",
      "Step: 2900  \tTraining loss: 0.3259895443916321\n",
      "Step: 2900  \tTraining accuracy: 0.8410910367965698\n",
      "Step: 2900  \tValid loss: 0.3950754702091217\n",
      "Step: 3000  \tTraining loss: 0.32573527097702026\n",
      "Step: 3000  \tTraining accuracy: 0.8411489725112915\n",
      "Step: 3000  \tValid loss: 0.3948769271373749\n",
      "Step: 3100  \tTraining loss: 0.3255046010017395\n",
      "Step: 3100  \tTraining accuracy: 0.8412030935287476\n",
      "Step: 3100  \tValid loss: 0.39472487568855286\n",
      "Step: 3200  \tTraining loss: 0.3253013789653778\n",
      "Step: 3200  \tTraining accuracy: 0.8412537574768066\n",
      "Step: 3200  \tValid loss: 0.39462560415267944\n",
      "Step: 3300  \tTraining loss: 0.32512006163597107\n",
      "Step: 3300  \tTraining accuracy: 0.8412857055664062\n",
      "Step: 3300  \tValid loss: 0.39454931020736694\n",
      "Step: 3400  \tTraining loss: 0.32495105266571045\n",
      "Step: 3400  \tTraining accuracy: 0.841315746307373\n",
      "Step: 3400  \tValid loss: 0.39449140429496765\n",
      "Step: 3500  \tTraining loss: 0.3247789740562439\n",
      "Step: 3500  \tTraining accuracy: 0.8413293361663818\n",
      "Step: 3500  \tValid loss: 0.394450843334198\n",
      "Step: 3600  \tTraining loss: 0.32454216480255127\n",
      "Step: 3600  \tTraining accuracy: 0.8413707613945007\n",
      "Step: 3600  \tValid loss: 0.3944397568702698\n",
      "Step: 3700  \tTraining loss: 0.3242628872394562\n",
      "Step: 3700  \tTraining accuracy: 0.8414098620414734\n",
      "Step: 3700  \tValid loss: 0.3944334089756012\n",
      "Step: 3800  \tTraining loss: 0.3239745795726776\n",
      "Step: 3800  \tTraining accuracy: 0.8414469361305237\n",
      "Step: 3800  \tValid loss: 0.3944300413131714\n",
      "Step: 3900  \tTraining loss: 0.3237220048904419\n",
      "Step: 3900  \tTraining accuracy: 0.8414952158927917\n",
      "Step: 3900  \tValid loss: 0.3944210410118103\n",
      "Step: 4000  \tTraining loss: 0.3235000669956207\n",
      "Step: 4000  \tTraining accuracy: 0.841541051864624\n",
      "Step: 4000  \tValid loss: 0.3943949341773987\n",
      "Step: 4100  \tTraining loss: 0.32330116629600525\n",
      "Step: 4100  \tTraining accuracy: 0.8415846824645996\n",
      "Step: 4100  \tValid loss: 0.3943581283092499\n",
      "Step: 4200  \tTraining loss: 0.32312169671058655\n",
      "Step: 4200  \tTraining accuracy: 0.8416139483451843\n",
      "Step: 4200  \tValid loss: 0.3943259119987488\n",
      "Step: 4300  \tTraining loss: 0.32295703887939453\n",
      "Step: 4300  \tTraining accuracy: 0.8416417837142944\n",
      "Step: 4300  \tValid loss: 0.394283264875412\n",
      "Step: 4400  \tTraining loss: 0.322805255651474\n",
      "Step: 4400  \tTraining accuracy: 0.841668426990509\n",
      "Step: 4400  \tValid loss: 0.3942444324493408\n",
      "Step: 4500  \tTraining loss: 0.32266584038734436\n",
      "Step: 4500  \tTraining accuracy: 0.8417280316352844\n",
      "Step: 4500  \tValid loss: 0.3942115306854248\n",
      "Step: 4600  \tTraining loss: 0.32253962755203247\n",
      "Step: 4600  \tTraining accuracy: 0.8417850136756897\n",
      "Step: 4600  \tValid loss: 0.39418265223503113\n",
      "Step: 4700  \tTraining loss: 0.32242336869239807\n",
      "Step: 4700  \tTraining accuracy: 0.8418285846710205\n",
      "Step: 4700  \tValid loss: 0.3941475749015808\n",
      "Step: 4800  \tTraining loss: 0.3223159909248352\n",
      "Step: 4800  \tTraining accuracy: 0.8418703675270081\n",
      "Step: 4800  \tValid loss: 0.3941185772418976\n",
      "Step: 4900  \tTraining loss: 0.3222169280052185\n",
      "Step: 4900  \tTraining accuracy: 0.8419209122657776\n",
      "Step: 4900  \tValid loss: 0.3940927982330322\n",
      "Step: 5000  \tTraining loss: 0.3221265971660614\n",
      "Step: 5000  \tTraining accuracy: 0.8419796228408813\n",
      "Step: 5000  \tValid loss: 0.3940727114677429\n",
      "Step: 5100  \tTraining loss: 0.32204264402389526\n",
      "Step: 5100  \tTraining accuracy: 0.8420360088348389\n",
      "Step: 5100  \tValid loss: 0.3940523862838745\n",
      "Step: 5200  \tTraining loss: 0.3219638764858246\n",
      "Step: 5200  \tTraining accuracy: 0.8421000838279724\n",
      "Step: 5200  \tValid loss: 0.3940316438674927\n",
      "Step: 5300  \tTraining loss: 0.32188984751701355\n",
      "Step: 5300  \tTraining accuracy: 0.8421520590782166\n",
      "Step: 5300  \tValid loss: 0.3940093219280243\n",
      "Step: 5400  \tTraining loss: 0.32181990146636963\n",
      "Step: 5400  \tTraining accuracy: 0.8422115445137024\n",
      "Step: 5400  \tValid loss: 0.3939874470233917\n",
      "Step: 5500  \tTraining loss: 0.32175374031066895\n",
      "Step: 5500  \tTraining accuracy: 0.8422781229019165\n",
      "Step: 5500  \tValid loss: 0.3939622938632965\n",
      "Step: 5600  \tTraining loss: 0.3216905891895294\n",
      "Step: 5600  \tTraining accuracy: 0.8423423171043396\n",
      "Step: 5600  \tValid loss: 0.3939388394355774\n",
      "Step: 5700  \tTraining loss: 0.3216302692890167\n",
      "Step: 5700  \tTraining accuracy: 0.842404305934906\n",
      "Step: 5700  \tValid loss: 0.3939138352870941\n",
      "Step: 5800  \tTraining loss: 0.3215724229812622\n",
      "Step: 5800  \tTraining accuracy: 0.8424640893936157\n",
      "Step: 5800  \tValid loss: 0.39388152956962585\n",
      "Step: 5900  \tTraining loss: 0.32151657342910767\n",
      "Step: 5900  \tTraining accuracy: 0.8425217866897583\n",
      "Step: 5900  \tValid loss: 0.3938523530960083\n",
      "Step: 6000  \tTraining loss: 0.3214626908302307\n",
      "Step: 6000  \tTraining accuracy: 0.8425775766372681\n",
      "Step: 6000  \tValid loss: 0.393815279006958\n",
      "Step: 6100  \tTraining loss: 0.32141032814979553\n",
      "Step: 6100  \tTraining accuracy: 0.8426315784454346\n",
      "Step: 6100  \tValid loss: 0.3937799334526062\n",
      "Step: 6200  \tTraining loss: 0.32135945558547974\n",
      "Step: 6200  \tTraining accuracy: 0.842683732509613\n",
      "Step: 6200  \tValid loss: 0.39373597502708435\n",
      "Step: 6300  \tTraining loss: 0.32130974531173706\n",
      "Step: 6300  \tTraining accuracy: 0.8427342772483826\n",
      "Step: 6300  \tValid loss: 0.3936918377876282\n",
      "Step: 6400  \tTraining loss: 0.32126128673553467\n",
      "Step: 6400  \tTraining accuracy: 0.8427832126617432\n",
      "Step: 6400  \tValid loss: 0.3936465084552765\n",
      "Step: 6500  \tTraining loss: 0.32121366262435913\n",
      "Step: 6500  \tTraining accuracy: 0.8428306579589844\n",
      "Step: 6500  \tValid loss: 0.3935956656932831\n",
      "Step: 6600  \tTraining loss: 0.3211669921875\n",
      "Step: 6600  \tTraining accuracy: 0.8428766131401062\n",
      "Step: 6600  \tValid loss: 0.3935462236404419\n",
      "Step: 6700  \tTraining loss: 0.3211214244365692\n",
      "Step: 6700  \tTraining accuracy: 0.8429211974143982\n",
      "Step: 6700  \tValid loss: 0.3934870660305023\n",
      "Step: 6800  \tTraining loss: 0.32107701897621155\n",
      "Step: 6800  \tTraining accuracy: 0.8429494500160217\n",
      "Step: 6800  \tValid loss: 0.3934340178966522\n",
      "Step: 6900  \tTraining loss: 0.321033239364624\n",
      "Step: 6900  \tTraining accuracy: 0.8429842591285706\n",
      "Step: 6900  \tValid loss: 0.3933755159378052\n",
      "Step: 7000  \tTraining loss: 0.32099026441574097\n",
      "Step: 7000  \tTraining accuracy: 0.8430180549621582\n",
      "Step: 7000  \tValid loss: 0.39332136511802673\n",
      "Step: 7100  \tTraining loss: 0.32094767689704895\n",
      "Step: 7100  \tTraining accuracy: 0.8430365324020386\n",
      "Step: 7100  \tValid loss: 0.3932690918445587\n",
      "Step: 7200  \tTraining loss: 0.3209054470062256\n",
      "Step: 7200  \tTraining accuracy: 0.8430545330047607\n",
      "Step: 7200  \tValid loss: 0.39321771264076233\n",
      "Step: 7300  \tTraining loss: 0.3208635151386261\n",
      "Step: 7300  \tTraining accuracy: 0.8430719971656799\n",
      "Step: 7300  \tValid loss: 0.39316773414611816\n",
      "Step: 7400  \tTraining loss: 0.3208217918872833\n",
      "Step: 7400  \tTraining accuracy: 0.8430889844894409\n",
      "Step: 7400  \tValid loss: 0.39311936497688293\n",
      "Step: 7500  \tTraining loss: 0.3207797706127167\n",
      "Step: 7500  \tTraining accuracy: 0.8431054949760437\n",
      "Step: 7500  \tValid loss: 0.3930736482143402\n",
      "Step: 7600  \tTraining loss: 0.3207375109195709\n",
      "Step: 7600  \tTraining accuracy: 0.8431215882301331\n",
      "Step: 7600  \tValid loss: 0.3930279016494751\n",
      "Step: 7700  \tTraining loss: 0.3206946849822998\n",
      "Step: 7700  \tTraining accuracy: 0.843137264251709\n",
      "Step: 7700  \tValid loss: 0.39298316836357117\n",
      "Step: 7800  \tTraining loss: 0.3206506073474884\n",
      "Step: 7800  \tTraining accuracy: 0.8431590795516968\n",
      "Step: 7800  \tValid loss: 0.3929345905780792\n",
      "Step: 7900  \tTraining loss: 0.320605605840683\n",
      "Step: 7900  \tTraining accuracy: 0.8431802988052368\n",
      "Step: 7900  \tValid loss: 0.39288631081581116\n",
      "Step: 8000  \tTraining loss: 0.320559561252594\n",
      "Step: 8000  \tTraining accuracy: 0.8432010412216187\n",
      "Step: 8000  \tValid loss: 0.39284074306488037\n",
      "Step: 8100  \tTraining loss: 0.32051244378089905\n",
      "Step: 8100  \tTraining accuracy: 0.8432212471961975\n",
      "Step: 8100  \tValid loss: 0.39279720187187195\n",
      "Step: 8200  \tTraining loss: 0.3204639256000519\n",
      "Step: 8200  \tTraining accuracy: 0.8432409763336182\n",
      "Step: 8200  \tValid loss: 0.3927460312843323\n",
      "Step: 8300  \tTraining loss: 0.3204144239425659\n",
      "Step: 8300  \tTraining accuracy: 0.8432601690292358\n",
      "Step: 8300  \tValid loss: 0.39269912242889404\n",
      "Step: 8400  \tTraining loss: 0.32036396861076355\n",
      "Step: 8400  \tTraining accuracy: 0.8432789444923401\n",
      "Step: 8400  \tValid loss: 0.39265644550323486\n",
      "Step: 8500  \tTraining loss: 0.3203127384185791\n",
      "Step: 8500  \tTraining accuracy: 0.8432973027229309\n",
      "Step: 8500  \tValid loss: 0.39261364936828613\n",
      "Step: 8600  \tTraining loss: 0.3202613294124603\n",
      "Step: 8600  \tTraining accuracy: 0.8433092832565308\n",
      "Step: 8600  \tValid loss: 0.3925745487213135\n",
      "Step: 8700  \tTraining loss: 0.32020944356918335\n",
      "Step: 8700  \tTraining accuracy: 0.8433209657669067\n",
      "Step: 8700  \tValid loss: 0.39252686500549316\n",
      "Step: 8800  \tTraining loss: 0.32015758752822876\n",
      "Step: 8800  \tTraining accuracy: 0.8433323502540588\n",
      "Step: 8800  \tValid loss: 0.3924870193004608\n",
      "Step: 8900  \tTraining loss: 0.32010599970817566\n",
      "Step: 8900  \tTraining accuracy: 0.843349277973175\n",
      "Step: 8900  \tValid loss: 0.3924507200717926\n",
      "Step: 9000  \tTraining loss: 0.32005444169044495\n",
      "Step: 9000  \tTraining accuracy: 0.8433601260185242\n",
      "Step: 9000  \tValid loss: 0.3924095034599304\n",
      "Step: 9100  \tTraining loss: 0.3200030028820038\n",
      "Step: 9100  \tTraining accuracy: 0.8433707356452942\n",
      "Step: 9100  \tValid loss: 0.39238184690475464\n",
      "Step: 9200  \tTraining loss: 0.31995153427124023\n",
      "Step: 9200  \tTraining accuracy: 0.8433811068534851\n",
      "Step: 9200  \tValid loss: 0.3923448920249939\n",
      "Step: 9300  \tTraining loss: 0.3199000060558319\n",
      "Step: 9300  \tTraining accuracy: 0.8433912396430969\n",
      "Step: 9300  \tValid loss: 0.39231520891189575\n",
      "Step: 9400  \tTraining loss: 0.31984856724739075\n",
      "Step: 9400  \tTraining accuracy: 0.8434011936187744\n",
      "Step: 9400  \tValid loss: 0.39228400588035583\n",
      "Step: 9500  \tTraining loss: 0.31979694962501526\n",
      "Step: 9500  \tTraining accuracy: 0.8434109091758728\n",
      "Step: 9500  \tValid loss: 0.3922518789768219\n",
      "Step: 9600  \tTraining loss: 0.31974539160728455\n",
      "Step: 9600  \tTraining accuracy: 0.8434257507324219\n",
      "Step: 9600  \tValid loss: 0.392223984003067\n",
      "Step: 9700  \tTraining loss: 0.31969407200813293\n",
      "Step: 9700  \tTraining accuracy: 0.8434402942657471\n",
      "Step: 9700  \tValid loss: 0.392192542552948\n",
      "Step: 9800  \tTraining loss: 0.31964266300201416\n",
      "Step: 9800  \tTraining accuracy: 0.8434545397758484\n",
      "Step: 9800  \tValid loss: 0.39216703176498413\n",
      "Step: 9900  \tTraining loss: 0.3195911943912506\n",
      "Step: 9900  \tTraining accuracy: 0.8434633016586304\n",
      "Step: 9900  \tValid loss: 0.39214083552360535\n",
      "Step: 10000  \tTraining loss: 0.31953927874565125\n",
      "Step: 10000  \tTraining accuracy: 0.8434821367263794\n",
      "Step: 10000  \tValid loss: 0.3921104669570923\n",
      "Step: 10100  \tTraining loss: 0.3194873631000519\n",
      "Step: 10100  \tTraining accuracy: 0.843500554561615\n",
      "Step: 10100  \tValid loss: 0.39208245277404785\n",
      "Step: 10200  \tTraining loss: 0.319435179233551\n",
      "Step: 10200  \tTraining accuracy: 0.8435186147689819\n",
      "Step: 10200  \tValid loss: 0.39205875992774963\n",
      "Step: 10300  \tTraining loss: 0.3193826377391815\n",
      "Step: 10300  \tTraining accuracy: 0.8435363173484802\n",
      "Step: 10300  \tValid loss: 0.39203229546546936\n",
      "Step: 10400  \tTraining loss: 0.3193298280239105\n",
      "Step: 10400  \tTraining accuracy: 0.8435537219047546\n",
      "Step: 10400  \tValid loss: 0.3920036256313324\n",
      "Step: 10500  \tTraining loss: 0.3192768692970276\n",
      "Step: 10500  \tTraining accuracy: 0.8435707688331604\n",
      "Step: 10500  \tValid loss: 0.3919818103313446\n",
      "Step: 10600  \tTraining loss: 0.31922295689582825\n",
      "Step: 10600  \tTraining accuracy: 0.8435922861099243\n",
      "Step: 10600  \tValid loss: 0.3919537365436554\n",
      "Step: 10700  \tTraining loss: 0.31916865706443787\n",
      "Step: 10700  \tTraining accuracy: 0.8436133861541748\n",
      "Step: 10700  \tValid loss: 0.3919224143028259\n",
      "Step: 10800  \tTraining loss: 0.31911346316337585\n",
      "Step: 10800  \tTraining accuracy: 0.8436341285705566\n",
      "Step: 10800  \tValid loss: 0.39189478754997253\n",
      "Step: 10900  \tTraining loss: 0.3190574645996094\n",
      "Step: 10900  \tTraining accuracy: 0.843654453754425\n",
      "Step: 10900  \tValid loss: 0.3918650448322296\n",
      "Step: 11000  \tTraining loss: 0.31900039315223694\n",
      "Step: 11000  \tTraining accuracy: 0.8436744809150696\n",
      "Step: 11000  \tValid loss: 0.3918360471725464\n",
      "Step: 11100  \tTraining loss: 0.3189340829849243\n",
      "Step: 11100  \tTraining accuracy: 0.8436940908432007\n",
      "Step: 11100  \tValid loss: 0.39179128408432007\n",
      "Step: 11200  \tTraining loss: 0.31885436177253723\n",
      "Step: 11200  \tTraining accuracy: 0.8437133431434631\n",
      "Step: 11200  \tValid loss: 0.3917232155799866\n",
      "Step: 11300  \tTraining loss: 0.31878435611724854\n",
      "Step: 11300  \tTraining accuracy: 0.8437322378158569\n",
      "Step: 11300  \tValid loss: 0.39169859886169434\n",
      "Step: 11400  \tTraining loss: 0.318721741437912\n",
      "Step: 11400  \tTraining accuracy: 0.8437597751617432\n",
      "Step: 11400  \tValid loss: 0.3916805386543274\n",
      "Step: 11500  \tTraining loss: 0.31866106390953064\n",
      "Step: 11500  \tTraining accuracy: 0.8437868356704712\n",
      "Step: 11500  \tValid loss: 0.3916635811328888\n",
      "Step: 11600  \tTraining loss: 0.31859973073005676\n",
      "Step: 11600  \tTraining accuracy: 0.8438133597373962\n",
      "Step: 11600  \tValid loss: 0.39164304733276367\n",
      "Step: 11700  \tTraining loss: 0.31853753328323364\n",
      "Step: 11700  \tTraining accuracy: 0.8438395261764526\n",
      "Step: 11700  \tValid loss: 0.3916202187538147\n",
      "Step: 11800  \tTraining loss: 0.31847435235977173\n",
      "Step: 11800  \tTraining accuracy: 0.843865156173706\n",
      "Step: 11800  \tValid loss: 0.39159712195396423\n",
      "Step: 11900  \tTraining loss: 0.3184102475643158\n",
      "Step: 11900  \tTraining accuracy: 0.8438904285430908\n",
      "Step: 11900  \tValid loss: 0.3915732502937317\n",
      "Step: 12000  \tTraining loss: 0.31834548711776733\n",
      "Step: 12000  \tTraining accuracy: 0.8439152240753174\n",
      "Step: 12000  \tValid loss: 0.3915502429008484\n",
      "Step: 12100  \tTraining loss: 0.31827977299690247\n",
      "Step: 12100  \tTraining accuracy: 0.8439311981201172\n",
      "Step: 12100  \tValid loss: 0.39152792096138\n",
      "Step: 12200  \tTraining loss: 0.3182133734226227\n",
      "Step: 12200  \tTraining accuracy: 0.8439469337463379\n",
      "Step: 12200  \tValid loss: 0.3915071487426758\n",
      "Step: 12300  \tTraining loss: 0.3181460499763489\n",
      "Step: 12300  \tTraining accuracy: 0.8439624309539795\n",
      "Step: 12300  \tValid loss: 0.391482412815094\n",
      "Step: 12400  \tTraining loss: 0.3180791139602661\n",
      "Step: 12400  \tTraining accuracy: 0.8439776301383972\n",
      "Step: 12400  \tValid loss: 0.3914653956890106\n",
      "Step: 12500  \tTraining loss: 0.31801170110702515\n",
      "Step: 12500  \tTraining accuracy: 0.8439925909042358\n",
      "Step: 12500  \tValid loss: 0.39144623279571533\n",
      "Step: 12600  \tTraining loss: 0.3179449737071991\n",
      "Step: 12600  \tTraining accuracy: 0.8440073132514954\n",
      "Step: 12600  \tValid loss: 0.39142417907714844\n",
      "Step: 12700  \tTraining loss: 0.3178776204586029\n",
      "Step: 12700  \tTraining accuracy: 0.8440218567848206\n",
      "Step: 12700  \tValid loss: 0.3913986384868622\n",
      "Step: 12800  \tTraining loss: 0.31781005859375\n",
      "Step: 12800  \tTraining accuracy: 0.8440361022949219\n",
      "Step: 12800  \tValid loss: 0.39137110114097595\n",
      "Step: 12900  \tTraining loss: 0.31774193048477173\n",
      "Step: 12900  \tTraining accuracy: 0.8440501689910889\n",
      "Step: 12900  \tValid loss: 0.39134421944618225\n",
      "Step: 13000  \tTraining loss: 0.3176731765270233\n",
      "Step: 13000  \tTraining accuracy: 0.8440639972686768\n",
      "Step: 13000  \tValid loss: 0.39131176471710205\n",
      "Step: 13100  \tTraining loss: 0.3176034390926361\n",
      "Step: 13100  \tTraining accuracy: 0.8440815210342407\n",
      "Step: 13100  \tValid loss: 0.39127883315086365\n",
      "Step: 13200  \tTraining loss: 0.31753280758857727\n",
      "Step: 13200  \tTraining accuracy: 0.8440987467765808\n",
      "Step: 13200  \tValid loss: 0.39124447107315063\n",
      "Step: 13300  \tTraining loss: 0.31746119260787964\n",
      "Step: 13300  \tTraining accuracy: 0.8441157341003418\n",
      "Step: 13300  \tValid loss: 0.3912076950073242\n",
      "Step: 13400  \tTraining loss: 0.31738847494125366\n",
      "Step: 13400  \tTraining accuracy: 0.8441324830055237\n",
      "Step: 13400  \tValid loss: 0.3911624252796173\n",
      "Step: 13500  \tTraining loss: 0.31731468439102173\n",
      "Step: 13500  \tTraining accuracy: 0.8441489338874817\n",
      "Step: 13500  \tValid loss: 0.39111876487731934\n",
      "Step: 13600  \tTraining loss: 0.31723979115486145\n",
      "Step: 13600  \tTraining accuracy: 0.8441689014434814\n",
      "Step: 13600  \tValid loss: 0.391079306602478\n",
      "Step: 13700  \tTraining loss: 0.31716394424438477\n",
      "Step: 13700  \tTraining accuracy: 0.8441886305809021\n",
      "Step: 13700  \tValid loss: 0.3910423815250397\n",
      "Step: 13800  \tTraining loss: 0.31708699464797974\n",
      "Step: 13800  \tTraining accuracy: 0.8442080020904541\n",
      "Step: 13800  \tValid loss: 0.39099669456481934\n",
      "Step: 13900  \tTraining loss: 0.3170091211795807\n",
      "Step: 13900  \tTraining accuracy: 0.8442344665527344\n",
      "Step: 13900  \tValid loss: 0.3909618854522705\n",
      "Step: 14000  \tTraining loss: 0.3169301152229309\n",
      "Step: 14000  \tTraining accuracy: 0.8442568778991699\n",
      "Step: 14000  \tValid loss: 0.3909241855144501\n",
      "Step: 14100  \tTraining loss: 0.3168505132198334\n",
      "Step: 14100  \tTraining accuracy: 0.8442753553390503\n",
      "Step: 14100  \tValid loss: 0.3908849060535431\n",
      "Step: 14200  \tTraining loss: 0.31677010655403137\n",
      "Step: 14200  \tTraining accuracy: 0.844290018081665\n",
      "Step: 14200  \tValid loss: 0.3908434510231018\n",
      "Step: 14300  \tTraining loss: 0.3166888654232025\n",
      "Step: 14300  \tTraining accuracy: 0.8443045020103455\n",
      "Step: 14300  \tValid loss: 0.39081060886383057\n",
      "Step: 14400  \tTraining loss: 0.3166069984436035\n",
      "Step: 14400  \tTraining accuracy: 0.8443151712417603\n",
      "Step: 14400  \tValid loss: 0.39077338576316833\n",
      "Step: 14500  \tTraining loss: 0.316524863243103\n",
      "Step: 14500  \tTraining accuracy: 0.844332754611969\n",
      "Step: 14500  \tValid loss: 0.39074045419692993\n",
      "Step: 14600  \tTraining loss: 0.3164423406124115\n",
      "Step: 14600  \tTraining accuracy: 0.8443500995635986\n",
      "Step: 14600  \tValid loss: 0.390702486038208\n",
      "Step: 14700  \tTraining loss: 0.31635934114456177\n",
      "Step: 14700  \tTraining accuracy: 0.8443741202354431\n",
      "Step: 14700  \tValid loss: 0.39066675305366516\n",
      "Step: 14800  \tTraining loss: 0.31627583503723145\n",
      "Step: 14800  \tTraining accuracy: 0.8443978428840637\n",
      "Step: 14800  \tValid loss: 0.39062777161598206\n",
      "Step: 14900  \tTraining loss: 0.3161923289299011\n",
      "Step: 14900  \tTraining accuracy: 0.8444212079048157\n",
      "Step: 14900  \tValid loss: 0.3905934691429138\n",
      "Step: 15000  \tTraining loss: 0.31610849499702454\n",
      "Step: 15000  \tTraining accuracy: 0.8444442749023438\n",
      "Step: 15000  \tValid loss: 0.39056655764579773\n",
      "Step: 15100  \tTraining loss: 0.3160246014595032\n",
      "Step: 15100  \tTraining accuracy: 0.844467043876648\n",
      "Step: 15100  \tValid loss: 0.3905304968357086\n",
      "Step: 15200  \tTraining loss: 0.31594082713127136\n",
      "Step: 15200  \tTraining accuracy: 0.8444895148277283\n",
      "Step: 15200  \tValid loss: 0.39049920439720154\n",
      "Step: 15300  \tTraining loss: 0.31585726141929626\n",
      "Step: 15300  \tTraining accuracy: 0.8445150256156921\n",
      "Step: 15300  \tValid loss: 0.3904755115509033\n",
      "Step: 15400  \tTraining loss: 0.31577354669570923\n",
      "Step: 15400  \tTraining accuracy: 0.8445369005203247\n",
      "Step: 15400  \tValid loss: 0.3904484212398529\n",
      "Step: 15500  \tTraining loss: 0.3156900405883789\n",
      "Step: 15500  \tTraining accuracy: 0.8445584177970886\n",
      "Step: 15500  \tValid loss: 0.3904261291027069\n",
      "Step: 15600  \tTraining loss: 0.3156067132949829\n",
      "Step: 15600  \tTraining accuracy: 0.8445797562599182\n",
      "Step: 15600  \tValid loss: 0.39040523767471313\n",
      "Step: 15700  \tTraining loss: 0.3155246675014496\n",
      "Step: 15700  \tTraining accuracy: 0.8446007966995239\n",
      "Step: 15700  \tValid loss: 0.3903849422931671\n",
      "Step: 15800  \tTraining loss: 0.3154437243938446\n",
      "Step: 15800  \tTraining accuracy: 0.8446247577667236\n",
      "Step: 15800  \tValid loss: 0.3903762102127075\n",
      "Step: 15900  \tTraining loss: 0.31536370515823364\n",
      "Step: 15900  \tTraining accuracy: 0.8446484208106995\n",
      "Step: 15900  \tValid loss: 0.390372633934021\n",
      "Step: 16000  \tTraining loss: 0.3152843415737152\n",
      "Step: 16000  \tTraining accuracy: 0.8446717858314514\n",
      "Step: 16000  \tValid loss: 0.3903460204601288\n",
      "Step: 16100  \tTraining loss: 0.3152056038379669\n",
      "Step: 16100  \tTraining accuracy: 0.8446980714797974\n",
      "Step: 16100  \tValid loss: 0.3903447389602661\n",
      "Step: 16200  \tTraining loss: 0.315127432346344\n",
      "Step: 16200  \tTraining accuracy: 0.8447239398956299\n",
      "Step: 16200  \tValid loss: 0.39032769203186035\n",
      "Step: 16300  \tTraining loss: 0.31505030393600464\n",
      "Step: 16300  \tTraining accuracy: 0.8447526693344116\n",
      "Step: 16300  \tValid loss: 0.3903287947177887\n",
      "Step: 16400  \tTraining loss: 0.3149734139442444\n",
      "Step: 16400  \tTraining accuracy: 0.844784140586853\n",
      "Step: 16400  \tValid loss: 0.39032110571861267\n",
      "Step: 16500  \tTraining loss: 0.3148971498012543\n",
      "Step: 16500  \tTraining accuracy: 0.8448152542114258\n",
      "Step: 16500  \tValid loss: 0.3903167247772217\n",
      "Step: 16600  \tTraining loss: 0.31482166051864624\n",
      "Step: 16600  \tTraining accuracy: 0.8448490500450134\n",
      "Step: 16600  \tValid loss: 0.39031118154525757\n",
      "Step: 16700  \tTraining loss: 0.3147466778755188\n",
      "Step: 16700  \tTraining accuracy: 0.8448824286460876\n",
      "Step: 16700  \tValid loss: 0.39030784368515015\n",
      "Step: 16800  \tTraining loss: 0.3146723508834839\n",
      "Step: 16800  \tTraining accuracy: 0.8449153900146484\n",
      "Step: 16800  \tValid loss: 0.3903118669986725\n",
      "Step: 16900  \tTraining loss: 0.31459853053092957\n",
      "Step: 16900  \tTraining accuracy: 0.8449479937553406\n",
      "Step: 16900  \tValid loss: 0.39031854271888733\n",
      "Step: 17000  \tTraining loss: 0.3145252764225006\n",
      "Step: 17000  \tTraining accuracy: 0.8449801802635193\n",
      "Step: 17000  \tValid loss: 0.39032626152038574\n",
      "Step: 17100  \tTraining loss: 0.31445226073265076\n",
      "Step: 17100  \tTraining accuracy: 0.8450120091438293\n",
      "Step: 17100  \tValid loss: 0.39032337069511414\n",
      "Step: 17200  \tTraining loss: 0.31438007950782776\n",
      "Step: 17200  \tTraining accuracy: 0.845043420791626\n",
      "Step: 17200  \tValid loss: 0.3903329372406006\n",
      "Step: 17300  \tTraining loss: 0.3143082559108734\n",
      "Step: 17300  \tTraining accuracy: 0.8450745344161987\n",
      "Step: 17300  \tValid loss: 0.3903370797634125\n",
      "Step: 17400  \tTraining loss: 0.3142368495464325\n",
      "Step: 17400  \tTraining accuracy: 0.8451052308082581\n",
      "Step: 17400  \tValid loss: 0.39033350348472595\n",
      "Step: 17500  \tTraining loss: 0.31416594982147217\n",
      "Step: 17500  \tTraining accuracy: 0.8451327085494995\n",
      "Step: 17500  \tValid loss: 0.39034008979797363\n",
      "Step: 17600  \tTraining loss: 0.3140951991081238\n",
      "Step: 17600  \tTraining accuracy: 0.8451598882675171\n",
      "Step: 17600  \tValid loss: 0.3903481960296631\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8451867\n",
      "Precision: 0.8880179\n",
      "Recall: 0.96707314\n",
      "F1 score: 0.88120455\n",
      "AUC: 0.68233174\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.845187   0.888018  0.967073  0.881205  0.682332  0.314038      0.845113   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.390302       0.845121   0.459248      8.0          0.001   50000.0   \n",
      "\n",
      "     steps  \n",
      "0  17681.0  \n",
      "35\n",
      "(4031, 4)\n",
      "(4031, 1)\n",
      "(2224, 4)\n",
      "(2224, 1)\n",
      "(1807, 4)\n",
      "(1807, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4819239675998688\n",
      "Step: 100  \tTraining accuracy: 0.8620689511299133\n",
      "Step: 100  \tValid loss: 0.49285459518432617\n",
      "Step: 200  \tTraining loss: 0.31948333978652954\n",
      "Step: 200  \tTraining accuracy: 0.8676093816757202\n",
      "Step: 200  \tValid loss: 0.33526068925857544\n",
      "Step: 300  \tTraining loss: 0.2907916009426117\n",
      "Step: 300  \tTraining accuracy: 0.8695608973503113\n",
      "Step: 300  \tValid loss: 0.3048652410507202\n",
      "Step: 400  \tTraining loss: 0.2791255712509155\n",
      "Step: 400  \tTraining accuracy: 0.8700783252716064\n",
      "Step: 400  \tValid loss: 0.2913650870323181\n",
      "Step: 500  \tTraining loss: 0.26944899559020996\n",
      "Step: 500  \tTraining accuracy: 0.870972216129303\n",
      "Step: 500  \tValid loss: 0.28130292892456055\n",
      "Step: 600  \tTraining loss: 0.26141178607940674\n",
      "Step: 600  \tTraining accuracy: 0.8724882006645203\n",
      "Step: 600  \tValid loss: 0.27249273657798767\n",
      "Step: 700  \tTraining loss: 0.2540590763092041\n",
      "Step: 700  \tTraining accuracy: 0.8737667798995972\n",
      "Step: 700  \tValid loss: 0.26441046595573425\n",
      "Step: 800  \tTraining loss: 0.2475312203168869\n",
      "Step: 800  \tTraining accuracy: 0.8759282231330872\n",
      "Step: 800  \tValid loss: 0.25718510150909424\n",
      "Step: 900  \tTraining loss: 0.24211713671684265\n",
      "Step: 900  \tTraining accuracy: 0.8784129023551941\n",
      "Step: 900  \tValid loss: 0.25091353058815\n",
      "Step: 1000  \tTraining loss: 0.23792903125286102\n",
      "Step: 1000  \tTraining accuracy: 0.8808967471122742\n",
      "Step: 1000  \tValid loss: 0.24581769108772278\n",
      "Step: 1100  \tTraining loss: 0.23500481247901917\n",
      "Step: 1100  \tTraining accuracy: 0.8829192519187927\n",
      "Step: 1100  \tValid loss: 0.24228394031524658\n",
      "Step: 1200  \tTraining loss: 0.2330716997385025\n",
      "Step: 1200  \tTraining accuracy: 0.8846763372421265\n",
      "Step: 1200  \tValid loss: 0.2398591935634613\n",
      "Step: 1300  \tTraining loss: 0.23184648156166077\n",
      "Step: 1300  \tTraining accuracy: 0.8864499926567078\n",
      "Step: 1300  \tValid loss: 0.2381993532180786\n",
      "Step: 1400  \tTraining loss: 0.2310798466205597\n",
      "Step: 1400  \tTraining accuracy: 0.8880252242088318\n",
      "Step: 1400  \tValid loss: 0.2372438758611679\n",
      "Step: 1500  \tTraining loss: 0.23061203956604004\n",
      "Step: 1500  \tTraining accuracy: 0.8893489241600037\n",
      "Step: 1500  \tValid loss: 0.23654872179031372\n",
      "Step: 1600  \tTraining loss: 0.23031537234783173\n",
      "Step: 1600  \tTraining accuracy: 0.8904698491096497\n",
      "Step: 1600  \tValid loss: 0.23611757159233093\n",
      "Step: 1700  \tTraining loss: 0.23012199997901917\n",
      "Step: 1700  \tTraining accuracy: 0.8914548754692078\n",
      "Step: 1700  \tValid loss: 0.2358027994632721\n",
      "Step: 1800  \tTraining loss: 0.22998595237731934\n",
      "Step: 1800  \tTraining accuracy: 0.8923698663711548\n",
      "Step: 1800  \tValid loss: 0.23561452329158783\n",
      "Step: 1900  \tTraining loss: 0.22984930872917175\n",
      "Step: 1900  \tTraining accuracy: 0.893226146697998\n",
      "Step: 1900  \tValid loss: 0.23531784117221832\n",
      "Step: 2000  \tTraining loss: 0.22975023090839386\n",
      "Step: 2000  \tTraining accuracy: 0.8940010070800781\n",
      "Step: 2000  \tValid loss: 0.2351662665605545\n",
      "Step: 2100  \tTraining loss: 0.22966015338897705\n",
      "Step: 2100  \tTraining accuracy: 0.8947002291679382\n",
      "Step: 2100  \tValid loss: 0.23501959443092346\n",
      "Step: 2200  \tTraining loss: 0.229572594165802\n",
      "Step: 2200  \tTraining accuracy: 0.8953344225883484\n",
      "Step: 2200  \tValid loss: 0.23485027253627777\n",
      "Step: 2300  \tTraining loss: 0.2294660061597824\n",
      "Step: 2300  \tTraining accuracy: 0.895912230014801\n",
      "Step: 2300  \tValid loss: 0.23479530215263367\n",
      "Step: 2400  \tTraining loss: 0.22937123477458954\n",
      "Step: 2400  \tTraining accuracy: 0.8964250683784485\n",
      "Step: 2400  \tValid loss: 0.23462559282779694\n",
      "Step: 2500  \tTraining loss: 0.22927701473236084\n",
      "Step: 2500  \tTraining accuracy: 0.8968960046768188\n",
      "Step: 2500  \tValid loss: 0.2344300001859665\n",
      "Step: 2600  \tTraining loss: 0.22918285429477692\n",
      "Step: 2600  \tTraining accuracy: 0.8973348736763\n",
      "Step: 2600  \tValid loss: 0.23421001434326172\n",
      "Step: 2700  \tTraining loss: 0.22908757627010345\n",
      "Step: 2700  \tTraining accuracy: 0.8977406024932861\n",
      "Step: 2700  \tValid loss: 0.2339683324098587\n",
      "Step: 2800  \tTraining loss: 0.22898469865322113\n",
      "Step: 2800  \tTraining accuracy: 0.8981168866157532\n",
      "Step: 2800  \tValid loss: 0.23370984196662903\n",
      "Step: 2900  \tTraining loss: 0.2288760542869568\n",
      "Step: 2900  \tTraining accuracy: 0.8984580039978027\n",
      "Step: 2900  \tValid loss: 0.23345398902893066\n",
      "Step: 3000  \tTraining loss: 0.22876714169979095\n",
      "Step: 3000  \tTraining accuracy: 0.8987802267074585\n",
      "Step: 3000  \tValid loss: 0.23318184912204742\n",
      "Step: 3100  \tTraining loss: 0.2286609709262848\n",
      "Step: 3100  \tTraining accuracy: 0.899081289768219\n",
      "Step: 3100  \tValid loss: 0.23290346562862396\n",
      "Step: 3200  \tTraining loss: 0.22855471074581146\n",
      "Step: 3200  \tTraining accuracy: 0.8993632793426514\n",
      "Step: 3200  \tValid loss: 0.2326272577047348\n",
      "Step: 3300  \tTraining loss: 0.22844961285591125\n",
      "Step: 3300  \tTraining accuracy: 0.8996278643608093\n",
      "Step: 3300  \tValid loss: 0.23236243426799774\n",
      "Step: 3400  \tTraining loss: 0.22834505140781403\n",
      "Step: 3400  \tTraining accuracy: 0.8998767137527466\n",
      "Step: 3400  \tValid loss: 0.23212234675884247\n",
      "Step: 3500  \tTraining loss: 0.22824156284332275\n",
      "Step: 3500  \tTraining accuracy: 0.9001075029373169\n",
      "Step: 3500  \tValid loss: 0.23188622295856476\n",
      "Step: 3600  \tTraining loss: 0.22813750803470612\n",
      "Step: 3600  \tTraining accuracy: 0.9003217816352844\n",
      "Step: 3600  \tValid loss: 0.23167546093463898\n",
      "Step: 3700  \tTraining loss: 0.22803354263305664\n",
      "Step: 3700  \tTraining accuracy: 0.9005277752876282\n",
      "Step: 3700  \tValid loss: 0.23149065673351288\n",
      "Step: 3800  \tTraining loss: 0.22792835533618927\n",
      "Step: 3800  \tTraining accuracy: 0.9007227420806885\n",
      "Step: 3800  \tValid loss: 0.23133210837841034\n",
      "Step: 3900  \tTraining loss: 0.22782272100448608\n",
      "Step: 3900  \tTraining accuracy: 0.9009043574333191\n",
      "Step: 3900  \tValid loss: 0.23118998110294342\n",
      "Step: 4000  \tTraining loss: 0.22771598398685455\n",
      "Step: 4000  \tTraining accuracy: 0.9010767936706543\n",
      "Step: 4000  \tValid loss: 0.23106269538402557\n",
      "Step: 4100  \tTraining loss: 0.227608785033226\n",
      "Step: 4100  \tTraining accuracy: 0.9012376070022583\n",
      "Step: 4100  \tValid loss: 0.2309453934431076\n",
      "Step: 4200  \tTraining loss: 0.22750107944011688\n",
      "Step: 4200  \tTraining accuracy: 0.901393711566925\n",
      "Step: 4200  \tValid loss: 0.23083502054214478\n",
      "Step: 4300  \tTraining loss: 0.22739310562610626\n",
      "Step: 4300  \tTraining accuracy: 0.9015454053878784\n",
      "Step: 4300  \tValid loss: 0.23072753846645355\n",
      "Step: 4400  \tTraining loss: 0.2272847592830658\n",
      "Step: 4400  \tTraining accuracy: 0.9016985893249512\n",
      "Step: 4400  \tValid loss: 0.23062196373939514\n",
      "Step: 4500  \tTraining loss: 0.2271767109632492\n",
      "Step: 4500  \tTraining accuracy: 0.9018505215644836\n",
      "Step: 4500  \tValid loss: 0.23051322996616364\n",
      "Step: 4600  \tTraining loss: 0.22706830501556396\n",
      "Step: 4600  \tTraining accuracy: 0.9019985198974609\n",
      "Step: 4600  \tValid loss: 0.2304128259420395\n",
      "Step: 4700  \tTraining loss: 0.2269599437713623\n",
      "Step: 4700  \tTraining accuracy: 0.9021454453468323\n",
      "Step: 4700  \tValid loss: 0.230317622423172\n",
      "Step: 4800  \tTraining loss: 0.22685177624225616\n",
      "Step: 4800  \tTraining accuracy: 0.9022836089134216\n",
      "Step: 4800  \tValid loss: 0.23021775484085083\n",
      "Step: 4900  \tTraining loss: 0.22674407064914703\n",
      "Step: 4900  \tTraining accuracy: 0.9024160504341125\n",
      "Step: 4900  \tValid loss: 0.23011529445648193\n",
      "Step: 5000  \tTraining loss: 0.22663642466068268\n",
      "Step: 5000  \tTraining accuracy: 0.9025431871414185\n",
      "Step: 5000  \tValid loss: 0.23000770807266235\n",
      "Step: 5100  \tTraining loss: 0.22652828693389893\n",
      "Step: 5100  \tTraining accuracy: 0.9026652574539185\n",
      "Step: 5100  \tValid loss: 0.22991739213466644\n",
      "Step: 5200  \tTraining loss: 0.22642052173614502\n",
      "Step: 5200  \tTraining accuracy: 0.9027753472328186\n",
      "Step: 5200  \tValid loss: 0.22982478141784668\n",
      "Step: 5300  \tTraining loss: 0.22631266713142395\n",
      "Step: 5300  \tTraining accuracy: 0.9028835892677307\n",
      "Step: 5300  \tValid loss: 0.22973109781742096\n",
      "Step: 5400  \tTraining loss: 0.22620443999767303\n",
      "Step: 5400  \tTraining accuracy: 0.9029901623725891\n",
      "Step: 5400  \tValid loss: 0.22964222729206085\n",
      "Step: 5500  \tTraining loss: 0.2260957956314087\n",
      "Step: 5500  \tTraining accuracy: 0.9030904769897461\n",
      "Step: 5500  \tValid loss: 0.22954973578453064\n",
      "Step: 5600  \tTraining loss: 0.22598619759082794\n",
      "Step: 5600  \tTraining accuracy: 0.9031916856765747\n",
      "Step: 5600  \tValid loss: 0.2294601947069168\n",
      "Step: 5700  \tTraining loss: 0.2258753925561905\n",
      "Step: 5700  \tTraining accuracy: 0.9032893180847168\n",
      "Step: 5700  \tValid loss: 0.22936846315860748\n",
      "Step: 5800  \tTraining loss: 0.22576147317886353\n",
      "Step: 5800  \tTraining accuracy: 0.9033856987953186\n",
      "Step: 5800  \tValid loss: 0.22924456000328064\n",
      "Step: 5900  \tTraining loss: 0.22564354538917542\n",
      "Step: 5900  \tTraining accuracy: 0.9034809470176697\n",
      "Step: 5900  \tValid loss: 0.2291674166917801\n",
      "Step: 6000  \tTraining loss: 0.2255242019891739\n",
      "Step: 6000  \tTraining accuracy: 0.9035645723342896\n",
      "Step: 6000  \tValid loss: 0.2290845662355423\n",
      "Step: 6100  \tTraining loss: 0.22540254890918732\n",
      "Step: 6100  \tTraining accuracy: 0.9036434292793274\n",
      "Step: 6100  \tValid loss: 0.22900259494781494\n",
      "Step: 6200  \tTraining loss: 0.225267693400383\n",
      "Step: 6200  \tTraining accuracy: 0.9037177562713623\n",
      "Step: 6200  \tValid loss: 0.2290288656949997\n",
      "Step: 6300  \tTraining loss: 0.22513628005981445\n",
      "Step: 6300  \tTraining accuracy: 0.9037876725196838\n",
      "Step: 6300  \tValid loss: 0.22891518473625183\n",
      "Step: 6400  \tTraining loss: 0.225004643201828\n",
      "Step: 6400  \tTraining accuracy: 0.9038572907447815\n",
      "Step: 6400  \tValid loss: 0.22880595922470093\n",
      "Step: 6500  \tTraining loss: 0.22486896812915802\n",
      "Step: 6500  \tTraining accuracy: 0.9039267301559448\n",
      "Step: 6500  \tValid loss: 0.22870758175849915\n",
      "Step: 6600  \tTraining loss: 0.22472824156284332\n",
      "Step: 6600  \tTraining accuracy: 0.9039902687072754\n",
      "Step: 6600  \tValid loss: 0.22862690687179565\n",
      "Step: 6700  \tTraining loss: 0.22458302974700928\n",
      "Step: 6700  \tTraining accuracy: 0.9040518403053284\n",
      "Step: 6700  \tValid loss: 0.22852285206317902\n",
      "Step: 6800  \tTraining loss: 0.22443291544914246\n",
      "Step: 6800  \tTraining accuracy: 0.9041134715080261\n",
      "Step: 6800  \tValid loss: 0.22841399908065796\n",
      "Step: 6900  \tTraining loss: 0.2242773026227951\n",
      "Step: 6900  \tTraining accuracy: 0.9041733145713806\n",
      "Step: 6900  \tValid loss: 0.22830097377300262\n",
      "Step: 7000  \tTraining loss: 0.22411733865737915\n",
      "Step: 7000  \tTraining accuracy: 0.9042314291000366\n",
      "Step: 7000  \tValid loss: 0.2281840741634369\n",
      "Step: 7100  \tTraining loss: 0.22395338118076324\n",
      "Step: 7100  \tTraining accuracy: 0.9042860865592957\n",
      "Step: 7100  \tValid loss: 0.22806861996650696\n",
      "Step: 7200  \tTraining loss: 0.22378648817539215\n",
      "Step: 7200  \tTraining accuracy: 0.9043375253677368\n",
      "Step: 7200  \tValid loss: 0.22795487940311432\n",
      "Step: 7300  \tTraining loss: 0.2236194908618927\n",
      "Step: 7300  \tTraining accuracy: 0.9043875336647034\n",
      "Step: 7300  \tValid loss: 0.22785328328609467\n",
      "Step: 7400  \tTraining loss: 0.22345493733882904\n",
      "Step: 7400  \tTraining accuracy: 0.9044294357299805\n",
      "Step: 7400  \tValid loss: 0.2277764528989792\n",
      "Step: 7500  \tTraining loss: 0.22329643368721008\n",
      "Step: 7500  \tTraining accuracy: 0.9044685363769531\n",
      "Step: 7500  \tValid loss: 0.22772160172462463\n",
      "Step: 7600  \tTraining loss: 0.22314685583114624\n",
      "Step: 7600  \tTraining accuracy: 0.9045082926750183\n",
      "Step: 7600  \tValid loss: 0.22766956686973572\n",
      "Step: 7700  \tTraining loss: 0.22300904989242554\n",
      "Step: 7700  \tTraining accuracy: 0.9045501947402954\n",
      "Step: 7700  \tValid loss: 0.22763212025165558\n",
      "Step: 7800  \tTraining loss: 0.22286655008792877\n",
      "Step: 7800  \tTraining accuracy: 0.9045878052711487\n",
      "Step: 7800  \tValid loss: 0.2274174839258194\n",
      "Step: 7900  \tTraining loss: 0.22273024916648865\n",
      "Step: 7900  \tTraining accuracy: 0.9046260714530945\n",
      "Step: 7900  \tValid loss: 0.22753915190696716\n",
      "Step: 8000  \tTraining loss: 0.2226225584745407\n",
      "Step: 8000  \tTraining accuracy: 0.9046618342399597\n",
      "Step: 8000  \tValid loss: 0.22746284306049347\n",
      "Step: 8100  \tTraining loss: 0.22252333164215088\n",
      "Step: 8100  \tTraining accuracy: 0.9046951532363892\n",
      "Step: 8100  \tValid loss: 0.2274940460920334\n",
      "Step: 8200  \tTraining loss: 0.22243468463420868\n",
      "Step: 8200  \tTraining accuracy: 0.9047185182571411\n",
      "Step: 8200  \tValid loss: 0.22752492129802704\n",
      "Step: 8300  \tTraining loss: 0.2223539650440216\n",
      "Step: 8300  \tTraining accuracy: 0.9047427773475647\n",
      "Step: 8300  \tValid loss: 0.2275070697069168\n",
      "Step: 8400  \tTraining loss: 0.22227801382541656\n",
      "Step: 8400  \tTraining accuracy: 0.9047664999961853\n",
      "Step: 8400  \tValid loss: 0.22750969231128693\n",
      "Step: 8500  \tTraining loss: 0.22220492362976074\n",
      "Step: 8500  \tTraining accuracy: 0.9047911167144775\n",
      "Step: 8500  \tValid loss: 0.22750766575336456\n",
      "Step: 8600  \tTraining loss: 0.22213715314865112\n",
      "Step: 8600  \tTraining accuracy: 0.9048151969909668\n",
      "Step: 8600  \tValid loss: 0.22752565145492554\n",
      "Step: 8700  \tTraining loss: 0.2220727503299713\n",
      "Step: 8700  \tTraining accuracy: 0.9048372507095337\n",
      "Step: 8700  \tValid loss: 0.22744551301002502\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.90486443\n",
      "Precision: 0.86423445\n",
      "Recall: 0.9139785\n",
      "F1 score: 0.9301773\n",
      "AUC: 0.9106628\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.904864   0.864234  0.913979  0.930177  0.910663  0.222015      0.904835   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.227415       0.904823    0.25238      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  8797.0  \n",
      "36\n",
      "(1421, 4)\n",
      "(1421, 1)\n",
      "(784, 4)\n",
      "(784, 1)\n",
      "(637, 4)\n",
      "(637, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100  \tTraining loss: 0.4844754636287689\n",
      "Step: 100  \tTraining accuracy: 0.8332160711288452\n",
      "Step: 100  \tValid loss: 0.49331897497177124\n",
      "Step: 200  \tTraining loss: 0.46417003870010376\n",
      "Step: 200  \tTraining accuracy: 0.8400187492370605\n",
      "Step: 200  \tValid loss: 0.4756297767162323\n",
      "Step: 300  \tTraining loss: 0.44194263219833374\n",
      "Step: 300  \tTraining accuracy: 0.8413792848587036\n",
      "Step: 300  \tValid loss: 0.45135560631752014\n",
      "Step: 400  \tTraining loss: 0.3899306654930115\n",
      "Step: 400  \tTraining accuracy: 0.8419623970985413\n",
      "Step: 400  \tValid loss: 0.3952227234840393\n",
      "Step: 500  \tTraining loss: 0.3514060974121094\n",
      "Step: 500  \tTraining accuracy: 0.8425208926200867\n",
      "Step: 500  \tValid loss: 0.3526088297367096\n",
      "Step: 600  \tTraining loss: 0.3326571583747864\n",
      "Step: 600  \tTraining accuracy: 0.8447316288948059\n",
      "Step: 600  \tValid loss: 0.3306438624858856\n",
      "Step: 700  \tTraining loss: 0.32463181018829346\n",
      "Step: 700  \tTraining accuracy: 0.8472906351089478\n",
      "Step: 700  \tValid loss: 0.32033559679985046\n",
      "Step: 800  \tTraining loss: 0.32072633504867554\n",
      "Step: 800  \tTraining accuracy: 0.8492611050605774\n",
      "Step: 800  \tValid loss: 0.31481051445007324\n",
      "Step: 900  \tTraining loss: 0.31811824440956116\n",
      "Step: 900  \tTraining accuracy: 0.8510576486587524\n",
      "Step: 900  \tValid loss: 0.31098315119743347\n",
      "Step: 1000  \tTraining loss: 0.3162557780742645\n",
      "Step: 1000  \tTraining accuracy: 0.852587103843689\n",
      "Step: 1000  \tValid loss: 0.3080718219280243\n",
      "Step: 1100  \tTraining loss: 0.3149043917655945\n",
      "Step: 1100  \tTraining accuracy: 0.853959321975708\n",
      "Step: 1100  \tValid loss: 0.30593258142471313\n",
      "Step: 1200  \tTraining loss: 0.3139226734638214\n",
      "Step: 1200  \tTraining accuracy: 0.8549704551696777\n",
      "Step: 1200  \tValid loss: 0.30415454506874084\n",
      "Step: 1300  \tTraining loss: 0.3132278621196747\n",
      "Step: 1300  \tTraining accuracy: 0.855819821357727\n",
      "Step: 1300  \tValid loss: 0.30276018381118774\n",
      "Step: 1400  \tTraining loss: 0.31273549795150757\n",
      "Step: 1400  \tTraining accuracy: 0.8565173149108887\n",
      "Step: 1400  \tValid loss: 0.30167877674102783\n",
      "Step: 1500  \tTraining loss: 0.31236183643341064\n",
      "Step: 1500  \tTraining accuracy: 0.8571428656578064\n",
      "Step: 1500  \tValid loss: 0.3008030354976654\n",
      "Step: 1600  \tTraining loss: 0.3120696246623993\n",
      "Step: 1600  \tTraining accuracy: 0.8576422929763794\n",
      "Step: 1600  \tValid loss: 0.30012229084968567\n",
      "Step: 1700  \tTraining loss: 0.3118288815021515\n",
      "Step: 1700  \tTraining accuracy: 0.8581025004386902\n",
      "Step: 1700  \tValid loss: 0.2995353639125824\n",
      "Step: 1800  \tTraining loss: 0.3116254210472107\n",
      "Step: 1800  \tTraining accuracy: 0.8585503101348877\n",
      "Step: 1800  \tValid loss: 0.29900985956192017\n",
      "Step: 1900  \tTraining loss: 0.3114475607872009\n",
      "Step: 1900  \tTraining accuracy: 0.8589687347412109\n",
      "Step: 1900  \tValid loss: 0.29853957891464233\n",
      "Step: 2000  \tTraining loss: 0.31128883361816406\n",
      "Step: 2000  \tTraining accuracy: 0.8593262434005737\n",
      "Step: 2000  \tValid loss: 0.29813361167907715\n",
      "Step: 2100  \tTraining loss: 0.3111365735530853\n",
      "Step: 2100  \tTraining accuracy: 0.8596488237380981\n",
      "Step: 2100  \tValid loss: 0.29775553941726685\n",
      "Step: 2200  \tTraining loss: 0.3109855353832245\n",
      "Step: 2200  \tTraining accuracy: 0.8599741458892822\n",
      "Step: 2200  \tValid loss: 0.2973932921886444\n",
      "Step: 2300  \tTraining loss: 0.3108336925506592\n",
      "Step: 2300  \tTraining accuracy: 0.8603174686431885\n",
      "Step: 2300  \tValid loss: 0.2970462441444397\n",
      "Step: 2400  \tTraining loss: 0.3106825053691864\n",
      "Step: 2400  \tTraining accuracy: 0.8606465458869934\n",
      "Step: 2400  \tValid loss: 0.29669955372810364\n",
      "Step: 2500  \tTraining loss: 0.31053727865219116\n",
      "Step: 2500  \tTraining accuracy: 0.8609487414360046\n",
      "Step: 2500  \tValid loss: 0.29638439416885376\n",
      "Step: 2600  \tTraining loss: 0.3103986084461212\n",
      "Step: 2600  \tTraining accuracy: 0.86122727394104\n",
      "Step: 2600  \tValid loss: 0.2960565388202667\n",
      "Step: 2700  \tTraining loss: 0.31027016043663025\n",
      "Step: 2700  \tTraining accuracy: 0.8614847660064697\n",
      "Step: 2700  \tValid loss: 0.2957356572151184\n",
      "Step: 2800  \tTraining loss: 0.3101513981819153\n",
      "Step: 2800  \tTraining accuracy: 0.8617234826087952\n",
      "Step: 2800  \tValid loss: 0.2954327464103699\n",
      "Step: 2900  \tTraining loss: 0.31004366278648376\n",
      "Step: 2900  \tTraining accuracy: 0.861933171749115\n",
      "Step: 2900  \tValid loss: 0.2951662540435791\n",
      "Step: 3000  \tTraining loss: 0.3099435865879059\n",
      "Step: 3000  \tTraining accuracy: 0.8621524572372437\n",
      "Step: 3000  \tValid loss: 0.29491451382637024\n",
      "Step: 3100  \tTraining loss: 0.3098483085632324\n",
      "Step: 3100  \tTraining accuracy: 0.8623573780059814\n",
      "Step: 3100  \tValid loss: 0.29467684030532837\n",
      "Step: 3200  \tTraining loss: 0.30975598096847534\n",
      "Step: 3200  \tTraining accuracy: 0.8625493049621582\n",
      "Step: 3200  \tValid loss: 0.2944752871990204\n",
      "Step: 3300  \tTraining loss: 0.3096652328968048\n",
      "Step: 3300  \tTraining accuracy: 0.8627185821533203\n",
      "Step: 3300  \tValid loss: 0.2943001985549927\n",
      "Step: 3400  \tTraining loss: 0.30957305431365967\n",
      "Step: 3400  \tTraining accuracy: 0.862835705280304\n",
      "Step: 3400  \tValid loss: 0.29412248730659485\n",
      "Step: 3500  \tTraining loss: 0.30947765707969666\n",
      "Step: 3500  \tTraining accuracy: 0.8629257082939148\n",
      "Step: 3500  \tValid loss: 0.29397261142730713\n",
      "Step: 3600  \tTraining loss: 0.30937710404396057\n",
      "Step: 3600  \tTraining accuracy: 0.8630303740501404\n",
      "Step: 3600  \tValid loss: 0.2938227355480194\n",
      "Step: 3700  \tTraining loss: 0.30926913022994995\n",
      "Step: 3700  \tTraining accuracy: 0.8631390333175659\n",
      "Step: 3700  \tValid loss: 0.2936771810054779\n",
      "Step: 3800  \tTraining loss: 0.30915215611457825\n",
      "Step: 3800  \tTraining accuracy: 0.8632418513298035\n",
      "Step: 3800  \tValid loss: 0.293523907661438\n",
      "Step: 3900  \tTraining loss: 0.30902403593063354\n",
      "Step: 3900  \tTraining accuracy: 0.863339364528656\n",
      "Step: 3900  \tValid loss: 0.2933686375617981\n",
      "Step: 4000  \tTraining loss: 0.3088826537132263\n",
      "Step: 4000  \tTraining accuracy: 0.8634140491485596\n",
      "Step: 4000  \tValid loss: 0.293199747800827\n",
      "Step: 4100  \tTraining loss: 0.30872488021850586\n",
      "Step: 4100  \tTraining accuracy: 0.8634850978851318\n",
      "Step: 4100  \tValid loss: 0.29300782084465027\n",
      "Step: 4200  \tTraining loss: 0.3085482716560364\n",
      "Step: 4200  \tTraining accuracy: 0.86356121301651\n",
      "Step: 4200  \tValid loss: 0.29279419779777527\n",
      "Step: 4300  \tTraining loss: 0.3083525002002716\n",
      "Step: 4300  \tTraining accuracy: 0.8636420369148254\n",
      "Step: 4300  \tValid loss: 0.2925470173358917\n",
      "Step: 4400  \tTraining loss: 0.30814069509506226\n",
      "Step: 4400  \tTraining accuracy: 0.8637109994888306\n",
      "Step: 4400  \tValid loss: 0.2922671139240265\n",
      "Step: 4500  \tTraining loss: 0.3079192638397217\n",
      "Step: 4500  \tTraining accuracy: 0.8637610673904419\n",
      "Step: 4500  \tValid loss: 0.2919662892818451\n",
      "Step: 4600  \tTraining loss: 0.3076971769332886\n",
      "Step: 4600  \tTraining accuracy: 0.8638012409210205\n",
      "Step: 4600  \tValid loss: 0.2916796803474426\n",
      "Step: 4700  \tTraining loss: 0.30748018622398376\n",
      "Step: 4700  \tTraining accuracy: 0.8638547658920288\n",
      "Step: 4700  \tValid loss: 0.2914056181907654\n",
      "Step: 4800  \tTraining loss: 0.3072742223739624\n",
      "Step: 4800  \tTraining accuracy: 0.8638986349105835\n",
      "Step: 4800  \tValid loss: 0.2911655902862549\n",
      "Step: 4900  \tTraining loss: 0.30704185366630554\n",
      "Step: 4900  \tTraining accuracy: 0.8639407157897949\n",
      "Step: 4900  \tValid loss: 0.29098373651504517\n",
      "Step: 5000  \tTraining loss: 0.3068346083164215\n",
      "Step: 5000  \tTraining accuracy: 0.8639882206916809\n",
      "Step: 5000  \tValid loss: 0.29086145758628845\n",
      "Step: 5100  \tTraining loss: 0.3066405951976776\n",
      "Step: 5100  \tTraining accuracy: 0.8639711141586304\n",
      "Step: 5100  \tValid loss: 0.2907567024230957\n",
      "Step: 5200  \tTraining loss: 0.3064754009246826\n",
      "Step: 5200  \tTraining accuracy: 0.8639546632766724\n",
      "Step: 5200  \tValid loss: 0.2906869053840637\n",
      "Step: 5300  \tTraining loss: 0.3063167333602905\n",
      "Step: 5300  \tTraining accuracy: 0.863932192325592\n",
      "Step: 5300  \tValid loss: 0.29064276814460754\n",
      "Step: 5400  \tTraining loss: 0.30616292357444763\n",
      "Step: 5400  \tTraining accuracy: 0.8639236688613892\n",
      "Step: 5400  \tValid loss: 0.2906249165534973\n",
      "Step: 5500  \tTraining loss: 0.30601540207862854\n",
      "Step: 5500  \tTraining accuracy: 0.8639541864395142\n",
      "Step: 5500  \tValid loss: 0.29060691595077515\n",
      "Step: 5600  \tTraining loss: 0.3058723509311676\n",
      "Step: 5600  \tTraining accuracy: 0.8639202117919922\n",
      "Step: 5600  \tValid loss: 0.2906084954738617\n",
      "Step: 5700  \tTraining loss: 0.3057360053062439\n",
      "Step: 5700  \tTraining accuracy: 0.8638812303543091\n",
      "Step: 5700  \tValid loss: 0.29060909152030945\n",
      "Step: 5800  \tTraining loss: 0.3056049048900604\n",
      "Step: 5800  \tTraining accuracy: 0.8638558387756348\n",
      "Step: 5800  \tValid loss: 0.2906201481819153\n",
      "Step: 5900  \tTraining loss: 0.3054819405078888\n",
      "Step: 5900  \tTraining accuracy: 0.863825261592865\n",
      "Step: 5900  \tValid loss: 0.2906820774078369\n",
      "Step: 6000  \tTraining loss: 0.30536311864852905\n",
      "Step: 6000  \tTraining accuracy: 0.8637957572937012\n",
      "Step: 6000  \tValid loss: 0.2907198965549469\n",
      "Step: 6100  \tTraining loss: 0.3052464425563812\n",
      "Step: 6100  \tTraining accuracy: 0.8637672066688538\n",
      "Step: 6100  \tValid loss: 0.2907445728778839\n",
      "Step: 6200  \tTraining loss: 0.30513933300971985\n",
      "Step: 6200  \tTraining accuracy: 0.8637396097183228\n",
      "Step: 6200  \tValid loss: 0.29075902700424194\n",
      "Step: 6300  \tTraining loss: 0.30503761768341064\n",
      "Step: 6300  \tTraining accuracy: 0.8637185096740723\n",
      "Step: 6300  \tValid loss: 0.2907622158527374\n",
      "Step: 6400  \tTraining loss: 0.30493804812431335\n",
      "Step: 6400  \tTraining accuracy: 0.8637091517448425\n",
      "Step: 6400  \tValid loss: 0.2908022105693817\n",
      "Step: 6500  \tTraining loss: 0.3048418462276459\n",
      "Step: 6500  \tTraining accuracy: 0.8636946082115173\n",
      "Step: 6500  \tValid loss: 0.29084157943725586\n",
      "Step: 6600  \tTraining loss: 0.3047481179237366\n",
      "Step: 6600  \tTraining accuracy: 0.8636805415153503\n",
      "Step: 6600  \tValid loss: 0.290891170501709\n",
      "Early stopping!\n",
      "\n",
      "Evaluation  on training set\n",
      "Accuracy: 0.8636669\n",
      "Precision: 0.8887135\n",
      "Recall: 0.9510135\n",
      "F1 score: 0.8929139\n",
      "AUC: 0.67803836\n",
      "   accuracy  precision    recall  f1_score       auc      loss  accuracy_val  \\\n",
      "0  0.863667   0.888713  0.951014  0.892914  0.678038  0.304702      0.863695   \n",
      "\n",
      "   loss_val  accuracy_test  loss_test  neurons  learning_rate  n_epochs  \\\n",
      "0  0.290603       0.863728   0.258329      8.0          0.001   50000.0   \n",
      "\n",
      "    steps  \n",
      "0  6641.0  \n"
     ]
    }
   ],
   "source": [
    "neurons = 8\n",
    "hist_flag=2\n",
    "\n",
    "\n",
    "\n",
    "for num, subj_file_path in enumerate(subj_files_list):\n",
    "    print(num)\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "    \n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "                \n",
    "#     file_path = file_path + \"/OddEvenPlays\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "    train_data_df= pd.read_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df = pd.read_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df = pd.read_csv(file_path+\"/val_data.csv\")\n",
    "\n",
    "    train_X, train_y, test_X, test_y,val_X,val_y = data_split_odd_even(train_data_df,test_data_df,val_data_df)\n",
    "\n",
    "    pretraining = False; \n",
    "    metric_out_df, prob_train, prob_test, prob_val = train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y)\n",
    "    \n",
    "    print(metric_out_df)\n",
    "    \n",
    "   \n",
    " \n",
    "    prob_train_df = pd.DataFrame(prob_train.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "    prob_test_df = pd.DataFrame(prob_test.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "    prob_val_df = pd.DataFrame(prob_val.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "\n",
    "    if hist_flag==0:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currO_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "    \n",
    "    \n",
    "    elif hist_flag==1:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevC_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "        \n",
    "        \n",
    "    elif hist_flag==2:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevR_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currOprevR_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currOprevR_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currOprevR_neurons=\"+str(neurons)+\".csv\")\n",
    "\n",
    "    elif hist_flag==3:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevRC_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "# ################################\n",
    "    elif hist_flag==4:\n",
    "        metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currprev_opts_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "        prob_train_df.to_csv(file_path + \"/prob_train_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_test_df.to_csv(file_path + \"/prob_test_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "        prob_val_df.to_csv(file_path + \"/prob_val_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "# #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
