{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/example_RKN\"\n",
    "# file_name = file_path + \"/subj_num_39.csv\"\n",
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subj_num_39\"\n",
    "# file_name = file_path + \"/experiment_data.csv\"\n",
    "\n",
    "file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_39/\"\n",
    "file_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_39/experiment_data.csv\"\n",
    "file_dopa_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/dopadata/subject_num_39/dopa_experiment_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>8.193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>2.349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>3.545</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.518</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.926</td>\n",
       "      <td>0.130208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.812</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           2.0 -30.0       0.0      -126.0         2.0     1.0   \n",
       "2         2           2.0  15.0      75.0         0.0         2.0     1.0   \n",
       "3         3           2.0 -35.0       0.0       -70.0         2.0     1.0   \n",
       "4         4           2.0   0.0      20.0       -30.0         2.0     1.0   \n",
       "5         5           2.0  25.0      56.0         0.0         1.0     0.0   \n",
       "6         6           2.0   0.0      45.0       -18.0         2.0     1.0   \n",
       "7         7           2.0  35.0      59.0         0.0         2.0     1.0   \n",
       "8         8           2.0 -20.0       0.0       -40.0         2.0     1.0   \n",
       "9         9           2.0  30.0      50.0         0.0         1.0     0.0   \n",
       "\n",
       "   Outcome      RT  Happiness  \n",
       "0      NaN     NaN   0.498698  \n",
       "1   -126.0   8.193        NaN  \n",
       "2      0.0  28.038        NaN  \n",
       "3    -70.0   2.349   0.000000  \n",
       "4    -30.0   3.545        NaN  \n",
       "5     25.0   7.518        NaN  \n",
       "6     45.0   7.135        NaN  \n",
       "7      0.0   6.926   0.130208  \n",
       "8      0.0   2.812        NaN  \n",
       "9     30.0   2.372        NaN  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df = pd.read_csv(file_name)\n",
    "task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>11.455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.190</td>\n",
       "      <td>0.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.557</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.614</td>\n",
       "      <td>0.321615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>2.599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           2.0  15.0      27.0         0.0         2.0     1.0   \n",
       "2         2           2.0 -35.0       0.0      -147.0         1.0     0.0   \n",
       "3         3           2.0   0.0      80.0       -96.0         1.0     0.0   \n",
       "4         4           2.0 -25.0       0.0       -56.0         2.0     1.0   \n",
       "5         5           2.0  35.0      78.0         0.0         1.0     0.0   \n",
       "6         6           2.0   0.0      80.0       -80.0         1.0     0.0   \n",
       "7         7           2.0 -35.0       0.0       -78.0         2.0     1.0   \n",
       "8         8           2.0  25.0     125.0         0.0         2.0     1.0   \n",
       "9         9           2.0   0.0      20.0        -4.0         2.0     1.0   \n",
       "\n",
       "   Outcome      RT  Happiness  \n",
       "0      NaN     NaN   0.656250  \n",
       "1     27.0   4.455        NaN  \n",
       "2    -35.0  11.455        NaN  \n",
       "3      0.0   3.190   0.617188  \n",
       "4      0.0   1.937        NaN  \n",
       "5     35.0   4.557        NaN  \n",
       "6      0.0   2.614   0.321615  \n",
       "7    -78.0   2.599        NaN  \n",
       "8    125.0   1.351        NaN  \n",
       "9     20.0   1.390        NaN  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dopa_task_df = pd.read_csv(file_dopa_name)\n",
    "dopa_task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subj_data_df = pd.DataFrame()\n",
    "# all_subj_dopa_data_df = pd.DataFrame()\n",
    "\n",
    "# for subj_num in range(11,27):\n",
    "# #     print(subj_num)\n",
    "#     file_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_\" + str(subj_num) + \"/experiment_data.csv\"\n",
    "#     all_subj_data_df = all_subj_data_df.append(pd.read_csv(file_name))\n",
    "#     file_dopa_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/dopadata/subject_num_\" + str(subj_num) + \"/dopa_experiment_data.csv\"\n",
    "#     all_subj_dopa_data_df = all_subj_dopa_data_df.append(pd.read_csv(file_dopa_name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_df  = all_subj_data_df\n",
    "# dopa_task_df = all_subj_dopa_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "#     task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "#     task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "#     task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "#     task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "#     task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "#     task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "#     task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "#     task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "#     task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "#     task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "#     return task_df\n",
    "\n",
    "# task_df = add_releveant_features (task_df)\n",
    "# dopa_task_df = add_releveant_features(dopa_task_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 300\n",
    "inputs = 20\n",
    "outputs = 1 ## note the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binned_EV_diff_task = pd.cut(task_df.loc[task_df.TrialNum!=0,['Safe']].values.reshape(task_df.loc[task_df.TrialNum!=0,['Safe']].shape[0]) - np.mean(task_df.loc[task_df.TrialNum!=0,['BigRisky','SmallRisky']],1),bins = inputs,labels=False)\n",
    "\n",
    "# Binned_EV_diff_task.shape\n",
    "Binned_EV_diff_task = Binned_EV_diff_task.values.reshape(task_df.loc[task_df.TrialNum!=0,['Safe']].shape[0],-1)\n",
    "\n",
    "Binned_EV_diff_dopa_task = pd.cut(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe']].values.reshape(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe']].shape[0]) - np.mean(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['BigRisky','SmallRisky']],1),bins = inputs,labels=False)\n",
    "\n",
    "Binned_EV_diff_dopa_task = Binned_EV_diff_dopa_task.values.reshape(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe']].shape[0],-1)\n",
    "\n",
    "# Binned_EV_diff_dopa_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot_encoder=OneHotEncoder(sparse=False)\n",
    "\n",
    "# train_X = Binned_EV_diff_task\n",
    "# train_X = onehot_encoder.fit_transform(train_X)\n",
    "\n",
    "\n",
    "# test_X = Binned_EV_diff_dopa_task\n",
    "# test_X = onehot_encoder.fit_transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(Binned_EV_diff_task,train_y)\n",
    "# plt.xlabel('Binned_EV_diff')\n",
    "# plt.ylabel('Choice');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 20)\n",
      "(300,)\n",
      "(300, 20)\n",
      "(300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32).reshape(300)\n",
    "\n",
    "\n",
    "# ## TEST\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "test_y = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Choice']].values.astype(np.int32).reshape(300)\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "\n",
    "# extra_features = 5;\n",
    "\n",
    "train_X = Binned_EV_diff_task\n",
    "train_X = onehot_encoder.fit_transform(train_X)\n",
    "\n",
    "\n",
    "test_X = Binned_EV_diff_dopa_task\n",
    "test_X = onehot_encoder.fit_transform(test_X)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = train_X\n",
    "y_valid = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 20)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_layers= 5\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_neurons=n_neurons, n_layers=n_layers, name = None, activation = tf.nn.elu, initializer = he_init):\n",
    "    \n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        for layer in range(n_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation = activation,\n",
    "                                             kernel_initializer=initializer)\n",
    "#                                              , name=\"hidden%d\" % (layer + 1))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"DNN/tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)\n",
    "\n",
    "logdir = log_dir(\"mnist_dnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define FNN's architecture\n",
    "# n_inputs = 28*28 \n",
    "n_hidden1 = 500\n",
    "# n_hidden2 = 500\n",
    "# n_hidden3 = 500\n",
    "\n",
    "# n_outputs = 10\n",
    "\n",
    "\n",
    "## Placeholder nodes for input data and targets\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32,shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X,n_hidden1, name = \"hidden1\",activation=tf.nn.relu)\n",
    "#     hidden2 = tf.layers.dense(hidden1,n_hidden2, name = \"hidden2\",activation=tf.nn.relu)\n",
    "#     hidden3 = tf.layers.dense(hidden2,n_hidden3, name = \"hidden3\",activation=tf.nn.relu)\n",
    "\n",
    "    logits =  tf.layers.dense(hidden1,2, name = \"outputs\") # output before going through softmax\n",
    "    y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "    # Define loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)# error\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\") # mean cross entropy across the instances in the batch\n",
    "    loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "\n",
    "    # Optimizer and training_op\n",
    "learning_rate=0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    \n",
    "    # Evaluate the model \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    \n",
    "# initialize variables and saver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "loss_summary = tf.summary.scalar('xentropy',loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20)\n",
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X)) # random permutation of the indices\n",
    "    n_batches = len(X) // batch_size # number of batches\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of epochs and batch_size\n",
    "n_epochs = 1001\n",
    "batch_size = 300\n",
    "n_batches = np.ceil(m/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_deep_mnist_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = np.infty\n",
    "epochs_without_progress = 0\n",
    "max_epochs_without_progress = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 68.333% \tLoss: 0.60685\n",
      "Epoch: 5 \tValidation accuracy: 73.667% \tLoss: 0.52722\n",
      "Epoch: 10 \tValidation accuracy: 73.667% \tLoss: 0.50766\n",
      "Epoch: 15 \tValidation accuracy: 75.000% \tLoss: 0.49990\n",
      "Epoch: 20 \tValidation accuracy: 75.000% \tLoss: 0.49651\n",
      "Epoch: 25 \tValidation accuracy: 75.000% \tLoss: 0.49447\n",
      "Epoch: 30 \tValidation accuracy: 75.000% \tLoss: 0.49453\n",
      "Epoch: 35 \tValidation accuracy: 75.000% \tLoss: 0.49400\n",
      "Epoch: 40 \tValidation accuracy: 75.000% \tLoss: 0.49386\n",
      "Epoch: 45 \tValidation accuracy: 75.000% \tLoss: 0.49367\n",
      "Epoch: 50 \tValidation accuracy: 75.000% \tLoss: 0.49363\n",
      "Epoch: 55 \tValidation accuracy: 75.000% \tLoss: 0.49359\n",
      "Epoch: 60 \tValidation accuracy: 75.000% \tLoss: 0.49357\n",
      "Epoch: 65 \tValidation accuracy: 75.000% \tLoss: 0.49355\n",
      "Epoch: 70 \tValidation accuracy: 75.000% \tLoss: 0.49354\n",
      "Epoch: 75 \tValidation accuracy: 75.000% \tLoss: 0.49354\n",
      "Epoch: 80 \tValidation accuracy: 75.000% \tLoss: 0.49353\n",
      "Epoch: 85 \tValidation accuracy: 75.000% \tLoss: 0.49352\n",
      "Epoch: 90 \tValidation accuracy: 75.000% \tLoss: 0.49352\n",
      "Epoch: 95 \tValidation accuracy: 75.000% \tLoss: 0.49352\n",
      "Epoch: 100 \tValidation accuracy: 75.000% \tLoss: 0.49352\n",
      "Epoch: 105 \tValidation accuracy: 75.000% \tLoss: 0.49351\n",
      "Epoch: 110 \tValidation accuracy: 75.000% \tLoss: 0.49351\n",
      "Epoch: 115 \tValidation accuracy: 75.000% \tLoss: 0.49351\n",
      "Epoch: 120 \tValidation accuracy: 75.000% \tLoss: 0.49351\n",
      "Epoch: 125 \tValidation accuracy: 75.000% \tLoss: 0.49351\n",
      "Epoch: 130 \tValidation accuracy: 75.000% \tLoss: 0.49351\n",
      "Epoch: 135 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 140 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 145 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 150 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 155 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 160 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 165 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 170 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 175 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 180 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 185 \tValidation accuracy: 75.000% \tLoss: 0.49350\n",
      "Epoch: 190 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 195 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 200 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 205 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 210 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 215 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 220 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 225 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 230 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 235 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 240 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 245 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 250 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 255 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 260 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 265 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 270 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 275 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 280 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 285 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 290 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 295 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 300 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 305 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 310 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 315 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 320 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 325 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 330 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 335 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 340 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 345 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 350 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 355 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 360 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 365 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 370 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 375 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 380 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 385 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 390 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 395 \tValidation accuracy: 75.000% \tLoss: 0.49349\n",
      "Epoch: 400 \tValidation accuracy: 75.000% \tLoss: 0.49348\n",
      "Epoch: 405 \tValidation accuracy: 75.000% \tLoss: 0.49348\n",
      "Epoch: 410 \tValidation accuracy: 75.000% \tLoss: 0.49348\n",
      "Epoch: 415 \tValidation accuracy: 75.000% \tLoss: 0.49348\n",
      "Epoch: 420 \tValidation accuracy: 75.000% \tLoss: 0.49348\n",
      "Epoch: 425 \tValidation accuracy: 75.000% \tLoss: 0.49348\n",
      "Early stopping\n",
      "Test accuracy: 0.7300000190734863\n",
      "Test loss: 0.514650285243988\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "#     if os.path.isfile(checkpoint_epoch_path):\n",
    "#         # if the checkpoint file exists, restore the model and load the epoch number\n",
    "#         with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "#             start_epoch = int(f.read())\n",
    "#         print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "#         saver.restore(sess, checkpoint_path)\n",
    "#     else:\n",
    "        start_epoch=0\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            for X_batch, y_batch in shuffle_batch(train_X, train_y, batch_size):\n",
    "                sess.run(training_op,feed_dict= {X:X_batch, y:y_batch})\n",
    "\n",
    "            accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
    "\n",
    "            file_writer.add_summary(accuracy_summary_str, epoch)\n",
    "            file_writer.add_summary(loss_summary_str, epoch)\n",
    "\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                print(\"Epoch:\", epoch,\n",
    "                      \"\\tValidation accuracy: {:.3f}%\".format(accuracy_val * 100),\n",
    "                      \"\\tLoss: {:.5f}\".format(loss_val))\n",
    "                saver.save(sess, checkpoint_path)\n",
    "                with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                    f.write(b\"%d\" % (epoch + 1)) # write contents to file\n",
    "                if loss_val < best_loss:\n",
    "                    saver.save(sess, final_model_path) # if loss is decreasing\n",
    "                    best_loss = loss_val\n",
    "                else:\n",
    "                    epochs_without_progress += 5 ## if loss is not decreasing for 5 epochs stop training\n",
    "                    if epochs_without_progress > max_epochs_without_progress:\n",
    "                        print(\"Early stopping\")\n",
    "                        break\n",
    "#             acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "#             acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "#             print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "        acc_test = accuracy.eval(feed_dict={X: test_X, y: test_y})\n",
    "        print('Test accuracy: {}'.format(acc_test))\n",
    "            \n",
    "        loss_test = loss.eval(feed_dict={X: test_X, y: test_y})\n",
    "        print('Test loss: {}'.format(loss_test))\n",
    "        \n",
    "        probchoice_train = y_proba.eval(feed_dict={X: test_X, y: test_y})\n",
    "        \n",
    "        probchoice_test = y_proba.eval(feed_dict={X: test_X, y: test_y})\n",
    "                     \n",
    "#     save_path = saver.save(sess,\"./my_model_final.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4997376e-01, 5.5002624e-01],\n",
       "       [8.3333319e-01, 1.6666679e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [9.1070642e-06, 9.9999094e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [9.9993002e-01, 6.9970585e-05],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [1.8747093e-01, 8.1252909e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [9.9992764e-01, 7.2354589e-05],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [8.3333319e-01, 1.6666679e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [9.9992764e-01, 7.2354589e-05],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [5.3298891e-06, 9.9999464e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [9.9993002e-01, 6.9970585e-05],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [8.3333319e-01, 1.6666678e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [7.4998897e-01, 2.5001103e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [7.4998897e-01, 2.5001103e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [9.9993002e-01, 6.9970585e-05],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [9.1070642e-06, 9.9999094e-01],\n",
       "       [9.9993002e-01, 6.9970585e-05],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [8.3333319e-01, 1.6666679e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [9.1070642e-06, 9.9999094e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [8.3333319e-01, 1.6666679e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [5.3298891e-06, 9.9999464e-01],\n",
       "       [1.1733082e-05, 9.9998832e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1733082e-05, 9.9998832e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [8.3333319e-01, 1.6666679e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [5.3298891e-06, 9.9999464e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.3328987e-05, 9.9997663e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [9.9993002e-01, 6.9970585e-05],\n",
       "       [9.9994385e-01, 5.6196222e-05],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [9.1070642e-06, 9.9999094e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [9.9994385e-01, 5.6196222e-05],\n",
       "       [1.4114970e-05, 9.9998593e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [7.4998897e-01, 2.5001103e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.9993131e-01, 5.0006866e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [2.4321596e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.7499169e-01, 6.2500834e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [5.3298891e-06, 9.9999464e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [9.9993002e-01, 6.9970585e-05],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [1.4114970e-05, 9.9998593e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [4.4997376e-01, 5.5002624e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.8747094e-01, 8.1252909e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [7.4998897e-01, 2.5001103e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [3.1240547e-01, 6.8759453e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1169428e-05, 9.9998879e-01],\n",
       "       [2.4990456e-01, 7.5009543e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [6.4281756e-01, 3.5718241e-01],\n",
       "       [2.4321592e-01, 7.5678408e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01],\n",
       "       [1.1536069e-01, 8.8463926e-01]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probchoice_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
