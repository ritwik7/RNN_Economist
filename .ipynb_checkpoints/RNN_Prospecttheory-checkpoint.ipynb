{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Prospect Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/example_RKN\"\n",
    "# file_name = file_path + \"/subj_num_39.csv\"\n",
    "# file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subj_num_39\"\n",
    "# file_name = file_path + \"/experiment_data.csv\"\n",
    "\n",
    "file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_15/\"\n",
    "file_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_15/experiment_data.csv\"\n",
    "file_dopa_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/dopadata/subject_num_15/dopa_experiment_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PT_result.mat',\n",
       " 'LSTM_metrics_all_subjs.csv',\n",
       " 'loglikelihoods_all',\n",
       " 'loglikelihoods_all_all_features',\n",
       " 'LSTM_metrics_10neurons.csv',\n",
       " 'LSTM_metrics.csv',\n",
       " 'experiment_data.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>1.346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1.504</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>1.431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.824</td>\n",
       "      <td>0.627604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           1.0 -35.0       0.0      -175.0         2.0     0.0   \n",
       "2         2           1.0 -15.0       0.0       -37.0         2.0     0.0   \n",
       "3         3           1.0 -15.0       0.0       -27.0         1.0     1.0   \n",
       "4         4           1.0  15.0      42.0         0.0         1.0     1.0   \n",
       "5         5           1.0 -25.0       0.0       -56.0         2.0     0.0   \n",
       "6         6           1.0   0.0      65.0       -65.0         1.0     1.0   \n",
       "7         7           1.0   0.0      30.0       -45.0         2.0     0.0   \n",
       "8         8           1.0 -25.0       0.0       -56.0         2.0     0.0   \n",
       "9         9           1.0   0.0      80.0       -66.0         1.0     1.0   \n",
       "\n",
       "   Outcome     RT  Happiness  \n",
       "0      NaN    NaN   0.683594  \n",
       "1    -35.0  1.346        NaN  \n",
       "2    -15.0  1.848        NaN  \n",
       "3    -27.0  1.504        NaN  \n",
       "4      0.0  1.477   0.648438  \n",
       "5    -25.0  1.719        NaN  \n",
       "6    -65.0  1.431        NaN  \n",
       "7      0.0  1.549        NaN  \n",
       "8    -25.0  1.824   0.627604  \n",
       "9     80.0  1.295        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df = pd.read_csv(file_name)\n",
    "task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.552083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.798</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>1.623</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.872</td>\n",
       "      <td>0.549479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.725</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           2.0  15.0      54.0         0.0         2.0     1.0   \n",
       "2         2           2.0   0.0      30.0       -20.0         2.0     1.0   \n",
       "3         3           2.0 -15.0       0.0       -75.0         1.0     0.0   \n",
       "4         4           2.0 -35.0       0.0      -175.0         1.0     0.0   \n",
       "5         5           2.0  20.0      36.0         0.0         1.0     0.0   \n",
       "6         6           2.0 -35.0       0.0      -126.0         1.0     0.0   \n",
       "7         7           2.0  35.0     111.0         0.0         2.0     1.0   \n",
       "8         8           2.0  30.0      84.0         0.0         2.0     1.0   \n",
       "9         9           2.0  30.0     150.0         0.0         2.0     1.0   \n",
       "\n",
       "   Outcome     RT  Happiness  \n",
       "0      NaN    NaN   0.578125  \n",
       "1      0.0  1.418        NaN  \n",
       "2     30.0  1.327        NaN  \n",
       "3    -15.0  1.845        NaN  \n",
       "4    -35.0  1.033   0.552083  \n",
       "5     20.0  1.798        NaN  \n",
       "6    -35.0  1.623        NaN  \n",
       "7      0.0  1.872   0.549479  \n",
       "8      0.0  1.725        NaN  \n",
       "9    150.0  0.999        NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dopa_task_df = pd.read_csv(file_dopa_name)\n",
    "dopa_task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for running a batch of all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subj_data_df = pd.DataFrame()\n",
    "all_subj_dopa_data_df = pd.DataFrame()\n",
    "\n",
    "for subj_num in range(11,13):\n",
    "#     print(subj_num)\n",
    "    file_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_\" + str(subj_num) + \"/experiment_data.csv\"\n",
    "    all_subj_data_df = all_subj_data_df.append(pd.read_csv(file_name))\n",
    "    file_dopa_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/dopadata/subject_num_\" + str(subj_num) + \"/dopa_experiment_data.csv\"\n",
    "    all_subj_dopa_data_df = all_subj_dopa_data_df.append(pd.read_csv(file_dopa_name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subj_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subj_data_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_subj_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-69a53bd093bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtask_df\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mall_subj_data_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdopa_task_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_subj_dopa_data_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_subj_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "task_df  = all_subj_data_df\n",
    "dopa_task_df = all_subj_dopa_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "    task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "    task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "    task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "    task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "    task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "    task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "    task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "    task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "    return task_df\n",
    "\n",
    "task_df = add_releveant_features (task_df)\n",
    "dopa_task_df = add_releveant_features(dopa_task_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dopa_task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>1.346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1.504</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>1.431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.824</td>\n",
       "      <td>0.627604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.110</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>2.383</td>\n",
       "      <td>0.619792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>2.747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>1.248</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.345</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.664</td>\n",
       "      <td>0.639323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.473</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1.672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.553385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646</td>\n",
       "      <td>0.575521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.806</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.511719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.352</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.380208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.288</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>1.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.197</td>\n",
       "      <td>0.415365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>276</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1.288</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>1.070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.436198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>280</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.579427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>1.278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.582</td>\n",
       "      <td>0.584635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.245</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.502604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272</td>\n",
       "      <td>0.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.068</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.296</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.102</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.008</td>\n",
       "      <td>0.410156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0           0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1           1           1.0 -35.0       0.0      -175.0         2.0     0.0   \n",
       "2           2           1.0 -15.0       0.0       -37.0         2.0     0.0   \n",
       "3           3           1.0 -15.0       0.0       -27.0         1.0     1.0   \n",
       "4           4           1.0  15.0      42.0         0.0         1.0     1.0   \n",
       "5           5           1.0 -25.0       0.0       -56.0         2.0     0.0   \n",
       "6           6           1.0   0.0      65.0       -65.0         1.0     1.0   \n",
       "7           7           1.0   0.0      30.0       -45.0         2.0     0.0   \n",
       "8           8           1.0 -25.0       0.0       -56.0         2.0     0.0   \n",
       "9           9           1.0   0.0      80.0       -66.0         1.0     1.0   \n",
       "10         10           1.0  30.0      74.0         0.0         1.0     1.0   \n",
       "11         11           2.0 -15.0       0.0       -42.0         1.0     0.0   \n",
       "12         12           2.0 -30.0       0.0       -55.0         2.0     1.0   \n",
       "13         13           2.0 -20.0       0.0       -56.0         1.0     0.0   \n",
       "14         14           2.0   0.0      45.0       -30.0         2.0     1.0   \n",
       "15         15           2.0  25.0      62.0         0.0         2.0     1.0   \n",
       "16         16           2.0  30.0      95.0         0.0         2.0     1.0   \n",
       "17         17           2.0  20.0      56.0         0.0         2.0     1.0   \n",
       "18         18           2.0  25.0      46.0         0.0         1.0     0.0   \n",
       "19         19           2.0   0.0      20.0       -16.0         2.0     1.0   \n",
       "20         20           2.0 -15.0       0.0       -75.0         1.0     0.0   \n",
       "21         21           1.0   0.0      65.0       -26.0         1.0     1.0   \n",
       "22         22           1.0   0.0      80.0       -32.0         1.0     1.0   \n",
       "23         23           1.0  35.0     126.0         0.0         1.0     1.0   \n",
       "24         24           1.0   0.0      80.0      -160.0         2.0     0.0   \n",
       "25         25           1.0   0.0      20.0       -24.0         2.0     0.0   \n",
       "26         26           1.0   0.0      30.0       -25.0         1.0     1.0   \n",
       "27         27           1.0   0.0      80.0       -53.0         1.0     1.0   \n",
       "28         28           1.0 -25.0       0.0      -105.0         2.0     0.0   \n",
       "29         29           1.0  15.0      42.0         0.0         1.0     1.0   \n",
       "..        ...           ...   ...       ...         ...         ...     ...   \n",
       "271       271           2.0   0.0      45.0       -14.0         2.0     1.0   \n",
       "272       272           2.0  35.0      70.0         0.0         2.0     1.0   \n",
       "273       273           2.0 -25.0       0.0       -42.0         2.0     1.0   \n",
       "274       274           2.0  25.0      70.0         0.0         2.0     1.0   \n",
       "275       275           2.0   0.0      45.0       -68.0         1.0     0.0   \n",
       "276       276           2.0   0.0      20.0       -13.0         2.0     1.0   \n",
       "277       277           2.0 -30.0       0.0       -95.0         1.0     0.0   \n",
       "278       278           2.0   0.0      80.0      -160.0         1.0     0.0   \n",
       "279       279           2.0  30.0     108.0         0.0         2.0     1.0   \n",
       "280       280           2.0   0.0      30.0        -6.0         2.0     1.0   \n",
       "281       281           1.0   0.0      45.0       -90.0         2.0     0.0   \n",
       "282       282           1.0  35.0     175.0         0.0         1.0     1.0   \n",
       "283       283           1.0   0.0      80.0       -24.0         1.0     1.0   \n",
       "284       284           1.0   0.0      45.0       -45.0         1.0     1.0   \n",
       "285       285           1.0  15.0      30.0         0.0         2.0     0.0   \n",
       "286       286           1.0 -35.0       0.0       -64.0         1.0     1.0   \n",
       "287       287           1.0 -20.0       0.0       -50.0         2.0     0.0   \n",
       "288       288           1.0 -35.0       0.0       -98.0         2.0     0.0   \n",
       "289       289           1.0  35.0      98.0         0.0         1.0     1.0   \n",
       "290       290           1.0 -35.0       0.0      -111.0         2.0     0.0   \n",
       "291       291           2.0 -15.0       0.0       -42.0         1.0     0.0   \n",
       "292       292           2.0   0.0      30.0       -45.0         1.0     0.0   \n",
       "293       293           2.0   0.0      45.0       -90.0         1.0     0.0   \n",
       "294       294           2.0  20.0      34.0         0.0         1.0     0.0   \n",
       "295       295           2.0  15.0      33.0         0.0         2.0     1.0   \n",
       "296       296           2.0  20.0      36.0         0.0         1.0     0.0   \n",
       "297       297           2.0  35.0      98.0         0.0         2.0     1.0   \n",
       "298       298           2.0 -20.0       0.0       -56.0         1.0     0.0   \n",
       "299       299           2.0 -20.0       0.0       -63.0         1.0     0.0   \n",
       "300       300           2.0 -20.0       0.0       -84.0         1.0     0.0   \n",
       "\n",
       "     Outcome     RT  Happiness  \n",
       "0        NaN    NaN   0.683594  \n",
       "1      -35.0  1.346        NaN  \n",
       "2      -15.0  1.848        NaN  \n",
       "3      -27.0  1.504        NaN  \n",
       "4        0.0  1.477   0.648438  \n",
       "5      -25.0  1.719        NaN  \n",
       "6      -65.0  1.431        NaN  \n",
       "7        0.0  1.549        NaN  \n",
       "8      -25.0  1.824   0.627604  \n",
       "9       80.0  1.295        NaN  \n",
       "10       0.0  1.110        NaN  \n",
       "11     -15.0  2.383   0.619792  \n",
       "12     -55.0  2.747        NaN  \n",
       "13     -20.0  1.398        NaN  \n",
       "14     -30.0  1.248   0.531250  \n",
       "15      62.0  1.345        NaN  \n",
       "16      95.0  1.037        NaN  \n",
       "17      56.0  1.664   0.639323  \n",
       "18      25.0  3.473        NaN  \n",
       "19     -16.0  1.672        NaN  \n",
       "20     -15.0  1.094        NaN  \n",
       "21     -26.0  0.920   0.553385  \n",
       "22      80.0  0.989        NaN  \n",
       "23       0.0  1.037        NaN  \n",
       "24       0.0  1.646   0.575521  \n",
       "25       0.0  1.366        NaN  \n",
       "26     -25.0  0.806        NaN  \n",
       "27     -53.0  0.958   0.511719  \n",
       "28     -25.0  1.135        NaN  \n",
       "29       0.0  1.352        NaN  \n",
       "..       ...    ...        ...  \n",
       "271    -14.0  0.896   0.380208  \n",
       "272     70.0  5.288        NaN  \n",
       "273    -42.0  1.998        NaN  \n",
       "274      0.0  1.197   0.415365  \n",
       "275      0.0  1.386        NaN  \n",
       "276    -13.0  1.288        NaN  \n",
       "277    -30.0  1.070        NaN  \n",
       "278      0.0  1.184   0.436198  \n",
       "279    108.0  1.147        NaN  \n",
       "280     -6.0  0.917        NaN  \n",
       "281      0.0  1.318        NaN  \n",
       "282    175.0  1.032   0.579427  \n",
       "283     80.0  0.865        NaN  \n",
       "284    -45.0  1.278        NaN  \n",
       "285     15.0  2.582   0.584635  \n",
       "286      0.0  2.440        NaN  \n",
       "287    -20.0  1.245        NaN  \n",
       "288    -35.0  0.920        NaN  \n",
       "289      0.0  1.031   0.502604  \n",
       "290    -35.0  0.992        NaN  \n",
       "291    -15.0  1.295        NaN  \n",
       "292      0.0  1.272   0.479167  \n",
       "293      0.0  1.068        NaN  \n",
       "294     20.0  1.296        NaN  \n",
       "295     33.0  1.015        NaN  \n",
       "296     20.0  1.102   0.520833  \n",
       "297      0.0  0.917        NaN  \n",
       "298    -20.0  0.998        NaN  \n",
       "299    -20.0  1.024        NaN  \n",
       "300    -20.0  1.008   0.410156  \n",
       "\n",
       "[301 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define task parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 300\n",
    "inputs = 3\n",
    "outputs = 2\n",
    "\n",
    "# adjust target(t) to depend on input (t-1)\n",
    "# df.Property = df.Property.shift(-1)\n",
    "\n",
    "\n",
    "# # # remove nans as a result of the shifted values\n",
    "# df = df.iloc[:-1,:]\n",
    "# df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(0,task_df.shape[0],301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_df.loc[task_df.TrialNum!=0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dopa_task_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_X, trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialNum</th>\n",
       "      <th>SideOfScreen</th>\n",
       "      <th>Safe</th>\n",
       "      <th>BigRisky</th>\n",
       "      <th>SmallRisky</th>\n",
       "      <th>SideChosen</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>RT</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>1.346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>1.504</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>1.431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.549</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.824</td>\n",
       "      <td>0.627604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialNum  SideOfScreen  Safe  BigRisky  SmallRisky  SideChosen  Choice  \\\n",
       "0         0           NaN   NaN       NaN         NaN         NaN     NaN   \n",
       "1         1           1.0 -35.0       0.0      -175.0         2.0     0.0   \n",
       "2         2           1.0 -15.0       0.0       -37.0         2.0     0.0   \n",
       "3         3           1.0 -15.0       0.0       -27.0         1.0     1.0   \n",
       "4         4           1.0  15.0      42.0         0.0         1.0     1.0   \n",
       "5         5           1.0 -25.0       0.0       -56.0         2.0     0.0   \n",
       "6         6           1.0   0.0      65.0       -65.0         1.0     1.0   \n",
       "7         7           1.0   0.0      30.0       -45.0         2.0     0.0   \n",
       "8         8           1.0 -25.0       0.0       -56.0         2.0     0.0   \n",
       "9         9           1.0   0.0      80.0       -66.0         1.0     1.0   \n",
       "\n",
       "   Outcome     RT  Happiness  \n",
       "0      NaN    NaN   0.683594  \n",
       "1    -35.0  1.346        NaN  \n",
       "2    -15.0  1.848        NaN  \n",
       "3    -27.0  1.504        NaN  \n",
       "4      0.0  1.477   0.648438  \n",
       "5    -25.0  1.719        NaN  \n",
       "6    -65.0  1.431        NaN  \n",
       "7      0.0  1.549        NaN  \n",
       "8    -25.0  1.824   0.627604  \n",
       "9     80.0  1.295        NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(task_df[['BigRisky','SmallRisky']],1).shape\n",
    "# np.mean(task_df.loc[task_df.TrialNum!=0,['BigRisky','SmallRisky']],1)\n",
    "# mp.mean(task_df[['BigRisky','SmallRisky']],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(task_df.loc[task_df.TrialNum!=0,['BigRisky','SmallRisky']],1)\n",
    "# task_df.loc[task_df.TrialNum!=0,['Safe']].values.reshape(task_df.loc[task_df.TrialNum!=0,['Safe']].shape[0]).shape\n",
    "                                 \n",
    "\n",
    "# task_df.loc[task_df.TrialNum!=0,['Safe']].values.reshape(task_df.loc[task_df.TrialNum!=0,['Safe']].shape[0]) - np.mean(task_df.loc[task_df.TrialNum!=0,['BigRisky','SmallRisky']],1)\n",
    "\n",
    "# inputs \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binned_EV_diff_task = pd.cut(task_df.loc[task_df.TrialNum!=0,['Safe']].values.reshape(task_df.loc[task_df.TrialNum!=0,['Safe']].shape[0]) - np.mean(task_df.loc[task_df.TrialNum!=0,['BigRisky','SmallRisky']],1),bins = inputs,labels=False)\n",
    "\n",
    "# Binned_EV_diff_task.shape\n",
    "Binned_EV_diff_task = Binned_EV_diff_task.values.reshape(task_df.loc[task_df.TrialNum!=0,['Safe']].shape[0],-1)\n",
    "\n",
    "Binned_EV_diff_dopa_task = pd.cut(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe']].values.reshape(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe']].shape[0]) - np.mean(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['BigRisky','SmallRisky']],1),bins = inputs,labels=False)\n",
    "\n",
    "Binned_EV_diff_dopa_task = Binned_EV_diff_dopa_task.values.reshape(dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe']].shape[0],-1)\n",
    "\n",
    "# Binned_EV_diff_dopa_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Binned_EV_diff_task,train_y)\n",
    "plt.xlabel('Binned_EV_diff')\n",
    "plt.ylabel('Choice');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder=OneHotEncoder(sparse=False)\n",
    "\n",
    "train_X = Binned_EV_diff_task\n",
    "train_X = onehot_encoder.fit_transform(train_X)\n",
    "\n",
    "\n",
    "test_X = Binned_EV_diff_dopa_task\n",
    "test_X = onehot_encoder.fit_transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = {'x_1': train_X[:,0],'x_2': train_X[:,1],'x_3': train_X[:,2], 'y':train_y[:,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.DataFrame(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for n in range(0,10):\n",
    "# s = train_df.sample(frac=1).reset_index(drop=True)\n",
    "# train_df = pd.concat([train_df, s]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.reshape(-1,300,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# include_ind = np.setdiff1d(np.arange(task_df.shape[0]),np.arange(0,task_df.shape[0],301))\n",
    "# include_ind = np.arange(1,task_df.shape[0])\n",
    "# X_y_split\n",
    "## TRAIN\n",
    "# train_X = task_df.loc[include_ind,['Safe','BigRisky','SmallRisky']].values\n",
    "# train_y = task_df.loc[include_ind,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "train_y = task_df.loc[task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "# ## TEST\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky']].values\n",
    "test_y = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Choice']].values.astype(np.int32)\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "\n",
    "# train_X = task_df.loc[task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "# test_X = dopa_task_df.loc[dopa_task_df.TrialNum!=0,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "\n",
    "# extra_features = 5;\n",
    "\n",
    "train_X = Binned_EV_diff_task\n",
    "train_X = onehot_encoder.fit_transform(train_X)\n",
    "\n",
    "\n",
    "test_X = Binned_EV_diff_dopa_task\n",
    "test_X = onehot_encoder.fit_transform(test_X)\n",
    "\n",
    "print(train_X.shape)\n",
    "\n",
    "# # center and scale\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "# train_X = scaler.fit_transform(train_X)\n",
    "# test_X = scaler.fit_transform(test_X)\n",
    "\n",
    "# train_X[0,-extra_features + 1:]= 0;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_X = np.array(train_X).reshape(-1,time_steps,inputs)\n",
    "# test_X = np.array(test_X).reshape(-1,time_steps,inputs)\n",
    "\n",
    "\n",
    "#  # reshape input to 3D array\n",
    "# encode_categorical = train_X.reshape(len(train_X), 1)\n",
    "# encode_categorical_test = test_X.reshape(len(test_X), 1)\n",
    "# train_X = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "# test_X= onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_X = train_X[None,:,:]\n",
    "test_X = test_X[None,:,:]\n",
    "\n",
    "\n",
    "# # one-hot encode the outputs\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "encode_categorical_test = test_y.reshape(len(test_y), 1)\n",
    "\n",
    "train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "test_y = onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "\n",
    "# train_y =  train_y.reshape(-1,time_steps,outputs)\n",
    "# test_y =  test_y.reshape(-1,time_steps,outputs)\n",
    "\n",
    "\n",
    "\n",
    "train_y = train_y[None,:,:]\n",
    "test_y = test_y[None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_X)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 3)\n",
      "(1, 300, 2)\n",
      "(1, 300, 3)\n",
      "(1, 300, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(?, 300, 3)\n",
      "(?, 300, 2)\n",
      "(?, 300, 2)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00005\n",
    "epochs = 1000\n",
    "batch_size = int(train_X.shape[0])\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "\n",
    "print(batch_size)\n",
    "\n",
    "\n",
    "num_batches = 100\n",
    "\n",
    "length = train_X.shape[0]\n",
    "display = 10 ## display loss function every display trials\n",
    "neurons = 100 ## number of neurons in LSTM cell\n",
    "save_step = 100\n",
    "\n",
    "\n",
    "best_loss_val = np.infty\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "\n",
    "# # clear graph (if any) before running\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, time_steps, inputs])\n",
    "y = tf.placeholder(tf.float32, [None, time_steps, outputs])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# LSTM Cell\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=neurons, activation=tf.nn.relu)\n",
    "cell_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "# # pass into Dense layer\n",
    "stacked_outputs = tf.reshape(cell_outputs, [-1, time_steps,neurons])\n",
    "out = tf.layers.dense(inputs=stacked_outputs, units=outputs,kernel_initializer=he_init) ## logits layer kernel_initializer=he_init\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "probability = tf.nn.softmax(out)\n",
    "\n",
    "\n",
    "# squared error loss or cost function for linear regression\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=y, logits=out))\n",
    "\n",
    "\n",
    "\n",
    "# # optimizer to minimize cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.argmax(y,2))\n",
    "# print(tf.arg_max(out,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.metrics.accuracy(labels =  tf.argmax(y, 2),\n",
    "                          predictions = tf.argmax(out, 2),\n",
    "                          name = \"accuracy\")\n",
    "# print(accuracy) -- this is a tuple\n",
    "acc_up,acc_val = accuracy\n",
    "\n",
    "precision = tf.metrics.precision(labels=tf.argmax(y, 2),\n",
    "                                 predictions=tf.argmax(out, 2),\n",
    "                                 name=\"precision\")\n",
    "prec_up,prec_val = precision\n",
    "\n",
    "\n",
    "recall = tf.metrics.recall(labels=tf.argmax(y, 2),\n",
    "                           predictions=tf.argmax(out, 2),\n",
    "                           name=\"recall\")\n",
    "\n",
    "auc = tf.metrics.auc(labels=tf.argmax(y, 2),\n",
    "                           predictions=tf.argmax(out, 2),\n",
    "                           name=\"auc\")\n",
    "f1 = 2 * accuracy[1] * recall[1] / ( precision[1] + recall[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 10  \tTraining loss: 0.6676582098007202\n",
      "Step: 10  \tTraining accuracy: 0.5899999737739563\n",
      "Step: 10  \tTest accuracy: 0.5899999737739563\n",
      "Step: 10  \tTest loss: 0.6675723791122437\n",
      "Step: 10  \tTrain_Likelihood: -200.23786979913712\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 20  \tTraining loss: 0.664567232131958\n",
      "Step: 20  \tTraining accuracy: 0.5899999737739563\n",
      "Step: 20  \tTest accuracy: 0.5899999737739563\n",
      "Step: 20  \tTest loss: 0.6659116744995117\n",
      "Step: 20  \tTrain_Likelihood: -199.31089687347412\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 30  \tTraining loss: 0.6629459261894226\n",
      "Step: 30  \tTraining accuracy: 0.5899999737739563\n",
      "Step: 30  \tTest accuracy: 0.5899999737739563\n",
      "Step: 30  \tTest loss: 0.6636416912078857\n",
      "Step: 30  \tTrain_Likelihood: -198.82458537817\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 40  \tTraining loss: 0.6599171161651611\n",
      "Step: 40  \tTraining accuracy: 0.5919047594070435\n",
      "Step: 40  \tTest accuracy: 0.5916666388511658\n",
      "Step: 40  \tTest loss: 0.6620497703552246\n",
      "Step: 40  \tTrain_Likelihood: -197.91614750027657\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 50  \tTraining loss: 0.6569161415100098\n",
      "Step: 50  \tTraining accuracy: 0.5918518304824829\n",
      "Step: 50  \tTest accuracy: 0.5920000076293945\n",
      "Step: 50  \tTest loss: 0.660004198551178\n",
      "Step: 50  \tTrain_Likelihood: -197.0159993469715\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 60  \tTraining loss: 0.6497601270675659\n",
      "Step: 60  \tTraining accuracy: 0.5951515436172485\n",
      "Step: 60  \tTest accuracy: 0.5958333611488342\n",
      "Step: 60  \tTest loss: 0.6558958888053894\n",
      "Step: 60  \tTrain_Likelihood: -194.86953806877136\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 70  \tTraining loss: 0.6507381200790405\n",
      "Step: 70  \tTraining accuracy: 0.5969230532646179\n",
      "Step: 70  \tTest accuracy: 0.5985714197158813\n",
      "Step: 70  \tTest loss: 0.6532999277114868\n",
      "Step: 70  \tTrain_Likelihood: -195.16290900111198\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 80  \tTraining loss: 0.6498076915740967\n",
      "Step: 80  \tTraining accuracy: 0.5993333458900452\n",
      "Step: 80  \tTest accuracy: 0.6002083420753479\n",
      "Step: 80  \tTest loss: 0.6543798446655273\n",
      "Step: 80  \tTrain_Likelihood: -194.88379511237144\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 90  \tTraining loss: 0.6453031301498413\n",
      "Step: 90  \tTraining accuracy: 0.6013725399971008\n",
      "Step: 90  \tTest accuracy: 0.602222204208374\n",
      "Step: 90  \tTest loss: 0.652669370174408\n",
      "Step: 90  \tTrain_Likelihood: -193.53274658322334\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 100  \tTraining loss: 0.6345782279968262\n",
      "Step: 100  \tTraining accuracy: 0.6038596630096436\n",
      "Step: 100  \tTest accuracy: 0.6048333048820496\n",
      "Step: 100  \tTest loss: 0.6489464044570923\n",
      "Step: 100  \tTrain_Likelihood: -190.31579142808914\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 110  \tTraining loss: 0.6426184177398682\n",
      "Step: 110  \tTraining accuracy: 0.605555534362793\n",
      "Step: 110  \tTest accuracy: 0.6066666841506958\n",
      "Step: 110  \tTest loss: 0.6471063494682312\n",
      "Step: 110  \tTrain_Likelihood: -192.72729271650314\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 120  \tTraining loss: 0.6407371759414673\n",
      "Step: 120  \tTraining accuracy: 0.6092753410339355\n",
      "Step: 120  \tTest accuracy: 0.6105555295944214\n",
      "Step: 120  \tTest loss: 0.6442723274230957\n",
      "Step: 120  \tTrain_Likelihood: -192.16295844316483\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 130  \tTraining loss: 0.645101010799408\n",
      "Step: 130  \tTraining accuracy: 0.6111999750137329\n",
      "Step: 130  \tTest accuracy: 0.611923098564148\n",
      "Step: 130  \tTest loss: 0.6461461186408997\n",
      "Step: 130  \tTrain_Likelihood: -193.47200945019722\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 140  \tTraining loss: 0.6384324431419373\n",
      "Step: 140  \tTraining accuracy: 0.6133333444595337\n",
      "Step: 140  \tTest accuracy: 0.6141666769981384\n",
      "Step: 140  \tTest loss: 0.6443740725517273\n",
      "Step: 140  \tTrain_Likelihood: -191.47179850935936\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 150  \tTraining loss: 0.6217358708381653\n",
      "Step: 150  \tTraining accuracy: 0.6160919666290283\n",
      "Step: 150  \tTest accuracy: 0.6169999837875366\n",
      "Step: 150  \tTest loss: 0.638218104839325\n",
      "Step: 150  \tTrain_Likelihood: -186.46379327774048\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 160  \tTraining loss: 0.6180635094642639\n",
      "Step: 160  \tTraining accuracy: 0.6191397905349731\n",
      "Step: 160  \tTest accuracy: 0.6198958158493042\n",
      "Step: 160  \tTest loss: 0.6380811333656311\n",
      "Step: 160  \tTrain_Likelihood: -185.36220574378967\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 170  \tTraining loss: nan\n",
      "Step: 170  \tTraining accuracy: 0.6135353446006775\n",
      "Step: 170  \tTest accuracy: 0.6077451109886169\n",
      "Step: 170  \tTest loss: nan\n",
      "Step: 170  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 180  \tTraining loss: nan\n",
      "Step: 180  \tTraining accuracy: 0.6020952463150024\n",
      "Step: 180  \tTest accuracy: 0.5969444513320923\n",
      "Step: 180  \tTest loss: nan\n",
      "Step: 180  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 190  \tTraining loss: nan\n",
      "Step: 190  \tTraining accuracy: 0.591891884803772\n",
      "Step: 190  \tTest accuracy: 0.5872806906700134\n",
      "Step: 190  \tTest loss: nan\n",
      "Step: 190  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 200  \tTraining loss: nan\n",
      "Step: 200  \tTraining accuracy: 0.5827350616455078\n",
      "Step: 200  \tTest accuracy: 0.5785833597183228\n",
      "Step: 200  \tTest loss: nan\n",
      "Step: 200  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 210  \tTraining loss: nan\n",
      "Step: 210  \tTraining accuracy: 0.5744715332984924\n",
      "Step: 210  \tTest accuracy: 0.5707142949104309\n",
      "Step: 210  \tTest loss: nan\n",
      "Step: 210  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 220  \tTraining loss: nan\n",
      "Step: 220  \tTraining accuracy: 0.5669767260551453\n",
      "Step: 220  \tTest accuracy: 0.5635606050491333\n",
      "Step: 220  \tTest loss: nan\n",
      "Step: 220  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "Step: 230  \tTraining loss: nan\n",
      "Step: 230  \tTraining accuracy: 0.5601481199264526\n",
      "Step: 230  \tTest accuracy: 0.5570290088653564\n",
      "Step: 230  \tTest loss: nan\n",
      "Step: 230  \tTrain_Likelihood: nan\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n",
      "0 out_of_ 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-ad06b1c11f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 sess.run(training_op, feed_dict = {X: train_X,\n\u001b[0;32m---> 30\u001b[0;31m                                                    y: train_y})\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmini_batch_num\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     saver.restore(sess, \"./checkpts/RNN_LST_model_subject_num_11_final.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    # Train the model\n",
    "    for steps in range(epochs):\n",
    "        mini_batch = zip(range(0, length, batch_size),\n",
    "                   range(batch_size, length+1, batch_size))\n",
    "\n",
    "        ## ----- BATCHES of random permuted samples from X and y are use to train the network ------\n",
    "\n",
    "        for mini_batch_num in range(0,num_batches):\n",
    "            \n",
    "#             print(mini_batch_num)\n",
    "        # train data in mini-batches\n",
    "#             for (start, end) in mini_batch:\n",
    "\n",
    "                rnd_idx = np.random.permutation((train_X).shape[1])\n",
    "#                 print(rnd_idx)\n",
    "        \n",
    "                train_X, train_y =train_X[:,rnd_idx,:], train_y[:,rnd_idx,:]\n",
    "            \n",
    "#                 print(train_X[0,0,:])\n",
    "\n",
    "                sess.run(training_op, feed_dict = {X: train_X,\n",
    "                                                   y: train_y})\n",
    "\n",
    "                if mini_batch_num % 100 ==0:\n",
    "                    print(str(mini_batch_num),'out_of_',str(num_batches))\n",
    "            \n",
    "            # print(train_y[start:end,:])\n",
    "#               sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "#                                                y: train_y[start:end,:,:]})\n",
    "\n",
    "        ## ------------------------------------------------------------------\n",
    "\n",
    "        # print training performance \n",
    "        if (steps+1) % display == 0:\n",
    "            # evaluate loss function on training set\n",
    "            loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "            print('Step: {}  \\tTraining loss: {}'.format((steps+1), loss_fn))\n",
    "            \n",
    "            acc_train = acc_val.eval(feed_dict={X: train_X, y: train_y})\n",
    "            print('Step: {}  \\tTraining accuracy: {}'.format((steps+1), acc_train))\n",
    "            \n",
    "            \n",
    "            acc_test = acc_val.eval(feed_dict={X: test_X, y: test_y})\n",
    "            print('Step: {}  \\tTest accuracy: {}'.format((steps+1), acc_test))\n",
    "            \n",
    "            loss_test = loss.eval(feed_dict={X: test_X, y: test_y})\n",
    "            print('Step: {}  \\tTest loss: {}'.format((steps+1), loss_test))\n",
    "            \n",
    "            \n",
    "            probchoice = probability.eval(feed_dict = {X: train_X, y: train_y})\n",
    "#             prob_test = probability.eval(feed_dict = {X: test_X, y: test_y})\n",
    "            \n",
    "            ll = np.dot(train_y[0,:,0],np.log(probchoice[0,:,0]+0.0001)) + np.dot(train_y[0,:,1],np.log(probchoice[0,:,1]+0.0001))\n",
    "            print('Step: {}  \\tTrain_Likelihood: {}'.format((steps+1), ll))            \n",
    "\n",
    "            \n",
    "            \n",
    "#             prec_test = prec_val.eval(feed_dict={X: train_X, y: train_y})\n",
    "#             print('Step: {}  \\tTraining Precision: {}'.format((steps+1), prec_test))\n",
    "\n",
    "            if loss_fn < best_loss_val:\n",
    "                    best_loss_val = loss_fn\n",
    "                    checks_since_last_progress = 0\n",
    "            else:\n",
    "                    checks_since_last_progress += 1\n",
    "        \n",
    "        \n",
    "        ## EARLY STOPPING\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "            \n",
    "        if (steps+1) % save_step ==0:\n",
    "            save_path = saver.save(sess, \"./checkpts/RNN_LST_model_EV5eatures.ckpt\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    # evaluate model accuracy\n",
    "    acc, prec, recall, f1,auc = sess.run([accuracy, precision, recall, f1,auc],\n",
    "                                     feed_dict = {X: train_X, y: train_y})\n",
    "    probchoice = probability.eval(feed_dict = {X: train_X, y: train_y})\n",
    "    prob_test = probability.eval(feed_dict = {X: test_X, y: test_y})\n",
    "\n",
    "    print('\\nEvaluation  on training set')\n",
    "    print('Accuracy:', acc[1])\n",
    "    print('Precision:', prec[1])\n",
    "    print('Recall:', recall[1])\n",
    "    print('F1 score:', f1)\n",
    "    print('AUC:', auc[1])\n",
    "    \n",
    "#     print(\"probability\",probchoice)\n",
    "    \n",
    "    save_path = saver.save(sess, \"./checkpts/RNN_LST_model_EV5eatures.ckpt\")\n",
    "\n",
    "    \n",
    "\n",
    "metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,auc[1],loss_fn,acc_test,loss_test,neurons,learning_rate,epochs]).reshape(-1,11),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\",\"loss\",\"accuracy_test\",\"loss_test\",\"neurons\",\"learning_rate\",\"n_epochs\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6868843547503154"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-ll/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(probchoice[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 2)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probchoice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-199.94980651140213\n"
     ]
    }
   ],
   "source": [
    "## for a specific subject\n",
    "ll = np.dot(train_y[0,:,0],np.log(probchoice[0,:,0]+0.0001)) + np.dot(train_y[0,:,1],np.log(probchoice[0,:,1]+0.0001))\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03844468573097459"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ll/(np.log(0.5)*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probchoice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-2ebac7618291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prob' is not defined"
     ]
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-68d15ebcb35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloglike_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloglike_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubj_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloglike_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobchoice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobchoice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloglike_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "loglike_train=[]; loglike_test =[];\n",
    "for subj_num in range(11,27):\n",
    "    loglike_train.append(np.dot(train_y[subj_num-11,:,0],np.log(probchoice[subj_num-11,:,0]+0.0001)) + np.dot(train_y[subj_num-11,:,1],np.log(probchoice[subj_num-11,:,1]+0.0001)) )\n",
    "    loglike_test.append(np.dot(test_y[subj_num-11,:,0],np.log(prob_test[subj_num-11,:,0]+0.0001)) + np.dot(test_y[subj_num-11,:,1],np.log(prob_test[subj_num-11,:,1]+0.0001)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-205.91729319095612]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglike_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-206.15156835317612]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglike_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_df = pd.DataFrame(np.array([loglike_train,loglike_test]).T,columns = ['loglike_train','loglike_test'])\n",
    "loglike_df.to_csv(file_path+\"loglikelihoods_all_all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll- loglike_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= probchoice.reshape(-1,2)\n",
    "# plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4929397 , 0.5070602 ],\n",
       "        [0.48746133, 0.5125387 ],\n",
       "        [0.48164418, 0.51835585],\n",
       "        [0.47595498, 0.524045  ],\n",
       "        [0.47064322, 0.5293568 ],\n",
       "        [0.46571314, 0.53428686],\n",
       "        [0.46112385, 0.5388762 ],\n",
       "        [0.4567324 , 0.5432676 ],\n",
       "        [0.43078476, 0.56921524],\n",
       "        [0.41136676, 0.5886332 ],\n",
       "        [0.41878548, 0.5812145 ],\n",
       "        [0.4247638 , 0.5752362 ],\n",
       "        [0.42815208, 0.5718479 ],\n",
       "        [0.42970338, 0.5702966 ],\n",
       "        [0.45360482, 0.5463951 ],\n",
       "        [0.44397387, 0.55602616],\n",
       "        [0.4634141 , 0.5365859 ],\n",
       "        [0.44986176, 0.5501382 ],\n",
       "        [0.44252172, 0.55747825],\n",
       "        [0.46163863, 0.5383613 ],\n",
       "        [0.44736418, 0.55263585],\n",
       "        [0.4172428 , 0.5827572 ],\n",
       "        [0.41709957, 0.58290046],\n",
       "        [0.4186676 , 0.5813324 ],\n",
       "        [0.39658356, 0.60341644],\n",
       "        [0.4281546 , 0.5718454 ],\n",
       "        [0.4017575 , 0.59824246],\n",
       "        [0.4064832 , 0.5935168 ],\n",
       "        [0.4118341 , 0.5881659 ],\n",
       "        [0.44132566, 0.55867434],\n",
       "        [0.43276104, 0.567239  ],\n",
       "        [0.42952138, 0.5704786 ],\n",
       "        [0.42681852, 0.5731815 ],\n",
       "        [0.42445132, 0.57554865],\n",
       "        [0.4481862 , 0.55181384],\n",
       "        [0.46245682, 0.53754324],\n",
       "        [0.423945  , 0.57605505],\n",
       "        [0.42074826, 0.57925165],\n",
       "        [0.42055368, 0.5794464 ],\n",
       "        [0.4201108 , 0.57988924],\n",
       "        [0.41942835, 0.58057165],\n",
       "        [0.41858092, 0.5814191 ],\n",
       "        [0.39382017, 0.60617983],\n",
       "        [0.39866906, 0.601331  ],\n",
       "        [0.40390545, 0.5960946 ],\n",
       "        [0.40734115, 0.59265894],\n",
       "        [0.38544324, 0.61455667],\n",
       "        [0.3924234 , 0.6075766 ],\n",
       "        [0.39918184, 0.60081816],\n",
       "        [0.37985107, 0.6201489 ],\n",
       "        [0.36569023, 0.6343097 ],\n",
       "        [0.37875956, 0.62124044],\n",
       "        [0.3901665 , 0.60983354],\n",
       "        [0.3979299 , 0.6020701 ],\n",
       "        [0.4296847 , 0.57031536],\n",
       "        [0.42223504, 0.577765  ],\n",
       "        [0.41982758, 0.5801725 ],\n",
       "        [0.41782942, 0.5821706 ],\n",
       "        [0.41605666, 0.58394337],\n",
       "        [0.41443542, 0.5855646 ],\n",
       "        [0.41292167, 0.58707833],\n",
       "        [0.3868813 , 0.6131187 ],\n",
       "        [0.39170924, 0.60829073],\n",
       "        [0.3970411 , 0.60295886],\n",
       "        [0.40060765, 0.5993923 ],\n",
       "        [0.3784079 , 0.6215921 ],\n",
       "        [0.38559216, 0.61440784],\n",
       "        [0.39266664, 0.6073334 ],\n",
       "        [0.4245311 , 0.5754689 ],\n",
       "        [0.41682482, 0.5831751 ],\n",
       "        [0.41450617, 0.58549386],\n",
       "        [0.41269305, 0.5873069 ],\n",
       "        [0.41116062, 0.58883935],\n",
       "        [0.40980497, 0.590195  ],\n",
       "        [0.4085672 , 0.59143275],\n",
       "        [0.4340055 , 0.56599444],\n",
       "        [0.4223119 , 0.5776881 ],\n",
       "        [0.39285704, 0.607143  ],\n",
       "        [0.4226906 , 0.57730937],\n",
       "        [0.41513786, 0.5848621 ],\n",
       "        [0.41342947, 0.5865705 ],\n",
       "        [0.4398376 , 0.56016237],\n",
       "        [0.42747086, 0.57252914],\n",
       "        [0.42217305, 0.577827  ],\n",
       "        [0.41829938, 0.5817007 ],\n",
       "        [0.3913589 , 0.6086411 ],\n",
       "        [0.39476135, 0.6052387 ],\n",
       "        [0.39936414, 0.60063577],\n",
       "        [0.4024861 , 0.5975139 ],\n",
       "        [0.4044655 , 0.5955345 ],\n",
       "        [0.40560478, 0.5943952 ],\n",
       "        [0.40613553, 0.59386444],\n",
       "        [0.40623683, 0.5937632 ],\n",
       "        [0.40603426, 0.59396577],\n",
       "        [0.40561032, 0.5943896 ],\n",
       "        [0.43134117, 0.5686588 ],\n",
       "        [0.42016998, 0.57983   ],\n",
       "        [0.41538736, 0.58461267],\n",
       "        [0.41191143, 0.5880886 ],\n",
       "        [0.40928072, 0.5907193 ],\n",
       "        [0.4072374 , 0.5927626 ],\n",
       "        [0.40560305, 0.59439695],\n",
       "        [0.40425578, 0.5957442 ],\n",
       "        [0.37831727, 0.62168264],\n",
       "        [0.4106279 , 0.5893721 ],\n",
       "        [0.40525964, 0.59474033],\n",
       "        [0.38139895, 0.61860096],\n",
       "        [0.36411184, 0.63588816],\n",
       "        [0.40260154, 0.59739846],\n",
       "        [0.40155822, 0.5984418 ],\n",
       "        [0.40451846, 0.5954815 ],\n",
       "        [0.40645453, 0.5935455 ],\n",
       "        [0.40760818, 0.5923918 ],\n",
       "        [0.40818727, 0.59181273],\n",
       "        [0.43532553, 0.56467444],\n",
       "        [0.4243395 , 0.57566047],\n",
       "        [0.41976634, 0.5802337 ],\n",
       "        [0.41636738, 0.58363265],\n",
       "        [0.41372222, 0.5862778 ],\n",
       "        [0.38719797, 0.612802  ],\n",
       "        [0.39143437, 0.6085656 ],\n",
       "        [0.37275073, 0.6272493 ],\n",
       "        [0.38175112, 0.6182488 ],\n",
       "        [0.3670561 , 0.63294387],\n",
       "        [0.35613585, 0.6438641 ],\n",
       "        [0.37090498, 0.629095  ],\n",
       "        [0.3838578 , 0.6161423 ],\n",
       "        [0.39282358, 0.6071764 ],\n",
       "        [0.42585745, 0.5741425 ],\n",
       "        [0.39553174, 0.6044682 ],\n",
       "        [0.39897648, 0.60102355],\n",
       "        [0.3807442 , 0.6192557 ],\n",
       "        [0.38898677, 0.61101323],\n",
       "        [0.424046  , 0.575954  ],\n",
       "        [0.4460944 , 0.5539056 ],\n",
       "        [0.46155193, 0.53844804],\n",
       "        [0.44509912, 0.5549008 ],\n",
       "        [0.43698552, 0.5630145 ],\n",
       "        [0.45785075, 0.5421493 ],\n",
       "        [0.44222757, 0.55777246],\n",
       "        [0.43446243, 0.5655376 ],\n",
       "        [0.42865798, 0.571342  ],\n",
       "        [0.42420307, 0.5757969 ],\n",
       "        [0.42072648, 0.5792735 ],\n",
       "        [0.3939935 , 0.60600644],\n",
       "        [0.39768946, 0.60231054],\n",
       "        [0.40228352, 0.5977164 ],\n",
       "        [0.4053357 , 0.5946643 ],\n",
       "        [0.40721062, 0.59278935],\n",
       "        [0.4082254 , 0.5917746 ],\n",
       "        [0.40862867, 0.5913713 ],\n",
       "        [0.40859804, 0.591402  ],\n",
       "        [0.40825504, 0.59174496],\n",
       "        [0.40770087, 0.5922991 ],\n",
       "        [0.4331407 , 0.56685936],\n",
       "        [0.4219635 , 0.5780365 ],\n",
       "        [0.44425473, 0.55574536],\n",
       "        [0.42977685, 0.57022315],\n",
       "        [0.4504844 , 0.5495156 ],\n",
       "        [0.43432385, 0.5656762 ],\n",
       "        [0.42639577, 0.5736042 ],\n",
       "        [0.42071933, 0.57928073],\n",
       "        [0.41652554, 0.58347446],\n",
       "        [0.41337532, 0.5866246 ],\n",
       "        [0.41096246, 0.5890375 ],\n",
       "        [0.40907195, 0.59092796],\n",
       "        [0.40754864, 0.5924514 ],\n",
       "        [0.43272343, 0.5672766 ],\n",
       "        [0.42099497, 0.57900506],\n",
       "        [0.44330657, 0.5566935 ],\n",
       "        [0.4286371 , 0.571363  ],\n",
       "        [0.39788342, 0.60211664],\n",
       "        [0.39861363, 0.6013863 ],\n",
       "        [0.40150085, 0.5984992 ],\n",
       "        [0.40348324, 0.5965168 ],\n",
       "        [0.40471774, 0.59528226],\n",
       "        [0.40538582, 0.5946142 ],\n",
       "        [0.40564007, 0.59435993],\n",
       "        [0.40558615, 0.5944138 ],\n",
       "        [0.40531448, 0.59468555],\n",
       "        [0.40488267, 0.5951174 ],\n",
       "        [0.40433085, 0.59566915],\n",
       "        [0.40369517, 0.59630483],\n",
       "        [0.40300745, 0.5969925 ],\n",
       "        [0.4022907 , 0.59770924],\n",
       "        [0.4015613 , 0.59843874],\n",
       "        [0.40083092, 0.5991691 ],\n",
       "        [0.40010816, 0.59989184],\n",
       "        [0.399399  , 0.60060096],\n",
       "        [0.3736333 , 0.62636673],\n",
       "        [0.37908217, 0.6209178 ],\n",
       "        [0.3851432 , 0.6148568 ],\n",
       "        [0.38939083, 0.61060923],\n",
       "        [0.39224777, 0.6077522 ],\n",
       "        [0.36930913, 0.6306909 ],\n",
       "        [0.37619933, 0.62380064],\n",
       "        [0.3833972 , 0.6166028 ],\n",
       "        [0.3884655 , 0.61153454],\n",
       "        [0.39189395, 0.608106  ],\n",
       "        [0.3941254 , 0.6058746 ],\n",
       "        [0.39550027, 0.60449964],\n",
       "        [0.3962657 , 0.6037344 ],\n",
       "        [0.3965875 , 0.6034125 ],\n",
       "        [0.39660582, 0.6033942 ],\n",
       "        [0.39642116, 0.60357887],\n",
       "        [0.3961001 , 0.6038999 ],\n",
       "        [0.39569417, 0.6043058 ],\n",
       "        [0.3700319 , 0.62996805],\n",
       "        [0.37564152, 0.6243585 ],\n",
       "        [0.38190857, 0.6180915 ],\n",
       "        [0.3618847 , 0.6381153 ],\n",
       "        [0.37039363, 0.62960637],\n",
       "        [0.37887162, 0.6211284 ],\n",
       "        [0.38491818, 0.6150818 ],\n",
       "        [0.3890753 , 0.61092466],\n",
       "        [0.391842  , 0.60815793],\n",
       "        [0.39361352, 0.6063865 ],\n",
       "        [0.42173257, 0.5782674 ],\n",
       "        [0.4112986 , 0.58870137],\n",
       "        [0.40737706, 0.592623  ],\n",
       "        [0.37993658, 0.62006336],\n",
       "        [0.41172212, 0.5882779 ],\n",
       "        [0.40518954, 0.59481055],\n",
       "        [0.40446338, 0.59553665],\n",
       "        [0.40396526, 0.5960347 ],\n",
       "        [0.4034954 , 0.59650457],\n",
       "        [0.40301782, 0.5969822 ],\n",
       "        [0.40251327, 0.5974867 ],\n",
       "        [0.40199336, 0.5980066 ],\n",
       "        [0.4284035 , 0.57159656],\n",
       "        [0.41695726, 0.5830427 ],\n",
       "        [0.4122792 , 0.5877209 ],\n",
       "        [0.4364041 , 0.56359583],\n",
       "        [0.45112073, 0.54887927],\n",
       "        [0.43349126, 0.56650877],\n",
       "        [0.4248806 , 0.5751194 ],\n",
       "        [0.41881126, 0.58118874],\n",
       "        [0.4144057 , 0.58559424],\n",
       "        [0.38692516, 0.6130748 ],\n",
       "        [0.39022937, 0.60977066],\n",
       "        [0.3949051 , 0.60509485],\n",
       "        [0.37434104, 0.6256589 ],\n",
       "        [0.38204768, 0.6179523 ],\n",
       "        [0.36650908, 0.6334909 ],\n",
       "        [0.37711513, 0.6228848 ],\n",
       "        [0.38696522, 0.6130348 ],\n",
       "        [0.3702771 , 0.6297229 ],\n",
       "        [0.38020194, 0.61979806],\n",
       "        [0.38942647, 0.61057353],\n",
       "        [0.39571804, 0.60428196],\n",
       "        [0.37581915, 0.62418085],\n",
       "        [0.38409036, 0.61590964],\n",
       "        [0.39195707, 0.60804296],\n",
       "        [0.3972798 , 0.6027202 ],\n",
       "        [0.40070957, 0.5992905 ],\n",
       "        [0.40277675, 0.5972233 ],\n",
       "        [0.40388387, 0.5961161 ],\n",
       "        [0.43083918, 0.5691608 ],\n",
       "        [0.42025548, 0.5797445 ],\n",
       "        [0.41580886, 0.5841912 ],\n",
       "        [0.38787198, 0.6121281 ],\n",
       "        [0.39133006, 0.60866994],\n",
       "        [0.39593154, 0.60406846],\n",
       "        [0.3990454 , 0.6009546 ],\n",
       "        [0.37661216, 0.6233878 ],\n",
       "        [0.38355005, 0.6164499 ],\n",
       "        [0.39060372, 0.6093963 ],\n",
       "        [0.37145743, 0.62854254],\n",
       "        [0.38025466, 0.6197454 ],\n",
       "        [0.38864306, 0.611357  ],\n",
       "        [0.3944168 , 0.60558325],\n",
       "        [0.3982412 , 0.6017588 ],\n",
       "        [0.4006433 , 0.5993568 ],\n",
       "        [0.40203473, 0.59796524],\n",
       "        [0.4027163 , 0.59728366],\n",
       "        [0.37802732, 0.6219727 ],\n",
       "        [0.3839463 , 0.61605376],\n",
       "        [0.41735554, 0.5826445 ],\n",
       "        [0.38685167, 0.61314833],\n",
       "        [0.3908474 , 0.60915256],\n",
       "        [0.37293217, 0.62706786],\n",
       "        [0.40928546, 0.5907146 ],\n",
       "        [0.40651366, 0.59348637],\n",
       "        [0.40812477, 0.59187526],\n",
       "        [0.40910834, 0.59089166],\n",
       "        [0.38583627, 0.6141637 ],\n",
       "        [0.36889356, 0.63110644],\n",
       "        [0.37996745, 0.62003255],\n",
       "        [0.39020693, 0.609793  ],\n",
       "        [0.397234  , 0.60276604],\n",
       "        [0.40187514, 0.59812486],\n",
       "        [0.404808  , 0.595192  ],\n",
       "        [0.38223618, 0.6177639 ],\n",
       "        [0.38894045, 0.61105955],\n",
       "        [0.39561555, 0.6043845 ],\n",
       "        [0.400093  , 0.59990704],\n",
       "        [0.4029148 , 0.59708524],\n",
       "        [0.40455538, 0.5954446 ],\n",
       "        [0.40536332, 0.59463674],\n",
       "        [0.4055691 , 0.59443086]]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probchoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 300, 2)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loglike = np.dot(train_y.reshape(-1,2)[:,0],np.log(probchoice.reshape(-1,2)+0.0001)[:,0]) + np.dot(train_y.reshape(-1,2)[:,1],np.log(probchoice.reshape(-1,2)+0.0001)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-417.8953369855881\n"
     ]
    }
   ],
   "source": [
    "# print(loglike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0096517675991006"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - loglike/(np.log(0.5)*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,auc[1],loss_fn,probchoice,acc_test,loss_test,prob_test,neurons,learning_rate,epochs]).reshape(-1,13),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\",\"loss\",\"probchoice\",\"accuracy_test\",\"loss_test\",\"prob_test\",\"neurons\",\"learning_rate\",\"n_epochs\"])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>loss</th>\n",
       "      <th>probchoice</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>prob_test</th>\n",
       "      <th>neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.57285</td>\n",
       "      <td>0.689693</td>\n",
       "      <td>0.26961</td>\n",
       "      <td>0.321996</td>\n",
       "      <td>0.577448</td>\n",
       "      <td>0.68207</td>\n",
       "      <td>[[[0.5028481, 0.4971519], [0.4913881, 0.508611...</td>\n",
       "      <td>0.57279</td>\n",
       "      <td>0.682568</td>\n",
       "      <td>[[[0.49896055, 0.50103945], [0.48632938, 0.513...</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision   recall  f1_score       auc     loss  \\\n",
       "0  0.57285  0.689693  0.26961  0.321996  0.577448  0.68207   \n",
       "\n",
       "                                          probchoice accuracy_test loss_test  \\\n",
       "0  [[[0.5028481, 0.4971519], [0.4913881, 0.508611...       0.57279  0.682568   \n",
       "\n",
       "                                           prob_test neurons learning_rate  \\\n",
       "0  [[[0.49896055, 0.50103945], [0.48632938, 0.513...     100         1e-05   \n",
       "\n",
       "  n_epochs  \n",
       "0     2000  "
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path\n",
    "metric_out_df.to_csv(file_path+\"LSTM_metrics_all_subjs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probchoice_all_df = pd.DataFrame([probchoice,prob_test],columns =['probchoice','prob_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpts/RNN_LST_model_subject_num_11_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./checkpts/RNN_LST_model_subject_num_11_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(probchoice[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = pd.DataFrame(probchoice.reshape(-1,2),columns = {'action_0','action_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_0</th>\n",
       "      <th>action_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.502848</td>\n",
       "      <td>0.497152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491388</td>\n",
       "      <td>0.508612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491984</td>\n",
       "      <td>0.508016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469915</td>\n",
       "      <td>0.530085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.484155</td>\n",
       "      <td>0.515845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.473913</td>\n",
       "      <td>0.526087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.474276</td>\n",
       "      <td>0.525724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.463028</td>\n",
       "      <td>0.536972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.447558</td>\n",
       "      <td>0.552442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.447536</td>\n",
       "      <td>0.552464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_0  action_1\n",
       "0  0.502848  0.497152\n",
       "1  0.491388  0.508612\n",
       "2  0.491984  0.508016\n",
       "3  0.469915  0.530085\n",
       "4  0.484155  0.515845\n",
       "5  0.473913  0.526087\n",
       "6  0.474276  0.525724\n",
       "7  0.463028  0.536972\n",
       "8  0.447558  0.552442\n",
       "9  0.447536  0.552464"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(probchoice.reshape(-1,2))\n",
    "plt.ylim([0.25,0.75])\n",
    "plt.ylabel(\"Probchoice\");\n",
    "plt.xlabel(\"Trials\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5866916"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_15/'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,auc[1]]).reshape(-1,5),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([acc[1],prec[1],recall[1],f1,auc[1]]).reshape(-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_out_df.to_csv(file_path+\"LSTM_metrics.csv\")\n",
    "# metric_out_df.to_csv(file_path+\"LSTM_metrics_lr05.csv\")\n",
    "metric_out_df.to_csv(file_path+\"LSTM_metrics_10neurons.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subj_metrics_df = pd.DataFrame()\n",
    "for subj_num in range(11,26):\n",
    "#     print(subj_num)\n",
    "    file_name = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/subject_num_\" + str(subj_num) + \"/LSTM_metrics.csv\"\n",
    "    all_subj_metrics_df = all_subj_metrics_df.append(pd.read_csv(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653649</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.472657</td>\n",
       "      <td>0.578463</td>\n",
       "      <td>0.673517</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.889571</td>\n",
       "      <td>0.699521</td>\n",
       "      <td>0.543325</td>\n",
       "      <td>0.676040</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.589942</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.661651</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.562712</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.717855</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.660161</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.219753</td>\n",
       "      <td>0.545996</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.605948</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>0.746546</td>\n",
       "      <td>0.553775</td>\n",
       "      <td>0.648313</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.608295</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.770507</td>\n",
       "      <td>0.651851</td>\n",
       "      <td>0.684488</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>0.533178</td>\n",
       "      <td>0.674514</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539802</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>0.495348</td>\n",
       "      <td>0.660351</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.582996</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.755914</td>\n",
       "      <td>0.603900</td>\n",
       "      <td>0.672934</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.681617</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.438561</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  accuracy  precision    recall  f1_score       auc      loss  \\\n",
       "0           0  0.616667   0.616667  1.000000  0.762887  0.500000  0.653649   \n",
       "0           0  0.603333   0.576471  0.371212  0.472657  0.578463  0.673517   \n",
       "0           0  0.573333   0.568627  0.889571  0.699521  0.543325  0.676040   \n",
       "0           0  0.716667   0.716667  1.000000  0.834951  0.500000  0.589942   \n",
       "0           0  0.590000   0.590000  1.000000  0.742138  0.500000  0.661651   \n",
       "0           0  0.563333   0.562712  0.988095  0.717855  0.505411  0.660161   \n",
       "0           0  0.593333   0.666667  0.151515  0.219753  0.545996  0.663565   \n",
       "0           0  0.613333   0.605948  0.942197  0.746546  0.553775  0.648313   \n",
       "0           0  0.653333   0.608295  0.874172  0.770507  0.651851  0.684488   \n",
       "0           0  0.573333   0.700000  0.102941  0.147009  0.533178  0.674514   \n",
       "0           0  0.773333   0.000000  0.000000       NaN  0.500000  0.539802   \n",
       "0           0  0.573333   0.250000  0.007937  0.035282  0.495348  0.660351   \n",
       "0           0  0.616667   0.582996  0.923077  0.755914  0.603900  0.672934   \n",
       "0           0  0.570000   0.570000  1.000000  0.726115  0.500000  0.681617   \n",
       "0           0  0.830000   0.000000  0.000000       NaN  0.500000  0.438561   \n",
       "\n",
       "   learning_rate  n_epochs  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00005    2000.0  \n",
       "0        0.00005    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  \n",
       "0        0.00001    2000.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subj_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subj_metrics_df[\"pseudoR2\"]=1+all_subj_metrics_df.loss/(np.log(0.5)*300)\n",
    "all_subj_metrics_df[\"test_pseudoR2\"]=1+all_subj_metrics_df.loss/(np.log(0.5)*300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_file_path = \"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/placdata/\"\n",
    "PT_file_name = PT_file_path  + \"PT_loss.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_metrics = pd.read_csv(PT_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT_metrics.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_number</th>\n",
       "      <th>PT_loss</th>\n",
       "      <th>PT_pseudoR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>81.160098</td>\n",
       "      <td>0.609702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>159.474231</td>\n",
       "      <td>0.233091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>171.936892</td>\n",
       "      <td>0.173158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>113.557085</td>\n",
       "      <td>0.453906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>8.021925</td>\n",
       "      <td>0.961423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>64.471021</td>\n",
       "      <td>0.689960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>111.244149</td>\n",
       "      <td>0.465029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>133.319149</td>\n",
       "      <td>0.358870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>16.799920</td>\n",
       "      <td>0.919209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>43.594714</td>\n",
       "      <td>0.790354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>117.752046</td>\n",
       "      <td>0.433732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>60.262084</td>\n",
       "      <td>0.710201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>107.505168</td>\n",
       "      <td>0.483009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>149.257056</td>\n",
       "      <td>0.282225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>96.780830</td>\n",
       "      <td>0.534583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26</td>\n",
       "      <td>102.310428</td>\n",
       "      <td>0.507991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28</td>\n",
       "      <td>127.181507</td>\n",
       "      <td>0.388386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>37.328830</td>\n",
       "      <td>0.820486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>163.100213</td>\n",
       "      <td>0.215654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>117.658301</td>\n",
       "      <td>0.434183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>91.442263</td>\n",
       "      <td>0.560256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>158.940983</td>\n",
       "      <td>0.235655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34</td>\n",
       "      <td>146.488302</td>\n",
       "      <td>0.295540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>35</td>\n",
       "      <td>63.927930</td>\n",
       "      <td>0.692572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36</td>\n",
       "      <td>88.129209</td>\n",
       "      <td>0.576188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37</td>\n",
       "      <td>62.169885</td>\n",
       "      <td>0.701026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38</td>\n",
       "      <td>65.596010</td>\n",
       "      <td>0.684550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39</td>\n",
       "      <td>137.085788</td>\n",
       "      <td>0.340757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40</td>\n",
       "      <td>93.823903</td>\n",
       "      <td>0.548802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>41</td>\n",
       "      <td>114.537550</td>\n",
       "      <td>0.449191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject_number     PT_loss  PT_pseudoR2\n",
       "0               11   81.160098     0.609702\n",
       "1               12  159.474231     0.233091\n",
       "2               13  171.936892     0.173158\n",
       "3               14  113.557085     0.453906\n",
       "4               15    8.021925     0.961423\n",
       "5               16   64.471021     0.689960\n",
       "6               17  111.244149     0.465029\n",
       "7               18  133.319149     0.358870\n",
       "8               19   16.799920     0.919209\n",
       "9               20   43.594714     0.790354\n",
       "10              21  117.752046     0.433732\n",
       "11              22   60.262084     0.710201\n",
       "12              23  107.505168     0.483009\n",
       "13              24  149.257056     0.282225\n",
       "14              25   96.780830     0.534583\n",
       "15              26  102.310428     0.507991\n",
       "17              28  127.181507     0.388386\n",
       "18              29   37.328830     0.820486\n",
       "19              30  163.100213     0.215654\n",
       "20              31  117.658301     0.434183\n",
       "21              32   91.442263     0.560256\n",
       "22              33  158.940983     0.235655\n",
       "23              34  146.488302     0.295540\n",
       "24              35   63.927930     0.692572\n",
       "25              36   88.129209     0.576188\n",
       "26              37   62.169885     0.701026\n",
       "27              38   65.596010     0.684550\n",
       "28              39  137.085788     0.340757\n",
       "29              40   93.823903     0.548802\n",
       "30              41  114.537550     0.449191"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT_metrics = PT_metrics[PT_metrics.PT_loss !=0]\n",
    "PT_metrics.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [y for y in a if y not in b]\n",
    "# [PT_metrics.Subject_number(a) for a in range(11,22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT_metrics.loc[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_number</th>\n",
       "      <th>PT_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>81.160098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>159.474231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>171.936892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>113.557085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>8.021925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>64.471021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>111.244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>133.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>16.799920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>43.594714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>117.752046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>60.262084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>107.505168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>149.257056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>96.780830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject_number     PT_loss\n",
       "0               11   81.160098\n",
       "1               12  159.474231\n",
       "2               13  171.936892\n",
       "3               14  113.557085\n",
       "4               15    8.021925\n",
       "5               16   64.471021\n",
       "6               17  111.244149\n",
       "7               18  133.319149\n",
       "8               19   16.799920\n",
       "9               20   43.594714\n",
       "10              21  117.752046\n",
       "11              22   60.262084\n",
       "12              23  107.505168\n",
       "13              24  149.257056\n",
       "14              25   96.780830"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT_metrics.loc[0:14,['Subject_number','PT_loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subj_metrics_df.loc[0:12,['Subject_number']]= PT_metrics.loc[0:12,['Subject_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# sns.set(style=\"ticks\")\n",
    "ax = sns.barplot(y=\"accuracy\", data=all_subj_metrics_df, capsize=.2)\n",
    "# sns.catplot(y=\"accuracy\",data=all_subj_metrics_df)sns.catplot(y=\"accuracy\",data=all_subj_metrics_df,kind=\"box\")\n",
    "\n",
    "plt.ylim([0 ,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.catplot(y=\"accuracy\",data=all_subj_metrics_df)\n",
    "sns.catplot(y=\"accuracy\",data=all_subj_metrics_df,kind=\"box\")\n",
    "# sns.catplot(y=\"accuracy\",data=all_subj_metrics_df,kind=\"violin\")\n",
    "\n",
    "plt.ylim([0.5,0.8])\n",
    "plt.xlabel('RNN (100 neurons)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(y=\"loss\",data=all_subj_metrics_df,kind=\"box\",color=\"grey\")\n",
    "# plt.title(\"n=\"+str(all_subj_metrics_df.shape[0]))\n",
    "plt.ylim([0.5,0.75])\n",
    "plt.xlabel('RNN (100 neurons)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(y=\"pseudoR2\",data=all_subj_metrics_df,kind=\"box\",color=\"grey\")\n",
    "# plt.title(\"n=\"+str(all_subj_metrics_df.shape[0]))\n",
    "# plt.ylim([0.5,0.75])\n",
    "plt.ylim([0.9,1])\n",
    "plt.xlabel('RNN (100 neurons)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(y=\"PT_loss\",data = PT_metrics.loc[0:14,:],kind=\"box\",color=\"grey\")\n",
    "# plt.title(\"n=\"+str(all_subj_metrics_df.shape[0]))\n",
    "# plt.ylim([0.5,0.75])\n",
    "plt.xlabel('PT');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(y=\"PT_pseudoR2\",data = PT_metrics.loc[0:14,:],kind=\"box\",color=\"grey\")\n",
    "# plt.title(\"n=\"+str(all_subj_metrics_df.shape[0]))\n",
    "# plt.ylim([0.5,0.75])\n",
    "plt.xlabel('PT');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons and WilcoxonSigned Rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=0.0, pvalue=0.0006549583433856954)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_stats.wilcoxon(all_subj_metrics_df.loss,PT_metrics.loc[0:14].PT_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax= plt.subplots(figsize=(10,10))\n",
    "ax.scatter(all_subj_metrics_df.pseudoR2,PT_metrics.loc[0:14].PT_pseudoR2)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "ax.plot(lims,lims,color='black',alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('Pseudo R2 RNN (100 Neurons)',Fontsize=14);\n",
    "ax.set_ylabel('Pseudo R2 Prospect Theory',Fontsize=14);\n",
    "\n",
    "# ax.set_xlim([100,300])\n",
    "# ax.set_ylim([100,300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=0.0, pvalue=0.0006549583433856954)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_stats.wilcoxon(all_subj_metrics_df.pseudoR2,PT_metrics.loc[0:14].PT_pseudoR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
