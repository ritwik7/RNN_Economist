{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as sc_stats\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "onehot_encoder=OneHotEncoder(sparse=False)\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "time_steps = 1\n",
    "inputs = 4\n",
    "outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_releveant_features(task_df):\n",
    "\n",
    "\n",
    "    task_df['PrevOutcome']=task_df['Outcome'].shift(1)\n",
    "    task_df.loc[1,'PrevOutcome']= 0\n",
    "\n",
    "    task_df['PrevChoice']=task_df['Choice'].shift(1)\n",
    "    task_df.loc[1,'PrevChoice']= 0\n",
    "\n",
    "    task_df['PrevSafe']=task_df['Safe'].shift(1)\n",
    "    task_df.loc[1,'PrevSafe']= 0\n",
    "\n",
    "    task_df['PrevBigRisky']=task_df['BigRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevBigRisky']= 0\n",
    "\n",
    "    task_df['PrevSmallRisky']=task_df['SmallRisky'].shift(1)\n",
    "    task_df.loc[1,'PrevSmallRisky']= 0\n",
    "    \n",
    "    task_df['PrevRT']=task_df['RT'].shift(1)\n",
    "    task_df.loc[1,'PrevRT']= 0\n",
    "    \n",
    "#     task_df['RPE'] =  task_df['Outcome'].shift(1) - 0.5*(task_df['BigRisky'].shift(1) + \n",
    "    \n",
    "    return task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_kback_features(task_df):\n",
    "\n",
    "    for k in range(1,11):\n",
    "        task_df[str(k)+'backOutcome']=task_df['Outcome'].shift(k)\n",
    "        task_df[str(k)+'backChoice']=task_df['Choice'].shift(k)\n",
    "        task_df[str(k)+'backSafe']=task_df['Safe'].shift(k)\n",
    "        task_df[str(k)+'backBigRisky']=task_df['BigRisky'].shift(k)\n",
    "        task_df[str(k)+'backSmallRisky']=task_df['SmallRisky'].shift(k)\n",
    "\n",
    "    return task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y,seq_length_batch): \n",
    "    reset_graph()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 50000\n",
    "    batch_size = 1#int(train_X.shape[0]/2)\n",
    "    # batch_size = 100\n",
    "    length = train_X.shape[0]\n",
    "    display = 100\n",
    "    neurons = neurons\n",
    "\n",
    "    num_batches = 100\n",
    "    seq_len = 10\n",
    "\n",
    "    percent_above_PT = 1\n",
    "\n",
    "    train_threshold = 1.5#PT_R2 + percent_above_PT\n",
    "\n",
    "\n",
    "    save_step = 100\n",
    "\n",
    "\n",
    "    best_loss_val = np.infty\n",
    "    checks_since_last_progress = 0\n",
    "    max_checks_without_progress = 1000\n",
    "\n",
    "\n",
    "    # clear graph (if any) before running\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    seq_length = tf.placeholder(tf.int32, [None])\n",
    "    time_steps=train_X.shape[1]\n",
    "    X = tf.placeholder(tf.float32, [None, time_steps, inputs])\n",
    "\n",
    "    y = tf.placeholder(tf.float32, [None, outputs])\n",
    "\n",
    "    # LSTM Cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=neurons, activation=tf.nn.relu)\n",
    "    cell_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "#     cell_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "    # pass into Dense layer\n",
    "    stacked_outputs = tf.reshape(cell_outputs, [-1, neurons])\n",
    "    out = tf.layers.dense(inputs=stacked_outputs, units=outputs)\n",
    "\n",
    "    probability = tf.nn.softmax(out)\n",
    "\n",
    "    # squared error loss or cost function for linear regression\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=y, logits=out))\n",
    "\n",
    "    # optimizer to minimize cost\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels =  tf.argmax(y, 1),\n",
    "                          predictions = tf.argmax(out, 1),\n",
    "                          name = \"accuracy\")\n",
    "    precision = tf.metrics.precision(labels=tf.argmax(y, 1),\n",
    "                                 predictions=tf.argmax(out, 1),\n",
    "                                 name=\"precision\")\n",
    "    recall = tf.metrics.recall(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"recall\")\n",
    "    f1 = 2 * accuracy[1] * recall[1] / ( precision[1] + recall[1] )\n",
    "\n",
    "    acc_up,acc_val = accuracy\n",
    "    auc = tf.metrics.auc(labels=tf.argmax(y, 1),\n",
    "                           predictions=tf.argmax(out, 1),\n",
    "                           name=\"auc\")\n",
    "    \n",
    "    valid_store = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #######################\n",
    "#         saver.restore(sess, \"./checkpts/Original_RNN_LSTM_8features_v2.ckpt\")\n",
    "#         saver.restore(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "        \n",
    "        if pretraining == True:\n",
    "\n",
    "            saver.restore(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        #######################\n",
    "        \n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "\n",
    "        # Train the model\n",
    "        for steps in range(epochs):\n",
    "            mini_batch = zip(range(0, length, batch_size),\n",
    "                       range(batch_size, length+1, batch_size))\n",
    "\n",
    "            # train data in mini-batches\n",
    "            for (start, end) in mini_batch:\n",
    "    #             print(start,end)\n",
    "    \n",
    "    #############################################################################\n",
    "#                 sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "#                                                    y: train_y[start:end,:], seq_length: seq_length_batch}) \n",
    "                sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "                                                   y: train_y[start:end,:]}) \n",
    "    #############################################################################\n",
    "    \n",
    "    \n",
    "            ## train data in batches of length subsequence\n",
    "\n",
    "    #         for k in range(num_batches):\n",
    "    #             X_seq, y_seq = random_subsequence(train_X,train_y,seq_len)\n",
    "\n",
    "    #             sess.run(training_op, feed_dict = {X:X_seq,y:y_seq}) \n",
    "            loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "            loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "            # print training performance \n",
    "            if (steps+1) % display == 0:\n",
    "                # evaluate loss function on training set\n",
    "\n",
    "\n",
    "                loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining loss: {}'.format((steps+1), loss_fn))\n",
    "\n",
    "                acc_train = acc_val.eval(feed_dict={X: train_X, y: train_y})\n",
    "                print('Step: {}  \\tTraining accuracy: {}'.format((steps+1), acc_train))\n",
    "\n",
    "\n",
    "                acc_test = acc_val.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest accuracy: {}'.format((steps+1), acc_test))\n",
    "\n",
    "                loss_test = loss.eval(feed_dict={X: test_X, y: test_y})\n",
    "    #             print('Step: {}  \\tTest loss: {}'.format((steps+1), loss_test))\n",
    "\n",
    "                accu_val = acc_val.eval(feed_dict={X: val_X, y: val_y})\n",
    "\n",
    "                loss_val = loss.eval(feed_dict={X: val_X, y: val_y})\n",
    "                print('Step: {}  \\tValid loss: {}'.format((steps+1), loss_val))\n",
    "\n",
    "                valid_store.append(loss_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (1 + loss_fn/np.log(0.5)) > train_threshold:\n",
    "                    print(\"Threshold achieved, quit training\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            if loss_val < best_loss_val:\n",
    "\n",
    "                        best_loss_val = loss_val\n",
    "                        checks_since_last_progress = 0\n",
    "            else:\n",
    "                            checks_since_last_progress += 1\n",
    "\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if checks_since_last_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "\n",
    "            if (steps+1) % save_step ==0:\n",
    "                                save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#                 save_path = saver.save(sess, \"./checkpts/RNN_Internet_LSTM_model_5features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     evaluate model accuracy\n",
    "        acc, prec, recall, f1, AUC = sess.run([accuracy, precision, recall, f1,auc],\n",
    "                                         feed_dict = {X: train_X, y: train_y})\n",
    "        prob_train = probability.eval(feed_dict = {X: train_X, y: train_y})\n",
    "        prob_test = probability.eval(feed_dict = {X: test_X, y: test_y})\n",
    "        prob_valid = probability.eval(feed_dict = {X: val_X, y: val_y})\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nEvaluation  on training set')\n",
    "        print('Accuracy:', acc[1])\n",
    "        print('Precision:', prec[1])\n",
    "        print('Recall:', recall[1])\n",
    "        print('F1 score:', f1)\n",
    "        print('AUC:', AUC[1])\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_v2_DATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "        \n",
    "#         save_path = saver.save(sess, \"./checkpts/OriginalDATA_RNN_LSTM_8features.ckpt\")\n",
    "#         save_path = saver.save(sess, \"./checkpts/LaterDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "#         save_path = saver.save(sess, \"./checkpts/Later_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## APP DATA\n",
    "#         save_path = saver.save(sess, \"./checkpts/Original_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "        save_path = saver.save(sess, \"./checkpts/Later_v2_APPDATA_RNN_LSTM_8features.ckpt\")\n",
    "\n",
    "\n",
    "    metric_out_df= pd.DataFrame(np.array([acc[1],prec[1],recall[1],f1,AUC[1],loss_fn,accu_val,best_loss_val,acc_test,loss_test,neurons,learning_rate,epochs,steps]).reshape(-1,14),columns =[\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"auc\",\"loss\",\"accuracy_val\",\"loss_val\",\"accuracy_test\",\"loss_test\",\"neurons\",\"learning_rate\",\"n_epochs\",\"steps\"])\n",
    "    return metric_out_df, prob_train, prob_test, prob_valid\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def random_subsequence(X,y,seq_len):\n",
    "    rnd  = random.randint(0,len(X)-seq_len)\n",
    "    X_seq, y_seq = X[rnd:rnd+seq_len,:], y[rnd:rnd+seq_len,:]\n",
    "    return X_seq, y_seq\n",
    "\n",
    "    print(y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_odd_even(train_data_df,test_data_df,val_data_df):\n",
    "\n",
    "#     train_len = 29\n",
    "#     test_len = 14\n",
    "#     val_len = 15\n",
    "\n",
    "    ##----------------- UNCOMMENT BELOW\n",
    "    \n",
    "    if hist_flag==0: ## CURR OPTIONS ONLY\n",
    "        \n",
    "    \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "    elif hist_flag==1: ## CURR OPTIONS, PREV ACTIONS:\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevChoice']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "        \n",
    "        \n",
    "      \n",
    "    elif hist_flag==2: # CURR OPTIONS, PREV OUTCOME        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif hist_flag==3: ## CURR OPTIONS, PREV ACTIONS, PREV OUTCOME\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevChoice','PrevOutcome']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "             \n",
    "        \n",
    "\n",
    "####### Prev O + C+ R + CurrO--------------------\n",
    "    elif hist_flag==4: # CURR OPTIONS, PREV ACTIONS, PREV OUTCOME, PREV OPTIONS\n",
    "        \n",
    "        train_X = train_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        train_y = train_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        test_X = test_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        test_y = test_data_df[['Choice']].values.astype(np.int32)\n",
    "\n",
    "        val_X = val_data_df[['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky']].values\n",
    "        val_y = val_data_df[['Choice']].values.astype(np.int32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ######## sampling \n",
    "    \n",
    "    \n",
    "#### - Prev RT+C+R+O + Curr O----------------------\n",
    "\n",
    "#     train_X = task_df.loc[task_df.TrialNum>1, ['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     train_y = task_df.loc[task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "#     test_X = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Safe','BigRisky','SmallRisky','PrevOutcome','PrevChoice','PrevSafe','PrevBigRisky','PrevSmallRisky','PrevRT']].values\n",
    "#     test_y = dopa_task_df.loc[dopa_task_df.TrialNum>1,['Choice']].values.astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### PRE TRAINING\n",
    "#     stop = int(0.7*len(train_X))\n",
    "#     print(stop)\n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y= train_X[:stop], train_X[stop:stop+int((len(train_X)-stop)/2)], train_X[stop+int((len(train_X)-stop)/2):],train_y[:stop], train_y[stop:stop+int((len(train_X)-stop)/2)], train_y[stop+int((len(train_X)-stop)/2):]\n",
    "    \n",
    "#     train_X, test_X, val_X, train_y, test_y, val_y = train_X, test_X, test_X, train_y, test_y, test_y\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "    print(val_X.shape)\n",
    "    print(val_y.shape)\n",
    "    print(test_X.shape)\n",
    "    print(test_y.shape)\n",
    "\n",
    "    # # center and scale\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.fit_transform(test_X)\n",
    "    val_X = scaler.fit_transform(val_X)\n",
    "\n",
    "\n",
    "#     train_X = train_X[:,None,:]\n",
    "#     val_X = val_X[:,None,:]\n",
    "#     test_X = test_X[:,None,:]\n",
    "\n",
    "\n",
    "    train_X = train_X[None,:,:]\n",
    "    val_X = val_X[None,:,:]\n",
    "    test_X = test_X[None,:,:]\n",
    "    \n",
    "    print(train_X.shape)\n",
    "\n",
    "\n",
    "    # # one-hot encode the outputs\n",
    "\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "    encode_categorical_test = test_y.reshape(len(test_y), 1)\n",
    "    encode_categorical_val = val_y.reshape(len(val_y),1)\n",
    "\n",
    "\n",
    "    train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "    test_y = onehot_encoder.fit_transform(encode_categorical_test).toarray()\n",
    "    val_y = onehot_encoder.fit_transform(encode_categorical_val).toarray()\n",
    "\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y, val_X,val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\")\n",
    "dir_path =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"\n",
    "\n",
    "subj_files_list =[]; ## list of subject_files fullfilling a criteria\n",
    "\n",
    "dir_files = [i for i in os.listdir(dir_path) if i.startswith('sub')]\n",
    "\n",
    "for subj_file_path in dir_files:\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "    mypath =file_path\n",
    "    \n",
    "    play_names = [i for i in os.listdir(mypath) if os.path.isfile(os.path.join(mypath,i)) and i.startswith('app')]   \n",
    "    \n",
    "    if len(play_names) >= 50: ## criteria\n",
    "        subj_files_list.append(subj_file_path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1189, 4)\n",
      "(1189, 1)\n",
      "(640, 4)\n",
      "(640, 1)\n",
      "(520, 4)\n",
      "(520, 1)\n",
      "(1, 1189, 4)\n",
      "1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/ritwik7/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n\t [[node Placeholder (defined at <ipython-input-27-0eaf7c39f9ba>:34) ]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-22d3d2fb07cd>\", line 55, in <module>\n    metric_out_df, prob_train, prob_test, prob_val = train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y, seq_length_batch)\n  File \"<ipython-input-27-0eaf7c39f9ba>\", line 34, in train_RNN\n    seq_length = tf.placeholder(tf.int32, [None])\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n\t [[node Placeholder (defined at <ipython-input-27-0eaf7c39f9ba>:34) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n\t [[{{node Placeholder}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-22d3d2fb07cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mpretraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmetric_out_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_out_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-0eaf7c39f9ba>\u001b[0m in \u001b[0;36mtrain_RNN\u001b[0;34m(neurons, train_X, train_y, test_X, test_y, val_X, val_y, seq_length_batch)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#                                                    y: train_y[start:end,:], seq_length: seq_length_batch})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n\u001b[0;32m--> 105\u001b[0;31m                                                    y: train_y[start:end,:]}) \n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;31m#############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n\t [[node Placeholder (defined at <ipython-input-27-0eaf7c39f9ba>:34) ]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-22d3d2fb07cd>\", line 55, in <module>\n    metric_out_df, prob_train, prob_test, prob_val = train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y, seq_length_batch)\n  File \"<ipython-input-27-0eaf7c39f9ba>\", line 34, in train_RNN\n    seq_length = tf.placeholder(tf.int32, [None])\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/ritwik7/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n\t [[node Placeholder (defined at <ipython-input-27-0eaf7c39f9ba>:34) ]]\n"
     ]
    }
   ],
   "source": [
    "neurons = 8\n",
    "hist_flag=2\n",
    "randomize_trials_flag=False\n",
    "\n",
    "\n",
    "for num, subj_file_path in enumerate(subj_files_list[0:1]):\n",
    "    print(num)\n",
    "\n",
    "# for subj_file_path in [subj_files_list[0]]:\n",
    "\n",
    "    file_path  =\"/Users/ritwik7/Dropbox (Personal)/Postdoc_UCL/DATA/rlab_incomplete_rewardSWB_code/by_RN/appdata/\"+ subj_file_path\n",
    "                \n",
    "#     file_path = file_path + \"/OddEvenPlays\"\n",
    "    file_path = file_path + \"/OddEvenPlays/RandomizedPlays1\"\n",
    "\n",
    "\n",
    "\n",
    "    train_data_df= pd.read_csv(file_path+\"/train_data.csv\")\n",
    "    test_data_df = pd.read_csv(file_path+\"/test_data.csv\")\n",
    "    val_data_df = pd.read_csv(file_path+\"/val_data.csv\")\n",
    "    \n",
    "    \n",
    "    ####### IMPORTANT ALTERATION\n",
    "    train_data_df = add_kback_features(train_data_df)\n",
    "    val_data_df = add_kback_features(val_data_df)\n",
    "    test_data_df = pd.read_csv(file_path+\"/test_data_new.csv\") ## otherwise testdata df would have NaNs for 1 back\n",
    "    \n",
    "    \n",
    "\n",
    "    if randomize_trials_flag==True:\n",
    "        file_path = file_path + \"/RandomizeTrials\"\n",
    "\n",
    "        #### FOR GENERATING RANDOMIZATIONS\n",
    "#         train_locs, test_locs, val_locs = generate_randomizations(train_data_df,test_data_df,val_data_df)\n",
    "\n",
    "        train_data_random_df, test_data_random_df,val_data_random_df, train_locs, test_locs, val_locs  = get_shuffled_data()\n",
    "\n",
    "        train_data_random_df, test_data_random_df,val_data_random_df = restore_input_feature(randomize_trials_flag,hist_flag)\n",
    "        \n",
    "        train_data_df , test_data_df, val_data_df = train_data_random_df, test_data_random_df, val_data_random_df\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "#     print(file_path)\n",
    "    \n",
    "    \n",
    "    train_X, train_y, test_X, test_y,val_X,val_y = data_split_odd_even(train_data_df,test_data_df,val_data_df)\n",
    "\n",
    "    seq_length_batch = train_X.shape[1]\n",
    "    print(seq_length_batch)\n",
    "    \n",
    "    pretraining = False; \n",
    "    metric_out_df, prob_train, prob_test, prob_val = train_RNN(neurons,train_X,train_y,test_X,test_y,val_X,val_y, seq_length_batch)\n",
    "    \n",
    "    print(metric_out_df)\n",
    "    \n",
    "   \n",
    " \n",
    "#     prob_train_df = pd.DataFrame(prob_train.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "#     prob_test_df = pd.DataFrame(prob_test.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "#     prob_val_df = pd.DataFrame(prob_val.reshape(-1,2),columns = {'action_0','action_1'})\n",
    "\n",
    "#     if hist_flag==0:\n",
    "#         metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currO_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_train_df.to_csv(file_path + \"/prob_train_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_test_df.to_csv(file_path + \"/prob_test_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_val_df.to_csv(file_path + \"/prob_val_currO_neurons=\"+str(neurons)+\".csv\")\n",
    "    \n",
    "    \n",
    "#     elif hist_flag==1:\n",
    "#         metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevC_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_train_df.to_csv(file_path + \"/prob_train_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_test_df.to_csv(file_path + \"/prob_test_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_val_df.to_csv(file_path + \"/prob_val_currOprevC_neurons=\"+str(neurons)+\".csv\")\n",
    "        \n",
    "        \n",
    "#     elif hist_flag==2:\n",
    "#         metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevR_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_train_df.to_csv(file_path + \"/prob_train_currOprevR_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_test_df.to_csv(file_path + \"/prob_test_currOprevR_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_val_df.to_csv(file_path + \"/prob_val_currOprevR_neurons=\"+str(neurons)+\".csv\")\n",
    "\n",
    "#     elif hist_flag==3:\n",
    "#         metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currOprevRC_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_train_df.to_csv(file_path + \"/prob_train_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_test_df.to_csv(file_path + \"/prob_test_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_val_df.to_csv(file_path + \"/prob_val_currOprevRC_neurons=\"+str(neurons)+\".csv\")\n",
    "# # ################################\n",
    "#     elif hist_flag==4:\n",
    "#         metric_out_df.to_csv(file_path+\"/LSTM_updated_Crossval_currprev_opts_metricsneurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_train_df.to_csv(file_path + \"/prob_train_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_test_df.to_csv(file_path + \"/prob_test_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "#         prob_val_df.to_csv(file_path + \"/prob_val_currentprevopts_neurons=\"+str(neurons)+\".csv\")\n",
    "# # #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
